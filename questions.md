## soru

> quest": "1 aylÄ±k eÄŸlenceli ve Ã¶ÄŸretici serÃ¼venin ardÄ±ndan ÅŸÃ¶yle bir yazÄ± yazmaya karar verdim umarÄ±m hepimiz iÃ§in faydalÄ± bir ay olmuÅŸtur. DeÄŸerli yorumlarÄ±nÄ±zÄ± bekliyorum :) Link](https://medium.com/@emrekarakoc36/yeni-baÅŸlayanlar-iÌ‡Ã§in-makine-Ã¶ÄŸrenimi-projeleri-76f940da6bd8)

> comments: 

1. ->  Kesinlikle Ã§ok faydalÄ± bir yazÄ± olmuÅŸ bence, iÅŸin pratiÄŸine baÅŸlamak isteyenler iÃ§in nerden baÅŸlanacaÄŸÄ±na (genelde veri seti bulmak da bu sÃ¼recin iÃ§inde) birebir ğŸ™‚ Tebrik ederim, yazÄ±larÄ±n devamÄ±nÄ± bekliyorum ğŸ™‚."

2. -> ->  teÅŸekkÃ¼rler ederim fethi ğŸ™‚ sayende de birÃ§ok ÅŸey Ã¶ÄŸrendik eksik olmağŸ™‚.",
3. ->  BaÅŸarÄ±lÄ± bir Ã§alÄ±ÅŸma olmuÅŸ eline saÄŸlÄ±k ğŸ™‚ gÃ¼ncellemek ister misin bilmiyorum ancak:SÄ±nÄ±fÄ±landÄ±rma Ã§alÄ±ÅŸmasÄ±nda bir klasik olan Titanik'i ve Regresyon Ã§alÄ±masÄ± iÃ§in Boston House Prices'Ä± da dahil edebilirsin istersen :))Ä°yi Ã§alÄ±ÅŸmalar ğŸ™‚.",
4. -> ->  hali hazÄ±rda kendi Ã§alÄ±ÅŸtÄ±klarÄ±mla bir yazÄ± yazmak istedim sÃ¶ylediklerine en kÄ±sa zamanda bakÄ±cam yorumun iÃ§in Ã§ok teÅŸekkÃ¼r ederim ğŸ™‚.",
5. -> GÃ¼zel fikir belki herkesin desteÄŸiyle daha da bÃ¼yÃ¼yebilir ğŸ™‚ belki faydasÄ± olur ilgilenenlere diye ben de Ã¶nceden yazidigim bir yazÄ±yÄ± paylaÅŸmak isterim sorun olmazsa .Makina Ã¶ÄŸrenmesi ile EEG sinyalleri den epilepsi hastalÄ±ÄŸÄ± tahmini [EEG Sinyallerinden Makine Ã–ÄŸrenmesi ile Epilepsi HastalÄ±ÄŸÄ± Tespiti](https://medium.com/kodluyoruz/eeg-sinyallerinden-makine-%C3%B6%C4%9Frenmesi-ile-epilepsi-hastal%C4%B1%C4%9F%C4%B1-tespiti-542aa61e2337) 

## soru

> quest": "Merhabalar, Ã¶ncelikle emeÄŸi geÃ§en herkese Ã§ok teÅŸekkÃ¼rler.  Final sÄ±navÄ± ile ilgili olarak bir sorum olacak. 17. soruda \"classifier that trains to 99% accuracy or above\" geÃ§iyor ama if koÅŸul yapÄ±sÄ± iÃ§erisinde \"if(logs.get('accuracy')&gt;0.99): \" denmiÅŸ. &gt;=0.99 olmasÄ± gerekmiyor mu? Ben bu ÅŸekilde olmasÄ± gerektiÄŸini dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼m iÃ§in diÄŸer ÅŸÄ±klara bakmadan #1 olarak iÅŸaretledim.",

> comments: 

1. -> ben altÄ± okuyamadan 2 dedim Ã§Ã¼nkÃ¼ if satÄ±rÄ±nÄ±n altÄ±nda girinti olmasÄ± gerekirdi diye tabiki yanlÄ±ÅŸ Ã§Ä±ktÄ± ğŸ™‚.

2. -> -> bu dediÄŸinizi Ã¶nce ben de dÃ¼ÅŸÃ¼ndÃ¼m ta ki en alttaki epoch=12 yi gÃ¶rene kadar ,bu noktada da ÅŸÃ¶yle dÃ¼ÅŸÃ¼ndÃ¼m burada syntax hatasÄ±ndan ziyade semantic hata istiyorlar bizden ve o soruda da 10 epochdan fazla olmasÄ±n tarzÄ± bir bilgi vardÄ± o yÃ¼zden 4. ÅÄ±kkÄ± seÃ§tim sonradan ğŸ™‚.

3. ->  -> Evet. Åu an fark ettim, haklÄ±sÄ±nÄ±z. #2 de yanlÄ±ÅŸ.

4. ->  Merhaba, hayÄ±r,bende aynÄ± hatayÄ± yaptÄ±m ya hep karÄ±ÅŸtÄ±rÄ±rm, " veya " ifadesi olduÄŸu iÃ§in bu ÅŸekilde oluyor. " ve " olmuÅŸ olsaydÄ± o zaman >= kullanÄ±rdÄ±k. Diye dÃ¼ÅŸÃ¼nÃ¼yorum.

5. ->  ->  BildiÄŸim kadarÄ±yla o ÅŸekilde olmuyor. EÄŸer \"veya\" kullanÄ±lmÄ±ÅŸsa \"veya\" ile baÄŸlanmÄ±ÅŸ koÅŸullardan herhangi birinin saÄŸlanmÄ±ÅŸ olmasÄ± sonucun doÄŸru olmasÄ±nÄ± saÄŸlar fakat \"ve\" kullanÄ±ldÄ±ysa \"ve\" ile baÄŸlanmÄ±ÅŸ koÅŸullarÄ±n tÃ¼mÃ¼nÃ¼n doÄŸru olmasÄ± bir gerekliliktir. BakÄ±nÄ±z Boolean Algebra: [Link](https://medium.com/i-math/intro-to-truth-tables-boolean-algebra-73b331dd9b94)"

 6. ->  ->  bende iÅŸte sÃ¼rekli karÄ±ÅŸtÄ±rÄ±rÄ±m bunlarÄ±( python Ã¼zerinde sadece) o yÃ¼zden hataya dÃ¼ÅŸerim sorgularÄ±m ama sizde ÅŸunu bi inceleyin isterseniz [Link](https://charon.me/posts/tf1)  Ã¶rneÄŸin aynÄ±sÄ± bu ÅŸekilde yapÄ±lmÄ±ÅŸ bu durumda bizim final sÄ±navÄ±ndaki soruya gÃ¶re girdide sÄ±kÄ±ntÄ± var ve epoch 12 hatasÄ± var1. Introduction to TensorFlow for AI, ML, and DLcharon.meA new programming paradigm Traditional Programming Paradigm V.S. Machine Learning Paradigm V.S. ML is all about a computer learning patterns that distinguish things E.g. X = -1, 0, 1, 2, 3, 4 Y = -3, -1, 1, 3, 5, 7 What is the pattern between them? Answer: Y = 2X - 1 Code: model =â€¦."

7. ->  ->  Bence bu sadece dÃ¼z bir if statement ve \"=\" koÅŸulu olmadÄ±ÄŸÄ± sÃ¼rece 99% accuracy'de koÅŸul saÄŸlanmamÄ±ÅŸ olacak.AynÄ± hatanÄ±n farklÄ± bir websitesinde yapÄ±lmÄ±ÅŸ olmasÄ± hatanÄ±n doÄŸru olduÄŸunu ispatlamaz diye dÃ¼ÅŸÃ¼nÃ¼yorum.

8. ->  ->  birden fazla sitede cevabÄ± bÃ¶yle ve bu operatÃ¶rlerin mantÄ±ksal karÅŸÄ±tlÄ±klarÄ±da var ama burda oda deÄŸil, onu geÃ§tim ÅŸÃ¶yle dÃ¼ÅŸÃ¼nÃ¼yorum bu soruyu mesela 18 yaÅŸ ve Ã¼stÃ¼ ehliyet alabilir bu durumda iki koÅŸuluda saÄŸlamak gerekiyor >= kullanmamÄ±z lazÄ±m, cevaplarÄ± merakla bekliyorum bende.
9. ->  Ben de 3 numaradan yana kullanmÄ±ÅŸtÄ±m tercihimi, sonra benim de gÃ¶zÃ¼m 2'ye kaydÄ± girinti olmasÄ± gerekirdi diye ama doÄŸru cevap 3 deÄŸilmiÅŸ. YanlÄ±ÅŸ diyen var demek ki 1 ve 2 de deÄŸil. Neden 4 acaba doÄŸru yapan biri bizi aydÄ±nlatabilir mi?

 10. -> ->  En fazla 10 epoch yapÄ±lmasÄ±nÄ± istemiÅŸti soruda, ama kodda 12 epoch koÅŸturulmuÅŸ. 2 weeks ago 3 people like this. Like ReportReply"

11. ->  Epoch maksimum 10 olmalÄ± diyordu soruda yani istediÄŸimiz accuracy rate Ã§Ä±kmasa bile 10 epoch ile modelimiz sÄ±nÄ±rlÄ± kalmalÄ±ydÄ± fakat 4. soruda epoch = 12 yazÄ±lmÄ±ÅŸ yanlÄ±ÅŸ bundan dolayÄ± diye dÃ¼ÅŸÃ¼nÃ¼yorum.

12. -> HaklÄ±sÄ±nÄ±z, >= 0.99 olmasÄ± gerekiyor ve if'in altÄ±nda indentation eksik, bu benim de dikkatimi Ã§ekti ancak #4 daha kavramsal bir yanlÄ±ÅŸ olduÄŸu iÃ§in tercih ettim."

13. ->  DoÄŸru cevaplar aÃ§Ä±klandÄ± mÄ±? Ä°kinci satÄ±rda indentation problemi var, program hata verir, hatta altÄ±ndaki satÄ±r da girdili olmalÄ±. CevabÄ±n iki olmasÄ± gerekmez mi? 

14. ->  bence bu soruda hangisi doÄŸruydu diye sorulmalÄ±ydÄ±. #1 iÃ§in = sembolÃ¼ yok , #2 iÃ§in if'e girmese hata alacaÄŸÄ±z #4 zaten epoch 10 dan fazla. Ben 4 yapmÄ±ÅŸtÄ±m fakat Ã¼zerine gerÃ§ekten dÃ¼ÅŸÃ¼ndÃ¼m en aÃ§Ä±k yanlÄ±ÅŸ bu geldi bir ara soru yanlÄ±ÅŸ mÄ± sorulmuÅŸ diye #3'Ã¼ bile iÅŸaretlemeyi dÃ¼ÅŸÃ¼ndÃ¼m. (YanlÄ±ÅŸ dÃ¼ÅŸÃ¼nÃ¼yorsam lÃ¼tfen dÃ¼zeltin.)"

15. ->  ->  Ne yazÄ±k ki, if iÃ§erisine girmese bile yazdÄ±rma durumu sÃ¶z konusu deÄŸil, ilgili fonksiyon tetiklendiÄŸi gibi IndentationError verecektir. Python da kod bloklarÄ± girintiler ile belirlendiÄŸi iÃ§in, #2 deki ifade python syntax'Ä±nda bir hata olarak karÅŸÄ±lanmakta.Ä°yi Ã§alÄ±ÅŸmalar."

16. ->  ->  evet haklÄ±sÄ±n hata alÄ±rÄ±z , dÃ¼zelttim.

17. ->  Benim gÃ¶rÃ¼ÅŸÃ¼m; \"if(logs.get('accuracy')>0.99) hatasÄ± ile epoch=12 hatasÄ± arasÄ±nda bir fark yok gibi. 2si de yazÄ±m hatasÄ± ve hatalÄ± Ã§alÄ±ÅŸmaya sebep oluyor. 2si de traningin farklÄ± sonlanmasÄ±na sebep olmaz mÄ±?

18. ->  ArkadaÅŸlarÄ±ma katÄ±lÄ±yorum, 1 ve 4 kesinlikle yanlÄ±ÅŸ evet, ayrÄ±ca ne tÃ¼r bir hata(semantic/syntax) olmasÄ± gerektiÄŸi ile ilgili bir bilgilendirme yok soruda ve ÅŸu ifade geÃ§iyor net bir ÅŸekilde \"When it reaches 99% or greater it should print out the string\" fakat indentation hatasÄ± sebebi ile stringi yazdÄ±rmasÄ± da sÃ¶z konusu deÄŸil bu sebeple sorunun iptal edilmesi veya 1 ve 2'nin de doÄŸru kabul edilmesi gerektiÄŸini dÃ¼ÅŸÃ¼nÃ¼yorum.

 19. ->  Ben de bu ÅŸekilde dÃ¼ÅŸÃ¼nerek #1 olan seÃ§eneÄŸi iÅŸaretledim..",
 20. ->  99 'a eÅŸit ve bÃ¼yÃ¼k diye metinde ifade edilirken kodda sadece 99'dan bÃ¼yÃ¼k olarak yazÄ±lmÄ±ÅŸ. Diger taraftan ise, bu kadar kompleks bir kod bloÄŸunda indent hatasÄ± yÃ¼zÃ¼nden bir ÅŸÄ±k iÅŸaretlenmemeli. Ã‡Ã¼nkÃ¼ soru Ã§ok gÃ¼zeldi ama cevap bu kadar basit olmamalÄ± ğŸ™‚

 21. ->  Merhaba -> , bence hangi cevabÄ±n daha doÄŸru olduÄŸunu tartÄ±ÅŸmÄ±yoruz, birden fazla doÄŸru cevap var ortada ifade edilmeye Ã§alÄ±ÅŸÄ±lan ÅŸey de bu.

 22. ->  Merhaba ->  , aslÄ±nda hangi cevabÄ±n daha doÄŸru olduÄŸu konusunda bir tespitte bulunmadÄ±m. Indent hatasÄ± gibi veya syntax hatasÄ± gibi hatalar compile yapan editor ler tarafÄ±ndan tespit edilebilir. Ã‡Ã¼nkÃ¼ if in altÄ±nda hiÃ§ kod yok. Daha kod Ã§alÄ±ÅŸmadan evvel gerÃ§ekleÅŸecek bir hata. bu gÃ¼zel soruda bÃ¶yle cevap olmamÄ±ÅŸ ama haddime deÄŸil naÃ§izane

 23. ->  Ben de #3 yaptÄ±m. activation function deÄŸiÅŸkeni tanÄ±mlanmadÄ±ÄŸÄ± iÃ§in \"tf.nn.softmax\" Normalde \"softmax\" veya \"relu\" yazmak yeterliydi. TanÄ±mlÄ± deÄŸiÅŸken olmazsa kullanÄ±lmamalÄ± diyor class iÃ§inde diye #3 yaptÄ±m. Did it right? ğŸ™‚

## soru 

> quest": "Merhabalar,  Final sÄ±navÄ±nÄ±n ilk sorusunda bir yazÄ±m hatasÄ± olabilir mi?  Ä°kinci ÅŸÄ±k; \"The regressor might overfit to test set if we don't use validation sets.\" Burada \"overfit to test set\" yerine \"overfit to training set\" olmasÄ± gerekmiyor mu?"

> comments:

1. -> Merhaba Toygar,HayÄ±r bir yazÄ±m yanlÄ±ÅŸÄ± yok. ÅÃ¶yle aÃ§Ä±klayayÄ±m, elimizde sadece training ve test setleri olduÄŸunu dÃ¼ÅŸÃ¼nelim. Modelimizi train seti ile eÄŸitip, hem train hem de test seti iÃ§in iyi bir sonuÃ§ verecek ÅŸekilde hiper parametrelerimizi ayarladÄ±k. Ancak burada modeli eÄŸitirken elimizdeki tÃ¼m setleri kullandÄ±k, yani hem train hem de test datamÄ±zÄ± iyi bir ÅŸekilde Ã¶ÄŸrendik. Ä°ÅŸte bu noktada test datasÄ±na da overfit oluÅŸabiliyor.Bunu engellemenin yolu da validation seti oluÅŸturmak. YukarÄ±daki iÅŸlemler gibi, train seti ile modeli eÄŸitiyor, validation seti ile hiperparametrelerimizi ayarlÄ±yoruz. Hem train hem de validation seti Ã¼zerinde tatminkar bir model kurduktan sonra modelimizi daha Ã¶nce hiÃ§ gÃ¶rmemiÅŸ olduÄŸu bir test seti ile test ediyoruz. Bu sayede modelimizin performansÄ±nÄ± gerÃ§eÄŸe yakÄ±n bir ÅŸekilde Ã¶lÃ§mÃ¼ÅŸ oluyoruz.DolayÄ±sÄ±yla validation seti kullanmak test datasÄ±na overfit etmeyi engelleme konusunda iÅŸe yarÄ±yor.Ä°yi Ã§alÄ±ÅŸmalar.

 2. ->  EÄŸitim setinden elde ettiÄŸin aÄŸÄ±rlÄ±klarÄ± test setindeki sonucu deÄŸerlendirerek gÃ¼ncelliyorsun. Yani eÄŸitim setine test setinin sonucuna gÃ¶re ÅŸekil veriyorsun. KÄ±sacasÄ± overfit olma durumu ya validation sete ya da test setine gÃ¶re olabiliyor.

 3. -> Ä°lk haftanÄ±n quzinde de sorulmuÅŸ olan bu sorunun cevabÄ± iÃ§in yazÄ±lan aÃ§Ä±klamayÄ± aÅŸaÄŸÄ±ya bÄ±rakÄ±yorum. UmarÄ±m faydalÄ± olur. \"Bu soruya veriye validation set eklemezsek ne olur'la baksak Ã§ok daha iyi olacak. Siz bir modelgeliÅŸtiriyorsunuz, training ve test seti ayÄ±rdÄ±nÄ±z, 100 Ã¶rnekten 80'i training 20'si test. Ev fiyatlarÄ±nÄ±tahminlemeye Ã§alÄ±ÅŸÄ±yorsunuz. Bir regresyon modeli train ettiniz, sonra iÃ§ine test verisinden 4 odalÄ± ve ikibanyolu bir ev koydunuz o da size bu evin fiyatÄ±nÄ±n 100 bin lira olmasÄ± gerektiÄŸini sÃ¶yledi, ama gerÃ§ekte oev (test verisindeki ev fiyatÄ± kolonu) 120 bin lira, buna gÃ¶re hatanÄ±za baktÄ±nÄ±z, parametrelerinizi deÄŸiÅŸtiripyeniden train ettiniz. Zamanla kendinizi bu test verisinden aldÄ±ÄŸÄ±nÄ±z hatalara gÃ¶re adapte ediyorsunuz,yani test verisine overfit ediyorsunuz. Farkettiyseniz test verisiyle hem parametreleri deÄŸiÅŸtiriyoruz hemde test ediyoruz, bu yanlÄ±ÅŸ, bu yÃ¼zden validation set ekliyoruz, hataya bakÄ±p parametre deÄŸiÅŸtirmeiÅŸlemini validation set'te yapÄ±yoruz, ardÄ±ndan yeni Ã§Ä±kan modeli test verisiyle test ediyoruz, bÃ¶ylecemodelin gerÃ§ekten iyi bir performans sergileyip sergilemediÄŸini gÃ¶rebiliyoruz.

 4. ->  Ä°lk haftanÄ±n quizinde bu soruyu yanlÄ±ÅŸ okumuÅŸ olmalÄ±yÄ±m.Ã–yleyse burada modelin *sadece* test setine overfit olmasÄ±ndan bahsetmiyoruz. Ki bu zaten mÃ¼mkÃ¼n deÄŸil. Test setine *de* overfit olmasÄ±ndan bahsediyoruz. Sorunum cÃ¼mleyi yanlÄ±ÅŸ yorumlamamla ilgili demek ki.

## soru

> quest": "Merhaba, konularÄ± tekrar ederken ÅŸu kÄ±sÄ±mÄ± tam kavrayamadÄ±ÄŸÄ±mÄ± fark ettim. AÃ§Ä±klayabilir misiniz lÃ¼tfen.

> comment

1. -> merhaba kendim Ã¶ÄŸrendiÄŸim kadarÄ±yla cevap vereceÄŸim yanlÄ±ÅŸÄ±m olabilir; Vanishing gradient iÃ§in; Bu problem sadece derin aÄŸlarda karÅŸÄ±mÄ±za Ã§Ä±kÄ±yor oraya Ã¶zel denebilir. Biz derin aÄŸlarda ne yapÄ±yorduk? Katmanlar arasÄ± inputtan outputa Forward propagation Outputa geldiÄŸimizde hatamÄ±z yÃ¼ksek olacaÄŸÄ± iÃ§in katmanlarda aralardaki weightleri gÃ¼ncellememiz lazÄ±m. Yani geri (back propagation) gelmemiz lazÄ±m. Bu ileri geri tÃ¼m epochlarda defalarca oluyor. Bu geri gelme esnasÄ±nda tÃ¼rev alÄ±yorduk, ancak iÅŸte tam burada vanishing problem baÅŸlÄ±yor, aralarda activasyon fonksiyonlarÄ± var, bu sigmoid olduÄŸunda deÄŸerleri 0-1arasÄ±na indiriyordu. Biz tÃ¼revi aldÄ±ÄŸÄ±mÄ±zda deÄŸer 0-1(Ã¶rn 0.5) aralÄ±ÄŸÄ±nda ise tÃ¼revini alabiliyoruz ve gÃ¼zel bir weight gÃ¼ncellemesi yapabiliyoruz. Ancak deÄŸer 0ya da1 e Ã§ok yakÄ±n olduÄŸunda tekrarlayan back propagationlarda artÄ±k modelimiz Ã§ok dÃ¼ÅŸÃ¼k tÃ¼rev sonuÃ§larÄ±yla weightleri cezalandÄ±ramamaya baÅŸlÄ±yor. BÃ¶ylece Vanishing gradient yani benim tabirimle model boÅŸa kÃ¼rek Ã§ekiyor ve Ã¶ÄŸrenme bir tÃ¼rlÃ¼ gerÃ§ekleÅŸmiyor. Bunu Ã¶nlemek iÃ§in aktivasyon fonksiyonunu deÄŸiÅŸtirip ReLU yapÄ±yorlar ki + deÄŸerlerde Vanishing olmasÄ±n.

###Â soru

> quest": "Merhaba, ilgilenenler iÃ§in yeni bir makale Matthews correlation coefficient (MCC) deÄŸerinin F1 score Ã¼zerine olan Ã¼stÃ¼nlÃ¼ÄŸÃ¼nÃ¼ tartÄ±ÅŸÄ±yor: [Link](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-019-6413-7)

# soru

> quest": "ArkadaÅŸlar merhaba,  AÅŸaÄŸÄ±da sizinle paylaÅŸtÄ±ÄŸÄ±m deÄŸerler hakkÄ±nda gÃ¶rÃ¼ÅŸleriniz nedir ?  TeÅŸekkÃ¼r ederim"

> comments: : 

1. ->  F1 Score Test ve Train'de gÃ¼zel bir ÅŸekilde 200 Epoch'da maximum(Test set'i Train set'den ayrÄ± olarak aldÄ±ÄŸÄ±nÄ±zÄ± dÃ¼ÅŸÃ¼nÃ¼rsek gayet gÃ¼zel sonuÃ§). 200'den sonra accuracy Test'de verimsizleÅŸiyor. Loss'da pek deÄŸiÅŸiklik olmuyor. 200 Epoch'un optimum deÄŸer, Ã¶ncesinde ve sonrasÄ±nda verimsiz olduÄŸu gÃ¶rÃ¼lÃ¼yor.

# soru
> > quest "Merhaba arkadaÅŸlar, Genel bir tekrar yapÄ±yorum ve Ã¶zellikle kod kÄ±smÄ±nda kafama takÄ±lan bazÄ± sorular oluyor. Ã–ncelikle Validation ve test set bÃ¶lÃ¼mÃ¼nde eklediÄŸim kodda validation_set=0.2 demek training setin'den mi %20 ayÄ±r demek istiyor. BÃ¶yle ise aslÄ±nda daha ilk baÅŸta Train_set, Validation_set ve test_seti ayÄ±rmak daha mantÄ±klÄ± olmaz mÄ±? Veya bir fark yaratÄ±r mÄ±?  Ä°kincisi Train_set ve test_seti kod yazarak nasÄ±l ayÄ±rabiliriz? Ã‡Ã¼nkÃ¼ burada hazÄ±r olan train ve test setlerini kullanmÄ±ÅŸ.  YardÄ±mcÄ± olursanÄ±z sevinirim. TeÅŸekkÃ¼rler"

> comments: ": 

1. -> [Link](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) 
scikit-learn 0.22.2 [documentation](scikit-learn.org) ve diÄŸer [Link](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)

2. ->  validation_set parametresi train datasÄ±ndan alÄ±r (yanlÄ±ÅŸ hatÄ±rlamÄ±yorsam listenin son elemanlarÄ±nÄ± alÄ±yordu). bundan dolayÄ± yukarÄ±da yolladÄ±ÄŸÄ±m fonksiyonu iki kere kullanÄ±p train,test,validation datasi ayarlamak daha mantÄ±klÄ±.

3.  ->  model.fit(x_train,y_train,validation_data=(x_val, y_val))bu ÅŸekilde validation datasÄ±nÄ± verebilirsin.

4. ->  x0, x1 ve x2 deÄŸiÅŸkenlerine baÄŸlÄ± olarak deÄŸiÅŸen y0 outputunun bulunduÄŸu .csv olarak formatlanmÄ±ÅŸ uydurma bir veri seti iÃ§in aÅŸaÄŸÄ±daki ÅŸekilde veriyi train ve test olarak ayÄ±rabilirsiniz. EÄŸer networkunuz keras ile oluÅŸturulmuÅŸsa fit ederken x_train, y_train verilerinden bir kÄ±smÄ± validation iÃ§in ayÄ±rabilirsiniz. OkuduÄŸunuz veri pandas dataframe'i yerine dÃ¼z numpy array olsa bile yine bu ÅŸekilde veriyi ayÄ±rÄ±p networkÃ¼nÃ¼ze baÄŸlÄ± olarak yine numpy array olarak kullanabilir ya da tensora Ã§evirebilirsiniz.

5. -> [Link](https://github.com/metobom/basit-cnnler-ve-keras-ile-uygulanislari) Biraz daha kafa aÃ§mak isterseniz repodaki get_data.py'Ä± inceleyebilirsiniz.GitHub - metobom/basit-cnnler-ve-keras-ile-uygulanislarigithub.com 

6. ->  Ã–rneÄŸin 10000 gÃ¶zlemimiz varsa slicing Ã¶zelliÄŸini kullanarak df_1[0 : 1000], df_2[1000 : 10000] uygulayarak 1000 e 9000 ÅŸeklinde ayÄ±rabiliyoruz. Ä°lk iÅŸlem, 0. indexten baÅŸlayÄ±p 1000. indexe kadar olanlarÄ± almamÄ±zÄ± saÄŸlÄ±yor. ikincisi de aynÄ± mantÄ±k. 

## soru


> quest": "Herkese merhaba, 4 haftayÄ± bitirdik ve son bir sÄ±navÄ±mÄ±z kaldÄ±, herkesi tebrik etmek istiyorum.   Benim bu alana adÄ±m atma sÃ¼recimde faydalandÄ±ÄŸÄ±m kaynaklarÄ± sizlerle paylaÅŸmak istiyorum. Ã–zellikle yeni baÅŸlamÄ±ÅŸsanÄ±z iÅŸinize yarayacÄ±ÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum.  Bence kursu bitirmemiz demek Machine Learning temelimizi Ã§ok daha saÄŸlam hale getirdiÄŸimiz anlamÄ±na geliyor. Neden mi? Bir sÃ¼redir bu alanla ilgileniyorum ve projeler Ã¼zerinde Ã§alÄ±ÅŸÄ±p pratik yapÄ±yorum hatta ÅŸu anda da elimde bir proje var fakat teorik aÃ§Ä±dan sÃ¼rekli eksiklikler hissediyordum ve bu kurstan sonra bu aÃ§Ä±ÄŸÄ±mÄ±n bÃ¼yÃ¼k oranda kapandÄ±ÄŸÄ±nÄ± farkettim. Konulara daha hakimim.  Kurs boyunca her hafta TÃ¼rkÃ§e notlar aldÄ±m, hem kaÄŸÄ±t Ã¼zerinde hem de Jupyter Notebook Ã¼zerinde. BunlarÄ± her hafta Github repo'mda gÃ¼ncelledim. NotlarÄ±n dÃ¼zenlemesini bitirdim. Sizlerle paylaÅŸmak istiyorum. Genel hatlarÄ± ile konularÄ± hatÄ±rlatacak notlar olduklarÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum. Son sÄ±navda iÅŸinize yarayabilir.   Blog tutmak, online notlar almak gerÃ§ekten faydalÄ± oluyor. Kesinlikle tavsiye ederim. BirÃ§ok kiÅŸinin faydalanabilecek olmasÄ± da gÃ¼zel hissettiriyor.  GitHub Repo: [Link](https://github.com/enesoriginal/ML-crash-course-notes) Son olarak, bÃ¶yle bir organizasyonu bizlere sunup aynÄ± zamanda sÃ¼reÃ§ boyunca emek veren ve zaman ayÄ±rÄ±p bizlere destek olan baÅŸta [Link](https://community.globalaihub.com/community/profile/aslii/)  -> olmak Ã¼zere tÃ¼m mentorlerimize ve arkadaÅŸlarÄ±ma teÅŸekkÃ¼r ediyorum.   Bu bir son deÄŸil, bÃ¼yÃ¼k bir maceranÄ±n ilk adÄ±mÄ±nÄ± atmÄ±ÅŸ bulunuyoruz.  ML kariyerinizde baÅŸarÄ±larâ€¦   BahsettiÄŸim ek kaynaklarÄ± yorum olarak bÄ±rakÄ±yorum.

> comments: ": 

 1. -> Youtube kanallarÄ±:StatQuest Machine Learning Playlist - Teorik aÃ§Ä±dan Ã§ok faydalÄ± oluyor. [Link](https://www.youtube.com/playlist?list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJFSentdex) Hem eÄŸlenceli hem Ã¶ÄŸretici bir kanal [Link](https://www.youtube.com/playlist?list=PLQVvvaa0QuDfKTOs3Keq_kaG2P55YRn5v) Bu sitelerin Medium BloglarÄ±nÄ± Ã¶neririm:Machine Learning Mastery [Link](https://machinelearningmastery.com/start-here/Towardsdatascience) - Veriler Ã¼zerinde hakimiyeti artÄ±racak bir sÃ¼rÃ¼ makale ve daha fazlasÄ± [Link](https://towardsdatascience.com/machine-learning/homeEÄŸitim) Ã¶ncesi veriyi gÃ¶rmemiz ve Ã¼zerinde iÅŸlemler yapabilmemiz aÃ§Ä±sÄ±ndan Pandas ve Matplotlib kÃ¼tÃ¼phanelerini bilmek de Ã§ok iÅŸe yarÄ±yor.Deep Learning TÃ¼rkiye'den Mert Ã‡obanoÄŸlu - Pandas Egzersileri [Link](https://www.youtube.com/playlist?list=PLk54I7lqQSsaV8SxQDj19JVKfE_cM-Skp)Learningwww.youtube.comMachine Learning covers a lot of topics and this can be intimidating. However, there is no reason to fear, this play list will help you trough it all, one st.


 2. ->  Ã–ncelikle Enes eline saÄŸlÄ±k. Teorik bilgileri githubta derlemen Ã§ok faydalÄ± oldu ben ve bu alana yeni baÅŸlayanlar iÃ§in. Tekrar teÅŸekkÃ¼r ederim.Bir de  [Link](https://pybilim.wordpress.com/) ilgilenler iÃ§in tavsiye edebilirim Ã¶zellikle kaynakÃ§a kÄ±smÄ±ndan Ã§ok faydalanÄ±yorum.
    "PythonBilimpybilim.wordpress.comPython ile bilimsel programlama, sayÄ±sal analiz, simÃ¼lasyon.

 3. -> Ellerine saÄŸlÄ±k Ã§ok yararlÄ± oldu fakat hafta 3Ã¼n classification konularÄ±nda precision tanÄ±mlaman biraz yanlÄ±ÅŸ olmuÅŸ sanÄ±rÄ±m, unutmadan gÃ¼ncellemeni Ã¶neririm.

 4. ->   -> TanÄ±mÄ±n ikinci cÃ¼mlesinden bahsediyorsan eÄŸer ? evet yanlÄ±ÅŸ yorumlanabilir. Onun yerine \"Ã‡obanÄ±n dÃ¼rÃ¼stlÃ¼ÄŸÃ¼nÃ¼ Ã¶lÃ§Ã¼yoruz\" diyebiliriz. TeÅŸekkÃ¼r ederim.

 ## soru

> quest": "Easy to let this grow stale(static model) Will adapt to changes, staleness issues avoided(dynamic model)  Merhabalar. Bu cÃ¼mlelerde anlatÄ±lmak istenen ne ve stale kelimesi hangi anlamda kullanÄ±lmÄ±ÅŸ?

> comments: ":

 1. ->  Static modelde elinizdeki sabit bir veriyle Ã¶ÄŸretiyorsunuz. Ã–rneÄŸin 2019 senesi Ä°stanbul ev fiyatlarÄ± veri setinizi kullanÄ±yorsunuz. Bu veriyle eÄŸittiÄŸiniz sistem bir sÃ¼re sonra eskiyecektir(stale). Dynamic model ile ise 2020 verilerini de kullanacaÄŸÄ±nÄ±z iÃ§in, daha doÄŸrusu sÃ¼rekli veriyle besleyeceÄŸiniz iÃ§in; deÄŸiÅŸikliklere uyum saÄŸlayacaktÄ±r.

## soru

> quest": "Herkese merhaba. Keras kullanarak bir model eÄŸitiyorum.Bu eÄŸitimden sonra ben bu eÄŸitilmiÅŸ modeli bir uygulamada kullanmak istiyorum.Yani bu modelde Ã¶ÄŸrendiÄŸim parametrelere gÃ¶re baÅŸka bir programda sadece karar vermek istiyorum.Bunu nasÄ±l yapabilirim? Aramam gereken ÅŸeyler neler yÃ¶nlendirebilirseniz sevinirim.

> comments: 

 1. ->  Merhaba, [Link](https://machinelearningmastery.com/save-load-keras-deep-learning-models)  linki size yardÄ±mcÄ± olacaktÄ±r.Ä°yi Ã§alÄ±ÅŸmalar.3 weeks ago 2 people like this.

 2. -> Keras'ta eÄŸittiÄŸiniz modeli bir dosyaya kaydedin, kullanmak istediÄŸiniz uygulamada bu dosyayÄ± load edip ilgili modele tahmin yaptÄ±rabilirsiniz. Modeli kaydetme ÅŸurada anlatÄ±lÄ±yor: [Link](https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model) , Prediction yapmak istediÄŸiniz programlama ortamÄ±na gÃ¶re load ve prediction aÅŸamalarÄ± deÄŸiÅŸiklik gÃ¶sterecektir.FAQ - Keras Documentationkeras. x[Link](https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model3) 
    " "
x

## soru

> quest": "ML modelimizdeki bias sadece modelimizi beslediÄŸimiz veriden mi kaynaklanÄ±r? Modelimiz kendiliÄŸinden bir Ã¶nyargÄ± geliÅŸtirebilir mi?

> comments: ": 

 1.  ->  Merhaba, sanÄ±rÄ±m bÃ¶yle bir durum sÃ¶z konusu. Linkini ekelediÄŸim videoda 1:28den itibaren bahsettiÄŸi latent bias buna Ã¶rnek olabilir. KurduÄŸumuz algoritamalar bazen cinsiyet, Ä±rk ya da herhangi bir baÅŸka Ã¶zellikle yanlÄ±ÅŸ baÄŸlantÄ±lar kurabiliyor. Hatam ya da eksiÄŸim varsa dÃ¼zeltirseniz sevinirim. Kolay gelsin. [Link](https://youtu.be/59bMh59JQDoMachine) Learning and Human Biasyoutu.beAs researchers and engineers, our goal is to make machine learning technology work for everyone.3 weeks ago 6 people like this.
 
 1.   ->  video sÃ¼per teÅŸekkÃ¼ler. yine de bizim modele vermiÅŸ olduÄŸumuz veri ile alakalÄ±. bence model kendi kendine bir bias oluÅŸturmuyor, eÄŸer bir Ã§ocuÄŸa sÃ¼rekli erkek fizikÃ§i resimlerini gÃ¶sterirsek, Ã§ocuk, kadÄ±n fizikÃ§i olamayacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nebilir, onun gibi bir ÅŸey. aslÄ±nda Ã§ok ilginÃ§ ve derin bir konu yapay zekanÄ±n etiksel boyutu. kÃ¼Ã§Ã¼k bir hikaye duymuÅŸtum bu konularla ilgili;bir araÃ§ sigortasÄ± ÅŸirketi yapay zeka kullandÄ±ÄŸÄ±nda kadÄ±n sÃ¼rÃ¼cÃ¼lere aylÄ±k olarak daha fazla Ã¼cret Ã§Ä±kartÄ±yormuÅŸ. kadÄ±nlarÄ±n kaza oranÄ± daha yÃ¼ksek olduÄŸu iÃ§in (en azÄ±ndan verilen veride Ã¶yle). ama iyi araÃ§ kullanan kadÄ±nlar haksÄ±z yere fazla para Ã¶demiÅŸ oluyor. ama olayÄ±n doÄŸruluk kÄ±smÄ± da var. milyonlarca gÃ¶zlem tesadÃ¼f olamaz, kadÄ±nlar % olarak daha Ã§ok kaza yapÄ±yormuÅŸ. bilmiyorum Ã¼zerine Ã§ok dÃ¼ÅŸÃ¼nÃ¼lmesi gereken ÅŸeyler ğŸ™‚3,
    
 2. ->  ->  Evet haklÄ±sÄ±n, bir Ã§ocuÄŸa fizikÃ§iler data setinden random bir ÅŸekilde fizikÃ§i resimleri gÃ¶stersek halihazÄ±rda erkek fizikÃ§i yÃ¼zdesi daha fazla olduÄŸu iÃ§in ona karÅŸÄ± bir bias geliÅŸtirebilir. Yani gÃ¼nÃ¼mÃ¼zdeki mevcut durumda Ã§ocuÄŸun bias geliÅŸtirmemesi iÃ§in data setini manipÃ¼le etmemiz(yani kadÄ±n fizikÃ§ileri daha gÃ¶rÃ¼nÃ¼r yapmamÄ±z) gerekebilir. Bu anolojinin makine Ã¶ÄŸrenmesindeki karÅŸÄ±lÄ±ÄŸÄ± ne olur ya da saÄŸlÄ±klÄ± bir anoloji olur mu emin deÄŸilim. GerÃ§ekten 
    ucu aÃ§Ä±k bir konu

 3.  ->  ->  Bunu da izlemenizi tavsiye ederim [Discrimination / Bias ](https://www.youtube.com/watch?v=jEcDzHYonLU) playlist [Link](https://www.youtube.com/playlist?list=PLuyk1nLMhRm5aV6_eeUIuj_MKEekvwGDR3) 

 ## soru

> quest "Merhaba, 9. soruyu anlayamadÄ±m yardÄ±mcÄ± olabilir misiniz acaba? AÄŸÄ±rlÄ±klarÄ± input'tan baÅŸlayarak ileriye veya output'tan baÅŸlayarak geriye doÄŸru gÃ¼ncelleyerek ilerleyebiliriz tamam fakat niye bu 3 boyutlu olmalÄ±, regresyon olduÄŸu iÃ§in mi? Bu bir sÄ±nÄ±flandÄ±rma problemi olsa 2 boyut yeterli olur muydu? Sadece feed forward veya sadece back propagation kullanÄ±lmasÄ± gereken durumlar var mÄ±? Ã‡ok teÅŸekkÃ¼rler ÅŸimdiden.

> comments: 

 1.  Merhaba,Burada 3 boyutlu bir embedding'imiz var. Her boyut ayrÄ± bir nÃ¶ronu iÅŸaret eder. (Ã–rneÄŸin film verisetimizi daha dÃ¼ÅŸÃ¼k boyutlu bir dÃ¼zleme indirgemek istediÄŸimizde ve film tÃ¼rÃ¼nÃ¼ bir boyut olarak dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼mÃ¼zde bu aslÄ±nda bir nÃ¶ron olur ve ayrÄ± hesaplama gerektirir. 4 boyutlu dÃ¼zleme indirirsek 4 nÃ¶ron olur.)Feed Forward modelimizin eÄŸitilme ÅŸeklidir ve feed forward ile modelimizi eÄŸitebilirsiniz. Ancak bu nural networkte eÄŸittiÄŸiniz modelin costunu minimize etmek isterseniz (-ki muhtemelen isteyeceksinz) gradient descent yÃ¶ntemine baÅŸvurmalÄ±sÄ±nÄ±z. Burada da iÅŸin iÃ§ine back propagation giriyor Ã§Ã¼nkÃ¼ back propagation ile her nÃ¶ronun weight'ini tekrar ayarlayabiliyorsunuz. (Ã‡Ã¼nkÃ¼ neural networkte layerlar arasÄ±nda geri gidebiliyorsunuz)HatalÄ± olduÄŸum yer varsa dÃ¼zeltilmesinden memnun olurum.Ä°yi Ã§alÄ±ÅŸmalar.

 ## soru

> quest "Merhabalar,herkese Ã§ok teÅŸekkÃ¼rler. BÃ¶yle soru -cevap platformuna hep ihtiyacÄ±mÄ±zÄ±n olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yorum. Yani kendi adÄ±ma sÃ¶yleyecek olursam benim ihtiyacÄ±m var Ã§oÄŸu ÅŸeyin mantÄ±ÄŸÄ±nÄ± buradaki soru cevaplardan kavradÄ±m ve cevaplara eÅŸ zamanlÄ± ulaÅŸmak gerÃ§ekten Ã§ok gÃ¼zeldi. Bu platform gibi soru-cevap platformu aÃ§mayÄ± dÃ¼ÅŸÃ¼nÃ¼yor musunuz? Herkesin eline emeÄŸine saÄŸlÄ±k baÄŸlandÄ±ÄŸÄ±m benimsediÄŸim bir kurs oldu teÅŸekkÃ¼rler

> comments: 

 1.  Merhaba TuÄŸba, Turkish AI Hub iÃ§erisinde tÃ¼m sorularÄ±nÄ± TÃ¼rkÃ§e olarak dilediÄŸin zaman paylaÅŸabilirsin ğŸ˜‰
1.   ->  TeÅŸekkÃ¼r ederim iyi ki varsÄ±nÄ±z ğŸ™‚
 2. ->  Program tamamen sonlandÄ±ktan sonra \"Machine Learning Crash Course\" bÃ¶lÃ¼mÃ¼ne de girme fÄ±rsatÄ±mÄ±z olacak mÄ±? Girebilirsek faydalÄ± olur Ã§Ã¼nkÃ¼ burada gÃ¼zel bir geÃ§miÅŸ var.,
 3. ->  Merhaba, tabii bu hub hep aÃ§Ä±k kalacak sadece 15 MayÄ±s'tan sonra soru sorabilme durumunu kapatÄ±yoruz. SorularÄ±nÄ±zÄ± Turkish AI Hub iÃ§inden sorabilirsiniz bu tarihten sonra ğŸ™‚

 ## soru

> quest "Merhaba,  Hafta 4 - Soru #8 ile ilgili olarak,  \"Classifying people as eligible for a credit (positive) or not (negative)\" ÅŸÄ±kkÄ± iÃ§in de precision'a odaklanmamÄ±z gerekmez mi?  Modelin, bir kiÅŸinin kredi verilmeye uygun olup olmadÄ±ÄŸÄ±nÄ± tespit iÃ§in bankalar tarafÄ±ndan kullanÄ±ldÄ±ÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nelim. Model iki tÃ¼rlÃ¼ yanÄ±labilir;  1 - GerÃ§ekte krediye uygun olmayan birini \"krediye uygundur\" olarak etiketleyebilir (false positive) 2 - GerÃ§ekte krediye uygun olan birini \"krediye uygun deÄŸil\" olarak etiketleyebilir (false negative)   Banka burada herhalde 1 no'lu hata tipinden (false positive) kaÃ§Ä±nmak isteyecektir zira bu hata diÄŸerine nazaran daha maliyetli. Kredinin geri Ã¶demesini yapamayacak birine kredi verildi.  False positive'lerin sayÄ±sÄ±nÄ± azaltmak da precision'Ä± artÄ±racaÄŸÄ± iÃ§in, ilgili ÅŸÄ±kkÄ±n da doÄŸru cevap olmasÄ± gerektiÄŸini dÃ¼ÅŸÃ¼nÃ¼yorum."

> comments: 

 1.   Ben de size katÄ±lÄ±yorum. Sistemin eligible olmayan birini eligible olarak tahmin etmesi bankaya zorluk Ã§Ä±karabilir. Yani false positive sayÄ±sÄ±nÄ±n azaltÄ±lmasÄ± gerekiyor.

 2.  Ben de bÃ¶yle dÃ¼ÅŸÃ¼nÃ¼yorum. Mail olayÄ±nÄ±n precisiona Ã¶nem verdiÄŸini bilmeme raÄŸmen sÄ±rf kredi durumunun daha elzem olduÄŸunu dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼m iÃ§in kredi ÅŸÄ±kkÄ±nÄ± seÃ§tim.

 3.  Ben de sizin gibi kararsÄ±z kalarak yanlÄ±ÅŸ yaptÄ±m. Hala da kararsÄ±zÄ±m bu konuda ama en son ÅŸu sonuca vardÄ±m kendimce ğŸ™‚ AslÄ±nda kredi verme kararÄ±nda banka iÃ§in FP i azaltmak daha Ã¶nemli ancak kredi alabilecek olumlu mÃ¼ÅŸteriye kredi verilmemesi de kaynaklarÄ±n verimsiz kullanÄ±lmasÄ±na yol aÃ§ar aslÄ±nda. O nedenle FN i de azaltmak Ã¶nemli aslÄ±nda. Bu nedenle F1 skoruna bakmak daha doÄŸru olacak sanÄ±rÄ±m. Ek olarak gerÃ§ek hayatta ise bu probleme iliÅŸkin mÃ¼ÅŸterilerin kredi batma olasÄ±lÄ±ÄŸÄ± hesaplanÄ±rken logistic regresyon ile modellenip accuracy ratio ve roc curve e bakÄ±ldÄ±ÄŸÄ± uygulamalar biliyorum.
    
 1.   AynÄ± mantÄ±k ile dÃ¼ÅŸÃ¼nerek bende aynÄ± ÅŸÄ±kkÄ± iÅŸaretledim. DiÄŸerlerinde recall daha Ã¶nemli bir durumdayken kredi iÃ§in precision bence daha Ã¶nemli konumda Ã§Ã¼nkÃ¼ hatalÄ± kredi verme lÃ¼ksÃ¼ yok.
 2.  Bana da Ã¶yle geldi, Precision: positive tanÄ±mlamalarÄ±n ne kadarÄ±nÄ±n doÄŸru olduÄŸuyla ilgileniyor. Bu durumda credit (positive) , bunun dÄ±ÅŸÄ±nda kalan kÄ±sÄ±m negative ile bilgi vermez mi diye dÃ¼ÅŸÃ¼nmedim deÄŸil ğŸ™‚

 3.  Bence sadece fp deÄŸil fn lere de bakÄ±lmasÄ± gerekildiÄŸi iÃ§in ben o ÅŸÄ±kkÄ± iÅŸaretlemedim. Ne de olsa krediye uygun olan birine kredi vermemekte sÄ±kÄ±ntÄ± Ã§Ä±karabilir.,
 4. ->  Zaten mesele iki hata tÃ¼rÃ¼ arasÄ±nda seÃ§im yapmakta, krediye uygun olmayan birine onay vermek mi, krediye uygun olan birine red vermek mi ? Hangisi daha maliyetli?

## soru

> quest "Merhaba, Kurs iÃ§eriklerine son eriÅŸim tarihi hakkÄ±nda bilgi verebilir misiniz?  10 MayÄ±s'a kadar genel tekrar yapmayÄ± planlÄ±yorum


> comments: 

 1. Merhaba, kurs[Link](https://developers.google.com/machine-learning/crash-course) iÃ§eriklerine eriÅŸim iÃ§in bir zaman kÄ±sÄ±tlamasÄ± yok, istediÄŸin zaman eriÅŸebilirsin.

## soru

> quest "Ä°yi gÃ¼nler  Machine Learning Crash Course'un 15 mayÄ±sta kapanacaÄŸÄ±nÄ± sÃ¶ylemiÅŸtiniz, peki kursun devamÄ±ndaki data prep, clustering, testing and debugging, GANs.. gibi konular bulunan o kÄ±sÄ±mlarda mÄ± 15 mayÄ±sa kadar aÃ§Ä±k kalacak? Bunun hakkÄ±nda bilgi verebilir misiniz?

> comments: 

 1.  Global AI bÃ¼nyesindeki 'Machine Learning Crash Course' tan bahsedilmiÅŸ, ([Link](https://developers.google.com/machine-learning/crash-course) tamamÄ±yla Google bÃ¼nyesinde bir kurstur ğŸ™‚

 ## soru

> quest "Merhaba herkese. Fairness: Types of Bias bÃ¶lÃ¼mÃ¼ndeki bias Ã§eÅŸitlerini tam olarak anlayamadÄ±m. Bu konuda yardÄ±mcÄ± olabilirseniz sevinirim

> comments: 

 1.  Merhaba,Bu konu ile alakalÄ± bir yazÄ± yayÄ±nladÄ±m. Buradan inceleyebilirsiniz: [Link](https://medium.com/@ftfethi/hatas%C4%B1z-kul-olmaz-makine-%C3%B6%C4%9Frenmesinde-i%CC%87nsan-yanl%C4%B1l%C4%B1%C4%9F%C4%B1-ede8dc2255f1AklÄ±nÄ±za) takÄ±lan bir yer olursa sorabilrsiniz.Ä°yi Ã§alÄ±ÅŸmalar.

 2.  ->  Allah razÄ± olsun. TÃ¼rkÃ§e olunca o kadar kolay anladÄ±m ki, google kursta saÄŸolsun ilk defa duyduÄŸum kelimelerle cÃ¼mleleri uzata uzata anlatmaya Ã§alÄ±ÅŸmÄ±ÅŸ.

 3.  ->  Hepimizden razÄ± olsun ğŸ™‚ Yorumunuz iÃ§in Ã§ok teÅŸekkÃ¼r ederim yardÄ±mcÄ± olabildiysem ne mutlu bana ğŸ™‚

## soru

> quest "Merhabalar, Data Dependencies konusunu tam anlayamadÄ±m. Ã–zellikle  correlations ve feedback loops kÄ±sÄ±mlarÄ±nda kafam biraz karÄ±ÅŸtÄ±. YardÄ±mcÄ± olabilir misiniz?"

> comments: 
 
 1. Merhaba,Bu kÄ±sÄ±mda datalarÄ±mÄ±zÄ±n olmasÄ± gereken ÅŸekliyle alakalÄ± bilgiler verilmektedir.1.Reliability:DatamÄ±z reliable olmalÄ±. Ã–rneÄŸin biz datalara her zaman eriÅŸebilecek miyiz yoksa gÃ¼vensiz bir kaynaktan mÄ± geliyorlar? EÄŸer baÅŸka bir serverdan geliyorsa server sÄ±kÄ±ntÄ± Ã§Ä±kardÄ±ÄŸÄ±nda modelimizi de etkileyecektir. Veya bu datalar sadece aÄŸustos ayÄ±nda tatile giden insanlarÄ± mÄ± iÃ§eriyor.(burada stationary'i de bozuyor)2.VersioningBurada modelimiz deÄŸiÅŸecek mi sorusunu sormalÄ±yÄ±z. EÄŸer deÄŸiÅŸecekse ne sÄ±klÄ±kla ve deÄŸiÅŸtiÄŸi zaman nasÄ±l bileceksiniz? DatalarÄ±mÄ±z bir kaynaktan geliyorsa bu kaynak sorun Ã§Ä±kardÄ±ÄŸÄ±nda datalarÄ±mÄ±zÄ± almakta sorun yaÅŸayacaÄŸÄ±z. Burada bu sorunalra karÅŸÄ± bu kaynaktan aldÄ±ÄŸÄ±mÄ±z verilerin bir kopyasÄ±nÄ± oluÅŸturabilirsiniz.3.NecessityBir feature deÄŸeri gerÃ§ekten gerekli mi bunu sorar. Burada kÄ±sa sÃ¼reliÄŸine modelinizin performansÄ±nÄ± yÃ¼kseltecek bir feature bulup onu eklediÄŸinizde oluÅŸacak ekstra costu gÃ¶z Ã¶nÃ¼nde bulundurmalÄ±sÄ±nÄ±z. EÄŸer yeni bulduÄŸunuz bu feature bozulmaya uÄŸrayabilir bu yÃ¼zden bu feature'Ä± monitÃ¶rlemeniz gerekir.4.CorrelationsBurada bazÄ± featurelarÄ±n diÄŸer featurelar ile korele olabilecekleri sÃ¶ylenmiÅŸtir. Veri setinizde bu ÅŸekilde birbirine baÄŸlÄ± bulunan ve ayÄ±rmak iÃ§in ekstra strateji gerektiren baÅŸka featurelar var mÄ±?Correlated featurelar modelimizi her zaman geliÅŸtirecek veya her zaman kÃ¶tÃ¼ etkileyecek diye bir ÅŸey diyemeyiz ama onlarÄ± istemememiz iÃ§in nedenlerimiz:a)AlgoritmamÄ±zÄ±n daha da hÄ±zlÄ± Ã§alÄ±ÅŸmasÄ±: Curse of dimensionality nedeniyle ne kadar az feature'ImÄ±z olursa algoritmamÄ±z o kadar hÄ±zlÄ± Ã§alÄ±ÅŸÄ±r.b)Modelimizin yorumlanabilirliÄŸi artar: Ockham'Ä± hatÄ±rlarsanÄ±z bir model ne kadar basitse o kadar iyidir. Buradaki basitlik feature deÄŸerlerinin az olmasÄ± olarak yorumlanabilir.Burada correlated feature kÃ¶tÃ¼ bir ÅŸeydir diyemeyiz modelinizin yapÄ±sÄ±na gÃ¶re deÄŸiÅŸen bir olgudur bu.5.Feedback Loops:Bu kÄ±smÄ± uzun bir ÅŸekilde [Link](https://community.globalaihub.com/community/status/1321-1321-1588419875/#comment.5489.5298.5298) linkinde aÃ§Ä±klamÄ±ÅŸtÄ±m.TakÄ±ldÄ±ÄŸÄ±nÄ±z bir yer olursa sorabilirsiniz. YanlÄ±ÅŸÄ±m var ise dÃ¼zeltilmesinden memnun olurum.Ä°yi Ã§alÄ±ÅŸmalar.
    "Global AI Hubcommunity.globalaihub.comCome and join our community. Expand your network and get to know new people!

 2.  ->  Burada sizin corralated featurelarÄ±n bize kazanÃ§ saÄŸlamayacaÄŸÄ±nÄ± sÃ¶yleyerek ÅŸunu mu kastetmeye Ã§alÄ±ÅŸyorsunuz. Correlated featurelarÄ±mÄ±zÄ± birleÅŸtirip modele katmalÄ±yÄ±z Ã¶bÃ¼rtÃ¼rlÃ¼ tek baÅŸlarÄ±na bir anlam ifade etmeye biliyor ve bize ek yÃ¼k oluyor.

 3.  ->  Merhaba,EÄŸer imkanÄ±mÄ±z var ise featurelarÄ± birleÅŸtirip yeni feature elde etmemiz daha iiyi olacaktÄ±r ancak bazen bu correlated featurelardan oluÅŸan yeni feature deÄŸerimiz label ile korele olamayabilir. Zaten correlated feature her koÅŸulda kÃ¶tÃ¼dÃ¼r ve kullanmamalÄ±yÄ±z diyemeyiz evet feature sayÄ±sÄ± olarak yÃ¼k oluyor ve modelimzi kompleks hale getiriyor ama unutmamalÄ±yÄ±z ki istediÄŸimiz basitlik ve komplekslik arasÄ±ndaki en optimum yeri bulmak.Ä°yi Ã§alÄ±ÅŸmalar

## soru

> quest "Selamlar, Ã¶nceki konularÄ±mÄ±zdan aklÄ±ma takÄ±lan bir soruyu sormak istiyorum. AÅŸaÄŸÄ±da soruldu ise gÃ¶remedim.  Classification: Prediction Bias kÄ±smÄ±nda bias Ä±n kÃ¶k sebeplerin biri olarak Buggy pipeline da listelenmiÅŸ. Buggy pipeline nedir? nasÄ±l oluÅŸur?

> comments: 

 1. Emin olmamakla birlikte, dÃ¼ÅŸÃ¼ncemi paylaÅŸÄ±yorum: Bir tahminleme modeli oluÅŸturmak iÃ§in iÅŸletilen sÃ¼reÃ§lerim tÃ¼mÃ¼ (veri toplama, temizleme, feature engineering, training, evaluation vb.) pipeline. Bu adÄ±mlardan herhangi birinin uygulanÄ±ÅŸÄ±nda bir hata varsa elde ettiÄŸimiz pipeline \"buggy\" oluyor. Yani bu sanki biraz mevcut kategorilere ait olmayan hatalarÄ±n kategorisi. Ã–rneÄŸin, uygulamanÄ±n matris Ã§arpÄ±mÄ±nda bir hata yaptÄ±n, bu diÄŸer hata kategorilerinin hiÃ§birine girmiyor ama buggy pipeline olarak dÃ¼ÅŸÃ¼nÃ¼lebilir.

 2.  Merhaba,Pipeline, makine Ã¶ÄŸrenmesindeki akÄ±ÅŸlarÄ± otomatize etmek iÃ§in kullanÄ±lÄ±r. Pipeline hesaplamalarÄ±n bir derlemesi olan bir bileÅŸen dizisinden oluÅŸur. Veriler bu bileÅŸenler aracÄ±lÄ±ÄŸÄ±yla gÃ¶nderilir ve hesaplama yardÄ±mÄ± ile iÅŸlenir. EÄŸer pipeline da bug olursa verilerimiz yanlÄ±ÅŸ tahmin edilecektir.Pipeline ile ilgili daha fazla bilgi iÃ§in: [Link](https://medium.com/analytics-vidhya/what-is-a-pipeline-in-machine-learning-how-to-create-one-bda91d0ceacaÄ°yi) Ã§alÄ±ÅŸmalar.
    "WHAT IS A PIPELINE IN MACHINE LEARNING?HOW TO CREATE ONE?medium.comMachine Learning Is Burgeoning3,

## soru

> quest "Static vs. Dynamic Inference ve Data Dependencies konularÄ±nÄ± pek anlamadÄ±ÄŸÄ±mÄ± dÃ¼ÅŸÃ¼nmÃ¼yorum, sorularÄ±nda yanlÄ±ÅŸlarÄ±m var

> comments: 

 1. Merhaba,Inference kavramÄ± modelimizin tahminde bulunmasÄ± demektir diyebiliriz kaba ve kÄ±sa bir tabirle. Burada static ve dynamic inference dediÄŸi onlibne offline inference diyebiliriz.Offline inference'ta statik bir veri kÃ¼meniz vardÄ±r.Online inference'ta sorgu geldikÃ§e eÄŸitime sokulur.Online inference'ta daha fazla veriniz vardÄ±r fakat zaman kÄ±sÄ±tlamanÄ±z vardÄ±r.Offline inference iyi(+) ve kÃ¶tÃ¼(-) yÃ¶nleri:+ Tahmin costunu dÃ¼ÅŸÃ¼nmek zorunda deÄŸilsiniz+ Tahminlerimizi verify edebiliriz Ã§Ã¼nkÃ¼ verisetinde olmayan bir ÅŸey tahmin etmiyoruz.-Sadece bildiÄŸimiz ÅŸeyleri predict edebiliriz.Online inference iyi(+) ve kÃ¶tÃ¼(-) yÃ¶nleri:+Yeni veri geldikÃ§e onun hakkÄ±nda tahmin yapabiliriz.-YoÄŸun hesaplama gerektirir, gecikmeye Ã§ok duyarlÄ±dÄ±r. Bu da modelin kompleksitesini kÄ±sÄ±tlayabilir.-:Modelinizi daha yoÄŸun monitÃ¶rlemeniz gerekmektedir.Data Dependencies konusunu [Link](https://community.globalaihub.com/community/status/1338-1338-1588435795/#comment.5507.5315.5315)linkinde aÃ§Ä±klamaya Ã§alÄ±ÅŸtÄ±m. Sorunuz olursa sorabilirsiniz.Ä°yi Ã§alÄ±ÅŸmalar.

 2.  Online inference i sÃ¼rekli canlÄ± veri akan bir sistemdeki sorgulama yapmaya Ã§alÄ±ÅŸmak gibi dÃ¼ÅŸÃ¼nebilirsin. Ã–rneÄŸin twitter to tt olan bir konu Ã¼zerinde sorgulama yapÄ±yorsun. Offline inference te ise stream olmayan bir veri setinin sonuÃ§larÄ±ndan bahsedebiliriz.

## soru

> quest "Merhaba,  Embedding kÄ±smÄ±nda Logit Layer'Ä±n foksiyonunu tam olarak anlamadÄ±m. YardÄ±mcÄ± olabilirseniz sevinirim.

> comments: 

 1.  Merhaba,Logit layer kÄ±smÄ± aslÄ±nda output katmanÄ± yani bizim outputumuz.0 dan 9 a kadar elle yazÄ±lmÄ±ÅŸ rakamlarÄ± tespit eden bir modelimiz olsaydÄ± logit layerÄ±mÄ±z yani outputumuz, her biri farklÄ± bir rakamÄ± temsil eden 10 farklÄ± nÃ¶rondan oluÅŸacaktÄ±, en yÃ¼ksek outputu veren nÃ¶ron da bizim cevabÄ±mÄ±z olacaktÄ±.Movie recommendation Ã¶rneÄŸinde de amacÄ±mÄ±z 500 bin film arasÄ±ndan 2-3 tane film izlemiÅŸ bir izleyiciye bu filmler arasÄ±ndan hangi filmleri Ã¶nerebileceÄŸimizi hesaplayan bir model oluÅŸturmak. Outputumuz Ã¶rneÄŸin 500 bin den 4-5 tane film olacak. Bunun iÃ§in, her bir film iÃ§in bir nÃ¶ron olacak ÅŸekilde 500 bin nÃ¶ron iÃ§eren bir logit layer katmanÄ± oluÅŸturuyoruz, modelimiz hangi filmleri Ã¶nerdiyse o filmlerin nÃ¶ronlarÄ± Ã§Ä±kÄ±ÅŸ veriyor.

## soru

> quest "Merhaba arkadaÅŸlar,  ML Engineering bÃ¶lÃ¼mÃ¼ Data Dependencies baÅŸlÄ±ÄŸÄ±nÄ±n altÄ±ndaki soruyu tam yapamadÄ±m ve bahsedilen feedback loop kavramÄ±nÄ± anlamadÄ±ÄŸÄ±mÄ± farkettim. YardÄ±mcÄ± olabilir misiniz?

> comments: 

 1. Merhaba, anladÄ±ÄŸÄ±m kadarÄ±yla feedback loops dediÄŸimiz kavramda modelin kendi ya da baÅŸka modelin verilerini etkilemesi sÃ¶z konusu, mesela model a model b'nin sonuÃ§larÄ±nÄ± doÄŸrudan ya da dolaylÄ± olarak input feature olarak kullanabilir. Sistemin kalitesi input featurelarÄ±n kalitesine baÄŸlÄ±, Ã§Ã¶p giren Ã§Ã¶p Ã§Ä±kar mantÄ±ÄŸÄ±yla modelimizi test, verify, monitoring dediÄŸimiz aÅŸamalardan geÃ§irmeliyiz. Sorunun doÄŸru cevabÄ±nda olan seÃ§eneklerimizi aÃ§Ä±klamaya Ã§alÄ±ÅŸayÄ±m.1)\"A book-recommendation model that suggests novels its users may like based on their popularity (i.e., the number of times the books have been purchased)\" KullanÄ±cÄ±lara popÃ¼lerliÄŸe gÃ¶re roman Ã¶neren kitap tavsiye modelinde en Ã§ok satÄ±lan kitaplarÄ±n daha Ã§ok Ã¶nerilmesi satÄ±n almayÄ± arttÄ±rabilir. Girdi olarak geri beslediÄŸi iÃ§in aynÄ± kitaplarÄ± Ã¶nerme olasÄ±lÄ±ÄŸÄ± artar.2) \" A traffic-forecasting model that predicts congestion at highway exits near the beach, using beach crowd size as one of its features.\" sahile yakÄ±n otoyol Ã§Ä±kÄ±ÅŸlarÄ±nÄ±n tÄ±kanÄ±klÄ±ÄŸÄ±nÄ± tahmin eden model, plaj kalabalÄ±ÄŸÄ± boyutunu feature olarak kullanmÄ±ÅŸ ve trafik yoÄŸun olduÄŸu zaman insanlar alternatif planlar yapar ve dÃ¶ngÃ¼ bÃ¶ylece devam eder. 3) \"A university-ranking model that rates schools in part by their selectivityâ€”the percentage of students who applied that were admitted.\" burada anladÄ±ÄŸÄ±m kadarÄ±yla okullarÄ± seÃ§iciliklerine gÃ¶re deÄŸerlendiren bir Ã¼niversite ranking modeli var. Ve sÄ±ralamada en yÃ¼ksek dereceli okullar daha Ã§ok ilgi gÃ¶receÄŸi iÃ§in bu diÄŸer senenin sonuÃ§larÄ±nÄ± etkiler.

 2. Not: YazdÄ±klarÄ±mÄ±n tamamÄ± gÃ¶zÃ¼kmediÄŸi iÃ§in devamÄ±nÄ± resim olarak paylaÅŸÄ±yorum.Merhaba,Feedback Loop bir modelin outputunun kendisini veya baÅŸka modeli etkilemesidir. Ã–rneÄŸin elimizde A ve B modelleri olsun ve A'nÄ±n outputunu B'yi etkiliyor olsun. A eÄŸer hatalÄ± bir model ise outputu da hatalÄ± olacaktÄ±r ve B de dolayÄ±sÄ± ile hatalÄ± olacaktÄ±r.Crash Course'taki Ã¶rnek Ã¼zerinden ilerlersek:A modelimiz hatalÄ± olup X hissesini almaya karar veriyor olsun. Bu stok alÄ±mÄ± stok fiyatÄ±nÄ± yÃ¼kseltecektir. B modelimiz de bu stok fiyatlarÄ±nÄ± input alÄ±yor olsun. B modeli kolayca X hissesinin fiyatÄ± konusunda hatalÄ± bir sonuca ulaÅŸacaktÄ±r. Bunun nedeni kendisini etkileyen A modelinin hatalÄ± hatalÄ± olmasÄ±dÄ±r. B modeli bu fiyata gÃ¶re bu hisseyi alÄ±p satmaya karar verebilir. AynÄ± zamanda B'Nin sonucu da A'yÄ± etkileyebilir.Dipnot: Makine Ã–ÄŸrenmesinde modellerimiz hep hatalÄ±dÄ±r(gerÃ§ek deÄŸere yakÄ±n tahmin Ã¼retse de gerÃ§ek deÄŸeri Ã¼retmez). Burada hatadan kastÄ±mÄ±z buggy durumu yani mdoelimizin normal dÄ±ÅŸÄ± hatalÄ± olmasÄ±dÄ±r.Soruya gelirsek de sorumuzda bize hangi modelin feedback loop olmaya aÃ§Ä±k olduÄŸunu soruyor;Burada doÄŸru cevaplar Ã¼zerinden aÃ§Ä±klamamÄ± yapayÄ±m Ã¶nce:1.A book-recommendation model that suggests novels its users may like based on their popularity (i.e., the number of times the books have been purchased).Burada satÄ±lan kitap sayÄ±sÄ±na gÃ¶re kitaplarÄ±n popÃ¼laritesi Ã¶lÃ§Ã¼lÃ¼r ve kulalnÄ±cÄ±ya bununla ilgili bir Ã¶neride bulunulur. Modelin inpute deÄŸerine kitaplarÄ±n satÄ±lma sayÄ±sÄ± diyelim outputa da Ã¶nerilecek kitap diyelim. Ã–neride bulunulan kitaplarÄ±n ise satÄ±ÅŸlarÄ±nÄ±n artmasÄ± olasÄ±dÄ±r yani bu modelin kendi outputu aslÄ±nda kendi inputunu etkilemiÅŸtir. (Output kitap Ã¶nerisi - input bu Ã¶neriye baÄŸlÄ± artan satÄ±ÅŸ sayÄ±sÄ±)2.A university-ranking model that rates schools in part by their selectivityâ€”the percentage of students who applied that were admitted.Burada okullarÄ± seÃ§iciliklerine gÃ¶re derecelendirmek istiyoruz. Burada seÃ§cilik dediÄŸimiz ÅŸey de baÅŸvuranlardan kabul edilen Ã¶ÄŸrencilerin yÃ¼zdesidir. Burada ise ÅŸu etkiyle karÅŸÄ±laÅŸÄ±rÄ±z: en yÃ¼ksek derecede olan okula ek ilgi uyanabilir ve aldÄ±klarÄ± baÅŸvuru sayÄ±sÄ± artabilir. Bu okullar kontenjanÄ± aynÄ± tutup aynÄ± sayÄ±da Ã¶ÄŸrenci kabul etmeye devam ederse seÃ§icilik artacaktÄ±r. (Ã§Ã¼nkÃ¼ baÅŸvuran sayÄ±sÄ± artÄ±yor.) Bu ÅŸekilde modelin outputu inputunu etkilemiÅŸ diyebilriz. (input seÃ§icilik oranÄ±, output derece)3.A traffic-forecasting model that predicts congestion at highway exits near the beach, using beach crowd size as one of its features.Burada modelimiz sahile yakÄ±n otoyol sÄ±kÄ±ÅŸÄ±klÄ±ÄŸÄ±nÄ± tahmin ederken plajdaki kalabalÄ±ÄŸÄ± feature olarak kullanÄ±yor.Burada plaja gitmeyi dÃ¼ÅŸÃ¼nen insanlar trafik olduÄŸu tahmin edilirse plaja gitmekten vagzeÃ§ebilir bÃ¶ylece kalabalÄ±k azalÄ±r ve kalabalÄ±k azalÄ±rsa otoyol aÃ§Ä±lacaÄŸÄ± iÃ§in bu sefer plaja gitmeyi dÃ¼ÅŸÃ¼nenler plaja gitmek isteyecek ve orayÄ± kalabalÄ±klalÅŸtÄ±rarak trafiÄŸi arttÄ±racaktÄ±r. (input plaj kalabalÄ±ÄŸÄ±, output sahile yakÄ±n otoyolun sÄ±kÄ±ÅŸÄ±klÄ±k durumu)HatalÄ± olanlara gelirsek:1.A face-attributes model that detects whether a person is smiling in a photo, which is regularly trained on a database of stock photography that is automatically updated monthly.Burada modelimizn yÃ¼zÃ¼mÃ¼zdeki mimikleri tahmin etmesinin kendisine veya baÅŸka bir modele etkisi yoktur. Modelimiz bu tahminyle bir dÃ¶ngÃ¼ durumu oluÅŸturmamaktadÄ±r. Sadece gÃ¼len yÃ¼z, aÄŸlayan yÃ¼z vb tahminlerde bulunmuÅŸtur.2.A housing-value model that predicts house prices, using size (area in square meters), number of bedrooms, and geographic location as features.Burada modelimizin outputu modelimizin featurelarÄ±nÄ± etkilememektedir. Ã–rneÄŸin Londrada 6 odalÄ± 300 metrekare 2 yatak odalÄ± bir evin fiyatÄ± 500000 pound olarak tahmin edilirse bu tahmin bizim yatak odasÄ±

 ## soru

> quest "Merhabalar herkese, keyifli haftasonlarÄ± :)  Ben \"Fairness: Evaluating for Bias\" iÃ§eriÄŸinden bir soru sormak istiyorum. Verilen Ã¶rneÄŸi tekrar Ã¶zetlersek; 500 erkek ve 500 kadÄ±n hastanÄ±n tÄ±bbi kayÄ±tlarÄ±nÄ± almÄ±ÅŸlar ve tÃ¼mÃ¶r olup olmadÄ±ÄŸÄ±nÄ± tespit eden bir model geliÅŸtirmiÅŸler. Model performansÄ± sonucu recall %80, precision %73 Ã§Ä±kmÄ±ÅŸ. SonrasÄ±nda test datasÄ±nÄ± kadÄ±n ve erkek olarak ikiye ayÄ±rÄ±p performansÄ± incelediklerinde;  KadÄ±n hastalar iÃ§in perfomans: precision %91, recall %91 Erkek hastalar iÃ§in performans: precision %67, recall % 54 olduÄŸu gÃ¶rÃ¼lmÃ¼ÅŸ, buradan bias Ä±n Ã¶nemini anlÄ±yoruz demiÅŸ.  Burada tam olarak hangi tip bias olabilir (selection, reporting, implicit vs.) ? Dataset imbalanced (negative sayÄ±sÄ± pozitif sayÄ±sÄ±ndan daha fazla) ama erkek-kadÄ±n ayrÄ±ldÄ±ÄŸÄ±nda iki grup iÃ§in de oran aynÄ±. Bu hata farkÄ± erkeklerde gÃ¶rÃ¼len tÃ¼mÃ¶rÃ¼n tespit edilmesi daha zor olduÄŸu iÃ§in olabilir mi?  Ã‡Ã¶zÃ¼m olarak sample sayÄ±sÄ±nÄ± artÄ±rmaktan baÅŸka modelde nasÄ±l bir deÄŸiÅŸiklik yapÄ±labilir? Cinsiyeti (e-k) ilave bir feature olarak versek performansÄ±mÄ±z artar mÄ±ydÄ±?  TartÄ±ÅŸmaya aÃ§Ä±ktÄ±r, teÅŸekkÃ¼rler ğŸ™‚",

> comments: 

 1. Validation set 500E/500K olarak ayrÄ±lmÄ±ÅŸ ancak training set hakkÄ±nda bilgi verilmemiÅŸ. Training set'te bir coverage bias sÃ¶zkonusu olabilir. Sadece validation set sonucuna bakarak cinsiyeti bir feature olarak eklemek doÄŸru olmayabilir (gerÃ§ekten de bias var ise). Bu noktada, eÄŸitim materyelinde de anlatÄ±ldÄ±ÄŸÄ± gibi, bir tÄ±bbi uzmana danÄ±ÅŸÄ±p, cinsiyetin hastalÄ±ÄŸa etkisinin biyolojik temeli olup olmadÄ±ÄŸÄ± Ã¶ÄŸrenilebilir. EÄŸer bÃ¶yle bir temel var ise feature olarak eklenebilir.

## soru

> quest "Merhaba. Static vs. Dynamic Training kÄ±smÄ±nda anlamadÄ±ÄŸÄ±m bazÄ± kÄ±sÄ±mlar oldu. FotoÄŸrafta altÄ± Ã§izili olan maddeleri aÃ§Ä±klayabilir misiniz ? 

> comments: 

 1.  Burada anlatmak istediÄŸi ÅŸeyler ÅŸu, monitoring'ten kastÄ± modele girdilerin izlenmesi gerekiyor. modele giren ÅŸeylerin, eÄŸitilmiÅŸ modelin yapÄ±sÄ±nÄ± bozmamasÄ±nÄ± bekleriz, o yÃ¼zden inputlar (eÄŸer feedback odaklÄ± bir sistem kullanÄ±yorsak) Ã§ok Ã¶nemli. Statik model iÃ§in diyor ki, yine girdileri izlemeniz gerekiyor ve bu modelin geÃ§erliliÄŸini kaybetmesi Ã§ok kÄ±sa bir zaman alÄ±r. Dinamik model iÃ§in de, giren datayÄ± izlemeniz ve gerekmektedir. Data karantinasÄ±ndan aslÄ±nda ne demek istediÄŸini az Ã§ok anlarsÄ±nÄ±z. Son altÄ± Ã§izili yer de ÅŸunu sÃ¶ylÃ¼yor, statik modelimiz geÃ§erliliÄŸini kÄ±sa zamanda kaybederken, dinamik modelimiz bu sÃ¼reÃ§ten daha yavaÅŸ etkileniyor Ã§Ã¼nkÃ¼ sÃ¼rekli gÃ¼ncel veri geliyor ve model bunlara gÃ¶re kendini yeniliyor

 ## soru

> quest "Merhaba ArkadaÅŸlar, \"Embeddings as lookup tables\" bÃ¶lÃ¼mÃ¼nÃ¼ anlayamadÄ±m. YardÄ±mcÄ± olabilir misinz?  Ã‡ok teÅŸekkÃ¼rler"

> comments: 

 1.  Merhaba,[Link](https://community.globalaihub.com/community/status/1002-1002-1588159848) bu postun altÄ±nda bu konu tartÄ±ÅŸÄ±ldÄ±, kafanÄ±zda soru iÅŸareti olursa yanÄ±tlamaktan memnuniyet duyarÄ±m.Ä°yi Ã§alÄ±ÅŸmalar.

## soru

> quest "Merhaba nu haftaki konumuza alakalÄ± olmamakla birlikte geÃ§miÅŸ haftalarda konu olan back propagation konusunun ne olduÄŸunu pek anlayamadÄ±m bunu biz neden kullanÄ±yoruz?

> comments: 

 1. Neural network ta basitÃ§e; girdiler, hidden layers, Ã§Ä±ktÄ± katmanÄ±. Modelimizi kurduk. Forward propagation ile baÅŸladÄ±k. Burada biz farazi deÄŸerler vererek iÅŸlemleri giriÅŸ katmanÄ±ndan Ã§Ä±kÄ±ÅŸ katmanÄ±na kadar gÃ¶tÃ¼rÃ¼yoruz ancak tabiki hatamÄ±z sonunda yÃ¼ksek Ã§Ä±kÄ±cak. Ne yapmamÄ±z lazÄ±m geri dÃ¶nÃ¼p (back propagation) parametreleri gÃ¼ncelleyeceÄŸiz. Bu geri dÃ¶nme direk en baÅŸa dÃ¶nme olarak deÄŸil, nasÄ±l geldiysek tek tek katmanlar arasÄ± dÃ¶nÃ¼ÅŸ yapÄ±yoruz. Ã§Ä±kÄ±ÅŸ- hidden layers- girdilerin ilk aÄŸÄ±rlÄ±klarÄ±na kadar. Bu geri dÃ¶nme iÅŸlemini tÃ¼rev alarak yapÄ±yoruz tabi ki. Backpropagation'Ä± tamamladÄ±ÄŸÄ±mÄ±zda en baÅŸa yani inputlarÄ±n aÄŸÄ±rlÄ±klarÄ±na gelmiÅŸ oluyoruz. Sonra tekrar forward propagation yapÄ±yoruz Ã§Ä±ktÄ±ya geliyoruz, hatamÄ±za bakÄ±yoruz, olmadÄ± mÄ± tekrar back propagation ....Back propagationa baÅŸladÄ±ÄŸÄ±nda her parametre iÃ§in aldÄ±ÄŸÄ±n tÃ¼revler hatanÄ±n yÃ¼ksek Ã§Ä±kmasÄ±na sebep olan parametreler iÃ§in ceza deÄŸeri oluyor.

 2.  Merhaba,Back propagation yapmamÄ±zÄ±n sebebi neural network'Ã¼mÃ¼zÃ¼n hatasÄ±nÄ± minimize edebilmek. Back propagation yaptÄ±ÄŸÄ±mÄ±zda gradient descent yapmaya olanak saÄŸlÄ±yoruz. AÅŸaÄŸÄ±daki resmi dÃ¼ÅŸÃ¼nÃ¼n. Burada hidden layerÄ±mÄ±zdaki her nÃ¶ronun weight hata oranÄ±mÄ±zÄ± etkiliyor. Bizim bu weight deÄŸerleriyle oynama yaparak hata oranÄ±mÄ±zÄ± minimize etmemiz lazÄ±m. Ama hidden layer weightleir de input layer weightleri tarafÄ±ndan etkileniyor yani hidden layerÄ± deÄŸiÅŸtirmek iÃ§in input layer'a kaddar uzanÄ±p oaradaki weightleri deÄŸiÅŸtirmemiz lazÄ±m. Bu sayede neural network'Ã¼mÃ¼z layerlarda geri giderek uygun weight ayarlamalarÄ±nÄ± gradient descent kullanarak yapabilir.Ä°yi Ã§alÄ±ÅŸmalar.

 3. Merhaba Ã–zkaya,Back propagation iÅŸlemi aslÄ±nda modelimizi train ettiÄŸimiz iÅŸlem oluyor.Modelimizi hiperparametrelerini ayarladÄ±ktan sonra rastgele weight deÄŸerleri ile train datasÄ± Ã¼zerinde tahmin yapacak ÅŸekilde Ã§alÄ±ÅŸtÄ±rÄ±yoruz. Bu iÅŸlem sonucunda elde ettiÄŸimiz deÄŸerler modelimizin tahmin ettiÄŸi deÄŸerler oluyor ve gerÃ§ekte olmasÄ± gereken deÄŸerler ile karÅŸÄ±laÅŸtÄ±rÄ±yoruz.Bu karÅŸÄ±laÅŸtÄ±rma sonucunda Ã§Ä±kan loss deÄŸerleri ile modelimizin weightlerini geriye doÄŸru gÃ¼ncelliyoruz. Bu iÅŸleme back propagation deniyor. Bu iÅŸlem ile amacÄ±mÄ±z lossu mÃ¼mkÃ¼n olduÄŸunca azaltmak.Ä°ÅŸlemde tÃ¼rev kullanÄ±lÄ±yor Ã§Ã¼nkÃ¼ hangi neuronun sonucu ne kadar deÄŸiÅŸtirdiÄŸini bularak her bir neuronun optimum weight deÄŸerini set etmeye Ã§alÄ±ÅŸÄ±yoruz.AÅŸaÄŸÄ±da paylaÅŸtÄ±ÄŸÄ±m linki incelemen Ã§ok faydalÄ± olacaktÄ±r. BasitÃ§e bir neural network Ã¼zerinde feed forward ve back propagation iÅŸlemleri gÃ¶steriliyor.Ä°yi Ã§alÄ±ÅŸmalar.[Link](https://developers-dot-devsite-v2-prod.appspot.com/machine-learning/crash-course/backprop-scroll) [Developersdevelopers-dot-devsite-v2-prod.appspot.com](https://developers-dot-devsite-v2-prod.appspot.com/machine-learning/crash-course/backprop-scroll) 

## soru

> quest "Merhaba, Neural Networkler ile ilgili bulduÄŸum yararlÄ± olabileceÄŸini dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼m bir kaynaÄŸÄ± sizlerle paylaÅŸmak istedim. OldukÃ§a aÃ§Ä±klamalÄ± ve eÄŸlenceli anlatÄ±m tarzÄ±yla anlamanÄ±za yardÄ±mcÄ± olacaÄŸÄ±nÄ± umuyorum. [Link](https://www.youtube.com/watch?v=XJ7HLz9VYz0&amp;list=PLRqwX-V7Uu6aCibgK1PTWWu9by6XFdCfh\) Bu playlist neural networkler ile ilgilidir daha fazlasÄ± iÃ§in kanalÄ± inceleyebilirsiniz. Herkese iyi Ã§alÄ±ÅŸmalar dilerim.",

> comments: 

 1. GÃ¼zel paylaÅŸÄ±m teÅŸekkÃ¼rler. 3-4 gÃ¼n kadar Ã¶nce Embedding konusunu Ã§alÄ±ÅŸÄ±rken bu kanalÄ± keÅŸfetmiÅŸtim ve word2vec konusunu daha iyi kavrayabilmemde kanaldaki ÅŸu video oldukÃ§a yardÄ±mcÄ± olmuÅŸtu:[What is word2vec](https://www.youtube.com/watch?v=LSS_bos_TPI12.1) 

 ## soru

> quest "Merhaba, Neural Networks-&gt;Structure bÃ¶lÃ¼mÃ¼nde lineer olmayan modelimizi hidden layer yardÄ±mÄ±yla lineer bir modele Ã§evirebiliyoduk biliyorduk. Bir hidden layer iÅŸimizi gÃ¶rÃ¼rken neden ikinci bir hidden layere ihtiyaÃ§ duduk.

> comments: 

 1.  Merhabalar,Daha fazla katman demek,teorik olarak daha fazla detay demektir.Hidden Layer'larda,Ã¶zellik Ã§Ä±karÄ±mÄ± yapÄ±lÄ±r yani 'Ã¶zellikler Ã¶ÄŸrenilir.'Daha fazla katman,daha fazla node ve weight demektir,biliyoruz ki modelimiz veriyi tahmin gÃ¼cÃ¼nÃ¼ 'node' ve 'weight' lerden alÄ±r.Bu yÃ¼zden dir ki,birden fazla hidden layer kullanÄ±yoruz.Bunu,beynimizden ilham alarak hayal edebiliriz.Beynimiz milyarlarca birbirinie baÄŸlÄ± nÃ¶ronlardan (node) oluÅŸan ve bu nÃ¶ronlar arasÄ±ndaki iletiÅŸim (weight) sayesinde dÃ¼ÅŸÃ¼nÃ¼r. Ki 'Artificial Neural Network' alanÄ± da tamamÄ±yla buradan ilham almÄ±ÅŸtÄ±r.LÃ¼tfen eksik veya yanlÄ±ÅŸ olduÄŸum bir yer varsa bilgilendiriniz ğŸ™‚

 2.  'Linear olmayan modeli hidden layer yardimiyla linear modele ceviriyoruz' ifadesi butunuyle yanlis.Hidden layer ekleyerek modelini daha komplex hale getirerek modelin daha fazla feature ogrenmesine olanak veriyorsun..Layer larinda kullandigin non-linear activation function ile non-lineariteyi yakalamis oluyorsun.

## soru

> quest "merhabalar, bu haftanÄ±n konusu deÄŸil ama aklÄ±ma takÄ±ldÄ±. Scale ve kategorik dÃ¶nÃ¼ÅŸtÃ¼rme(encoding) iÅŸlemlerini modeli split etmeden Ã¶nce mi yapmak gerekir yoksa split ettikten sonra mÄ±? EÄŸer split ettikten sonraysa y test ve train iÃ§in de bunlarÄ± yapmak gerekiyor mu?

> comments: 

 1. Evet,en azÄ±ndan kategorik dÃ¶nÃ¼ÅŸtÃ¼rmeyi kullanacaÄŸÄ±nÄ±z tÃ¼m veriler Ã¼zerinde gerÃ§ekleÅŸtirip,modelin iÅŸleyebilmesi iÃ§in encode en iyisidir. Scale iÅŸlemine gelirsek, y_test ve y_train gibi Label yani sÄ±nÄ±f-Ã§Ã¶zÃ¼m-Ã§Ä±kÄ±ÅŸ belirten setler,genellikte Encoding iÅŸlemi ile kullanÄ±ma hazÄ±r hale gelebilirler.Verisetindeki anlam,iÅŸlem yÃ¼kÃ¼,iÅŸlem hassasiyeti vs gibi parametlere gÃ¶re scale ve encoding iÅŸlemlerinin yeri deÄŸiÅŸebilir.Ancak kodlama esnasÄ±nda,en azÄ±ndan kendi gÃ¶rdÃ¼ÄŸÃ¼m ve yazdÄ±ÄŸÄ±m Ã¶rneklerde,ayÄ±rma iÅŸlemi yapÄ±ldÄ±ktan sonra Scale-Encoding-Preprocessing gibi iÅŸlemler yapÄ±lÄ±r,kodun okunabilirliÄŸi arttÄ±rÄ±lÄ±r. AyrÄ±ca,aynÄ± verisetinden split edilmiÅŸ alt-gruplarÄ±n farklÄ± iÅŸlemlere tabi tutulabileceÄŸini unutmamak lazÄ±m.KÄ±saca,tutorial ve state-of-art Ã§alÄ±ÅŸmalarÄ±nÄ± inceleyip,kendinize gÃ¶re bir yol haritasÄ± Ã§Ä±karmayÄ± denemenizi tavsiye ederim.Eksik veya yanlÄ±ÅŸ ifade ettiÄŸim bir ÅŸey varsa sÃ¶ylemekten Ã§ekinmeyin lÃ¼tfen ğŸ™‚,

## soru

> quest "Merhabalar, genel tekrar yaparken iki konuda anlamadÄ±ÄŸÄ±m yerler olduÄŸunu farkettim.  1-) playground exercise bÃ¶lÃ¼mlerinde turuncu ve mavi alanlar arasÄ±nda bazen Ã§ok net ve keskin bir beyaz Ã§izgi olurken bazen arada kalan bu beyaz alan daha geniÅŸ ve bulut gibi daÄŸÄ±nÄ±k olarak bulunuyor bunun anlamÄ± nedir?  2-) Sparse vektÃ¶r ve sparse representation kavramlarÄ±nÄ± tam oturtamadÄ±m. bir vektÃ¶r eÄŸer Ã§ok fazla zero iÃ§eriyorsa buna sparse vektÃ¶r diyoruz ancak sparse representation bunun tam tersi olarak sadece non-zero elemanlarÄ±n gÃ¶sterimi olarak karÅŸÄ±mÄ±za Ã§Ä±kÄ±yor. Burada anlam karmaÅŸasÄ± yaÅŸadÄ±ÄŸÄ±m bir yer olduÄŸunu ve gÃ¶zden kaÃ§Ä±rdÄ±ÄŸÄ±mÄ± dÃ¼ÅŸÃ¼nÃ¼yorum.  CevaplarÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederim.

> comments: 

 1.  Merhaba,1. Modeliniz eÄŸitilirken eÄŸitim ve test seti random olarak daÄŸÄ±ldÄ±ÄŸÄ± iÃ§in eÄŸitiminiz her seferinde aynÄ± performansÄ± vermez. Bu yÃ¼zden her zaman aynÄ± sonucu elde edemezsiniz.3. Sparse VektÃ¶rÃ¼mÃ¼z one hot veya multi hot encoding vektÃ¶rÃ¼ olabilir ve iÃ§serisinde 0lara nazaran Ã§ok az 1 deÄŸeri vardÄ±r Ã§ok gereksiz 0 deÄŸeri vardÄ±r. Sparse representation'Ä±mÄ±z ise sparse vektÃ¶rlerdeki 0 olan deÄŸerleri deÄŸil 1 olan deÄŸerleri alÄ±p feature olarak kullanma iÅŸlemimizdir. Bunu yapma sebebimiz ise 0 olan deÄŸerlerin Ã§ok olduÄŸu bir vektÃ¶r hem performans hem de storage olarak problem oluÅŸturmaya yaklaÅŸmÄ±ÅŸ olacaktÄ±r.Ä°yi Ã§alÄ±ÅŸmalar.

 2. ->  cevaplar iÃ§in teÅŸekkÃ¼rler ancak birinci sorumu doÄŸru soramamÄ±ÅŸÄ±m sanÄ±rÄ±m. Ä°ki alan arasÄ±ndaki Ã§izginin net olmasÄ±ndan ne gibi bir anlam Ã§Ä±karabiliriz? mesela turuncu ve mavi arasÄ±ndaki beyaz alan ince bir Ã§izgi oluyorsa model daha iyi Ã¶ÄŸrenmiÅŸ veya karmaÅŸÄ±klÄ±ÄŸÄ± daha yÃ¼ksektir gibi bir yorum Ã§Ä±karmamÄ±z mÃ¼mkÃ¼n mÃ¼dÃ¼r?

 3.   ->  Renk Ã§ok yoÄŸunsa modelimiz tahminlerini daha emin bir ÅŸekilde gerÃ§ekleÅŸtiriyoe, yoÄŸun deÄŸilse de tam tersini sÃ¶yleyebiliriz. Beyaz Ã§izgimiz hipotez fonksiyonumuzun grafiÄŸe dÃ¶kÃ¼lmÃ¼ÅŸ halidir ve tam emin olmamakla beraber bu alanÄ±n Ã§ok geniÅŸlemesi veya Ã§ok daralmasÄ± bu modelimizin performansÄ±nÄ±n kÃ¶tÃ¼ olduÄŸunu gÃ¶stermektedir.Ä°yi Ã§alÄ±ÅŸmalar.3,

## soru

> quest "Merhaba, bu kÄ±sÄ±mda neden native_country ve occupation'Ä± embeddings olarak alÄ±rken diÄŸerlerini one-hot encoding olarak aldÄ±k?

> comments: 

 1. Merhaba,Bunun nedeni indicator_column parametre olarak kategorik bir veri alÄ±r, embedding_column ise sparse bir vektÃ¶r alÄ±r.occupation = tf.feature_column.categorical_column_with_hash_bucket(\"occupation\", hash_bucket_size=1000)native_country = tf.feature_column.categorical_column_with_hash_bucket(\"native_country\", hash_bucket_size=1000)Kod satÄ±rlarÄ±nda bu iki feature iÃ§in possible range'i bilmememizden Ã¶tÃ¼rÃ¼ her bir feature deÄŸerini sayÄ± deÄŸerine Ã§evirmeyi amaÃ§lÄ±yoruz.Bu nedenle de bu iki feature deÄŸerimiz sparse vektÃ¶r olmuÅŸ oluyor ve embedding_column ile bu iki sparse vektÃ¶r olan feature deÄŸerlerini daha dÃ¼ÅŸÃ¼k boyutlu bir dÃ¼zleme oturtuyoruz.

 2.   ->  buradaki hash_bucket dediÄŸimiz ÅŸey nedir? teÅŸekkÃ¼rler,
 3. ->  Merhaba,[Link](https://community.globalaihub.com/community/status/687-687-1587030142/#comment.4200.4092.4092) yorumumda hash_bucket'Ä± anlatmÄ±ÅŸtÄ±m.

## soru

> quest "Merhabalar herkese ve kolaylÄ±klar dilerim.LSTM- Long Short Term Memory networks nedir? Hangi durumlarda kullanÄ±rÄ±z? DÃ¶rt katmandan oluÅŸmasÄ±nÄ±n sebebi nedir? Tam anlayamadÄ±ÄŸÄ±m bir konu oldu.  AÃ§Ä±klamalar iÃ§in ÅŸimdiden Ã§ok teÅŸekkÃ¼r ederim. ",

> comments: 

1.  AÅŸaÄŸÄ±daki urlye bak aradÄ±ÄŸÄ±n sorularÄ±n cevabÄ±nÄ± bulacaksÄ±n.[Uzun-KÄ±sa SÃ¼reli Bellek (Long Short-Term Memory](https://devhunteryz.wordpress.com/2018/07/14/uzun-kisa-sureli-bellek-long-short-term-memory/) 
2.   ->  teÅŸekkÃ¼r ederim,

### soru 

> quest "Merhabalar, herkese kolay gelsin Ã¶ncelikle. Prediction bias konusunda kafama takÄ±lan birkaÃ§ soru var. California'daki ev fiyatlarÄ± Ã¶rneÄŸinden yola Ã§Ä±karsak evlerin gerÃ§ek ortalama fiyatlarÄ± ile bizim tahmin ettiÄŸimiz fiyatlarÄ±n ortalamasÄ± aynÄ± Ã§Ä±karsa prediction biasÄ±mÄ±z 0 olur gibi bir sonuca vardÄ±m yanlÄ±ÅŸ anlamadÄ±ysam. Ancak ortalama deÄŸer kullandÄ±ÄŸÄ±mÄ±z iÃ§in aslÄ±nda her bir Ã¶rneÄŸi tek tek ele aldÄ±ÄŸÄ±mÄ±zda Ã§Ä±kacak hatalarÄ± gÃ¶zden kaÃ§Ä±rmÄ±ÅŸ oluyoruz. 40 -60 ile 10-90 ikililerinin ortalamasÄ±nÄ±n aynÄ± olmasÄ± gibi. Bu yÃ¼zden prediction biasÄ±n sonucunu yorumlarken neye dikkat etmeliyiz? AyrÄ±ca ortalamalarÄ±n bir fonksiyonu olmasÄ±na raÄŸmen positive labellarÄ±n frekansÄ±(sÄ±klÄ±ÄŸÄ±) ile ilgili bilgiye bizi nasÄ±l yÃ¶nlendiriyor? AralarÄ±ndaki iliÅŸkiyi Ã§Ã¶zebilmiÅŸ deÄŸilim, yardÄ±mcÄ± olabilirseniz sevinirim.",

> comments: 

1.  Merhaba, dediÄŸiniz gibi hatalarÄ± gÃ¶zden kaÃ§Ä±rabiliriz. o yÃ¼zden 0 olmasÄ± modelimizin mÃ¼kemmel olduÄŸu hakkÄ±nda saÄŸlÄ±klÄ± bir bilgi veremez. ancak 0'a uzak bir deÄŸer elde edersek modelimizin yanlÄ±ÅŸ olduÄŸunu belirleyebiliriz. doÄŸruluÄŸu deÄŸil de problemi tespit etmek iÃ§in kullanÄ±lÄ±yor diye dÃ¼ÅŸÃ¼nÃ¼yorum. positive label iÃ§in ise; prediction bias kavramÄ± logistic regression baÅŸlÄ±ÄŸÄ±nda anlatÄ±lmÄ±ÅŸ. logistic regressionda binary classification yapÄ±yorduk. dolayÄ±sÄ±yla deÄŸerlerimiz 0 ve 1 olduÄŸunda ve ortalamasÄ±nÄ± aldÄ±ÄŸÄ±mÄ±zda direkt olarak positive labellarÄ±n frekansÄ± hakkÄ±nda bir fikir edinebiliriz. prediction bias 0.20 Ã§Ä±karsa olduÄŸundan daha fazla positive tahmin yapmÄ±ÅŸÄ±z diyebiliriz mesela.",
2.   ->  Ã§ok teÅŸekkÃ¼rler
3.  Sizin verdiÄŸiniz Ã¶rnekten yola Ã§Ä±karsak gerÃ§ek deÄŸerlerin ortalamasÄ±nÄ±n 50 olduÄŸu bir veride 40-60 ve 10-90 tahminlerini Ã¼reten modellerin ikisinde de prediction bias = 0 dÄ±r. Fakat ikincisinde prediction variance Ã§ok daha yÃ¼ksek. Ä°lk model daha iyidir diyebiliriz. Hatta 51-52 tahminlerini Ã¼reten bir model, kÃ¼Ã§Ã¼k bir pred.bias ortaya Ã§Ä±karsa bile prediction variance neredeyse sÄ±fÄ±r olduÄŸu iÃ§in daha kabul edilebilirdir.",

### soru

> quest "Merhabalar, 2.haftanÄ±n quizi ile ilgili bir sorum vardÄ±. 8.soruda sparse representationlarÄ± ne zaman kullandÄ±ÄŸÄ±mÄ±zÄ± sormuÅŸ ve cevap olarak da \"When data size is large and most of feature value that we are interested in is zero. \" demiÅŸ. Ancak aÃ§Ä±klama kÄ±smÄ±nda yalnÄ±zca sÄ±fÄ±r olmayanlarÄ±n depolanmasÄ±ndan bahsettmiÅŸ. Sadece sÄ±fÄ±r olmayanlarÄ± depoluyorsak non-zero olanlarla ilgileniyor olmaz mÄ±yÄ±z? Bu kÄ±sÄ±m biraz kafamÄ± karÄ±ÅŸtÄ±rdÄ±. Åimdiden aÃ§Ä±klamanÄ±z iÃ§in teÅŸekkÃ¼rler.",

> comments: 

1.  GÃ¶kÃ§e merhaba,\"When data size is large and most of feature value that we are interested in is zero.\" ile anlatÄ±lmak istenen, datadaki Ã§oÄŸu feature'Ä±n sÄ±fÄ±r olmasÄ± durumu. DediÄŸin gibi non-zero olanlarla ilgilenmiÅŸ oluyoruz, aÃ§Ä±klama kÄ±smÄ±ndan anladÄ±ÄŸÄ±n doÄŸru.Verilen ÅŸÄ±kkÄ±n anlamÄ± ile ilgili bir yanlÄ±ÅŸ anlaÅŸÄ±lma var sanÄ±rÄ±m.",
2.  ->  YardÄ±mlarÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederim,
3.  Merhabalar, ne zaman ve niÃ§in seyrek (sparse) gÃ¶sterim kullanÄ±lÄ±r sorusunun cevabÄ±nÄ± gÃ¶rsel olarak ekledim. Burada seyrek gÃ¶sterimin amacÄ± Ã§ok fazla sayÄ±da niteliÄŸin (feature) deÄŸerinin sÄ±fÄ±r olmasÄ± ve veri setimizinde bÃ¼yÃ¼k olduÄŸu durumlarda kullanÄ±lmaktadÄ±r. Senin sorunun cevabÄ±, bir Ã§ok nitelik sÄ±fÄ±r olduÄŸu iÃ§in (beni ilgilendiren durum) geri kalan az miktarda niteliÄŸi saklÄ±yorum. Tersten bakarsak eÄŸer bir Ã§ok deÄŸer sÄ±fÄ±r olmasaydÄ± (yine beni ilgilendiren durum) seyrek gÃ¶sterim kullanamazdÄ±m. Yani burada az sayÄ±da niteliÄŸimiz sÄ±fÄ±r olmadÄ±ÄŸÄ± iÃ§in deÄŸil,Ã§ok sayÄ±da niteliÄŸimiz sÄ±fÄ±r olduÄŸu iÃ§in seyrek (sparse) gÃ¶sterim kullanÄ±lÄ±yor. UmarÄ±m aÃ§Ä±k olmuÅŸtur ğŸ™‚",
4.  ->  TeÅŸekkÃ¼rler ğŸ™‚

### soru 

> quest "Merhaba arkadaÅŸlar, Embeddings&gt;Obtaining Embeddings bÃ¶lÃ¼mÃ¼nde yer alan \"Training an Embedding as Part of a Larger Model\" kÄ±smÄ±nÄ± pek anlayamadÄ±m. YardÄ±mcÄ± olabilir misiniz?",

> comments: 

1.  Merhaba,Word2vec iÅŸleminin amacÄ± sÄ±nÄ±flandÄ±rma yapmak deÄŸil kelimelerimizi numerik veriye Ã§evirmektir. Word2vec iÅŸlemi sonucunda embedding elde ederiz. Bu word2vec iÅŸlemini daha geniÅŸ bir modelimizin bir parÃ§asÄ± olarak kullanabiliriz. Bu yaklaÅŸÄ±mla daha Ã¶zelleÅŸtirilmiÅŸ bir embedding elde ederiz ancak bu iÅŸ embedding'in ayrÄ± eÄŸitilmesine oranla daha uzun sÃ¼rer.[Link](https://developers.google.com/machine-learning/crash-course/embeddings/obtaining-embeddings) sayfasÄ±ndaki figÃ¼r 5'te pembe nÃ¶ronlar ekstra embedding katmanÄ±mÄ±z olup diÄŸer feature ve hidden layerlarla da birleÅŸtirilebilirler bÃ¶ylece modelimiz daha Ã¶zelleÅŸtirilmiÅŸ bir embeddinge sahip olur. Embedding layerÄ±mÄ±zdan Ã§Ä±kan sonucumuz numerik olur. Burada kÄ±sacasÄ± embedding iÅŸlemi yapan yeni bir hidden layerÄ± modelimize yerleÅŸtirdik bÃ¶ylece daha bÃ¼yÃ¼k bir modelin parÃ§asÄ± olarak embedding iÅŸlemini gerÃ§ekleÅŸtirmiÅŸ olduk.Ä°yi Ã§alÄ±ÅŸmalar.",
[Embeddings: Obtaining Embeddings  |  Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course/embeddings/obtaining-embeddings3)
2. ->  Bu yapÄ±yÄ± anlamakta gÃ¼Ã§lÃ¼k Ã§ekiyorum. Buradan sormanÄ±n daha uygun olacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼ndÃ¼m.,
3.  ->  teÅŸekkÃ¼r ederim ÅŸimdi anladÄ±m.
4.  -> Merhaba yorumunuzu geÃ§ farkettim kusuruma bakmayÄ±n.Bu yapÄ± bizim modelimizin yapÄ±sÄ±. Modelimizde kullanÄ±cÄ±larÄ±n filmler i ve diÄŸer featurelarÄ± belirlediÄŸimiz 3 boyutlu embedding iiÅŸlemine sokup 3 boyutlu dÃ¼zleme indirgiyoruz. Burada pembe nÃ¶ronlar ekstra embedding katmanlarÄ±mÄ±z olur. Bu katmanlar sayesinde embedding daha Ã¶zelleÅŸtirilmiÅŸ olur. Burada logits dediÄŸimiz katman softmax katmanÄ±mÄ±zdÄ±r yani sonuÃ§ katmanÄ±. Softmax seÃ§ilen softmax tipine gÃ¶re (full veya candidate) belli output seti iÃ§in bir probabilty hesaplamasÄ± yapar. Bu softmax sonuÃ§larÄ±yla saÄŸdaki sarÄ±msÄ± dikdÃ¶rtgenin temsil ettiÄŸi gerÃ§ek deÄŸerlerini kÄ±yaslarÄ±z ve softmax loss hesaplarÄ±z.Ä°yi Ã§alÄ±ÅŸmalar.,

### soru

> quest "Merhaba, Embeddings: Translating to a Lower-Dimensional Space kÄ±smÄ±nda biraz kafam karÄ±ÅŸtÄ±. Bag of words'un embedding ile iliÅŸkisini ve matrix multiplication'u anlayamadÄ±m. YardÄ±mcÄ± olabilir misiniz? TeÅŸekkÃ¼r ederim. [Link](https://developers.google.com/machine-learning/crash-course/embeddings/translating-to-a-lower-dimensional-space)

> comments: 

1.  Merhaba, matrix multiplication'u Ã¶zet olarak Ã§izmeye Ã§alÄ±ÅŸtÄ±m, umarÄ±m okunur4 weeks ago 13 people like this.Like ReportReply",
2.  ->  TeÅŸekkÃ¼r ederim ğŸ™‚
3. Merhaba,Ã–ncelikle Word Embedding'i aÃ§Ä±klayayÄ±m. Word Embedding kelimeleri daha dÃ¼ÅŸÃ¼k boyutlu bir dÃ¼zleme oturtup (vektÃ¶r olarak) bu vektÃ¶rler arasÄ±nda matematiksel iÅŸlemler yaptÄ±kÃ§a yeni anlamlÄ± vektÃ¶rler(bunlara diÄŸer textler de diyebiliriz) elde ettiÄŸimiz bir NLP sÃ¼recidirMakine Ã¶ÄŸrenmesi algoritmamÄ±z plain textleri olduklarÄ± formunda iÅŸleyemediÄŸinden word embedding yÃ¶ntemine baÅŸvuruyoruz.Burada word embedding ile textlerin dil anlamlarÄ±nÄ± oldukÃ§a yakalamaya Ã§alÄ±ÅŸÄ±yoruz.Her bir wordÃ¼mÃ¼z kategorik bir veriydi ve bunlarÄ± one hot-multi hot encoding ile numerik veriye Ã§evirerek iÅŸleme sokabilirdik ama bu sefer de oluÅŸacak sparse vektÃ¶rÃ¼mÃ¼z performans sorunlarÄ±na yol aÃ§acaktÄ±.(Ã¶rneÄŸin 100000000 kelimelik bir dictionarynizde cat kelimesini one hot encoding ile gÃ¶stermek istediÄŸinizde vektÃ¶rÃ¼nÃ¼zde sadece 1 adet 1 deÄŸeriniz ve 99999999 tane 0 deÄŸeri olacaktÄ±r ve elinizde sparse bir vektÃ¶r olacaktÄ±r)Ã–rneÄŸin ÅŸÃ¶yle bir cÃ¼mlemiz olsun: \"Word Embedding kelimeleri numaralara Ã§evirir.\"Dictionary: CÃ¼mlemizdeki unique kelimeler listesi. YukarÄ±daki cÃ¼mlemize gÃ¶re dictionary'miz: ['Word','Embedding','kelimeleri','numaralara','Ã§evirir']VektÃ¶rlerimizi One Hot Encoding kullanarak gÃ¶sterebiliriz Ã¶rneÄŸin numaralara kelimesi iÃ§in vektÃ¶rÃ¼mÃ¼z: [0,0,0,1,0] olur. Tek bir kelime Ã¶ÄŸesi iÃ§in dense vektÃ¶rÃ¼ elde etmek iÃ§in, o Ã¶ÄŸeye karÅŸÄ±lÄ±k gelen sÃ¼tunu alÄ±rsÄ±nÄ±z.Sparse multi-hot encoding tÃ¼rÃ¼nde olan bir vektÃ¶rÃ¼ Ã§evirebilmeniz iÃ§in her embeddingi alÄ±p bunlarÄ± birbiriyle toplayabilirsiniz.Count Vector cÃ¼mlenizde unique kelimelerin tekrar sayÄ±sÄ±nÄ± tutar. Ã–rneÄŸin elimizde aÅŸaÄŸÄ±daki gibi bir dictionary'miz olsun:['mÃ¼dÃ¼r','gerÃ§ekten','kedi']Ã–rneÄŸin \"mÃ¼dÃ¼r gerÃ§ekten mÃ¼dÃ¼r mÃ¼dÃ¼r\" sorusunu count vector'e Ã§evirdiÄŸimizde:['mÃ¼dÃ¼r','gerÃ§ekten','kedi']3 1 0Burada sÃ¶ylenen de eÄŸer bu vektÃ¶rÃ¼ dense vektÃ¶re Ã§evirmek istersek her birininn embeddingini almadan Ã¶nce gÃ¶rÃ¼ntÃ¼lenme sayÄ±sÄ± kadar Ã§arpabiliriz. Burada bu toplama ve Ã§arpma iÅŸlemi aslÄ±nda vektÃ¶r toplama ve Ã§arpÄ±mÄ±dÄ±r. Matrix Ã§arpÄ±mÄ± kuralÄ±na gÃ¶re ilk vektÃ¶rÃ¼nÃ¼z(sparse'Ä±mÄ±z) 1xM boyuttaysa ve ikinci vektÃ¶rÃ¼nÃ¼z(Embedding'imiz) MxN boyuttaysa Ã§arpÄ±m sonucu 1xN boyutta olur.Not: -> 'Ä±n eklemeleriyle aÃ§Ä±klama yeniden dÃ¼zenlenmiÅŸtir.Ä°yi Ã§alÄ±ÅŸmalar.3 weeks ago 6 people like this.Like ReportReply",
4.  TeÅŸekkÃ¼r ederim ğŸ™‚ -> ,
5.  ->  Burada embedding konusunda yaptiginiz aciklamalar maalesef pek saglikli degil Bu sebeple bu aciklamanin baska arkadaslara tavsiye edilmesini dogru bulmuyorum.,
6.  ->  Merhaba,EleÅŸtiriniz iÃ§in teÅŸekkÃ¼r ederim. SaÄŸlÄ±klÄ± olmadÄ±ÄŸÄ±nÄ± dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼nÃ¼z yerde bana yardÄ±mcÄ± olmanÄ±zÄ± ve ben de size olabileceksem yardÄ±mcÄ± olmaya Ã§alÄ±ÅŸmak isterim. EÄŸer yardÄ±mcÄ± olamayacaksam da mutlaka yerime yardÄ±mcÄ± olacaklardÄ±r.
7.  ->  Word embedding taniminizi ve neden word embedding kullaniyoruz konusundaki aciklamalarinizda sorun var.Sorun tam olarak 'word embedding icin textleri numerik yapiya cevirmemizdir ' cumlesi ve 'Makine Ã¶ÄŸrenmesi algoritmamÄ±z plain textleri olduklarÄ± formunda iÅŸleyemediÄŸinden word embedding yÃ¶ntemine baÅŸvuruyoruz.'cumleleridir.,
8. ->  DÃ¼zeltmeleriniz ve yorumunuz iÃ§in Ã§ok teÅŸekkÃ¼r ederim.Burada word embeddingin text'i numerik yapÄ±ya Ã§evirmek iÃ§in olduÄŸunu sÃ¶ylediÄŸimde aslÄ±nda bu textlerin dil anlamlarÄ±nÄ± oldukÃ§a yakalamaya Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±zÄ± da eklemeliydim. Burada makine Ã¶ÄŸrenmesi algoritmamÄ±z textleri(kategorik veri olduklarÄ± iÃ§in) one veya multi hot encoding kullanarak da eÄŸitebilirdi fakat bu sparse vektÃ¶r sorununa yol aÃ§ardÄ± bu yÃ¼zden bunun yerine word embedding tercih ediyoruz demeliydim. Son olarak Word embedding iÃ§in kelimeleri daha dÃ¼ÅŸÃ¼k boyutlu bir dÃ¼zleme oturtup (vektÃ¶r olarak) bu vektÃ¶rler arasÄ±nda matematiksel iÅŸlemler yaptÄ±kÃ§a yeni anlamlÄ± vektÃ¶rler(bunlara diÄŸer textler de diyebiliriz) elde ettiÄŸimiz bir NLP sÃ¼recidir diye de bahsetmeliydim. Halen yanlÄ±ÅŸlarÄ±m var ise dÃ¼zeltmenizden ve doÄŸrularÄ±nÄ± Ã¶ÄŸrenmekten memnun olurum, eÄŸer yanlÄ±ÅŸÄ±m yoksa yukarÄ±daki cevabÄ±mÄ± bu ÅŸekilde gÃ¼ncellemek isterim.Ä°yi Ã§alÄ±ÅŸmalar.
9.  ->  Bu aciklamanizda one hot coding veya multi one codig kullanmak sparse vektor sorununa yol acar kisminda sorun var.Sparse vektor sorunu diye bir sorun yok Sorun curse of dimensionality olabilir.,
10.  Embedding konusunu duzgun Turkce kelimelerle anlatabilecegim bir yaziya basladim ancak Turkce ifade etmek kolay degil.Ama yazimi tamamlayip paylasacagim,
11.  ->  ÅÃ¶yle ki bu problemde Ã§ok fazla kelime iÃ§eren bir dictionaryniz varsa bu kelimeleri one hot encoding ile ifade etmek sparse sorununa yol aÃ§acaktÄ±r Ã¶rneÄŸin 100000000 kelimelik bir dictionarynizde cat kelimesini one hot encoding ile gÃ¶stermek istediÄŸinizde vektÃ¶rÃ¼nÃ¼zde sadece 1 adet 1 deÄŸeriniz ve 99999999 tane 0 deÄŸeri olacaktÄ±r ve elinizde sparse bir vektÃ¶r olacaktÄ±r bu da performans problemlerine yol aÃ§acaktÄ±r. Sparse vektÃ¶r sorunundan kastÄ±m buydu. YazÄ±nÄ±zÄ± sabÄ±rsÄ±zlÄ±kla bekliyorum okuyup bilmediklerimi Ã¶ÄŸrenmek isterim ama ÅŸu an hatalarÄ±mÄ± dÃ¼zeltip burada kurs alan arkadaÅŸlarÄ±ma bilgiyi daha hÄ±zlÄ± iletmek isterim. YazÄ±m sÃ¼resince kolaylÄ±klar ve iyi Ã§alÄ±ÅŸmalar dilerim.3,
12.  ->  Tesekkur ederim

### soru 

> quest "Merhabalar, Embeddings bÃ¶lÃ¼mÃ¼nde \"Lack of meaningfull \" kÄ±smÄ±nda  anlatÄ±lmak istenileni tam anlayamadÄ±m. Bu kÄ±sÄ±mda yardÄ±mcÄ± olabilir misiniz?",

> comments: 

1. Merhaba,Lack of Meaningful Relations Between Vectors, Sparse representation'da oluÅŸabilecek problemlerden biridir. Ã–rneÄŸin siz RGB kanallarÄ±nÄ±n piksel deÄŸerlerini image sÄ±nÄ±flandÄ±rÄ±cÄ±sna sokarsanÄ±z vektÃ¶rlerin yakÄ±nlÄ±klarÄ±ndan sÃ¶z etmek mantÄ±klÄ± olur. Ã–rneÄŸin kÄ±rmÄ±zÄ±msÄ± mavi saf maviye daha yakÄ±n olur. Bu yakÄ±nlÄ±k hem anlamsal bir yakÄ±nlÄ±k hemde dÃ¼zlemdeki geometrik yakÄ±nlÄ±ktÄ±r.Ancak \"at\" iÃ§in 1247. indeksi 1 olan bir vektÃ¶r, \"antilop\" iÃ§in 50.430. indeksi 1 olan bir vektÃ¶re \"televizyon\" iÃ§in 238. indeksinde 1 olan bir vektÃ¶re yakÄ±n olduÄŸu kadar olmayacaktÄ±r. Yani at, televizyona daha yakÄ±n olacaktÄ±r ama antilopa daha yakÄ±n olmasÄ± gerkiyordu mantÄ±k olarak.BunlarÄ± da embedding yaparak aÅŸabiliriz. Embeddingde kendi belirlediÄŸimiz boyut kadar dÃ¼zleme tÃ¼m eÄŸitim Ã¶rneklerimizi oturtturup yakÄ±nlÄ±klarÄ±na gÃ¶re tahminlerde bulunuyoruz. Burada kendi belirlediÄŸimiz dÃ¼zlem boyutlarÄ± sayesinde filmleri daha sistematik ÅŸekilde daha kÃ¼Ã§Ã¼k boyutlu bir dÃ¼zleme oturtuyoruz.Ä°yi Ã§alÄ±ÅŸmalar.4 weeks ago 7 people like this.Like ReportReply",
2.   ->  TeÅŸekkÃ¼r ederim, bÃ¶yle daha aÃ§Ä±k oldu",

### soru 

> quest "Merhabalar herkese , embeddings kÄ±sÄ±mÄ±nÄ± kafamda tam oturtamadÄ±m . AnladÄ±ÄŸÄ±m kadarÄ± ile daha iyi bir prediction iÃ§in uzay Ã¼zerinde aÄŸÄ±rlÄ±klarÄ±na gÃ¶re vektÃ¶rler belirliyoruz . BÃ¶ylelikle daha rahat sÄ±nÄ±flandÄ±rabiliyor ve feature'lar arasÄ±ndaki iliÅŸkiyi daha net gÃ¶rebiliyoruz. Bundan sonrasÄ±nda bunu yapmak iÃ§in modelimizde tam olarak ne yaptÄ±ÄŸÄ±mÄ±zÄ± ve Ã¶zellikle \"Embeddings: Translating to a Lower-Dimensional Space\" , \"Embeddings: Translating to a Lower-Dimensional Space\" kÄ±sÄ±mlarÄ±nÄ± tam olarak oturtamadÄ±m yardÄ±mcÄ± olabilirseniz Ã§ok sevinirim , ÅŸimdiden teÅŸekkÃ¼r ederim...",

> comments: 

1. Merhaba,Embedding kullanÄ±lan senaryolarda input deÄŸerlerimiz continuosu bir valur deÄŸil discrete bir deÄŸerdir. Yani inputlarÄ±mÄ±zÄ±n Ã§eÅŸitliliÄŸi sÄ±nÄ±rlÄ±dÄ±r Ã¶rneÄŸin kullanÄ±cÄ±nÄ±n izlediÄŸi filmlere gÃ¶re bir Ã¶neri yapma modelimizde inputlarÄ±mÄ±z bizim izlediÄŸimiz filmler olacaktÄ±r ve bu filmler de sistemde tanÄ±mlÄ± olan filmlerden biri olmak zorundadÄ±r.Burada bu Ã¶neri sistemini kullanabilmek adÄ±na elimizdeki filmleri bir dÃ¼zleme oturtup farklÄ± Ã¶zelliklere gÃ¶re kategorilendirmemiz daha saÄŸlÄ±klÄ± olacaktÄ±r. TÃ¼m bu kategoriler bir boyutu temsil eder Ã¶rneÄŸim filmlerimizi (YaÅŸ kategorisi, ve filmin korku olup olmadÄ±ÄŸÄ±) bu iki kategoride ele almak istersek iki boyutlu bir dÃ¼zlemde filmlerimizi yerleÅŸtirmiÅŸ oluruz. Burada yaptÄ±ÄŸÄ±mÄ±z elimizdeki input deÄŸerlerini daha az boyutlu (2,3 veya daha fazla boyut sayÄ±sÄ± size kalmÄ±ÅŸ) bir dÃ¼zlemde inceleyebilmek ve birbirilerine yakÄ±nlÄ±klarÄ±na gÃ¶re aynÄ± kefeye koyabilmek. Burada birbirine yakÄ±n olarak konumlandÄ±rÄ±lan filmleri Ã¶nerebilirsiniz. Ã–rneÄŸin Silent Hill filmi korku tÃ¼rÃ¼nde ve yaÅŸ sÄ±nÄ±rlamasÄ± +18 olan bir filmdir. Star Wars ise Fantastik ve Silent Hill filmine gÃ¶re hiÃ§ korkunÃ§ deÄŸildir bu yÃ¼zden dÃ¼zlemimizde ilgili eksenin korku tarafÄ±na gÃ¶re negatif tarafÄ±nda olacaktÄ±r. ([Link](https://developers.google.com/machine-learning/crash-course/embeddings/motivation-from-collaborative-filtering#arrange-movies-in-a-two-dimensional-space) altÄ±ndaki resmi 2 boyutlu olarak Ã¶rnek alabilirsiniz.) Bu yÃ¼zden de Silent Hill filmini izlemiÅŸ birine Star Wars filmini Ã¶nermezsiniz. GerÃ§ek dÃ¼nyada bu saydÄ±ÄŸÄ±m iki kriterden Ã§ok daha fazla kriter vardÄ±r hatta filmin aÃ§Ä±klamasÄ± bile bir kriter sayÄ±labilir. KÄ±sacasÄ± embedding dediÄŸimiz ÅŸey bÃ¼yÃ¼k sparse (iÃ§inde Ã§ok 0 ve az 1 bulunan vektÃ¶rler) vektÃ¶rleri aralarÄ±ndaki semantic iliÅŸkiyi koruyarak daha dÃ¼ÅŸÃ¼k boyutlu bir dÃ¼zlemde gÃ¶sterir. Bir diÄŸer tanÄ±mÄ± ise kategorik inputlarÄ± continuous valuelara Ã§evirir diye yapabiliriz. Ã‡Ã¼nkÃ¼ dÃ¼zlemdeki konumlarÄ± bir nokta ifade edecek ve bu noktalar artÄ±k ilgili kategorik verimizi tanÄ±mlayan deÄŸer olacaktÄ±r. (Boyut sayÄ±sÄ± ve kadar fazlaysa noktanÄ±n bileÅŸenleri daha fazladÄ±r Ã¶rneÄŸin 2 boyutlu embeddingde bir input deÄŸerimizi x1,x2 ile tanÄ±mlayabiliyorken 3 boyutlu embeddingde bu x1,x2,x3 olacaktÄ±r.)Embeddings: Translating to a Lower-Dimensional Space kÄ±smÄ±nda ise yukarÄ±da bahsettiÄŸim gibi yÃ¼ksek boyutlu verilerinizi daha dÃ¼ÅŸÃ¼k boyutlu bir alana eÅŸleyerek sparsity sorunlarÄ±nÄ± Ã§Ã¶zebilirsiniz. Bu yeni oluÅŸacak dÃ¼zlemde artÄ±k bulunan noktalarÄ±mÄ±zÄ±n (eÄŸitim setimizden Ã¶rnekler Ã¶rneÄŸin film eÄŸitim setimizden Braveheart) birbirilerine olan uzaklÄ±klarÄ± baz alÄ±narak iÅŸlem yapÄ±lacaktÄ±r. Ã–rneÄŸin Silent Hill ve Star Wars filmlerinin birbirine bu dÃ¼zlemde yakÄ±n olmalarÄ±nÄ± beklemeyiz. Pozisyon, semantiÄŸe gÃ¶re verileri ayÄ±rabilir. Bu semantik ayÄ±rmasÄ± da makine Ã¶ÄŸrenmesi algoritmamÄ±zÄ±n Ã¶ÄŸrenmeye yararÄ± bÃ¼yÃ¼k olan belli patternleri de tespit etmesine yardÄ±mcÄ± olur. YalnÄ±z burada dimension sayÄ±sÄ±na dikkat etmemiz lazÄ±m ne Ã§ok bÃ¼yÃ¼k ne de Ã§ok az olmalÄ±. Ã‡ok bÃ¼yÃ¼k olmasÄ± Ã¶ÄŸrenmeyi daha da iyileÅŸitirirken sÃ¼reden ve kaynaktan gÃ¶tÃ¼rÃ¼r, Ã‡ok kÃ¼Ã§Ã¼k olmaÄ±s ise hÄ±zÄ± arttÄ±rÄ±r ama eÄŸitim tam anlamÄ±yla performanslÄ± olmaz. Her bir embedding aslÄ±nda iÃ§indeki deÄŸerlerin vektÃ¶r hallerini kapsar. Ã–rneÄŸin 2 boyutlu dÃ¼zlemimizde spider man filmi bizim film listemizde 2.sÄ±radaysa ve bizim 9999 filmimiz varsa [[0.2,1.2],[1.3,4],,....[-17,17.6] olacaktÄ±r. (Spider-man [1.3,4] noktasÄ±ndadÄ±r. Elinizde birden fazla film iÃ§eren bir sprase vektÃ¶r varsa buradaki 1 olan deÄŸerlerin hepsi iÃ§in ayrÄ± ayrÄ± embedding alÄ±p bunlarÄ± toplayabilirsiniz.EÄŸer yanlÄ±ÅŸÄ±m varsa dÃ¼zeltilmesinden memnun olurum.Ä°yi Ã§alÄ±ÅŸmalar dilerim.4 weeks ago 15 people like this.Like ReportReply",
2.  AyrÄ±ntÄ±lÄ± ve anlaÅŸÄ±lÄ±r bir aÃ§Ä±klama olmuÅŸ . Ã‡ok TeÅŸekkÃ¼r ederim , iyi Ã§alÄ±ÅŸmalar dilerim4,

###Â soru 

> quest "Merhaba arkadaÅŸlar, sizin iÃ§inde faydalÄ± olacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼ndÃ¼yÃ¼m makaleyi paylaÅŸÄ±yorum. Ä°yi okumalar ğŸ™‚  [Link](https://hackernoon.com/memorizing-is-not-learning-6-tricks-to-prevent-overfitting-in-machine-learning-820b091dc42)

> comments: 


### soru 

> quest "Merhaba, Embedding'i tam olarak oturmadÄ±. YardÄ±mcÄ± olabilir misiniz?",

> comments: 

1. Evet beni de Ã§ok zorladÄ±. Bu konuda biraz aÃ§Ä±klama yapÄ±lÄ±rsa memnun olurum.",
2.  1xN bir sparse vector'Ã¼ NxM bir embedding table ile Ã§arpÄ±p 1xM dense vector elde ederiz diyor ama bu embedding table'Ä±n dnn'de nasÄ±l hesaplandÄ±ÄŸÄ±nÄ± anlayamadÄ±m.",
3.  Embedding konusunu ben de anlayamadÄ±m. FarklÄ± kaynaklardan yararlanmamÄ±z gerekecek.",
4.  Embeddings temelde bir kategorik deÄŸiÅŸkenin mappingini ifade ediyor. AslÄ±nda olay manaya matematik katabilmek. Ã–rneÄŸin; King - Man + Women = Queen demek gibi aslÄ±nda. Bu yÃ¶ntemi One-hot encode vs ile yaparsam anlam iÅŸin iÃ§inde olmuyor. Ben basitÃ§e bÃ¶yle anladÄ±m. YanlÄ±ÅŸ anladÄ±ysam dÃ¼zeltirseniz sevinirim.4,
5.  Merhaba, embedding veya gÃ¶mme iÅŸlemini yapay sinir aÄŸlarÄ±nda Ã¼Ã§ temel iÅŸ iÃ§in kullanÄ±yoruz. Bunlar;1- \"Embedding space\" dediÄŸimiz bu dÃ¼zlemde en yakÄ±n komÅŸuyu bulup, \"Ã¶neri\" sistemlerinin daha efektif Ã§alÄ±ÅŸmasÄ±nÄ± saÄŸlayabilmek.2- denetimli Ã¶ÄŸrenimde bir girdi olarak kullanabilme.3- Kategoriler arasÄ±ndaki iliÅŸkileri ve konseptleri gÃ¶rselleÅŸtirebilme.Neden one-hot encoding kullanmÄ±yoruz sorusunun da iki temel cevabÄ± var ;1-YÃ¼ksek kardinalite deÄŸiÅŸkenleri iÃ§in (birÃ§ok benzersiz kategoriye sahip olanlar) one-hot vektÃ¶rÃ¼n boyutlarÄ± yÃ¶netilemez hale gelir.2- One-hot encoding'te, gÃ¶mme kategorilerinde olduÄŸu gibi birbirine yakÄ±n deÄŸerler, yakÄ±n yerlere yerleÅŸmiyor.Temel mantÄ±ÄŸÄ± bu, ileri okuma iÃ§in bakabilirsiniz. [Neural Network Embeddings](https://towardsdatascience.com/neural-network-embeddings-explained-4d028e6f0526)
6.  YorumlarÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederim. OlayÄ±n mantÄ±ÄŸÄ±nÄ± bir nebze kavradÄ±m. Bu iÅŸlemin nasÄ±l yapÄ±ldÄ±ÄŸÄ±nÄ± araÅŸtÄ±rdÄ±ÄŸÄ±mda iÅŸin iÃ§ine co-occurence, co-variance gibi matrixler girdi ve sanÄ±rÄ±m bir de prediction yoluyla(ki kursta bu yol anlatÄ±lÄ±yor sanÄ±rÄ±m) hesaplama yapÄ±lÄ±yor ben bu iÅŸlemi anlayamadÄ±m.",

### soru 

> quest "Neural Networks bolumu, playground exercise, Task 3 yanitinda gecen su ifade ile ilgili: \"3 neurons are enough because the XOR function can be expressed as a combination of 3 half-planes (ReLU activation).\" Ornegin bu task'da tek hidden layer'da filtreler gorsellestirilmis. her bir filtre gorunumu, ogrenilen weigth'ler kullanilarak b+w1*x1+w2*x2 linear kombinasyonu hesaplandiginda elde edilen ciktiya ReLu uygulandiginda elde edilen goruntu, degil mi? Burada bahsedilen XOR islemi nedir? Neden XOR anlamadim, bilginiz var mi?  Ikinci olarak, Task 4 yanitinda: \"A single hidden layer with 3 neurons can model the data, but there is no redundancy, so on many runs it will effectively lose a neuron and not learn a good model. A single layer with more than 3 neurons has more redundancy, and thus is more likely to converge to a good model.\" neden pek cok run yapildiginda bazi neuron'lar silinsin (regularization kullanmiyorum) ? neuron sayisinda redundancy olmasi istenen birsey mi? optimal neuran ve hidden layer sayisina nasil karar verecegiz?  Cok tesekkur ederim. ",

> comments: 

1.  XOR iÅŸlemi doÄŸrusal olmayan bir iÅŸlemdir. AND,OR iÅŸlemleri doÄŸrusal iÅŸlemlerdir. XOR iÅŸleminde 1,0=0 0,1=0 1,1=1 0,0=1 deÄŸerleri vardÄ±r. BunlarÄ± grafiÄŸe dÃ¶ktÃ¼ÄŸÃ¼mÃ¼z zaman iki sÄ±nÄ±fa ayÄ±rmak iÃ§in linear bir Ã§izgi Ã§izemiyoruz. Yani bu problem linear bir modelle Ã§Ã¶zÃ¼lemez. DoÄŸrusal bir model inÅŸa ederek bu problem Ã§Ã¶zÃ¼lebilir. Bu yÃ¼zden gizli katmanlara gelen linear giriÅŸleri doÄŸrusal olmayan Ã§Ä±kÄ±ÅŸa dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in aktivasyon fonksiyonlarÄ±(ReLu gibi) kullanÄ±lÄ±r. Bu sayede verinin doÄŸrusal olmayan Ã¶zelliklerini Ã¶ÄŸrenmiÅŸ olur.",
2. ->  DoÄŸrusal 'olmayan' bir model inÅŸa ederek bu problem Ã§Ã¶zÃ¼lebilir. mi olucak? fakat relu islemi ile XOR islemi ayni sey degil. ReLu ile surece nonlinear'lik katildigini anliyorum. XOR'un buradaki fonksyonu nedir? lineer combination yerine XOR ile mi onceki layer'in ciktilari birlestirilip sonraki layer'a iletiliyor?",
"3. -> -> eÄŸer simulator'Ä± Ã§alÄ±ÅŸtÄ±rmadan datanÄ±n daÄŸÄ±lÄ±mÄ±na bakarsan, noise 0 iken daha da net gÃ¶zÃ¼kÃ¼yor, sorun aslÄ±nda bu datanÄ±n daÄŸÄ±lÄ±mÄ±nÄ±n bir XOR problemi olmasÄ±. XOR linear olmadÄ±ÄŸÄ± iÃ§in onun nonlinear bir biÃ§imde modellenmesi gerekiyor. Senin de dediÄŸin gibi ReLU modele nonlinearity katmak iÃ§in kullanÄ±lÄ±yor. Zaten senin soru iÃ§inde paylaÅŸtÄ±ÄŸÄ±n ingilizce textte de bundan bahsedilmiÅŸ. XOR fonksiyonu ReLU aktivasyonu olarak ifade edilebilir diyor. Tekrar Ã¶zetlemek gerekirse linear olan layerlardan, XOR fonksiyonunu temsil edebilecek nonlinear bir network oluÅŸturabilmek iÃ§in ReLU aktivasyonu kullanÄ±lÄ±yor.",
4.  XOR sadece non-lineariteyi anlatmak icin kullaniliyor.Grafikte degerleri yerine koyup tek bir dogruyla iki farkli data grubunu ayiramadigini goruyorsun.Non lineariteyi perceptronla cozemeyecegini acikliyor. Ve artik non_linear olan problemini neural network olusturarak cozuyorsun.",
5. ->  siz ne dusunuyorsunuz?",
6. -> Merhaba,Burada her hidden layer kendisinden Ã¶nceki layerdaki nodelarÄ± daha da komplike ve nonlineer hale getirir. Yani 1 hidden layerÄ±mÄ±z var ise kendisinden Ã¶nceki input layer'Ä±ndaki nodelarÄ± (bu nodelar bizim feature deÄŸerlerimiz olur. Bu feature deÄŸerleri ile birlikte weight deÄŸerleri olur.) Burada bizim fonksiyon eÅŸleÅŸmesini (nodelarÄ±n her biri bir fonksiyon olduÄŸu iÃ§in aslÄ±nda node eÅŸleÅŸmesi) kontrol eden weight matrisleri olur. Bu matirsleri feature deÄŸerlerimizle Ã§arptÄ±ÄŸÄ±mÄ±zda o layer iÃ§in ilgili node Ã§Ä±ktÄ±larÄ±nÄ± elde ederiz. (Resim ile ekledim.) Burada bu lineer baÄŸÄ±ntÄ±larda aslÄ±nda sigmoidi alÄ±nmÄ±ÅŸ bir fonksiyonun tekrar sigmoidi alÄ±ndÄ±ÄŸÄ±nda daha komplike bir fonksioyon elde edeceÄŸimiz gÃ¶rÃ¼lebilir. (Ã–rneÄŸin a1,a2,a3 sigmoid bir fonksiyondur. h(x) fonksiyonunda ise bu sigmoid fonksiyonlarÄ±n direk olarak olmasa da tekrar sigmoidlerinin alÄ±ndÄ±ÄŸÄ± gÃ¶rÃ¼lebilir.)XOR olmasÄ±nÄ± sebebi aslÄ±nda ÅŸu, XOR'un bizim dÃ¼zlemimizi ayÄ±rÄ±ÅŸ ÅŸekli bizim problemimize uyuyor bu yÃ¼zden de Ã§Ã¶zÃ¼mÃ¼mÃ¼zÃ¼ XOR'a gÃ¶re uyarlamak istedik. Burada AND yÃ¶ntemiyle Ã§Ã¶zebileceÄŸimzi bir problem olsaydÄ± nÃ¶ronlarÄ±mÄ±zÄ± AND problemini implemente edebilecek ÅŸekilde tanÄ±mlayacaktÄ±k. Bunu yapmanÄ±n bir yolu ise tek hidden layerda 3 nÃ¶ron kullanmaktÄ±. Bu nÃ¶ronlardan her biri aynÄ± Ã§Ä±ktÄ±yÄ± Ã¼retmez bunun sebebi ilgili weight matrixleri ve ilgili nÃ¶ronun feature deÄŸerinin Ã§arpÄ±mlarÄ±dÄ±r. (Resmdeki denklemde theta2n 2.nÃ¶rÃ¼n iÃ§in, theta3n(n burada herhaangi bir sayÄ±) 3.nÃ¶ron iÃ§in iÅŸleme sokulacak weight deÄŸeridir.)2. ÅŸÄ±k iÃ§in ise ÅŸunu sÃ¶yleyebilrim. NÃ¶ronlarÄ±nÄ±z ve layerlarÄ±nÄ±z arttÄ±ÄŸÄ±nda kompleksiteniz artar ve modeliniz Ã§ÄŸrenmekten Ã§ok ezber yapar yani overfit olur.Burada 3 nÃ¶ronun problemi Ã§Ã¶zmeye eyetebileceÄŸini, fazlasÄ±nÄ±n overfittinge yol aÃ§arak fazlalÄ±k oalcaÄŸÄ±nÄ± sÃ¶ylemek istemiÅŸ.Problemlerin bÃ¼yÃ¼k Ã§oÄŸunluÄŸu tek katman kullanÄ±larak yapÄ±labilir ama modelinizin loss deÄŸeri tek katmanla azalmÄ±yorsa daha komplike bir yapÄ±ya yani ekstra bir layera ihtiyacÄ±nÄ±z vardÄ±r. NÃ¶ron sayÄ±sÄ± ise genelde input ve output nÃ¶ron adetleri arasÄ±nda olur. Bu nÃ¶ron ve layer deÄŸerlerini bir anda kafamÄ±zdan belirleyemeyiz problemimizin kompleksitesine gÃ¶re problemimizi bazÄ± metriklerle analiz edip bu analizlere gÃ¶re layer ve nÃ¶ron deÄŸerlerimizi belirleyebilriz ama belirlerken yukarÄ±da sÃ¶ylediÄŸim kÄ±sÄ±mlara dikkat etmeliyiz.Kaynak: [Link](https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw) AnlamadÄ±ÄŸÄ±nÄ±z bir yer olursa sorabilirsiniz.Ä°yi Ã§alÄ±ÅŸmalar.",

### soru 
 
> quest "Merhaba, hangi durumlarda L1, ve hangi durumlarda L2 regularization sececegimizin bir kurali var mi? Feature dimension cok buyukse her zaman L1 regularization mi seciyoruz?",

> comments: 

1.  Benim fikrime gÃ¶re hayÄ±r herhangi bir kural yok. L1 ve L2 modelden modele farklÄ± sonuÃ§lar sergileyebilir. Her ikisinide deneyip optimum sonuca ulaÅŸÄ±labilir diye dÃ¼ÅŸÃ¼nÃ¼yorum. Burada bizim hedeflerimizde Ã¶nemli, Ã¶rneÄŸin hesaplama aÃ§Ä±sÄ±nda RAM kullanÄ±mÄ± fazla olmayacak bir model hedefliyorsak elbette L1 daha uygun bir seÃ§enek olacaktÄ±r.",
2. ->  tesekkurler.",

### soru

> quest "Merhabalar, bu haftaya tamamlarken tam olarak hidden layer in modellerimize eklendiÄŸinde ne iÅŸe yaradÄ±ÄŸÄ±nÄ± kavrayamadÄ±m. Ben modele hangi durumda hidden  layer ekliyorum? Hangi durumlarda hidden layer lara  neuron ekliyorum? TeÅŸekkÃ¼rler ÅŸimdiden",

> comments: 

1. Merhaba,SÄ±nÄ±flandÄ±rma problemlerimizde lineerlik kullanamÄ±yoruz bunun nedenini Modelimizin inputlarÄ±nÄ± nonlineer olarak hesaplamak iÃ§in [Link](https://medium.com/@ftfethi/makine-%C3%B6%C4%9Frenmesinde-s%C4%B1n%C4%B1fland%C4%B1rma-problemlerine-neden-lineer-regresyon-i%CC%87le-yakla%C5%9Fm%C4%B1yoruz-5ede1e3b12d4) yazÄ±mda anlatmaya Ã§alÄ±ÅŸtÄ±m. Bu yÃ¼zden nonlineer yÃ¶ntemlere baÅŸvurmak zorundayÄ±z. Modelimiz Ã§ok karmaÅŸÄ±k nonlineeritelik iÃ§erebilir. Bunun iÃ§in neural networklere baÅŸvururuz. Neural networklerin amacÄ± InputlarÄ±mÄ±zÄ± karmaÅŸÄ±k nonlineer hale getirerek belli nonlineer problemleri Ã§Ã¶zebilmek. Input ve output arasÄ±na lineeritemizi nonlineer yapacak hidden layerlar ekliyoruz.(nerual networkte input ve output layerlarÄ± dÄ±ÅŸÄ±ndaki her layer hidden layerdÄ±r). Bu hidden layer'da nÃ¶ronlar bulunur ve bu nÃ¶ronlar farklÄ± nonlineer iÅŸlemler yapabilirler (ReLU, Sigmod vs) NÃ¶ronlarÄ±mÄ±zÄ±n artmasÄ± ilgili layerdan Ã¶nceli layerdaki nÃ¶ronlarÄ±n bilgilerinin daha komplike bir ÅŸekilde yorumlanmasÄ±na neden olur, fazladan hidden layer eklersek de modelimizin karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± arttÄ±rmÄ±ÅŸ oluruz. Yani modelimizin karmaÅŸÄ±klÄ±ÄŸÄ± o problemi Ã§Ã¶zmeye yetmiyorsa neuron ve hidden layer eklemeyi dÃ¼ÅŸÃ¼nebiliriz. Resimde hidden layer ve nÃ¶ronu anlatmaya Ã§alÄ±ÅŸtÄ±m.Ä°yi Ã§alÄ±ÅŸmalar.",
"Makine Ã–ÄŸrenmesinde SÄ±nÄ±flandÄ±rma Problemlerine Neden Lineer Regresyon Ä°le YaklaÅŸmÄ±yoruz?medium.comMerhabalar, Malum bu sÄ±ralar Covid-19 yÃ¼zÃ¼nden evdeyiz. Ben de kendimi nasÄ±l geliÅŸtirebilirim diye dÃ¼ÅŸÃ¼nmeye baÅŸladÄ±ÄŸÄ±mda senelerdirâ€¦4,
2.  Hidden layerlar modelin daha kompleks featurelarÄ± Ã¶ÄŸrenmesine yardÄ±mcÄ± olur. Normal bir XOR datasÄ±nÄ± Ã¶ÄŸrenirken 1 tane hidden layer iÅŸ gÃ¶recektir. Ama modele Ã¶ÄŸretmeye Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z veri seti daha karmaÅŸÄ±ksa ([Link](https://developers.google.com/machine-learning/crash-course/introduction-to-neural-networks/playground-exercises) buradaki spiral data gibi) 1 hidden layer Ã¶ÄŸrenmeye yeterli olmayacaktÄ±r. Daha kompleks Ã¶zellikler Ã¶ÄŸrenmek iÃ§in daha derin nÃ¶ron katmanlarÄ± gerekiyor kÄ±saca.Ama gereÄŸinden fazla hidden layer kullanÄ±rsak ve/veya hidden layerlara gereÄŸinden fazla node eklersek de modelimiz veri setine overfit olacaktÄ±r. O yÃ¼zden veriyi inceleyerek gerekli sayÄ±daki hidden layer-node ayarÄ±nÄ± tutturmak gerekiyor. (az kullanÄ±p underfit kalmamak ve Ã§ok kullanÄ±p overfit olmamak iÃ§in)",
3.  Hidden layer Ä±n amacÄ± verideki Ã¶nemli Ã¶zellikleri ortaya Ã§Ä±karmaktÄ±r. Ã–rneÄŸin bir kÃ¶pek resmimiz olsun. Modelimizde sadece bir gizli katman varsa modelimiz Ã¶ÄŸrenemez. 50 tane gizli katman olursa kÃ¶peÄŸin burnunu,kuyruÄŸunu,gÃ¶zÃ¼nÃ¼,gÃ¶vdesini vb. Ã¶zelliklerini Ã¶ÄŸrenir. Gizli katmanlara aktivasyon fonkisyonlarÄ± uygulanarak doÄŸrusal gelen giriÅŸleri doÄŸrusal olmayan Ã§Ä±kÄ±ÅŸlara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.4 weeks ago 4 people like this.Like ReportReply",
4.   ->  teÅŸekkÃ¼r ederim",
5.   ->  ->  ->  aÃ§Ä±klamalar iÃ§in Ã§ok teÅŸekkÃ¼r ederim ÅŸimdi daha iyi anladÄ±m",

### soru 

> quest "Merhaba, Accuracy icin derste sorulan su soruyu anlamadim: In which of the following scenarios would a high accuracy value suggest that the ML model is doing a good job?  Neden asagidaki secenek dogru? In the game of roulette, a ball is dropped on a spinning wheel and eventually lands in one of 38 slots. Using visual features (the spin of the ball, the position of the wheel when the ball was dropped, the height of the ball over the wheel), an ML model can predict the slot that the ball will land in with an accuracy of 4%.",

> comments: 

1.  Merhaba,--> Hangi senaryoda saÄŸlanmÄ±ÅŸ olan yÃ¼ksek accuracy(doÄŸruluk) deÄŸeri, modelimizin iyi bir iÅŸ Ã§Ä±kardÄ±ÄŸÄ±nÄ± gÃ¶sterir?DoÄŸru olan seÃ§enek: Rulet oyunu Ã¶rnek olarak verilmiÅŸ, ortada dÃ¶nmekte olan bir bir tekerliÄŸin iÃ§erisine bÄ±rakÄ±lan bir topun 38 hazneden birine dÃ¼ÅŸmesidir. GÃ¶rsel Ã¶zelliklerin kullanÄ±lmasÄ± ile bir ML modelinin %4 lÃ¼k bir accuracy ile topun nereye dÃ¼ÅŸeceÄŸini tahmin edebilmektedir.Sebebi ise normal de herhangi bir iÅŸlem yapÄ±lmaksÄ±zÄ±n bir tahmin yapacak olsak doÄŸru olarak tahmin etme oranÄ±mÄ±z: 1/38 olacak ki bu da yaklaÅŸÄ±k 2.63% deÄŸerine kaÅŸÄ±lÄ±k gelmektedir. ML %4 'lÃ¼k bir oran ile herhangi bir iÅŸlem yapÄ±lmaksÄ±zÄ±n yapÄ±lacak olan bir tahminden daha iyi sonuÃ§ vermektedir.. Burada 2.63% deÄŸerinden daha bÃ¼yÃ¼k oranlara sahip olan her ML modeli iÃ§in iyi bir iÅŸ Ã§Ä±karmÄ±ÅŸtÄ±r diyebiliriz.Ä°yi Ã§alÄ±ÅŸmalar.4 weeks ago 5 people like this.Like ReportReply",
2. Merhaba,Burada Ã¶ncelikle neden %99.99 accuracy oranÄ± olan modelimizin her zaman iyi bir iÅŸ yapamayacaÄŸÄ±nÄ± aÃ§Ä±klamaya Ã§alÄ±ÅŸalÄ±m. Siz hastalÄ±klarÄ±n %99.99'unu iyi tahmin edebilen bir modele sahipsiniz fakat belki modeliniz bÃ¼tÃ¼n hastalÄ±k ihtimallerini hasta deÄŸil olarak tahmin ettiÄŸinde de %99.99luk bir accuracy baÅŸarÄ±sÄ± elde edeceksiniz.Buradaki mantÄ±k [Link](https://community.globalaihub.com/?status/1133-1133-1587498846/ linkindeki soru altÄ±nda konuÅŸuldu.Burada eÄŸer hasta olan birine modelimiz hasta deÄŸil derse (%99.99 accuracy oranlÄ± hep hasta deÄŸil tahmini yapan modelimiz var.) hasta Ã¶lecektir.Rulet oyununda ise bir topun bir slota gelme oranÄ± %2.6'dir. Yani accuracy deÄŸerimiz %2.6'dir. Bu baÄŸlamda bir tahminin gerÃ§ekleÅŸme oranÄ± her seferinde 1/38'dir. Ancak burada modelimizin accuracy'si %4 olduÄŸu iÃ§in ve beklediÄŸimiz acuracy'den(%2.6) daha bÃ¼yÃ¼k bir tahmin accuracy'sine sahip olduÄŸu iÃ§in modelin doÄŸruluÄŸu \"sadece\"% 4 olmasÄ±na raÄŸmen, baÅŸarÄ±nÄ±n faydalarÄ± baÅŸarÄ±sÄ±zlÄ±ÄŸÄ±n dezavantajlarÄ±ndan Ã§ok daha aÄŸÄ±r basacaktÄ±r.Ä°yi Ã§alÄ±ÅŸmalar.Community",

### soru 

> quest "Merhabalar Precision ile Recall arasÄ±nda tam olarak fark nedir ?  TeÅŸekkÃ¼rler",

> comments: 

1.  Merhaba,[Link](https://community.globalaihub.com/?status/1482-1482-1587492075/#comment.4714.4568.4568) linkinde bunu aÃ§Ä±klamaya Ã§alÄ±ÅŸtÄ±m. Sorunuz olursa yanÄ±tlamaktan memnuniyet duyarÄ±m.Ä°yi Ã§alÄ±ÅŸmalar.Community4,

### soru 

> quest "Merhabalar,   - Ä°lk sorum neden test ve eÄŸitim setlerini neden ayÄ±rmÄ±ÅŸtÄ±k x ve y olarak yani 4 deÄŸiÅŸkene...    - Bir diÄŸer sorum da Flatten ve Dense layerler arasÄ±ndaki fark nedir?  (Resimler ektedir.)  Åimdiden teÅŸekkÃ¼rler! ğŸ™‚",

> comments: 

1.  GÃ¼naydÄ±n,ilk soru ile baÅŸlayayÄ±m. Verimizi ilk gÃ¶rselde 2 grup olarak DÃœÅÃœNÃœYORUZ aslÄ±nda.Train ve test seti. Oradaki kodda MNIST setini yÃ¼klerken bize 4 adet array dÃ¶nÃ¼yor; 1-)Train verisetinin Ã¶rnekleri (Example) yani x_train deÄŸiÅŸkeni , 2-)Train setinin etiketleri (labels yani ne olduklarÄ± kedi kÃ¶pek vs.) yani x_test deÄŸiÅŸkeni 3-)Test setinin Ã¶rnekleri (Predict edilmesini istediÄŸimiz Ã¶rnekler) 4-)Test setinin etiketleri (labels-yani predict/true deÄŸerlerin kontrolÃ¼ iÃ§in kullanÄ±lacak liste) y_test. Modelin eÄŸitimi ve deÄŸerlendirilmesi iÃ§in gerekli veriler ayrÄ±lmÄ±ÅŸ kÄ±saca ğŸ™‚",
2.  Ä°kinci soru iÃ§in; Gizli Katman (Hidden Layer) dediÄŸimiz yapÄ±nÄ±n tf.keras modÃ¼lÃ¼ndeki adÄ± Dense.Modelimize bir katman eklemek iÃ§in Dense modÃ¼lÃ¼nÃ¼ Ã§aÄŸÄ±rÄ±yoruz.Zaten aldÄ±ÄŸÄ± parametrelerden de anlaÅŸÄ±labiliyor. Flatten ise , N-boyutlu olarak gelen matrisin tek boyuta indirgeyerek (Height * Weight) tek boyutlu bir vektÃ¶r matrise Ã§evrilmesini saÄŸlar.Åu linkten ([Link](https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-step-3-flattening) nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± inceleyebilirsin.",
3. Ã‡ok teÅŸekkÃ¼r ederim",

### soru 

> quest "Herkese merhabalar,  Playground Exercises : A First Neural Network : Task 3 cevabÄ± olarak verilmiÅŸ aÅŸaÄŸÄ±daki ifadenin ne anlatmak istediÄŸini tam olarak anlayamadÄ±m. YardÄ±mcÄ± olursanÄ±z sevinirim. TeÅŸekkÃ¼rler. :) \"3 neurons are enough because the XOR function can be expressed as a combination of 3 half-planes (ReLU activation). You can see this from looking at the neuron images, which show the output of the individual neurons. In a good model with 3 neurons and ReLU activation, there will be 1 image with an almost vertical line, detecting X1 being positive (or negative; the sign may be switched), 1 image with an almost horizontal line, detecting the sign of X2, and 1 image with a diagonal line, detecting their interaction.\"",

> comments: 

1. Merhaba,Burada modelimizin nonlinear fonksiyonunu ReLU ve 3 nÃ¶ronlu tek bir hidden layer ile oluÅŸturabileceÄŸimizi ama loss aÃ§Ä±sÄ±ndan efektif olmayacaÄŸÄ±nÄ± sÃ¶ylemiÅŸ. Hidden Layer'Ä±mÄ±zÄ±n XOR fonksiyonunu ifade etmek istemesinin sebebi lineer fonksiyonumuzu bu sayede daha karmaÅŸÄ±k nonlinear bir yapÄ±ya Ã§evirmek. (XOR Ã§Ã¶zÃ¼mÃ¼nÃ¼ kullanarak yapmÄ±ÅŸ. Burada her mantÄ±ksal operatÃ¶r farklÄ± Ã§Ä±ktÄ±lar Ã¼retir Ã¶rneÄŸin AND, NAND, XOR gibi operatÃ¶rler. Burada bu problemin tanÄ±mÄ±na uyan operatÃ¶rÃ¼mÃ¼z ise XOR poeratÃ¶rÃ¼dÃ¼r ve 3 yarÄ± dÃ¼zlem ÅŸeklinde (her nÃ¶ron bir yarÄ± dÃ¼zlemi ifade eder.Her bir nÃ¶ronumuz farklÄ± bir fonksiyondur ve farklÄ± bir iÅŸ yapar.Hidden layerdaki ilk nÃ¶ronumuz x1 input'unun pozitif veya negatif olduÄŸunu algÄ±layan, neredeyse dikey bir Ã§izgiyi output olarak verir.Hidden layerdaki 2. nÃ¶ronumuz x2 inputunun pozitif veya negatif olduÄŸunu algÄ±layan neredeyse yatay bir Ã§izgiyi output olarak verir.Hidden layerdaki 3.nÃ¶ron ise bu iki inputun etkileÅŸimlerini algÄ±layan Ã§apraz bir Ã§izgi dÃ¶ndÃ¼rÃ¼r. Bu 3 nÃ¶ron output'u ise bizim output layer'ImÄ±za gÃ¶nderilir. Modelimizde loss oranÄ± optimum yakÄ±nsamayacaktÄ±r Ã§Ã¼nkÃ¼ daha Ã§ok nonlinearity iÃ§eren bir problemle karÅŸÄ± karÅŸÄ±yayÄ±z.Ä°yi Ã§alÄ±ÅŸmalar.4 weeks ago 8 people like this.Like ReportReply",
2.  ->  TeÅŸekkÃ¼r ederim.",

###Â soru 

> quest "Merhabalar, Neural Networks kÄ±smÄ±ndaki hem Playground hem de Programming egzersizlerinden sonra sormak istediÄŸim problem iÃ§in hidden layer sayÄ±sÄ± ve bu layer'lardaki nÃ¶ron sayÄ±sÄ± deneme yanÄ±malar sonucu mu saptanabilir ? Tabi ki overfitting ile karÅŸÄ±laÅŸmamak iÃ§in Ã§ok kompleks modeller tercih etmeyebiliriz ama daha iyi test loss yaratan kombinasyonu bulmak iÃ§in deneme-yanÄ±lma mÄ± yapÄ±lmalÄ± ? Ã‡ok teÅŸekkÃ¼rler.",

> comments: 

1.  Malesef kitapta yazÄ±lÄ± olan bir kuralÄ± yoktur bu iÅŸin,gÃ¼zel yanÄ± da o zaten.AraÅŸtÄ±rmalarÄ±n amacÄ± aslÄ±nda dediÄŸiniz konuda bir yol oluÅŸturmak ancak,dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼mÃ¼z zaman 'overfitting','underfitting','gradient vanish' vs gibi durumlarÄ±n hepsi araÅŸtÄ±rmalar yani deneme yanÄ±lmalar sonrasÄ±nda bulunmuÅŸtur.Ã–rneÄŸin Programming Exercise kÄ±smÄ±ndaki eÄŸitim sÃ¼reci 2-3 dakika bile sÃ¼rmÃ¼yorken,daha yÃ¼ksek Ã§Ã¶zÃ¼nÃ¼rlÃ¼k ve Ã¶zellikli (RGB-dimensions) gÃ¶rÃ¼ntÃ¼lerde,donanÄ±m gÃ¼cÃ¼ne ve veriseti boyutuna gÃ¶re saatlerce hatta gÃ¼nlerce sÃ¼ren eÄŸitim sÃ¼reÃ§leri vardÄ±r.Bu gibi durumlarda, deneme-yanÄ±lma aÅŸÄ±rÄ± verimsiz bir yÃ¶ntem olur. Åahsen en mantÄ±klÄ±sÄ±, benzer problemler Ã¼zerinde Ã§alÄ±ÅŸÄ±lmÄ±ÅŸ Ã§alÄ±ÅŸmalarÄ± inceleyerek,kendi yol haritanÄ±zÄ± Ã§Ä±karmanÄ±zdÄ±r.4 weeks ago 5 people like this.Like ReportReply",
2.  Gizli katman sayÄ±sÄ±, neuron sayÄ±sÄ± ve Ã¶ÄŸrenme katsayÄ±sÄ± gibi bÃ¼tÃ¼n hiper parametreler denem yanÄ±lma yÃ¶ntemiyle optimum seviyeye Ã§Ä±karÄ±lÄ±r. Zaten \"tuning\" ile kastettiÄŸimiz de bir nevi deneme yanÄ±lmadÄ±r. Fakat bu tuning iÅŸlemini daha organize ve sistematik bir hale getirmek iÃ§in Ã§eÅŸitli yÃ¶ntemler mevcut. (bkz. Grid Search) Bununla birlikte daha Ã§ok model geliÅŸtirerek tecrÃ¼be edindiÄŸinizde, yeni bir model oluÅŸtuturken nasÄ±l hiper parametreler seÃ§meniz gerektiÄŸine dair zihninizde bir takÄ±m sezgiler oluÅŸacaktÄ±r, bu da tuning kÄ±smÄ±nÄ± hÄ±zlandÄ±racaktÄ±r.",

### soru 

> quest "Merhabalar,   Regularization: Sparsity konusunda L0 regularization'Ä±n tam olarak ne yaptÄ±ÄŸÄ±nÄ± ve neden kullanamadÄ±ÄŸÄ±mÄ±zÄ± anlayamadÄ±m. YardÄ±mcÄ± olabilir misiniz?   Åimdiden teÅŸekkÃ¼rler.",

> comments: 

1.  L0, L1'in daha ilkel hali olarak dÃ¼ÅŸÃ¼nebiliriz. L0 modelimizde sÄ±fÄ±r olmayan weightleri sÃ¼rekli sayÄ±yor ve bunlarÄ± bir ÅŸekilde sÄ±fÄ±rlamaya Ã§alÄ±ÅŸÄ±yor. Bu tarzda bir metod ancak modelimizde belli bir kazanÃ§ varsa, iyi fit ediyorsa, mantÄ±klÄ± olabilir. Fakat sezgisel olarak mantÄ±klÄ± gÃ¶rÃ¼nen bu durum, pratikte modelimizi dÄ±ÅŸ bÃ¼key olmayan (non-convex) bir hale sokuyor ve dÄ±ÅŸ bÃ¼key olmayan modelleri optimize etmek diÄŸerlerine oranla daha zor. Ã‡Ã¼nkÃ¼ maliyet fonksiyonunda global minimum noktayÄ± bulmak zorlaÅŸÄ±yor, bunun yerine modelimiz yerel minimum noktaya yakÄ±nsayabiliyor. Bu sebeble L0'a nispeten yakÄ±n bir metod olan L1'Ä± kullanmak daha mantÄ±klÄ±. L1 her gÃ¶rdÃ¼ÄŸÃ¼ weighti sÄ±fÄ±rlamaya Ã§alÄ±ÅŸmak yerine bilgi Ã§ekemediÄŸi weightleri sÄ±fÄ±rlÄ±yor.4 weeks ago 12 people like this.Like ReportReply",

### soru 

> quest "Merhaba,  \"Multi-Class Neural Networks: Softmax\" baÅŸlÄ±klÄ± konuda \"Softmax layer must have same number of nodes as output layer.\" ifadesi geÃ§iyor.  Burada softmax layer, output layer'Ä±n kendisi deÄŸil mi? Zaten resimde de ayrÄ± bir output layer gÃ¶sterimi yok, son layer olarak softmax Ã§izilmiÅŸ.  Neden bu ÅŸekilde ifade etmiÅŸ olabilirler?",

> comments: 

1.  Merhaba,Softmax layerÄ±mÄ±z tipik olarak son layerÄ±mÄ±zdÄ±r. Burada benim anladÄ±ÄŸÄ±m ÅŸey oluÅŸturacaÄŸÄ±mÄ±z ihtimaller dizisi(sÄ±nÄ±f diye geÃ§er) kadar (Kedi mi?HayÄ±r. - KÃ¶pek mi? Evet. -Yumurta mÄ±?HayÄ±r gibi) node a sahip olmalÄ± Ã§Ã¼nkÃ¼ her sÄ±nÄ±f iÃ§in bir deÄŸer hesaplamasÄ± yapÄ±yoruz. (Ã–rnekte 5 node var Ã§Ã¼nkÃ¼ 5 sÄ±nÄ±fÄ±mÄ±z var)Ä°yi Ã§alÄ±ÅŸmalar.4 weeks ago 4 people like this.Like ReportReply",
2. ->  AnladÄ±m. AyrÄ± bir output layer sÃ¶zkonusu deÄŸil. Ã–nceki Ã¶rneklerdeki output layer'a iÅŸaret etmiÅŸler muhtemelen. TeÅŸekkÃ¼rler.",
3.  Ornekle aciklayayim.Classification yapacagiz.Classes = {agac : 0, insan : 1, araba: 2} olsun.Yani 3 tane sinifimiz olsun.Son layer da 3 tane node a ihtiyacim var cunku 3 tane output var.Kac tane sinifin varsa son layerda o kadar node a ihtiyacin var.Cok cok yaygin olarak networkteki diger layerlarda RELU activation function kullanilip, son layer da Softmax kullaniliyor cunku Softmax bize probabilistic distrubition sagliyor.Boylece siniflandirma yapilmis oluyor.4 weeks ago 5 people like this.Like ReportReply",

### soru 

> quest "Merhabalar herkese,  Benim sorum multi-class neural networklerde candidate sampling ile softmax yapÄ±lmasÄ± Ã¼zerine olacak. AnladÄ±ÄŸÄ±m kadarÄ±yla Ã§ok fazla class Ä±n olduÄŸu bir classification probleminde tÃ¼m class lar iÃ§in softmax iÅŸlemi yapmak Ã§ok uzun sÃ¼rÃ¼yor ve computational cost yÃ¼ksek oluyor. Bunu Ã¶nlemek iÃ§in training esnasÄ±nda bir sample iÃ§in train ederken o sample a ait class Ä±n output nÃ¶ronunu ve random seÃ§tiÄŸimiz diÄŸer classlardan bazÄ± nÃ¶ronlarÄ± alarak softmax iÅŸlemi yapÄ±yoruz.  Burada random seÃ§tiÄŸimiz  classlarÄ±n  sayÄ±sÄ±nÄ± biz mi belirliyoruz, bu da bir hyper parametre midir?  TeÅŸekkÃ¼rler ğŸ™‚",

> comments: 
   
1.  Sizinde bahsettiÄŸiniz Ã¼zere, softmax, sÄ±nÄ±f sayÄ±sÄ± az olduÄŸunda oldukÃ§a maliyetsiz bir yÃ¶ntem, ancak sÄ±nÄ±f sayÄ±sÄ± arttÄ±kÃ§a aÅŸÄ±rÄ± derecede pahalÄ± hale gelebiliyor. Candidate Sampling eÄŸitim metodu, Ã§ok sayÄ±da sÄ±nÄ±fa sahip problemlerde verimliliÄŸi artÄ±rabilir. Candidate Sampling metodunda olasÄ±lÄ±klar pozitif etiketlerin hepsi iÃ§in hesaplanÄ±rken, negatif etiketlerden rastgele seÃ§ilenler iÃ§in hesaplanÄ±r. Ä°ncelediÄŸim dÃ¶kÃ¼manda (bkz. [Link](https://www.tensorflow.org/extras/candidate_sampling.pdf) bu sÄ±nÄ±flarÄ±n nasÄ±l belirlendiÄŸine dair Ã§eÅŸitli formÃ¼ller verilmiÅŸ. KÄ±saca sÄ±nÄ±flarÄ±n sayÄ±sÄ±nÄ± biz belirlemiyoruz, bunu algoritma toplam sÄ±nÄ±f sayÄ±sÄ±na gÃ¶re belirliyor. Bunun yanÄ±nda candidate sampling metodunu kullanan alt algoritmalar mevcut, bunlarÄ±n her birinde farklÄ± formÃ¼ller kullanÄ±lÄ±yor olabilir.[Link](https://www.tensorflow.org/extras/candidate_sampling.pdfwww.tensorflow.org[Link](https://www.tensorflow.org/extras/candidate_sampling.pdf) ",
2.  ->  BahsettiÄŸiniz dÃ¶kÃ¼manÄ± ben de incelemiÅŸtim ama orada class larÄ±n seÃ§ilme probabilitysi ile ilgili formÃ¼ller var, kaÃ§ adet seÃ§ildiÄŸine dair herhangi bir bilgi yok. Sizin gÃ¶rdÃ¼ÄŸÃ¼nÃ¼z bir kÄ±sÄ±m varsa paylaÅŸabilirseniz sevinirim. TeÅŸekkÃ¼rler.",
3.  ->  Net bir biÃ§imde belirtmemiÅŸ olsalarda kaÃ§ adet seÃ§ildiÄŸini bu formÃ¼lÃ¼n ifade ettiÄŸini dÃ¼ÅŸÃ¼nÃ¼yorum. (Ci = Ti â‹ƒ S) Burada Ci: Adaylar KÃ¼mesi (KÃ¼me elemanÄ± sayÄ±sÄ± kadar rastgele sÄ±nÄ±f seÃ§iliyor), Ti: Hedef SÄ±nÄ±flar, S: DiÄŸer SÄ±nÄ±flar olarak belirtilmiÅŸ. AnladÄ±ÄŸÄ±m kadarÄ± ile aÃ§Ä±klamaya Ã§alÄ±ÅŸtÄ±m, zira bende sizinle beraber Ã¶ÄŸreniyorum umarÄ±m yardÄ±mÄ± dokunmuÅŸtur, ben teÅŸekkÃ¼r ederim",
4.  ->  AnladÄ±m, benim gÃ¶zÃ¼mden kaÃ§an bir kÄ±sÄ±m olabilir, varsa paylaÅŸabilir misiniz anlamÄ±nda sordum. BahsettiÄŸiniz kÄ±sÄ±ma tekrar bakacaÄŸÄ±m. YardÄ±mlarÄ±nÄ±z iÃ§in Ã§ok teÅŸekkÃ¼rler. Ä°yi Ã§alÄ±ÅŸmalar ğŸ™‚",
5.  Normalde multi- class problemlerde modelimiz her mumkun sinifin olasiligini hesapliyor.Ancak candidate sampling sirasinda sadece iliskili olan siniflarin olasiligini hesaplayip karar veriyor.Bir ornek verecek olursak siniflarimiz agac, kalem, masa, kopek, kedi, kamyon ve tir olsun. Biz modelimize kamyon resmini verip siniflandirmasini istedigimizde ilgisiz siniflarin olasiligini hesaplamakla ugrasmayip kamyon ve tiri hesaplayacaktir.Hangi siniflarin gozonune alinacagina modelimiz karar verecek ve gozonune alacagi class sayisi classlarin birbiriyle icinde bulundugu yakinliga ve bizim modele neyi verdigimize gore degisir.",
6.  ->  PaylaÅŸÄ±m iÃ§in teÅŸekkÃ¼rler ğŸ™ Peki bahsettiÄŸiniz Ã¶rnekte tÄ±rÄ±n yanÄ±nda kÃ¶peÄŸi almamasÄ± gerektiÄŸine nasÄ±l karar veriyor, classlarÄ±n birbirine yakÄ±nlÄ±ÄŸÄ±nÄ± nasÄ±l hesaplÄ±yor ve thresholda nasÄ±l karar veriyor, neden kÃ¶peÄŸi de dahil etmiyor? Onun dÄ±ÅŸÄ±nda training iÅŸleminde ilk sample Ä± eÄŸittiÄŸini dÃ¼ÅŸÃ¼nÃ¼n, hiÃ§bir class Ä±n weigthleri belirli deÄŸil, kamyon iÃ§in bir tane tÄ±r class Ä± ile softmax yapacaÄŸÄ±na nasÄ±l karar veriyor? Sizin bahsettiÄŸiniz random candidate sampling olmuyor gibi, doÄŸrudan candidate seÃ§iyorsunuz.",
7.  -> Verdigim ornek senin icin kafa karistirici olmus gibi gorunuyor.Ornegi degistirelim.Mesela siniflar hayvanlar olsun.Kedi, maymun, zurafa, fil, guvercin, kopek, muhabbet kusu.Kus resmi verdigimizde guvercin ve muhabbet kusu icin olasilik hesaplayacak.Digerleriyle ugrasmayacak.Mantigi bu ancak teknik olarak neyin nasil oldugunu anlamak icin modelin mimarisini gormeliyiz.GIthub a baktim bir iki ornek bulabilir miyim diye bulamadim.Konuyla ilgilisin gordugum kadariyla iyi bir ornek bulursan modeli beraber aciklamaya calisiriz.Bu arada upsampling ya downsampling gibi kavramlar bildik kavramlar ancak candidate sampling enteresan ybir kavram benim icin. de.",

###Â soru 

> quest "Merhaba ArkadaÅŸlar, Backpropagation'un hata caselerinin birisi olan \"Dead ReLU Units\" i anlayamadÄ±m. YardÄ±mcÄ± olur musunuz? TeÅŸekkÃ¼rler",

> comments: 

1.  ReLu fonksiyonunun doÄŸasÄ± gereÄŸi negatif girdi deÄŸerleri sÄ±fÄ±r Ã§Ä±ktÄ±sÄ±nÄ± Ã¼retiyor. Bu durum ReLu iÃ§in negatif girdi olacak olan aÄŸÄ±rlÄ±klÄ± Ã¶zelliklerin toplamÄ±nÄ±n modele hiÃ§ bir katkÄ±da bulunmamasÄ±na sebeb oluyor dolayÄ±sÄ±yla geri yayÄ±lÄ±m algoritmasÄ± gradient hesabÄ± sÃ¼resince bu girdi deÄŸerleri Ã¼zerinden bir akÄ±ÅŸ saÄŸlayamÄ±yor. Ã‡Ã¼nkÃ¼ sÄ±fÄ±rÄ±n tÃ¼revi yine sÄ±fÄ±rdÄ±r. Bu durumu Ã§Ã¶zmek iÃ§in daha kÃ¼Ã§Ã¼k bir Ã¶ÄŸrenme katsayÄ±sÄ± veya \"Leaky ReLu\" aktivasyon fonksiyonu kullanÄ±labilir. Leaky ReLu'nun orjinalin ReLu'dan farkÄ± negatif deÄŸerler iÃ§im direk sÄ±fÄ±r Ã§Ä±ktÄ±sÄ± Ã¼retmeyip, nispeten sÄ±fÄ±ra yakÄ±n fakat sÄ±fÄ±r olmayan Ã§Ä±ktÄ±lar Ã¼retmesidir. BÃ¶ylece aÄŸÄ±rlÄ±klÄ± toplamlarÄ± negatif olan Ã¶zelliklerin de azda olsa modele bir katkÄ±sÄ± olabiliyor. UmarÄ±m yardÄ±mÄ± dokunur. Ä°yi Ã§alÄ±ÅŸmalar.",
2.  ->  Learning rate i degistirmek Dead RELU units sorununu cozmez.",
3.  -> ",
4.  Ders iÃ§eriÄŸinde en altta bÃ¶yle bir aÃ§Ä±klama yapÄ±lmÄ±ÅŸ",
5.  ->  Dead RELU Unit sorunu activation functioni degistirerek cozulebilir.Ilk akla gelenler sigmoid ya da tanh activation functions.Tabiki bunlarda neuronlar olmesede vanishing gradients ya da exploding gradients problemleriinden kurtalamayacagiz.Leaky RELU cozum olabilir.Yada Leky RELU nun gelistirilmis sekli olan SELU kullanilabilir.Yalniz SELU yu lecun_normal initialization ve Alpha Dropout ile kullanmalisiniz.4,
6.  ->  Ä°nternet Ã¼zerinde birden fazla kaynakta learning rate'in dead relu iÃ§in Ã§Ã¶zÃ¼m olabileceÄŸi yazÄ±lmÄ±ÅŸ. Learning rate'in weightleri gÃ¼ncellemeye doÄŸrudan etkisi bulunduÄŸu aÃ§Ä±k bir durum. Bu noktada dÃ¼ÅŸÃ¼k bir gÃ¼ncelleme oranÄ±nÄ±n aÄŸÄ±rlÄ±klÄ± toplamlarÄ±n belli bir seviyenin Ã¼stÃ¼nde olmasÄ±na, dolayÄ±sÄ±yla sÄ±fÄ±rÄ±n altÄ±nda negatif deÄŸerlere dÃ¼ÅŸmesini engelleyebileceÄŸini dÃ¼ÅŸÃ¼nÃ¼yorum.",
7. Merhabalar,BildiÄŸimiz gibi relu nun esprisi Ã¶nceki katmandan gelen input sÄ±fÄ±rdan bÃ¼yÃ¼kse o inputu doÄŸrudan bir sonraki katmana aktarÄ±yor, sÄ±fÄ±rdan kÃ¼Ã§Ã¼kse sÄ±fÄ±r Ã§Ä±kÄ±ÅŸÄ± veriyor yani sonraki katmana bir Ã§Ä±kÄ±ÅŸ vermiyor.EÄŸer olur da training sÄ±rasÄ±nda reluya Ã¶nceki katmandan gelen input deÄŸeri sÄ±fÄ±rÄ±n altÄ±na dÃ¼ÅŸÃ¼rse relu sonraki katmana Ã§Ä±kÄ±ÅŸ vermiyor. Ã‡Ä±kÄ±ÅŸ vermediÄŸi iÃ§in de final outputta o relu nÃ¶ronunun bir etkisi olmuyor. Weightleri update etme iÅŸlemi back propagation ile yapÄ±ldÄ±ÄŸÄ± iÃ§in (output katmanÄ±ndan baÅŸlanÄ±p tÃ¼rev alÄ±narak katmanlardan geriye doÄŸru weightler update ediliyor) ve Ã§Ä±kÄ±ÅŸ vermeyen relunun outputta hiÃ§ etkisi olmadÄ±ÄŸÄ± iÃ§in back propogation iÅŸleminde o relu nÃ¶ronunun sonrasÄ±ndaki ve Ã¶ncesindeki weightler hiÃ§ deÄŸiÅŸmiyor, deÄŸiÅŸmediÄŸi iÃ§in de ona gelen input deÄŸeri sÄ±fÄ±rdan kÃ¼Ã§Ã¼k kalmaya devam ediyor, bu yÃ¼zden de nÃ¶ron hiÃ§ Ã§Ä±kÄ±ÅŸ veremiyor. BÃ¶ylece o nÃ¶ron sonraki iterasyonlarda hep Ã¶lÃ¼ kalÄ±yor :)Ã‡Ã¶zÃ¼m olarak learning rate i azaltabilirsiniz deniyor.4 weeks ago 9 people like this.Like ReportReply",
8.  TeÅŸekkÃ¼rler arkadaÅŸlar deÄŸerli bilgileriniz iÃ§in. Ä°yi Ã§alÄ±ÅŸmalar.",

### soru 

> quest "Merhaba , Neural Networks kÄ±smÄ±nda ki playground exercises bÃ¶lÃ¼mÃ¼ndeki A First Neural Network alÄ±ÅŸtÄ±rmalarÄ±nÄ± tam anlayamadÄ±m. YardÄ±mcÄ± olur musunuz ğŸ™‚",
> comments: 

1.  Merhaba Duygu, bu alistirmalarda neuron sayilarini ve hidden layer sayilarini arttirip azaltarak farkli activation functions lari sectigimiz ya da secili dataya gore degistirerek, L1 veya L2 regularizasyon tekniklerini deneyerek gozlem yapiyoruz.Oyun gibi.Degerleri degistir, farkli kombinasyonlari dene ve gozlem yap.",
2.  TamamdÄ±r teÅŸekkÃ¼r ederim ğŸ™‚",
3. Merhaba,Neural Networks bizim daha komplike nonlinear modelleri eÄŸitmemizde kullanÄ±lÄ±r. Neural networks'te input ve output layerlarÄ± arasÄ±nda koyacaÄŸÄ±mÄ±z hiddden layerlar vardÄ±r. Bu layerlar isteÄŸimize gÃ¶re activation layer yani nonliner iÅŸlem yapan layerlar olabilir. (Bir layerda nodelar -neuron diye de geÃ§ebilir- bulunur ve bunodelarÄ±n lineer mi non lineer mi olduÄŸunu seÃ§ebilirsiniz. Activation layer iÃ§ideki inputla output arasÄ±nda matematiksel kÃ¶prÃ¼ gÃ¶ren bir layer diyebiliriz.) Activation layer'daki nodelar ReLU, Sigmoid benzeri fonksiyonlardÄ±r ve lineerliÄŸi nonlineerliÄŸe Ã§evirebilir. BÃ¶ylece daha karmaÅŸÄ±k veri daÄŸÄ±lÄ±mlarÄ±na sahip bir eÄŸitim setini Ã¶ÄŸrenebilir.Task 1: Modelimizde lineer olan hidden(input ve output layer'I arasÄ±nda kalan her layer) bir layerÄ±mÄ±z var. Bu model doÄŸal olarak hiÃ§bir nonlinearity Ã¶ÄŸrenemez ve veri daÄŸÄ±lÄ±mÄ± daha komplike olan eÄŸitimleri efektif gerÃ§ekleÅŸtiremez.Task 2: Burada hidden layer'daki nÃ¶ron sayÄ±sÄ±nÄ± arttÄ±rmanÄ±z bir anlam ifade etmeyecektir Ã§Ã¼nkÃ¼ yine nonlinearlÄ±ÄŸÄ± saÄŸlayamÄ±yorsunuz.Task 3: Burada hidden layerÄ±mÄ±zdaki nÃ¶ron sayÄ±sÄ±nÄ± arttÄ±rÄ±p 3 yapmamÄ±z ve activation function olarak ReLU kullanmamÄ±z modelimizi lineerlikten Ã§Ä±karÄ±p nonlineerliÄŸe sokacaktÄ±r.(Burada 3 nÃ¶ronun XOR iÅŸlemi yaptÄ±ÄŸÄ±ndan bahseder. 1. nÃ¶ron x1 deÄŸerini dÃ¼zlemde ayÄ±rÄ±r, 2.nÃ¶ron x2 deÄŸerini dÃ¼zlemde ayÄ±rÄ±r, 3.nÃ¶ron ise bunlarÄ±n arasÄ±ndaki iliÅŸkiyi belirler.) Burada verilerin nondeterminisitk olmasÄ± sebebiyle her Ã§alÄ±ÅŸtÄ±rma esnasÄ±nda aynÄ± sonucu elde edemeyiz. Ancak burada nonlineerliÄŸe eriÅŸmek sadece bir baÅŸlangÄ±Ã§. Bu nonlineerliÄŸi modelimizin hatalarÄ±nÄ± minimize edecek ÅŸekilde efektif olarak bulmalÄ±yÄ±z. Burada layer arttÄ±kÃ§a modelimiz daha komplike iÅŸlemleri gerÃ§ekleÅŸtirip modelimizi daha komplike hale getirir. (Modelimiz komplike oldukÃ§a overfitting riski artar) Åu anda tek hidden layerÄ±mÄ±z var ve bu layerdaki 3 nÃ¶ron lineer inputlarÄ±mÄ±zÄ±n toplam aÄŸÄ±rlÄ±klarÄ±nÄ±n ReLU fonksiyon deÄŸerini hesaplar.Task 4: Burada hidden layer ve bu layerlara nÃ¶ron ekleyerek optimum lossu saÄŸlayacak modeli oluÅŸturmamÄ±zdan bahsediyor. Burada bilmemiz gereken ÅŸey hidden layer arttÄ±kÃ§a problemimizin outputunun daha da komplike olacaÄŸÄ±dÄ±r. Activaton Layerlar'daki nÃ¶ronlardan her biri bir Ã¶nceki layerda hesaplanmÄ±ÅŸ olan toplam weight deÄŸerlerini alÄ±p o deÄŸerleri akyivasyon tipi ne ise (sigmoid, lineer, ReLu vs) o iÅŸleme tabi tutmaktadÄ±r. Modelimizde kullandÄ±ÄŸÄ±mÄ±z layerlar ve iÃ§indeki nodelar sayesinde modelimizin bir Ã§ok ÅŸekli gÃ¶z Ã¶nÃ¼nde bulundurmasÄ±nda yardÄ±mcÄ± olduk. (Åekilden kastÄ±mÄ±z dÃ¼zlemde verileri ayÄ±rÄ±rken oluÅŸan ÅŸekil.) Bu bilgileri kullanarak hidden layer ve bu layerlardaki nÃ¶ron sayÄ±larÄ±mÄ±zÄ± azaltÄ±p/ArttÄ±rarak optimum modelimizdeki hidden layer, nÃ¶ron sayÄ±larÄ± ne olur?Ä°yi Ã§alÄ±ÅŸmalar.4 weeks ago 9 people like this.Like ReportReply",
4.  AnladÄ±m teÅŸekkÃ¼r ederim ğŸ™‚",

### soru 

> quest "ArkadaÅŸlar Merhaba,   Sigmoid activation function ile ReLU arasÄ±nda farkÄ± tam olarak anlayamadÄ±m. YardÄ±mcÄ± olabilir misiniz? TeÅŸekkÃ¼rler.",

> comments: 

1. Merhaba,Neural Network'te non-linear iÅŸlemleri activation fonksiyonlarÄ± yardÄ±mÄ±yla yaparÄ±z sigmoid ve ReLU iki farklÄ± aktivasyon fonksyonudur.Sigmoid fonksiyonumuzu bir ihtimal elde etmeye Ã§alÄ±ÅŸÄ±rken kullanÄ±yoruz Ã§Ã¼nkÃ¼ Ã§Ä±kacak output deÄŸerimiz 0-1 arasÄ±ndadÄ±r.ReLU'da ise eÄŸer deÄŸerimiz negatif ise bizde dÃ¶necek ReLU deÄŸeri 0 olur, eÄŸer pozitif ise sayÄ±nÄ±n kendisini dÃ¶ndÃ¼rÃ¼r. Yani pozitifse inputu olduÄŸu gibi output Ã¼zerinden dÃ¶ndÃ¼rÃ¼r.ReLU'nun daha Ã§ok tercih edilmesinin sebebi:-Sigmoid backpropagation esnasÄ±nda modelimizin vanishing gradient sorununu yaÅŸamasÄ±na neden olabilir Ã§Ã¼nkÃ¼ her adÄ±mda hatamÄ±zÄ± Ã¶nemli Ã¶lÃ§Ã¼de azaltÄ±r.Vanishing gradient inputa yakÄ±n olan nÃ¶ronlarÄ±n weight deÄŸerlerinin Ã§ok kÃ¼Ã§Ã¼k olmasÄ± demektir ki bu da ilgili layeÄ±rÄ±n Ã§ok yavaÅŸ veya hiÃ§ eÄŸitilmemesine yol aÃ§ar.- BÃ¼yÃ¼k nÃ¶ral networklerde sigmoid'e gÃ¶re daha hÄ±zlÄ±dÄ±r.Ancak ReLU'da negatif x deÄŸerinin sÄ±fÄ±ra eÅŸitlenmesi ReLU'nun negatif deÄŸerleri Ã§ok iyi maplemeyip eÄŸitemediÄŸi anlamÄ±na gelir.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 7 people like this.Like ReportReply",
2.   Ä°lk fark ReLU'nun Sigmoide gÃ¶re daha az hesaplama gerektirmesi. Ä°kinci fark Sigmoid fonksiyonunun gradient tabanlÄ± modellerde Gradient Vanishing diye adlandÄ±rÄ±lan bir probleme sebep olmasÄ±. Bu problemin sebebi Sigmoidin yÃ¼ksek deÄŸerli negatif ve pozitif inputlarda (weightler) dÃ¼ÅŸÃ¼k tÃ¼rev deÄŸerlerine sahip olmasÄ±. Ä°nputlar yÃ¼ksek deÄŸere sahip olmasa bile layerlarda aktivasyon fonksiyonu olarak Sigmoid kullanÄ±rsak layer sayÄ±sÄ± arttÄ±kÃ§a yine Sigmoidin tÃ¼rev deÄŸerlerinin kÃ¼Ã§Ã¼k olmasÄ±ndan dolayÄ± deÄŸerler gittikÃ§e kÃ¼Ã§Ã¼lÃ¼p anlamsÄ±zlaÅŸacak. ReLU'da Gradient Vanishing problemi olmadÄ±ÄŸÄ± iÃ§in tercih ediliyor. Fakat ReLU'da da negatif deÄŸerlerde 0 deÄŸeri verdiÄŸi iÃ§in weight kaybÄ± oluyor. EÄŸer olur da bir Ã§ok negatif weightimiz olursa bir Ã§ok kayÄ±p oluyor. ReLU'nun bu sÄ±kÄ±ntÄ±sÄ± iÃ§in de Leaky ReLU diye adlandÄ±rÄ±lan bir fonksiyon tercih ediliyor :D. AÅŸaÄŸÄ±daki grafik Leaky ReLU'ya ait.1 month ago 7 people like this.Like ReportReply",
3.   Sigmoid ve tÃ¼revinin grafiÄŸi:1 month ago 5 people like this.Like ReportReply",
4.  Oncelikle activation functioni matematiksel bir gecis kapisi ya da esik gibi de dusunebilirsin.Diyelimki 10 tane layerimiz var.Her birinde 10 tane neuron olsun.Ilk layerimiza inputlarimizi girdik.Bunlar weight degerleriyle carpiliyor ve activation function dan elde ettigimiz outputlar bir sonraki layerin noronlarina input olarak aktariliyor. Sigmoid ve Relu non linear activation fonksiyonlardir.Her ne kadar RELU nun grafigi linear gibi gorunsede non-lineardir.Non linear activation functions arificial neural network ve deep neural network te kullanilir.Bunun sebebi turevleri vardir ve bu durum backpropagationa olanak saglayarak ogrenmeyi gerceklestirir..Linear bir functionin turevi bir sabittir dolayisiyla neural networku tek bir layer a donustureceginden kullanilmaz..Sigmoid binary classification yapmak icin logistic regression da kullanilir.Softmax ise sigmoid in ozel bir halidir.Cok onemlidir.4 weeks ago 9 people like this.Like ReportReply",
5.  YardÄ±mlarÄ±nÄ±z iÃ§in Ã§ok teÅŸekkÃ¼rler arkadaÅŸlar.4,

### soru
> quest "Merhabalar , ben MentorlarÄ±mÄ±za ÅŸunu sormak istiyorum. Bu kursa hergÃ¼n 1 saatte bakÄ±labilir veya 1 gÃ¼n de 1 haftalÄ±k konular da bitirilebilir  saÃ§ma gelebilir ama siz bu olayÄ± iÅŸ olarak yapÄ±yorsunuz ve gÃ¼nlÃ¼k nasÄ±l bir Ã§alÄ±ÅŸma dÃ¼zeniniz var. Bir Ã¶neri sorusu olarak soruyorum sadece kurs iÃ§in deÄŸil gÃ¼nlÃ¼k hayatta iÅŸ olarak yaptÄ±ÄŸÄ±nÄ±z iÃ§in soruyorum VerimliliÄŸi arttÄ±rmak adÄ±na nasÄ±l bir yol Ã¶nerirsiniz ya da siz nasÄ±l bir yol izliyorsunuz kaÃ§ saatinizi hangi konuya ayÄ±rÄ±yorsunuz ?",
> comments: 
    "",
1.  bende ÅŸunu merak ediyorum detaylarla uÄŸralÄ±rken Ã§okzaman harcÄ±yorum bu seferde normalden Ã§ok geri kalÄ±yorum alt yapÄ± eksikliÄŸimde var bize bi yol gÃ¶sterin lÃ¼tfen4,
2.  Merhabalar,Nacizane kendi fikrimi belirtmek istersem sadece bu konuda deÄŸil hayatÄ±nÄ±za tatbik edeceÄŸiniz her iÅŸ iÃ§in Ã¶nerim ÅŸu olurdu. \"TaÅŸÄ± Delen Suyun GÃ¼cÃ¼ DeÄŸil, DamlalarÄ±n SÃ¼rekliliÄŸidir\".SaygÄ±larÄ±mla",

### soru

> quest "Merhabalar, sanÄ±rÄ±m sitedeki bir deÄŸiÅŸiklikten dolayÄ± sorularÄ±m kendi profilimde paylaÅŸÄ±yormuÅŸum hep, dolayÄ±sÄ±yla gÃ¶rÃ¼nmediÄŸi iÃ§in cevap alamadÄ±m. BazÄ±larÄ±nÄ± kendim hallettim fakat bazÄ±larÄ±nÄ± hala anlamÄ±ÅŸ deÄŸilim.  Yorumlara ekliyorum.   Åimdiden teÅŸekkÃ¼r ederim..",

> comments: 

1. L1 ve L2 regularizationu kafamda tam oturamÄ±yorum. Ama anladÄ±m yÃ¼zeysel olarak...** Mesela regularization sparse kÄ±smÄ±nÄ±n exercise kÄ±smÄ±nda iÅŸaretlediÄŸim deÄŸeri L1 neden sÄ±fÄ±rlamamÄ±ÅŸ, yanÄ±ndaki weightte sÄ±fÄ±rlama olmuÅŸ. SanÄ±rÄ±m anlamadÄ±m :/.",
2.  -> Merhaba,L1 regÃ¼larizasyonu weight deÄŸerlerini sÄ±fÄ±rlar. her adÄ±mda weight deÄŸerinden sabit bir deÄŸeri Ã§Ä±karÄ±r. Gereksiz feature deÄŸerlerinin (genelde sparse matrixteki 0 olan featuerlarÄ± dÃ¼ÅŸÃ¼nebilirsiniz) weight oranlarÄ±nÄ± sÄ±fÄ±rlarÄ±p onlarÄ± yok etmek iÃ§in kullanÄ±lÄ±r.L2 regÃ¼larizasyon overfit olmayÄ± Ã¶nlemek iÃ§in vardÄ±r ve weight deÄŸerlerini sÄ±fÄ±rlamaz. Ã‡Ã¼nkÃ¼ weight deÄŸerlerini sÄ±fÄ±rlarsa o weight'e baÄŸlÄ± feature'Ä± da yok etmiÅŸ olur.1 month ago 4 people like this.Like ReportReply",
3.  ->  Sadece L2 degil, L1, L2 ve Dropout her ucu de overfitting probleminin onune gecmek icin uygulanan regularization tekniklerdir.L1 i L2 ile karsilastirirsak, L2 weightslerin degerini cok kucultur ve bir kismini ihmal ederken, L1 weightsleri sifir yapar, daha radikaldir.Bunun icin cok genis datasetleriyle kullanmak yerinde olacaktir.Tensorflow dan emin degilim ancak Keras L1 ve L2 yu birlikte kullanmayi mumkun kiliyor.Hatta birde Dropout bile ekleyebilirsin ancak beraber kullanilmasi tavsiye edilmez.Regulerize edelim derken cok fazla feature kaybetmek istemeyiz..",
4.  ->  evet pratikte baktÄ±ÄŸÄ±nÄ±z zaman hepsi weight deÄŸerlerini dÃ¼ÅŸÃ¼rdÃ¼ÄŸÃ¼ iÃ§in overfiti Ã¶nleyen bir seÃ§enektir. Burada dikkat Ã§ekmek istediÄŸim nokta L2 regÃ¼larizasyonunun feature kaybÄ± olmadan regÃ¼larize etmesi, L1 regÃ¼larizasyonunun ise gereksiz feature deÄŸerleirni sÄ±fÄ±rladÄ±ÄŸÄ±ydÄ±. Bilgilendirme iÃ§in teÅŸekkÃ¼r ederim.Ä°yi Ã§alÄ±ÅŸmalar.4 weeks ago 4 people like this.Like ReportReply",
5. -> Yukarida ben de Fethi de L1 ve L2 hakkinda birseyler soyledigimizi ama senin sorunu cevaplamadigimizi farkettim.Aslinda 2 soru var.Neden 0.39 olan weight degerini sifirlarken 0.37 degerini sifirlamayip 0.31 e indirgemis ? Oncelikle L1 in degeri kucuk olan etkisi az olan weightsleri sifirlamasini bekliyoruz.Ancak ya weightslerin cok buyuk kisminin degeri kucukse o zaman hepsini sifirlayacak mi? Hayir.Belli bir kismini, modelin ezberlemsinin onune gececek kadar olanini sifirlasa yeter.Dropout da bu orani belirliyorsun.Mesela diyorsun ki % 50 sini etkisiz hale getir.Demekki ilk olarak bazi dusuk degerli weightslerin kalmaya devam etmesi normal.Peki eger dusuk degerli bir weight kalacaksa kotunun iyisi olsun yani dusuk degerlilerin en buyuk degerlisi kalmali dusuncesi mantikli geliyor.Dolayisiyla neden L1 in hepsini sifirlamadigini anliyoruz ancak neden sifirlamak icin 0.37 degerini degil de 0.39 u sectigini tam olarak anlayamiyorum.Belki soyle dusunebiliriz.Birbirinee cok yakin degerler dolayisiyla birini secmis. diyebiliriz:)",
6. ->  Evet aslÄ±nda iki soru vardÄ± bir de resimli olarak sormuÅŸtum ğŸ™‚ Ama benim soruÅŸ tarzÄ±mla alakalÄ± anlayamamÄ±ÅŸ olmanÄ±z Ã§ok normal, karÄ±ÅŸÄ±k sormuÅŸum ikinize de ayrÄ± ayrÄ± cevaplarÄ±nÄ±z iÃ§in Ã§ok teÅŸekkÃ¼r ederim. ÅŸimdi daha iyi oturdu kafamda... -> ",
7.  Merhaba. Buradan sormak daha doÄŸru geldi. Peki L1 ve L2 DÃ¼zenlemelerinin hangilerini hangi datasetlerde kullanmak daha mantÄ±klÄ±? Yani ÅŸÃ¶yle diyebilir miyiz; eÄŸer datasetiniz bÃ¼yÃ¼k, ayrÄ±k verileri iÃ§eriyor, Ã§oÄŸunluÄŸu 0 ise L1 dÃ¼zenleme kullanÄ±n",
8.  ->  Oncelikle L1, L2 ve Dropout cok katmanli neural network lerde overfitting i engellemek icin kullaniyoruz.Eger datasetin buyukse den ziyade soyle ifade etmek istiyorum:Feature larinin sayisi fazla ise L1 ile bunlarin bir kisminin gitmesinde cok sakinca yok geriye hala yeteri kadar feature kalacaktir diye dusunebilirsin.Ama sunu bilmelisin L1 in sifirladigi feature lari kaybediyorsun.Ancak L2 bu feature lari zero yapmiyor sadece daha da kucultup ignore ediyor.Dolayisiyla L2 daha guvenli gorunuyor..Multi Class programing orneklerinde MNIST dataseti icin verilen ornek uzerinde regulator lari degistirerek sonuclari karsilastirabilirsin.",
9.  ->  TeÅŸekkÃ¼r ederim",
10. AUC eÄŸrisi Ã§izilirken farklÄ± Thresholds deÄŸerleri alÄ±narak Ã§iziliyor. Peki, buradaki koda baktÄ±ÄŸÄ±mÄ±zda bu kÄ±smÄ± oluÅŸturan kod blogu hangisidir? (Classification Programlama Egzersizi KÄ±smÄ±nda Son Task).",
11.  -> Merhaba,tf.keras.metrics.AUC metodunda auc u hesaplamak iÃ§n kullanÄ±lan True Positive, True Negative, Falpse Positive ve False Negative deÄŸerleri oluÅŸturuluyor. Bu threshold sayÄ±sÄ±nÄ± da num_of_thresholds parametresi belirliyor. Thresholdlar auc metodu tarafÄ±ndan otomatik belirlendiÄŸi gibi thresholds parametresiyle de siz belirleyebilirsiniz.Kaynak: [Link](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/AUCÄ°yi Ã§alÄ±ÅŸmalar.tf.keras.metrics.AUC  |  TensorFlow Core v2.1.0www.tensorflow.org[Link](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/AUC1 month ago 3 people like this.Like ReportReply",
12. 3- Yine regularization playground exercise kÄ±smÄ±nda weight deÄŸerlerine baktÄ±ÄŸÄ±mÄ±zda sorulara cevap verirken kafam karÄ±ÅŸtÄ± (-) deÄŸerlerden dolayÄ±, yani eksi olan weight deÄŸerlerinin artÄ±p azalmasÄ± ile alakalÄ± - deÄŸerden 0'lanmasÄ± ya da 0'a yakÄ±nsamasÄ± acaba azalma olarak mÄ± deÄŸerlendiriliyor? Bir yeri kaÃ§Ä±rdÄ±m galiba.",
13.  -> Merhaba,Weightler azaldÄ±ÄŸÄ±nda veya arttÄ±ÄŸÄ±nda durumundan ziyade en optimum weight deÄŸerlerinde modelimiz efektif Ã§alÄ±ÅŸÄ±r. Weight deÄŸeri sÄ±fÄ±ra yakÄ±nsarsa bu weighte baÄŸlÄ± feature deÄŸerinin modelimizde o kadar az etkisi olur.Sorunuzu yanlÄ±ÅŸ anladÄ±ysam beni aydÄ±nlatÄ±n lÃ¼tfen.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 4 people like this.Like ReportReply",
14.  -> Merhabalar,(-) weight deÄŸerleri 0'a yakÄ±nsarken deÄŸerleri artmaktadÄ±r. Bu matematiksel olarak bÃ¶yledir. Ancak weightler iÃ§in negatif veya pozitif olmalarÄ± farketmeksizin 0'a yakÄ±nsadÄ±kÃ§a etkinlikleri azalÄ±r. Burada negatifliÄŸi, etkinin yÃ¶nÃ¼ olarak dÃ¼ÅŸÃ¼nebilirsiniz.DolayÄ±sÄ±yla sorunuzun cevabÄ± da (-) deÄŸerli bir weight'in 0'a yakÄ±nsamasÄ± etkinliÄŸinin azaldÄ±ÄŸÄ±nÄ±n gÃ¶stergesidir.Edit: ->  uyarÄ±sÄ± Ã¼zerine, ilk cÃ¼mleden \"mutlak\" kelimesi Ã§Ä±karÄ±ldÄ±.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 3 people like this.Like ReportReply",
15.  ->  Matematiksel olarak negative degerler 0 a yaklastikca mutlak degeri artmaz,0 dan uzaklastikca mutlak degeri artar..",
16.  ->  TeÅŸekkÃ¼rler, yazarken dikkatsizliÄŸime gelmiÅŸ..",
17.  ->  Rica ederim ğŸ™‚.",
18.  Eger weights leri hesaplarken kullandigimiz formulu gozonune alirsak weight degerinin negative olmasi, bir onceki weight degerinin yani formuldeki eski, update edilmemis weight degerinin learning rate ile loss degerinin carpimindan kucuk olmasi demektir.Bu durum bizi su soruya goturuyor.Negative weight degerinden sonra update edilen weight degerleri hep negative mi olur? Evet deseydik, loss degerinin her zaman pozitif bir deger oldugunu soyluyor olurduk ki loss negative olabilir.ornek:Negative Log Loss1 month ago 2 people like this.Like ReportReply",
19. L2'den L1'e geÃ§iÅŸi yorumlayamadÄ±m aslÄ±nda... Åu kÄ±sÄ±m.. ->  ->  ->  (-) deÄŸerler kafamÄ± karÄ±ÅŸtÄ±rdÄ±.. (-) deÄŸerden 0'a yakÄ±nsamÄ±ÅŸ, etkinlik azaldÄ± dememiz mi gerekiyor sonuÃ§ olarak.",
20.  L1 regÃ¼larizasyonunda siz weight deÄŸerinizin mutlak deÄŸerinden bir k sabiti Ã§Ä±karÄ±rsÄ±nÄ±z bu da L2 regÃ¼larizasyonuna gÃ¶re daha Ã§abuk 0'a yakÄ±nsamasÄ± demek. Mutlak deÄŸerden k sabiti Ã§Ä±kardÄ±ÄŸÄ±mÄ±z iÃ§in negatiflik pozitiflik L1 regÃ¼larizasyonunda fark oluÅŸturan bir etmen deÄŸildir yani negatiften yakÄ±nsamasÄ± ile pozitiften yakÄ±nsamasÄ± arasÄ±nda etkinlik farkÄ± yoktur.DolayÄ±sÄ±yla L2'den L1'e geÃ§erseniz Ã¶ÄŸrenilen tÃ¼m aÄŸÄ±rlÄ±klar azalÄ±r. Bunun yanÄ±nda L2'den L1'e geÃ§iÅŸ test kaybÄ± ve eÄŸitim kaybÄ± arasÄ±ndaki aralÄ±ÄŸÄ± da oldukÃ§a azaltÄ±r.L1 regularization rate'inin arttÄ±rÄ±lmasÄ± Ã¶ÄŸrenilen weight deÄŸerlerini azaltÄ±r ancak, dÃ¼zenlenme oranÄ± Ã§ok yÃ¼kselirse, model yakÄ±nsama yapamaz ve buna baÄŸlÄ± olarak loss deÄŸerleri Ã§ok yÃ¼ksek olur.1 month ago 2 people like this.Like ReportReply",
21. Ã§ok teÅŸekkÃ¼r ederim",

### soru 

> quest": "Merhaba GrafiÄŸi yorumlamakta gÃ¼Ã§lÃ¼k Ã§ektim yardÄ±mcÄ± olursanÄ±z sevinirim.  3 Ã§izgi neyi temsil ediyor x ve y eksenleri aÃ§Ä±klanmÄ±ÅŸ. -7 olarak tahmin edilmiÅŸ ortalama skor aslÄ±nda datada -8 e mi denk geliyormuÅŸ ? bunu anlamlandÄ±ramÄ±yorum bu benim iÃ§in ne ifade ediyor eksenlerin logaritmik oldugu sÃ¶ylenmiÅŸ fakat herhangi logitmik artÄ±ÅŸta gÃ¶remiyorum belkide gÃ¶zden kaÃ§Ä±rÄ±yorum. Bu kÃ¶tÃ¼ sÄ±nÄ±flandÄ±rmaya ait bir grafikse iyi bir sÄ±nÄ±flandÄ±rmaya grafigi neye benzemeliydi teÅŸekkÃ¼rler."

![image](image/2.jpg)

> comments":

1. -> Ã–ncelikle ÅŸunu sÃ¶yleyeyim ki; eksenler logaritmik olarak Ã¶lÃ§eklendirilmiÅŸ. Herhangi bir logaritmik artÄ±ÅŸtan bahsetmemizi gerektirecek bir grafik deÄŸil, yalnÄ±zca modelin tahminleri ile gerÃ§ek deÄŸerler arasÄ±ndaki Ã¶rtÃ¼ÅŸmeye baktÄ±ÄŸÄ±mÄ±z bir grafik.X ekseni modelin yaptÄ±ÄŸÄ± tahmini, Y ekseni ise gerÃ§ekteki deÄŸeri gÃ¶stermekte. Ortada yer alan pembemsi lineer Ã§izgi bizim tahminimiz ile gerÃ§ekteki (actual) deÄŸerinin tam Ã¶rtÃ¼ÅŸtÃ¼ÄŸÃ¼ durumda Ã§izilecek Ã§izgidir. Yani tahmin -6.000'da iken gerÃ§ek deÄŸeri de -6.000'da ise o point tam olarak pembemsi Ã§izginin Ã¼zerine dÃ¼ÅŸer. Ãœst ve altÄ±ndaki aÃ§Ä±k mavi ve yeÅŸilimsi Ã§izgiler ise tahmin ediyorum ki Ã¼st ve alt gÃ¼ven aralÄ±ÄŸÄ± limitleri. Tabiki her noktayÄ± hatasÄ±z olarak tahmin edemeyebiliriz bir miktar (%1, 5 belki 10) hata kabul edilebilir. Bu mavi ve yeÅŸil Ã§izgiler de bu gÃ¼ven aralÄ±ÄŸÄ±nÄ± temsil ediyor diye dÃ¼ÅŸÃ¼nÃ¼yorum. Tahmin verilerinin daha dÃ¼ÅŸÃ¼k olduÄŸu (-6.000 ve daha dÃ¼ÅŸÃ¼k) noktalarda Ã§izgilerin dÄ±ÅŸÄ±nda yer alma durumu sÃ¶z konusu. Bunlar bizim veriyi -en azÄ±ndan bir kÄ±smÄ±nÄ±- iyi tahmin edemediÄŸimizi gÃ¶steriyor. Bunun birkaÃ§ sebebi olabilir: Ä°lk sebebi heteroscedasticity, yani deÄŸiÅŸken varyans. Verinin belli bir kÄ±smÄ± daha fazla gÃ¼rÃ¼ltÃ¼ iÃ§eriyor olabilir. Lambda deÄŸerini olmasÄ± gerekenden yÃ¼ksek tutarak fazla regÃ¼larize etmiÅŸ olabilir ve training setimiz ana verimizin belli alt kÃ¼melerini yeteri kadar iyi temsil etmiyor olabilir.
2. ->  ->  eksenlerin logaritmik Ã¶lÃ§eklendirildiÄŸi crash course iÃ§erisinde yer alÄ±yor fakat eksenlerdeki deÄŸerlere bakÄ±nca logaritmik artÄ±ÅŸ gÃ¶remediÄŸim iÃ§in anlamada gÃ¼Ã§lÃ¼k Ã§ektim. 64 49 36 olarak yazÄ±lsaydÄ± mantÄ±klÄ± olurdu gibi ?",
3. ->  ->  Eksenler 10 100 1000 10000 ÅŸeklinde olsa idi logaritmik olur du..",
4. -> -> Burada Lambda cok kucukse de, yani model training set'e overfit olduysa, yine prediction bias fazla olmaz miydi? (yani over-regularization'in tam zitti da bu soruna yol acmaz mi?) Neden sadece Lambda'nin cok buyuk olmus olabilecegi dusunuluyor?",
5. -> -> YaklaÅŸÄ±m doÄŸru lambda olmasÄ± gerekenden fazla kÃ¼Ã§Ã¼k olursa overfit olur fakat prediction bias'Ä±n tanÄ±mÄ± ile alakalÄ± bir durum sÃ¶z konusu. FormÃ¼lÃ¼ bize ÅŸunu sÃ¶ylÃ¼yor:Tahminlerin ortalamasÄ± - Actual deÄŸerlerin ortalamasÄ± deÄŸerinin olabildiÄŸince az olmasÄ±ndan bahsediyor. LambdayÄ± olmasÄ± gerekenden Ã§ok bÃ¼yÃ¼k seÃ§ersek underfitting olacaÄŸÄ±ndan bizim modelin tahmin deÄŸerleri actual deÄŸerlerden uzak kalacaktÄ±r ve bu prediction bias'a sebep olacaktÄ±r. Fakat lambdayÄ± fazlaca kÃ¼Ã§Ã¼k seÃ§ersek overfitting olacak ve bizim modelin tahmin deÄŸerleri actual deÄŸerlere oldukÃ§a yakÄ±n olacaktÄ±r.Bu noktada dolaylÄ± bir problem sÃ¶z konusu olabilir. O da overfitting'den dolayÄ± test verisinin prediction bias'Ä±nÄ±n istenenden fazla olmasÄ±. DolaylÄ± bir etki olarak lambdayÄ± kÃ¼Ã§Ã¼k de seÃ§mek training verisi iÃ§in deÄŸil ancak test verisi iÃ§in prediction bias yaratabilir diyebiliriz.

### soru

> quest": "Merhaba arkadaÅŸlar. Burada kutucuk iÃ§erisine aldÄ±ÄŸÄ±m yeri anlayamadÄ±m . Muhtemelen bir yeri kaÃ§Ä±rdÄ±m , yardÄ±mcÄ± olabilirseniz Ã§ok sevinirim.",

![image](image/3.jpg)

> comments": 

1. ->  Merhaba,Kutucuk iÃ§erisine aldÄ±ÄŸÄ±nÄ±z ifade ReLU fonksiyonu, max(0, x)-> 0 ile x'den hangisi bÃ¼yÃ¼kse onu geri dÃ¶ndÃ¼rÃ¼r.",
2. ->  ->  Ã§ok teÅŸekkÃ¼r ederim ÅŸimdi anladÄ±m..",
3. ->  ReLU fonksiyonu 0'a kadar (negatif deÄŸerlerden 0'a kadar) 0 deÄŸeri, 0'dan sonra da kendi deÄŸerini (x deÄŸerini) verir.Ã¶rn: x=-2 olsun f(x)=0 olur.x=3 olsun f(x)=3 olur.",

### soru

> quest": "Merhaba, konularla tam baÄŸlantÄ±lÄ± olmasa da bir ÅŸey takÄ±ldÄ± kafama. Bu kurs sÃ¼recinde, temel kavramlar gÃ¶rdÃ¼k. Epoch, learning rate, batch size gibi.. Bunlar, makine Ã¶ÄŸrenmesinin temeli diyebilir miyiz? Demek istediÄŸim, flapy bird veya snake oynayan/Ã¶ÄŸrenen bir yapÄ± ile spam mail ayÄ±ran yapÄ±da benzer kavramlar bulunuyor mu? Yoksa, baÅŸka alanlarda baÅŸka kavramlar, baÅŸka temeller mi giriyor?", 

> comments":

 1. -> Tabii dÃ¼ÅŸÃ¼nÃ¼nce, veri seti olmazsa neyi batchlere ayÄ±racaÄŸÄ±z gibi bir soru da Ã§Ä±kabiliyor ortaya ama genel olarak anlaÅŸÄ±ldÄ±ÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum..",
 2. ->  Flapy bird oynayan yaoiyi bilmiyorum ğŸ™‚ Ancak spam mail ayiran yapi olarak tarif ettigin sey binary classification yapiyor,.",
 3. -> Flappy Bird/Snake gibi oyunlarÄ± Ã¶ÄŸretmek iÃ§in kullandÄ±ÄŸÄ±nÄ±z metoda gÃ¶re, temel kavramlar deÄŸiÅŸiklik gÃ¶sterecektir. Ã–rneÄŸin, yÄ±lan oyununu kendi kendine oynayan bir yazÄ±lÄ±m iÃ§in farklÄ± Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± olabilir.1 - Algoritmik yaklaÅŸÄ±m: Oyunun state'ine gÃ¶re bir sonraki hamleyi verecek algoritmayÄ± kendiniz kodlarsÄ±nÄ±z. Burada herhangi bir makine Ã¶ÄŸrenmesi sÃ¶zkonusu deÄŸil.2 - Supervised Learning: Modelinize yÃ¼zbinlerce etiketlenmiÅŸ training data verirsiniz. Burada inputlar farklÄ± oyun state'leri, label'lar da ilgili state iÃ§in oynanmasÄ± gereken doÄŸru hamle olabilir. Ã–nceden oynanmÄ±ÅŸ oyunlar ile model eÄŸitilebilir.3 - Reinforcement Learning: YapÄ±lan hamle serilerinin sonucunda Ã¶dÃ¼l/ceza sistemi uygulayarak modelin kendi kendine oynayarak Ã¶ÄŸrenmesi saÄŸlanabilir.4- Genetik Algoritmalar: Bir neural network'Ã¼n parametrelerini (weights & biases) yÄ±lanÄ±n genetiÄŸi olarak dÃ¼ÅŸÃ¼nebiliriz. Mutasyonlar ve crossoverlar ile yeni nesil yÄ±lanlar tÃ¼retilir ve en iyi performansÄ± gÃ¶sterenler seÃ§ilir. Bu bir dÃ¶ngÃ¼ halinde tekrar edilir ve giderek daha baÅŸarÄ±lÄ± (fit) yÄ±lanlar elde edilmiÅŸ olur.Bu baÅŸlÄ±klar iÃ§in benzer kavramlar mutlaka vardÄ±r ama hepsinin kendine Ã¶zgÃ¼ temel kavramlara sahip olduÄŸu aÅŸikar.",
 4. -> Ã‡ok teÅŸekkÃ¼r ederim, Ã§ok aÃ§Ä±klayÄ±cÄ± yorum olmuÅŸ..",

 ### soru 

> quest": "Merhabalar, ROC curve ve Auc 'un iÅŸlevini pek anlayamadÄ±m biz bunlarÄ± nede kullanÄ±yoruz bu bir zorunluluk mudur acaba?",

> comments":
1. ->  Merhaba,[Link](https://community.globalaihub.com/?status/1482-1482-1587629584/#comment.4782.4624.4624) yorumumda bunlarÄ± aÃ§Ä±klamaya Ã§alÄ±ÅŸtÄ±m. Zorunlu deÄŸillerdir ama yapmamÄ±z modelin performansÄ±nÄ± Ã¶lÃ§memiz aÃ§Ä±sÄ±ndan Ã¶nemlidir.Ä°yi Ã§alÄ±ÅŸmalar.Community."
2. ->  Precision/recall, F1-score, error rate, accuracy , ROC curve ve AUC classification icin kullanilan performans metriclerdir.Burada classification kisminin altini cizmek istiyorum cunku amacimiz prediction iyapmaksa RMSE, Pearson's correlate coefficient ve coefficient of determination kullanilir.Bu performans metrikleri genel olarak error analizi yapip modelimizi gelistirmeye yarar.",

### soru 

> quest": "Merhaba arkadaÅŸlar,  Roc curve'de neden TPR ve FPR adÄ± verilen iki parametreyi kullanÄ±yoruz? ve bir de FPR 'de neden True negativ'i hesaplamak yerine False positive'i hesaplÄ±yoruz?"

> comments": 

1. ->  Merhaba,TPR dediÄŸimiz parametre Recall metriÄŸidir aslÄ±nda. Recall ÅŸunu sorar True Positivelerin kaÃ§ tanesi modelimiz tarafÄ±ndan tahmin edildi? TPR deÄŸerimizin kullanÄ±m amacÄ± budur.TPR ve FPR deÄŸerleri birbirileri ile korelasyonludur ve curve'Ã¼mÃ¼zÃ¼ (1,1) noktasÄ±nda sÄ±nÄ±rlayabiliyoruz. FarklÄ± threshold deÄŸerlerinde bir deÄŸer(TRP Ã¶rnreÄŸin) artarken diÄŸer deÄŸer de (FPR Ã¶rneÄŸin) buna baÄŸlÄ± olarak artÄ±ÅŸ gÃ¶sterecektir. Bu deÄŸerleri kullandÄ±ÄŸÄ±mÄ±zda aynÄ± tahmin setinin tpr ve fpr deÄŸerlerini gÃ¶rebilmek, eÄŸer modelimizde bir problem var ise  [Understanding AUC - ROC Curvetowardsdatascience.comIn Machine Learning,](https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5) linkindeki How to speculate the performance of the model? kÄ±smÄ±nda bunlara deÄŸiniliyor) bu kolayca tespit edilebilir.Ä°yi Ã§alÄ±ÅŸmalar.",
2. ->  ->  merhaba, [Link](https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5) ÅŸu linkte tpr ve fpr deÄŸerlerinin birbirlerini pozitif yÃ¶nde etkilediÄŸi ifade edilmiÅŸ. Bu deÄŸerler birbirlerini hangi yÃ¶nde etkiliyor. AyrÄ±ca FPR =1-specifity olarak tanimlanmiÅŸ. Specifity kavramÄ± crash courseta aÃ§Ä±klanmamÄ±ÅŸ ama. Specifityden ne anlamalÄ±yÄ±z? TeÅŸekkÃ¼r ederim.",
"Understanding AUC - ROC Curvetowardsdatascience.comIn Machine Learning, performance measurement is an essential task. So when it comes to a classification problem, we can count on an AUC â€¦.",
3. ->   ->  Merhaba,Evet orada ufak bir anlaÅŸmazlÄ±k olmuÅŸ.TPR deÄŸeri sizin Recall deÄŸeriniz. Specifity deÄŸeriniz ise Recall deÄŸerinizin Positive classlar iÃ§in deÄŸil negative classlar iÃ§in hesaplanmÄ±ÅŸ deÄŸeridir.FPR deÄŸeriniz 1-Specifity'dir. Bu baÄŸlamda biz thresholdu arttÄ±rdÄ±ÄŸÄ±mÄ±zda TPR zaten artacaktÄ±r, specifity deÄŸerimiz dÃ¼ÅŸeceÄŸi iÃ§in FPR deÄŸerimiz artacaktÄ±r. Oradaki anlam karmaÅŸasÄ±nÄ± da dÃ¼zelttim. UyarÄ± iÃ§in teÅŸekkÃ¼rler.Ä°yi Ã§alÄ±ÅŸmalar..",
4. -> True Positive Rate = TPR = Recall =TP/(TP+FN) False False Positive Rate = FPR = FP / (FP+TN) = 1-(True Negative Rate) True Negative Rate = TNR = TN/(FP+TN) Roc Curve, True Positive Rate ile False Positive Rate arasindaki iliskiyi ifade ediyor.Ne yaptigimizi iyi anlayalim.Classification yapiyoruz.Bunun icin Precision/recall, F1-score, error rate, accuracy ve ROC curve performance metriklerimiz ve bunlardan yararlanarak hata analizi yapip modelimizi gelistirecegiz.Classification yaparken labellar probabilistic distrubition sonucunda belirleniyor.Roc curve icin true ya da false farketmez kesinlikle pozitif degerlerle ilgileniyoruz ve True, false olasiliklarin degisimine bakiyoruz.Ve tabiki TPR ve FNR 0 ve1 arasinda degerler aliyor.Son olarak sordugun soruya geldigimde FPR yi hesaplarken True Negative Rate i hesapliyorsun, false negativi degil..",
5. ->  [Link](https://youtu.be/4jRBRDbJemMROC) and AUC, Clearly Explained!youtu.beROC (Receiver Operator Characteristic) graphs and AUC (the area under the curve), are useful for consolidating the information from a ton of confusion matric...",
6. ->  ->  Videonun ozetle kismi cok iyi aciklamis.Roc corves threshold degerini belirlemeyi kolaylastiriyor.AUC ise hangi classification methodunun daha iyi oldugu konusunda karar vermemize yardim ediyor..",
7. ->  teÅŸekkÃ¼rler.",
8. -> Yalniz ROC egrisinden hangi threshold degerinin hangi sonuca vardigini cikarsayamiyoruz (thr degerine gore sirali degiller). O zaman bu egri uzerindeki noktalar bize threshold degerinin ne oldugu bilgisini vermiyor. degil mi? -> ",
9. ->  ->Evet, burada eÄŸri noktalar bize threshold deÄŸerini vermez. Burada AUC ile hesapladÄ±ÄŸÄ±mÄ±z zaten bÃ¼tÃ¼n threshold deÄŸerlerinde nasÄ±l bir performans elde edebileceÄŸimiz. ROC curve'Ã¼nde ise TPR ve FPR deÄŸerleriyle threshold'u elde edemeyiz."

### soru

> quest": "Merhabalar, birkaÃ§ sorum var onlarÄ± sÄ±rayla sormak istiyorum. Her soruyu yorum olarak atÄ±yorum.",

> comments": 

1. -> DiÄŸer Metriclerde, â€œclassification_thresholdâ€ deÄŸerini kullanÄ±rken (ki bu deÄŸer de 0.52) neden AUC iÃ§in kendimiz bir deÄŸer atadÄ±k? AyrÄ±ca bu deÄŸeri neye gÃ¶re belirledik?.",
2. -> Burada, model.add diye baÅŸlayarak yeni katmanlar ekliyoruz ve unitsâ€™de de katmanlarÄ±n ne kadar nÃ¶ron iÃ§ereceÄŸini belirliyoruz. Peki, neye gÃ¶re belirliyoruz? KaÃ§ katman olacaÄŸÄ±nÄ±, kaÃ§ nÃ¶ron olacaÄŸÄ±nÄ± neye gÃ¶re belirliyoruz?.",
3. -> -> Oncelikle novel bir model yaratirken kac layer ekleyecegini kimse sana soyleyemez.Mesela Oxford tarafindan yayinlanan vgg16 modelini dusun.Neye gore layer sayisini belirlediklerinin belli bir cevabi yok.Ayni sekilde 50 layerdan olusan Resnet 50 ya da Resnet 101.Ancak layer sayisi arttikca ve azaldikca neler oluyor sorusunun cevabi var.Layer sayisi arttikca modelin derinlesir komplex hale gelir.Overfitting probleminin ortaya cikma olasiligi artar..",
4. -> ->  Peki ama ÅŸu da var, overfittingden kaÃ§Ä±nma yollarÄ±mÄ±z; learning ratei ayarlamak, Ã¶ÄŸrenmeyi erken bÄ±rakmak gibi yÃ¶ntemler.. Yani optimum noktaya ulaÅŸana kadar, elimizdeki her ÅŸeyi ayarlayarak ilerleyeceÄŸiz, kimse bize neyin ne olduÄŸunu sÃ¶ylemiyor diyorsunuz, Ã¶yle mi?.",
5. ->  -> Kimse sana kac layer kullanacagini ya da kac tane kullanman gerektigini soyleyemez cunku kimse bilmiyor.Sadece cok layer eklenince ne oluyor az sayida layer ile ne oluyor kismini tecrube ederek ogreniyorsun.Dedigin gibi overfitting problemleri icin regularization tekniklerini kullaniyorsun.Son olarak, fazla sayida layer daha iyi model anlami tasimaz.Bazen daha basit bir modelle iyi sonuclar alirsin..",
6. -> Belki kaÃ§ kez soruldu amaâ€¦ SorularÄ±mÄ±zÄ± cevaplayan mentÃ¶rlerimiz ve diÄŸer yazÄ±larda da gÃ¶rÃ¼yorum, bu deÄŸerleri tecrÃ¼be edindikÃ§e ve benzer Ã§alÄ±ÅŸmalarÄ± inceledikÃ§e neler vereceÄŸimizi anlÄ±yoruz diyorlar. Fakat, Ã¶rneÄŸin learning rateâ€™in aÅŸÄ±rÄ± veya Ã§ok dÃ¼ÅŸÃ¼k olduÄŸunu lossâ€™taki sapmalardan veya hiÃ§ dÃ¼ÅŸmemesinden anlayabiliyorum. Fakat Epoch, batch sizeâ€™larÄ± gerÃ§ekten neye belirleyeceÄŸiz? Bu noktaya geldim hala kafam almÄ±yor...",
7.->  Oguzhan epochs ve batch_size konusunda ne kadar zamanin oldugu , en az kullanacagin datsetinin genisligi kadar onemli.Oncelikle epboch ve batch_ size in anlamini kavradigindan emin olmalisin.Bunun icin sunun gibi bir sorulara rahatlikla cevap vermelisin.Mesela training dataseti=32000 olsun.Eger batch_size = 32 ise training sirasinda kac iterasyon olacak? 1000 olacak.1000 iterasyonun tamamlamasi 1 epoch oldu demek degil mi? Daha hizlica 1 epoch tamamlansin modelimin performansi hakkinda hizlica fikir edinmek istiyorum dersen batch_size ini arttir. Training sirasinda total kaybini ve accuracy yi goreceksin.Traininge devam ederek kaybini azaltmaya accuracy i arttirmaya modelini gelistirmeye devam edebilirsin.epeochs = 10 yap ne kadar zaman aldigina bak.See zaman!",
8. -> ->  AnladÄ±m, Ã§ok teÅŸekkÃ¼r ederim ğŸ™‚.",
9. ->  ->  training dataset/batch_size = 1 epoch mu ediyor yani",
10. ->  ->  Yukarida verdigim ornege gore yazayim.Training_dataset / batch_size = 1000 iterasyon. Bu 1000 iterasyon tamamlandiginda yani training datasetindeki tum veriler bir kez training safhasindan gecip tamamlandiginda 1 epoch ediyor.",

### soru

> quest": "auc'un diÄŸer metriklerle mi yoksa yalnÄ±z baÅŸÄ±na konmasÄ± mÄ± daha mantÄ±klÄ± olur? ayrÄ±ca auc ve roc kavramlarÄ±nÄ± anlayamadÄ±m. TeÅŸekkÃ¼rler."

> comments": 

1. -> Merhaba,Positive Rate curve'Ã¼ Ã§eÅŸitli threshold deÄŸerlerinde precision ve recall arasÄ±ndaki dengeyi gÃ¶sterir. AUC'ta ise True Positive Rate(zaten recall oluyor, TP/TP+FN) ve False Positive Rate (FP/FP+TN) arasÄ±ndaki iliÅŸki grafiÄŸinin alanÄ± alÄ±narak her threshold deÄŸeri iÃ§in performans Ã¶lÃ§Ã¼lmeye Ã§alÄ±ÅŸÄ±lÄ±r.(Yani modelin toplam performansÄ±). Bu yÃ¼zden AUC'u kullandÄ±ÄŸÄ±nÄ±zda precision ve recall kullanmayabilirsiniz.Precision ve recall metrikleri sÄ±nÄ±flandÄ±rma modelimizin performansÄ±nÄ± farklÄ± aÃ§Ä±lardan Ã¶lÃ§er. Herhangi biri diÄŸerinden daha iyi diyemeyiz iki metriÄŸin de performansÄ± farklÄ± aÃ§Ä±lardan Ã¶lÃ§tÃ¼ÄŸÃ¼nÃ¼ bildiÄŸimizden threshold deÄŸerini ikisini de optimum dÃ¼zeyde tutacak ÅŸekilde ayarlayabiliriz.ROC grafiÄŸi her threshold deÄŸeri modelimizin iÃ§in True Positive Rate (namÄ± diÄŸer recall) ve False Positive Rate (negatif Ã¶rnekler iÃ§indeki yanlÄ±ÅŸ pozitiflerin oranÄ±nÄ± Ã¶lÃ§er) deÄŸerlerinin plot edildiÄŸi bir grafiktir. Bu grafikte TPR deÄŸerlerinin FPR edÄŸerlerine gÃ¶re daha bÃ¼yÃ¼k olmasÄ±nÄ± bekleriz nedenini [Link](https://community.globalaihub.com/?status/1133-1133-1587507559/#comment.4733.4585.4585) linkinde aÃ§Ä±klamaya Ã§alÄ±ÅŸtÄ±m. En performanslÄ± durum TRP deÄŸerinin 1, FPR deÄŸerinin 0 olmasÄ±yken en performanssÄ±z durum tam tersidir.( TPR 0, FPR 1 burada negatifleri pozitif, pozitifleri negatif diye tahmin eder.)AUC ise bu grafiÄŸin altÄ±nda kalan alanÄ± integral ile hesaplayarak aslÄ±nda her threshold deÄŸeri iÃ§in TPR ve FPR hesaplamasÄ±nÄ±n yapÄ±lmasÄ±nÄ± kolaylaÅŸtÄ±rmÄ±ÅŸ olur. Her threshold iÃ§in bu hesaplamalarÄ± tek tek yapmaktansa AUC (Area Under the Curve) kullanarak bu hesaplamayaÄ± integral ile kolayca yapar. Bu linkte de bazÄ± yararlÄ± aÃ§Ä±klamalar bulabileceÄŸinize inanÄ±yorum. [Link](https://community.globalaihub.com/?status/875-875-1587486608/#comment.4706.4558.4558) Ä°yi Ã§alÄ±ÅŸmalar.Community",
2. ->  ->  aÃ§Ä±klamanÄ±z iÃ§in teÅŸekkÃ¼r ederim..",

### soru

> quest": "Merhabalar,  Alttaki L2 regularisation konusu ile ilgili olarak, sayet feature'lardan birisi label ile korrole ise, regularisation olmasa bile bu feature'un weight'i yuksek cikmayacak mi? Yani baska bir deyisle non-informative feature'larin learning modelde weight'inin yuksek cikmasinin nedeni L2 regularisation mu yoksa aslinda zaten bu feature'larin label'lar ile korrole olmasi mi? Bu durumda \"non-informative ama label ile korrole feature'larin weight'inin L2 regularisation nedeniyle yukselmesi\" ifadesi dogru olur mu?  Tesekkurler,  L2 regularization may cause the model to learn a moderate weight for some non-informative features. Surprisingly, this can happen when a non-informative feature happens to be correlated with the label. In this case, the model incorrectly gives such non-informative features some of the \"credit\" that should have gone to informative features.",

> comments": 

1. -> Merhabalar, label Ile korrole olan non informative feature in katsayÄ±sÄ± L2 regularization olmadan da yÃ¼ksek Ã§Ä±kacaktÄ±r. Ancak L2 ile korrole olmayan featurelarin katsayÄ±larÄ± sÄ±fÄ±ra yaklaÅŸÄ±rken , korrole olan non informative featureimizinda katsaysi korrole olmasÄ± sebebiyle artacaktÄ±r. Yani baÅŸlangÄ±Ã§ta dÃ¼ÅŸÃ¼k bir katsayiya sahip olup L2 sebebiyle yÃ¼kselmiyor. Korrole olmasÄ± nedeniyle zaten diÄŸer korrole olmayan featurelardan yÃ¼ksek bir katsayiya sahip oluyor. EÄŸitim sonunda da label Ile arasÄ±nda bulunan korrelasyondan dolayÄ± katsayÄ±sÄ± artiyor.Edit: but durum spurious correlation (sahte korelasyon) olarak tanÄ±mlanmaktadÄ±r. Mesela yazin dondurma tÃ¼ketimi artmaktadÄ±r, aynÄ± ÅŸekilde denizde boÄŸularak olmelerde artmaktadÄ±r. BoÄŸularak Ã¶lmeleri arastirdigimiz modelimize dondurma tuketiminide ekledigimizi dÃ¼ÅŸÃ¼necek olursak bu durumda dondurma tÃ¼ketimi yazÄ±n gerÃ§ekleÅŸen Ã¶lÃ¼mler iÃ§in etkin bir deÄŸiÅŸken gibi gÃ¶rÃ¼necektir ve yÃ¼ksek bir weight'e sahip olacaktÄ±r.Ä°yi Ã§alÄ±ÅŸmalar.",
2. -> ->  Merhaba,Bunu 1 hafta kadar Ã¶nce sormuÅŸtum fakat yanÄ±t alamamÄ±ÅŸtÄ±m. Benzer bir konu olduÄŸundan hazÄ±r sizi bulmuÅŸken tekrar sorayÄ±m. YukarÄ±da x deÄŸiÅŸkenleri ile y arasÄ±ndaki bir korelasyondan sÃ¶z edilmiÅŸ. EÄŸer modelimizdeki x deÄŸiÅŸkenleri kendi arasÄ±nda 0.7 veya 0.8'den daha bÃ¼yÃ¼k bir korelasyona sahipse hiÃ§bir ÅŸey yokmuÅŸ gibi modeli Ã§alÄ±ÅŸtÄ±rmaya devam mÄ± etmeliyiz?.",
3. ->  -> Bu problem MultiCollinearity problemi olarak tanÄ±mlanÄ±r. AÃ§Ä±klayÄ±cÄ± deÄŸiÅŸkenlerin(X'lerin) arasÄ±nda yÃ¼ksek korelasyon olmasÄ± sebebiyle karÅŸÄ±mÄ±za Ã§Ä±kar. Bu sorunu gÃ¶rmezden gelerek Ã§alÄ±ÅŸmamÄ±za devam edebiliriz. Ya da soruna sebep olan deÄŸiÅŸkenlerden birini modelden Ã§Ä±kartabiliriz. Hangisi olacaÄŸÄ±na karar vermek iÃ§in her deÄŸiÅŸkenle deneyerek model performansÄ±mÄ±za bakabiliriz. Ya da Temel BileÅŸen Analizi, FaktÃ¶r Analizi gibi bir yÃ¶ntemler ile bu Ã§oklu doÄŸrusal baÄŸlantÄ± sorununu ortadan kaldÄ±rmaya Ã§alÄ±ÅŸabiliriz.Ã–zetle ne modelimizi optimal formuna getirmek iÃ§in her tÃ¼rlÃ¼ yaklaÅŸÄ±mÄ± deneyip Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z model iÃ§in en uygun yÃ¶ntemi tespit edip, bu ÅŸekilde Ã§alÄ±ÅŸmaya devam etmeliyiz..",
4. -> ->  VIF skorlarÄ± gÃ¶zetilerek Ln veya sqrt gibi bir dÃ¶nÃ¼ÅŸÃ¼m veyahut faktÃ¶r analizi yapmanÄ±n mÃ¼mkÃ¼n doÄŸru ama benim yukarÄ±da asÄ±l sormak istediÄŸim (Bunu net sormadÄ±m Ã¼stÃ¼ kapalÄ± olarak sormak istemiÅŸtim) niÃ§im multicollinearity durumunu derslerdeki hiÃ§bir videoda veya dÃ¶kÃ¼manda gÃ¶rmÃ¼yoruz. Bu durum niÃ§in es geÃ§iliyor? AynÄ± ÅŸekilde stationary durumu da birÃ§ok Ã¶rnekle es geÃ§ilmiÅŸ. Normalde istatistiksel bir analizin temeli olan heteroscedasticity, multicollinearity ve autocorrelation gibi durumlar sÄ±rf analizi devam ettirilmek adÄ±na gÃ¶rmezden geliniyor gibi geldi. Bu ne derece anlamlÄ±?.",
5. ->  -> ML ile Ä°statistiksel Analiz birbirlerinden ince bir Ã§izgi ile ayrÄ±lÄ±r. Bu noktada amacÄ±na gÃ¶re bahsettiÄŸiniz yaklaÅŸÄ±mlardan birini ya da bir kaÃ§Ä±nÄ± tercih ederiz. AmacÄ±mÄ±z tahmin deÄŸil yorumlamak ise, multicollinearity, heteroscedasticity/ homoscedasticity, stationarity gibi faktÃ¶rler dikkate alÄ±nmak durumunda iken, bÃ¼tÃ¼n bunlaramacÄ±mÄ±z tahmin olduÄŸunda model etkinliÄŸimizi artÄ±rabilecek bileÅŸenler haline gelebilmekte.EÄŸitim iÃ§eriÄŸi makina Ã¶ÄŸrenimi Ã¼zerine olmasÄ± sebebi ile, verinin iÅŸlenmesi model iÃ§in feature seÃ§imi, bunlarÄ±n anlamlÄ±lÄ±k testleri ve bahsettiÄŸiniz durumlarÄ±n testleri gibi istatistiksel yaklaÅŸÄ±mlara yer verilmemiÅŸ. BÃ¼tÃ¼n bunlar, gÃ¶rmezden geliniyor gibi deÄŸil de farklÄ± bir eÄŸitim konusu olarak dÃ¼ÅŸÃ¼nÃ¼lebilir.",
6. -> ->  AnladÄ±m teÅŸekkÃ¼rler..",

### soru

> quest": "ArkadaÅŸlar merhaba ben L1 Regularization'Ä± ve feature cross larÄ±n ne olduÄŸunu tam anlamadÄ±m galiba. YardÄ±mlarÄ±nÄ±zÄ± bekliyorum. Ã‡ok teÅŸekkÃ¼r ederim ğŸ™‚",

> comments": 

1. -> Merhaba, [Link](https://community.globalaihub.com/?status/774-774-1586937745/#comment.4123.4009.4009) linkinde feature cross kÄ±smÄ±nÄ± aÃ§Ä±klamaya Ã§alÄ±ÅŸtÄ±m ama ulaÅŸamazsanÄ±z aÅŸaÄŸÄ±ya alÄ±ntÄ±lÄ±yorum.\"Merhaba,Ã–ncelikle Feature Cross yapmamÄ±zÄ±n sebebi modelimizin verileri tek bir lineer Ã§izgiyle ayÄ±ramamasÄ±dÄ±r. Bu yÃ¶ntemle yeni bir feature elde edip bu yeni feature modelimizin eÄŸitim sÄ±rasÄ±nda verileri daha etkili ayÄ±rÄ±p daha etkili bir hipotez fonksiyonu elde etmesinde yardÄ±mcÄ± oluyor. Ã–rneÄŸin elinizde \"dil\" ve \"Ã¼lke\" kategorik featurelarÄ± olsun.Ã–rneÄŸin dil feature deÄŸerleri: \"TÃ¼rkÃ§e, Ä°ngilizce, Japonca\"Ãœlke deÄŸerleri de: \"TÃ¼rkiye, Ä°spanya, Kanada\" olsun.Bu iki kategorik veriyi One Hot Encoding kullanarak binary vector'e Ã§evirdiniz ki modelimiz numerik veri Ã¼zerinde Ã§alÄ±ÅŸabilsin.EÄŸer siz bu iki feature'Ä± yani iki binary vector deÄŸerini Ã§arparsanÄ±z elinizde 9 elemanlÄ± bir binary vector olur. Bu binary vector deÄŸerlerinden her biri bir ihtimali temsil eder. Ã–rneÄŸin:[TÃ¼rkÃ§e ve TÃ¼rkiye,TÃ¼rkÃ§e ve Ä°spanya,TÃ¼rkÃ§e ve Kanada, Ä°ngilizce ve TÃ¼rkÃ§e,.......] gibi.Siz ilgili ihtimalin olduÄŸu indeksteki deÄŸere 1 koyduÄŸunuz anda artÄ±k o eÄŸitim Ã¶rneÄŸi iÃ§in o deÄŸer geÃ§erlidir. Ã–rneÄŸin [1,0,0,0,0,0,0,0,0] yaptÄ±ÄŸÄ±nÄ±zda artÄ±k TÃ¼rkÃ§e ve TÃ¼rkiye deÄŸerini o eÄŸitim Ã¶rneÄŸi iÃ§in deÄŸer belirlemiÅŸ olursunuz. Buradaki amaÃ§ featurelarÄ±n tek tek tahmine katkÄ±sÄ±ndan daha Ã§ok katkÄ± saÄŸlamalarÄ±nÄ± saÄŸlayabilmek. Ã–rneÄŸin dil ve Ã¼lke featurelarÄ± kend baÅŸlarÄ±na feature olarak katkÄ± saÄŸlarlar ama iki feature'Ä± Ã§arpÄ±p elde ettiÄŸimiz yeni feature tahminde daha Ã§ok katkÄ± saÄŸlayacaktÄ±r.\"L1 regÃ¼larizasyon yapmamÄ±zÄ±n sebebi feature cross sonrasÄ± oluÅŸacak sparse matrixlerdeki 0 olan feature deÄŸerlerinin weightlerini 0layÄ±p onlarÄ± ortadan kaldÄ±rmaktÄ±r. L1 regÃ¼larizasyon weight deÄŸerlerimizden her adÄ±mda sabit bir k deÄŸerini Ã§Ä±karÄ±r ve sÄ±fÄ±rlar. L2 ile karÄ±ÅŸtÄ±rÄ±lmamalÄ±dÄ±r L2 overfit olmayÄ± engellemek iÃ§in her adÄ±mda weightten kendisinin belli bir yÃ¼zdelik dilimini Ã§Ä±karÄ±p onu 0'a yakÄ±nsatÄ±r ama asla sÄ±fÄ±rlamaz. L1 ise sparse matrixteki 0 deÄŸerindeki featurelarÄ±n weight deÄŸerlerini sÄ±fÄ±rlarlar.Sorunuz olursa sorabilrsiniz.Ä°yi Ã§alÄ±ÅŸmalar.Community",
2. -> MerhabalarFeature Cross: En basit hali ile elimizde bulunan featurelarÄ±mÄ±zÄ± Ã§arpmak anlamÄ±na geliyor. Mesela:OdaSayÄ±sÄ± = [3,5,6,3] ve Konum = [12,25,9,8] olsun: Feature Cross, bu iki feature'mizi eleman dÃ¼zeyinde Ã§arparak : KonumaGÃ¶reOdaSayÄ±sÄ± = [3x12, 5x25, 6x9, 3x8] olarak yeni bir sentetik feature elde etmiÅŸ oluyoruz. AslÄ±nda yaptÄ±ÄŸÄ±mÄ±z iÅŸlem her iki diziden aynÄ± indise sahip olan elemanlarÄ± alÄ±p Ã§arparak yeni bir diziye atamak oluyor.L1 Regularization ise, modelimize bir ceza parametresi olarak eklediÄŸimiz katsayÄ±sÄ± LAMBDA olan yeni bir parametre. Ve matematiksel formÃ¼lÃ¼: model katsayÄ±larÄ±mÄ±zÄ±n mutlak deÄŸerlerinin toplamÄ± olarak ifade edilmekte.(sum(abs(W_i)), i = 1,2,... p, p= feature sayÄ±sÄ±.) AMACIMIZ optimal bir ceza ile modelimizi en sade ve en etkin formuna getirebilmek. Optimal cezayÄ± uygulayabilmek iÃ§in LAMBDA parametresinin optimum deÄŸerini tahmin etmemiz gerekmektedir.Lambda'yÄ± 0 almamÄ±z halinde kurduÄŸumuz model ile Ã§alÄ±ÅŸmaya devam etmiÅŸ oluruz. Ã‡ok bÃ¼yÃ¼k bir deÄŸer seÃ§ersek bu sefer de underfit gibi bir sorun ile karÅŸÄ±laÅŸmÄ±ÅŸ oluruz. Bunlara dikkat ederek optimal deÄŸeri bulup modelimizi kuruyor olacaÄŸÄ±z.UmarÄ±m yeterince aÃ§Ä±k olmuÅŸtur ğŸ™‚Ä°yi Ã§alÄ±ÅŸmalar.",
3. ->  ->  Hocam burada yapmaya Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z ÅŸey ÅŸu mu? Yani Ã¶rneÄŸin amacÄ±mÄ±z dÃ¼nya Ã¼zerindeki yerleÅŸim yerlerindeki median_house_value deÄŸerlerini tahmin etmek olsun. Bunun iÃ§in Ã¶rneÄŸin latitude deÄŸerleri iÃ§in 200 bucket oluÅŸturalÄ±m, longitude deÄŸerleri iÃ§in de 300 bucket oluÅŸturursak. Toplamda 200x300 = 60000 hash_bucket Ä±mÄ±z olacak. DÃ¼nyanÄ±n % 70inin su olduÄŸunu(kara parÃ§asÄ± olmadÄ±ÄŸÄ±nÄ±) varsayarsak burada bir yerleÅŸim olmayacaÄŸÄ± iÃ§in bunlarÄ±n neredeyse 60000x0.7=42000 gereksiz bu yÃ¼zden bunlarÄ±n weight deÄŸerini 0 yapmayÄ± amaÃ§lÄ±yoruz. DoÄŸru mudur acaba ? Ã‡ok saÃ§ma bir soru olmuÅŸsa kusura bakmayÄ±n ben de kafamda tam oturtamadÄ±ÄŸÄ±m iÃ§in sordum..",
4. ->  ->  merhabalar, evet dediÄŸiniz gibi modelimizde bulunan gereksiz deÄŸiÅŸkenlerin weightlerini sÄ±fÄ±rlamak amaÃ§..",
5. ->  ->  TeÅŸekkÃ¼r ederim..",
6. ->  Ã‡ok teÅŸekkÃ¼r ederim ğŸ™‚.",

 ### soru

> quest": "Merhaba ArkadaÅŸlar, EklediÄŸim kÄ±smÄ± anlayamadÄ±m. YardÄ±mcÄ± olur musunuz? TeÅŸekkÃ¼rler"

> comments": 

1. -> Merhaba,Ã–ncelikle scale invariant ÅŸu demek; Ã¶zelliklerden birini Ã¶lÃ§eklendirmek(Ã¶rneÄŸin 0'dan farklÄ± bir sayÄ± ile Ã§arpmak) tahmin deÄŸerini deÄŸiÅŸtirmez. AUC'un scale invariant olmasÄ±nÄ±n Ã¶zelliÄŸi AUC'un hesapladÄ±ÄŸÄ± deÄŸer bizim tahminlerimizin mertebe sÄ±rasÄ±, Ã¶rneÄŸin Ã¼st kÄ±sÄ±mdaki output of log reg kÄ±smÄ±na bakarsanÄ±z burada hesaplanÄ±lan seÃ§ilen herhangi bir pozitif deÄŸerin seÃ§ilen herhangi bir negatif deÄŸerin saÄŸÄ±nda olmasÄ±dÄ±r.(modelin rastgele bir pozitif Ã¶rneÄŸi rastgele bir negatif Ã¶rnekten daha yÃ¼ksek sÄ±ralamasÄ± olasÄ±lÄ±ÄŸÄ±dÄ±r.) Bunu aÃ§Ä±klamam gerekirse;[Link](https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5) linkindeki resimler Ã¼zerinden anlatÄ±mÄ±mÄ± yapayÄ±m. Bu linkteki Image 6 ve 7'ye bakarsanÄ±z bizim istediÄŸimiz en performanslÄ± model yaklaÅŸÄ±mÄ± budur. TN ve TP deÄŸerlerimizin Threshold deÄŸeri itibariyle TN solda TP saÄŸda olacak ÅŸekilde ayrÄ±lmasÄ±dÄ±r. Ama biz genelde Image 8 ve 9'daki bir curve ve plot elde ederiz. Bunun nedeni iÅŸin iÃ§ine FP ve FN girmesidir yani false tahminlerimizin girmesidir. AUC'un en optimum olduÄŸ zaman predictionlarÄ±n TN ve TP olarakl sÄ±ralandÄ±ÄŸÄ± zamandÄ±r ve bu yÃ¼zden predictionlarÄ±mÄ±zÄ± prediction deÄŸerine gÃ¶re sÄ±raladÄ±ÄŸÄ±mÄ±zda TN deÄŸerinin TP deÄŸerinin solunda kalmasÄ± beklenir. AUC zaten bunu hesaplar.1.AUC scale-invariant'tÄ±r Ã§Ã¼nkÃ¼ burada biz bir prediction deÄŸerlerinin mutlak deÄŸerleriyle deÄŸil dizilim sÄ±ralarÄ±yla ilgileniyoruz. Tekrar hatÄ±rlatmam gerekirse istediÄŸimz ÅŸey TN deÄŸerlerinin TP deÄŸerlerinin solunda olmasÄ± (rank olarak TP'den dÃ¼ÅŸÃ¼k olmasÄ±) bÃ¶ylece TN ve TP deÄŸerlerimiz iyice ayrÄ±lÄ±p AUC deÄŸerimiz 1 olabilsin.2.AUC classification-threshold-invarianttÄ±r Ã§Ã¼nkÃ¼ burada hangi threshold'un seÃ§ildiÄŸine bakÄ±lmaksÄ±zÄ±n modelin tahminlerinin kalitesini Ã¶lÃ§er.Ancak bu iki durum da bazÄ± zamanlarda AUC'un kullanÄ±labilirliÄŸini kÄ±sÄ±tlamaktadÄ±r.1.Scale invariant olmasÄ± her zaman istenen bir durum deÄŸildir Ã§Ã¼nkÃ¼ probability outputlarÄ±mÄ±zÄ±n iyi bir ÅŸekilde kalibre edilmesini isteyebilirz. Bu da ranklerden ziyade absolute valuelarÄ±na ihtiyaÃ§ duyduÄŸumuz anlamÄ±na gelit ama AUC absolute valuelar ile deÄŸil TN ve TP deÄŸerlerinin dizilim rankÄ±yla ilgileniyordu.2.Classification-threshold-invariant da her zaman istenen bir durum deÄŸildir. Bunun nedeni ise FN ve FPler arasÄ±nda fazla bir cost aÃ§Ä±ÄŸÄ± olan durumlarda bir tip classification error deÄŸerinini(Ã–rneÄŸin sadece FP) mimize etmenin kritik olabileceÄŸindendir. azaltmak kritik olabilir. Bu minimize iÅŸlemini thresholdu yeniden ayarlayarak yapabilrisiniz ama burada hatÄ±rlarsak classification-threshold-invariant sayesinde modelin performansÄ± seÃ§ilen threshold deÄŸerine bakÄ±lmaksÄ±zÄ±n Ã¶lÃ§Ã¼lÃ¼yordu. O yÃ¼zden classification-threshold-invariant Ã¶zelliÄŸi bu tÃ¼r optimizasyonlar iÃ§in pek kullanÄ±ÅŸlÄ± olmayacaktÄ±r.Ä°yi Ã§alÄ±ÅŸmalar.",
[Understanding AUC - ROC Curve]([Link](https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5)
2. ->  ->  aÃ§Ä±klayÄ±cÄ± yazÄ± iÃ§in Ã§ok teÅŸekkÃ¼rler.",
3. ->  ->  Biz threshold deÄŸerini deÄŸiÅŸtirdiÄŸimizde TPR ve FPR'i dolayÄ±sÄ±yla ROC'i grafiÄŸinin ÅŸeklini deÄŸiÅŸtirmiÅŸ oluyoruz. Mesela threshold deÄŸerini arttÄ±rdÄ±ÄŸÄ±mÄ±zda yanlÄ±ÅŸ hesaplamÄ±yorsam TPR'nin de FPR'nin dÃ¼ÅŸmesini, en iyi ihtimal sabit kalmasÄ±nÄ± bekliyoruz. Ä°kisindeki deÄŸiÅŸim oranÄ±nÄ±n aynÄ± olmasÄ± Ã§ok zor olduÄŸu iÃ§in (yani deÄŸiÅŸim oranlarÄ± farklÄ±ysa birbirlerini kompanse etmeleri zor olduÄŸu iÃ§in) grafiÄŸinin integrali yani AUC de aynÄ± kalamazmÄ±ÅŸ gibi geliyor. Bu dÃ¼ÅŸÃ¼nÃ¼ÅŸteki hata nereden kaynaklanÄ±yor, Ã§eliÅŸkinin sebebi nedir bir tÃ¼rlÃ¼ bulamadÄ±m. YardÄ±mcÄ± olabilirseniz sevinirim.",
4. ->  ->  Merhaba,ROC curve'unu farklÄ± TPR ve FPR deÄŸerleri iÃ§in Ã§iziyoruz. Bu deÄŸerler fakrlÄ± thresholdlarda deÄŸiÅŸen deÄŸerlerdir. Threshold arttÄ±ÄŸÄ± zaman TPR deÄŸerimiz azalÄ±r. Bunu nedeni TP/(TP+FN) formÃ¼lÃ¼ndeki FN deÄŸerinin threshold deÄŸeri ile artmasÄ± olacaktÄ±r. FPR de 1-TPR olduÄŸu iÃ§in TPR dÃ¼ÅŸerken FPR'nin artmasÄ±nÄ± bekleriz ama bu artÄ±ÅŸ iki tarafta da aynÄ± ÅŸekilde olmaz (simple lineer bir artÄ±ÅŸ sergilemez.) ROC, farklÄ± threshold deÄŸerleri iÃ§in belirlenen bu TPR ve FPR deÄŸerlerinin Ã§izildiÄŸi bir grafik bu grafikte de TPR ile FPR'nin deÄŸiÅŸim oranlarÄ± aynÄ± olmadÄ±ÄŸÄ± ve hata oranÄ± (FP,FN) iÃ§eren bir modelimiz olduÄŸunu varsayarsa ROC curve'Ã¼mÃ¼z parabolik bir gÃ¶rÃ¼ntÃ¼ alacaktÄ±r. Her threshold deÄŸeri iÃ§in farklÄ± bir ROC curve'Ã¼ Ã§izilmez, ROC curve'Ã¼ her threshold deÄŸeri iÃ§in TPR ve FPR deÄŸerlerini iÃ§erir. Bu mantÄ±kla ROC curve'Ã¼ sabit kalacaÄŸÄ±ndan AUC deÄŸeri de sabit kalacaktÄ±r.Ä°yi Ã§alÄ±ÅŸmalar..",
5.  ->  ->  ROC curve zaten farklÄ± thresholdlar iÃ§in bÃ¼tÃ¼n senaryolarÄ± Ã¼zerinde barÄ±ndÄ±rÄ±yor. KavramlarÄ± karÄ±ÅŸtÄ±rmÄ±ÅŸÄ±m bir an. AnladÄ±m, Ã§ok teÅŸekkÃ¼r ederim..",
6. ->  Ã‡ok net aÃ§Ä±klayÄ±cÄ± bilgilerin iÃ§in Ã§ok teÅŸekkÃ¼rler ->  iyi Ã§alÄ±ÅŸmalar,

### soru

> quest": "Merhaba ArkadaÅŸlar, Accuracy kÄ±smÄ±nda eklediÄŸim yeri tam olarak anlayamadÄ±m. YardÄ±mcÄ± olabilir misiniz? TeÅŸekkÃ¼rler",

> ![image](image/1.jpg)

> comments": 
    
1. -> Merhaba,Burada demek istediÄŸi %91 accuracy deÄŸerinizin olmasÄ± ilk baÅŸta gÃ¼zel gÃ¶rÃ¼nebilir ama her seferinde benign tahmin eden bir modelin de %91 accuracy deÄŸeri olur. YukarÄ±sÄ±ndaki Ã¶rneÄŸe bakacak olursak elimizdeki tablo ÅŸu ÅŸekilde olacak;- M - BM 1 1B 8 90Bu kÄ±smÄ±n accuracy deÄŸeri 90+1/90+1+1+8=91/100Hepsi benign tahmin edilseydi oluÅŸacak tablo:- M - BM 0 0B 9 91Ã‡Ã¼nkÃ¼ 100 tane tahminimiz vardÄ± 100'Ã¼nÃ¼ benign olarak tahmin ettik ve bunlarÄ±n 9 tanesi malignanttÄ± yani false negative oldu. 91 tanesi ise true negative oldu. Bu durumda 91+0/91+9=91/100 olur yani burada accuracy'nin veri daÄŸÄ±lÄ±mÄ±nÄ±n dengesiz olduÄŸu(negatif ve pozitif deÄŸerler arasÄ±nda ayrÄ±klÄ±k olduÄŸunda) veri setlerinde tek baÅŸÄ±na yeterli olmayacaÄŸÄ±nÄ± sÃ¶ylemekte.HatalÄ± gÃ¶rdÃ¼ÄŸÃ¼nÃ¼z yer olursa dÃ¼zeltmekten Ã§ekinmeyin.Ä°yi Ã§alÄ±ÅŸmalar.",
2. ->  Accuracy hesaplandÄ±ÄŸÄ±nda %91 Ã§Ä±kÄ±yor. Buna bakarak sÄ±nÄ±flandÄ±rmanÄ±n baÅŸarÄ±lÄ± olduÄŸunu dÃ¼ÅŸÃ¼nebiliriz ama confusion matrixi incelediÄŸimizde daha farklÄ± bir tabloyla karÅŸÄ± karÅŸÄ±ya kalÄ±yoruz. FP ve TN deÄŸerlerine bakarsak, iyi huylu tÃ¼mÃ¶re(benign) sahip 91 hastamÄ±z var ve 90 kiÅŸide benign olduÄŸu tahmin edilmiÅŸ. 1 kiÅŸi yanlÄ±ÅŸ tahmin edilmiÅŸ. Bu baÅŸarÄ±lÄ± bir tahmin. Ancak, TP ve FN deÄŸerlerine bakarsak toplam 9 kiÅŸide kÃ¶tÃ¼ huylu tÃ¼mÃ¶r(malignant) var fakat modelimiz sadece 1 kiÅŸide olduÄŸunu tahmin etmiÅŸ. Kalan 8 kiÅŸide kÃ¶tÃ¼ huylu tÃ¼mÃ¶r tespit edilememesi oldukÃ§a kÃ¶tÃ¼ bir tahmin olduÄŸunu gÃ¶sterir. Burada da diyor ki dengesiz sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸ veri setlerinde(class-imbalanced dataset) yalnÄ±zca accuracy e bakmak ve buna gÃ¶re modelin iyi tahmin yapÄ±p yapmadÄ±ÄŸÄ±na karar vermek yeterli deÄŸildir. Bu veri setimiz de oldukÃ§a dengesiz, pozitif ve negatif etiket sayÄ±sÄ± arasÄ±nda Ã¶nemli derecede bir eÅŸitsizlik var.",
3. ->  Ã‡ok teÅŸekkÃ¼rler ->  ->  arkadaÅŸlar ÅŸimdi gayet iyi anladÄ±m ğŸ™‚.",

### soru 

> quest": "Burada prediction ve identifie arasÄ±ndaki fark nedir? TeÅŸekkÃ¼r ederim.",

> comments":

1. ->  Before/After aralarÄ±ndaki fark.Yani sonuÃ§lar Ã§Ä±kmadan Ã¶nce \"predict\" kelimesi kullanÄ±lÄ±rken, sonuÃ§larÄ± alÄ±p yorumladÄ±ktan sonra \"identified, addressed, classified\" vb. daha net anlamÄ± olan kelimeler kullanÄ±rÄ±z. Ki bu ÅŸekilde sonuÃ§larÄ±n elimizde olduÄŸunu onlara gÃ¶re yorum yaptÄ±ÄŸÄ±mÄ±zÄ± belirtmiÅŸ oluruz.Edit: Pardon dikkatsizliÄŸime geldi, Recall sonucu iÃ§in yorum yapÄ±lÄ±yormuÅŸ orada.Modelin etkinliÄŸinden bahsederken x% doÄŸru tahmin ediyor ÅŸeklinde ifade edilir. Ancak Recall bir Ã¶lÃ§Ã¼m birimidir. amacÄ± da What proportion of actual positives was identified correctly? sorusuna cevap vermektir. Yani tahmin ile ilgili deÄŸil de sonuÃ§ ile ilgilidir. Hali ile elimizde bulunan bilinen birÅŸeyi yorumlarken x% doÄŸru tahmin etmiÅŸ gibi bir ÅŸey kullanmayÄ±z. YukarÄ±da yazmÄ±ÅŸ olduÄŸum ilk paragraf kÄ±smi olarak doÄŸruydu.Ä°yi Ã§alÄ±ÅŸmalar.",
2. ->  ->  TeÅŸekkÃ¼r ederim..",
3. -> Kesinlik (Precision) ise Positive olarak tahminlediÄŸimiz deÄŸerlerin gerÃ§ekten kaÃ§ adedinin Positive olduÄŸunu gÃ¶stermektedir.DuyarlÄ±lÄ±k (Recall) ise Positive olarak tahmin etmemiz gereken iÅŸlemlerin ne kadarÄ±nÄ± Positive olarak tahmin ettiÄŸimizi gÃ¶steren bir metriktir.Ä°lk cÃ¼mlede eÄŸer bizim modelimiz 0.5 precision deÄŸerine sahipse bir tÃ¼mÃ¶rÃ¼n kÃ¶tÃ¼ huylu olduÄŸunu %50 oranÄ±nda doÄŸru \"tahmin\" eder demiÅŸ.Ä°kinci cÃ¼mlede ise eÄŸer modelimiz 0.11 recall deÄŸerine sahipse tÃ¼m kÃ¶tÃ¼ huylu tÃ¼mÃ¶rlerin %11'ini doÄŸru \"teÅŸhis etmiÅŸ\" demektir demiÅŸ.Burada aslÄ±nda anlam olarak kelimeler arasÄ±nda bir fark yok. Buradak fark precision ve recall arasÄ±ndaki farktÄ±r.Precision ÅŸunu sorar, olumlu tanÄ±mlarÄ±n ne kadarÄ± gerÃ§ekten doÄŸruydu?Ne demek istiyorum?Ã–rneÄŸin positive deÄŸerimiz kurdun tehdit oluÅŸturmasÄ± olsun. Biz kurdun tehdit oluÅŸturuÅŸunu kaÃ§ kere tahmin etmiÅŸiz ve bu tahminlerin kaÃ§Ä± doÄŸruydu bunun oranÄ±nÄ± yakaladÄ±ÄŸÄ±mÄ±zda precision'I bulmuÅŸ oluyoruz. Ã–rneÄŸin biz 7 kez kurdun tehdit oluÅŸunu doÄŸru tahmin edip, 5 kez de kurt tehdit oluÅŸturmuyorken tehdit oluÅŸunu tahmin edersek precision oranÄ±mÄ±z 7/7+5'ten 7/12 olur. Yani benim kurt benim iÃ§in tehdit oluÅŸturuyor dediklerimin kaÃ§Ä±nda kurt gerÃ§ekten bizim iÃ§in tehdit oluÅŸturuyordu?Recall ise ÅŸunu sorar, gerÃ§ek pozitiflerin ne kadarÄ± doÄŸru bir ÅŸekilde tahmin edildi? Ã–rneÄŸin kurt gerÃ§ekten tehdit oluÅŸturuyorken ben bu tehditlerin kaÃ§ tanesini doÄŸru tahmin edebildim. Kurdumuz bize 20 kez tehdit oluÅŸturuyor olsun. Biz bunlarÄ±n 13 tanesini doÄŸru bir ÅŸekilde kurt tehdit oluÅŸturuyor olarak tahmin edip, 7 kez yanlÄ±ÅŸ kurt tehdit oluÅŸturmuyor dersek bizim recall oranÄ±mÄ±z (13/13+7=13/20) olur. Yani kurdun benim iÃ§in her tehdit oluÅŸturuÅŸunda ben bunlarÄ±n kaÃ§ tanesini doÄŸru bir ÅŸekilde tahmin edebildim?Daha faydalÄ± bir link iÃ§in: [Link](https://medium.com/@gulcanogundur/do%C4%9Fruluk-accuracy-kesinlik-precision-duyarl%C4%B1l%C4%B1k-recall-ya-da-f1-score-300c925feb38) Ä°yi Ã§alÄ±ÅŸmalar."
4. DoÄŸruluk (Accuracy)Â , Kesinlik(Precision)Â , DuyarlÄ±lÄ±k(Recall) ya da F1 ScoreÂ ?medium.comVeri bilimi projelerinde en doÄŸru modelin hangisi olmasÄ± gerektiÄŸine karar vermek iÃ§in iÅŸ birimlerinden gelen talepleri iyiâ€¦1 month ago 13 people like this.Like ReportReply",
5. ->  ->  TeÅŸekkÃ¼r ederim..",

### soru 

> quest": "Merhaba, Genel olarak classification modelleri hakkÄ±nda birkaÃ§ sorum var. 1) AUC ve ROC Curve modelimizde tam olarak nasÄ±l kullanÄ±lÄ±yor? FarklÄ± thresholdlara gÃ¶re tp rate ve fp ratelerimizi hesaplayÄ±p ROC curve'Ã¼ oluÅŸturuyoruz. ROC Curve'Ã¼n altÄ±nda kalan alan da AUC oluyor. Bu alan bize modelin pozitif ve negatif Ã¶rnekleri ne kadar iyi ayÄ±rt ettiÄŸini veriyor. F-score'u en yÃ¼ksek threshold da en iyi threshold oluyor. Ancak bu threshold modele nasÄ±l dÃ¶nÃ¼yor? Yani gradient descentin weightleri deÄŸiÅŸtirdiÄŸi gibi bir mekanizma var mÄ± yoksa thresholdu kendimizin mi belirlemesi gerekiyor? (ki programlama Ã¶rneÄŸinde kendimiz belirliyorduk) 2) Lojistik regresyonun hata fonksiyonu neye gÃ¶re belirlendi? Ã‡alÄ±ÅŸma mantÄ±ÄŸÄ±nÄ± tam anlayamadÄ±m. 3) Regularization kÄ±smÄ±nÄ± eklemeden Ã¶nce weightleri  kendisinden learning rate * kayÄ±p fonksiyonunun tÃ¼revini Ã§Ä±kartarak deÄŸiÅŸtiriyorduk. Regularization kÄ±smÄ±nÄ± ekleyince weightlerden bir de ilaveten lambda * regularizationun tÃ¼revini Ã§Ä±kartarak mÄ± gÃ¼ncelliyoruz? UmarÄ±m aÃ§Ä±k olmuÅŸtur. CevaplarÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederim.

> "comments": 

1. -> Merhaba,AnladÄ±ÄŸÄ±m kadarÄ±yla:1. Threshold modele dÃ¶nÃ¼yor derken biz numerik bir verimizi alÄ±p, bu numerik verimizi threshold deÄŸerinden bÃ¼yÃ¼k kÃ¼Ã§Ã¼k olma durumlarÄ±na gÃ¶re yeni sentetik bir feature Ã¼zerinden ayÄ±rÄ±yoruz. (Yeni featureÄ±mÄ±z deÄŸer>threshold ise 1, deÄŸilse 0). Biz her gradient descent yaptÄ±ÄŸÄ±mÄ±zda aynÄ± threshold Ã¼zerinden modelimiz bu tahminleri Ã¶ÄŸreniyor ve test set Ã¼zerinde yaptÄ±ÄŸÄ± tahminlerini gÃ¼Ã§lendiriyor. Programlama egzersizinde de accuracy deÄŸeri 0.8 Ã§Ä±kÄ±yordu. Burada ROC, AUC ve F skorlarÄ±nÄ±n amacÄ± sÄ±nÄ±flandÄ±rma modelimizin performansÄ±nÄ± Ã¶lÃ§Ã¼p optimum threshold deÄŸerini bulmamÄ±za yardÄ±m etmek. Burada belli threshold deÄŸerlerine gÃ¶re accuracy, recall, precision, ROC, AUC ve F skoru deÄŸerlerimiz deÄŸiÅŸiklik gÃ¶sterecektir. Burada yapmamÄ±z gereken uygun threshold deÄŸerini bu metriklere bakarak bulabilmek.2.Hata fonksiyonundan kastÄ±nÄ±zÄ± L1 ve L2 regÃ¼lariazsyonu olarak anladÄ±ÄŸÄ±m iÃ§in soruya bu ÅŸekilde cevap vereceÄŸim.L1 regÃ¼larizasyonu sparsity matrix gibi (iÃ§inde milyonlarca trilyonlarca 0 olup az sayÄ±da 1 olan matrixler) RAM'de fazlasÄ±yla yer kaplayan matrixlerin weight deÄŸerlerini sÄ±fÄ±rlamaya yarar bÃ¶ylece gereksiz 0 deÄŸerlerini RAM'de tutmak zorunda kalmayÄ±z. Yani Ã¶nemsiz feature deÄŸerlerini de bÃ¶ylece yok etmiÅŸ olur. Ã‡Ã¼nkÃ¼ L1 regÃ¼larizasyon her adÄ±mda theta'nÄ±n mutlak deÄŸerinden sabit bir deÄŸer Ã§Ä±karÄ±r. Bu metodu feature selection iÃ§in kullanabiliriz.L2 regÃ¼larizasyonu ise theta deÄŸerlerini 0'a yaklaÅŸtÄ±rÄ±r fakat tamamen sÄ±fÄ±rlamaz. Her adÄ±mda theta deÄŸerinin belli bir yÃ¼zdesini eksiltir bu nedenle theta deÄŸeri asla 0 olamaz (0'a Ã§ok yaklaÅŸsa bile) L2'yi ise overfitting durumunu Ã¶nlemek amacÄ±yla theta deÄŸerlerini cezalandÄ±rmak iÃ§in kullanabiliriz. L2'de hiÃ§bir weight sÄ±fÄ±rlanmayacaÄŸÄ± iÃ§in feature deÄŸerleri eksilmez.3. Link yÃ¶nlendirmeleri Ã§alÄ±ÅŸÄ±yor mu emin olmadÄ±ÄŸÄ±m iÃ§in ekteki resmi ekledim. Regularizasyon yaptÄ±ÄŸÄ±nÄ±zda (L2) normalde cost function'Ä±nÄ±zÄ±n sonuna theta0 dÄ±ÅŸÄ±ndaki (Ã§Ã¼nkÃ¼ onun feature deÄŸeri yok) tÃ¼m theta deÄŸerlerinin karelerinin ortalamasÄ±*lambda ekliyordunuz. Gradient descent'te de her adÄ±mda cost function'Ä±n tÃ¼revini her theta deÄŸeri iÃ§in aldÄ±ÄŸÄ±nÄ±zdan dolayÄ± formÃ¼lde Repeat kÄ±smÄ±nÄ±n altÄ±nda kalan ÅŸekle dÃ¶ner ver aslÄ±ndaa lambdamÄ±z thetamÄ±zÄ± cezalandÄ±rmÄ±ÅŸ olur.HatalÄ± kÄ±sÄ±mlarÄ±m varsa dÃ¼zeltmelere aÃ§Ä±ÄŸÄ±m.Ä°yi Ã§alÄ±ÅŸmalar.",
2. ->  ->  GÃ¶rseldeki alpha learning rate mi?.",
3. ->  ->  Evet, alpha deÄŸeri learning rate..",
4. ->  Hata fonksiyonundan kastÄ±m Log Loss idi..",
5. -> ->  Hata fonksiyonunun log loss olmasÄ±nn sebebi ÅŸu(binary classification mantÄ±ÄŸÄ±nda yani iki farklÄ± label Ã§Ä±ktÄ±mÄ±zÄ±n olduÄŸnu dÃ¼ÅŸÃ¼nerek anlatacaÄŸÄ±m. Ã–rnek iyi huylu veya kÃ¶tÃ¼ huylu tÃ¼mÃ¶r.):Lojistik regresyon 0 veya 1 arasÄ±nda olur Ã§Ã¼nkÃ¼ tahmin deÄŸeri dÃ¶ndÃ¼rÃ¼r. Sigmoid fonksiyondur. Buna istinaden de log loss fonksiyonumuz hatayÄ± tespit ederken label deÄŸeriyle tahmin deÄŸerini karÅŸÄ±laÅŸtÄ±rÄ±r, bir deÄŸerin doÄŸru tahmin edilip edilmediÄŸini kontrol eder. AÅŸaÄŸÄ±daki resimde log loss ve sigmoid fonksiyonlarÄ±nÄ±n 1 ve 0 arasÄ±nda olduÄŸunu gÃ¶rebilirsiniz. label deÄŸeriniz 1 ise ve siz 1 tahmin etmiÅŸseniz cost 0 olur, aksi halde -sonsuza kadar gider. Burad istediÄŸimiz label deÄŸerimizin doÄŸru tahmin edildiÄŸindeki ve edilmediÄŸindeki costu hesaplamak. EÄŸer siz continuous ve sonsuz bir deÄŸer kÃ¼mesi iÃ§erisindeki costu hesaplamak isteseydiniz deÄŸerlerinizi 1-0 ile kÄ±yaslamanÄ±z mantÄ±ksÄ±z olacaktÄ±.UmarÄ±m aÃ§Ä±klayÄ±cÄ± olabilmiÅŸimdir.Ä°yi Ã§alÄ±ÅŸmalar.."

![image](image/4.jpg)

6. ->  Merhaba, resimdeki yi'ler gerÃ§ek deÄŸerlerimiz. p(yi) ise tahminimiz (0 ile 1 arasÄ±nda). Dikkat ederseniz bizim gerÃ§ek y deÄŸerimiz yani label = 1 ise eÅŸitliÄŸin saÄŸ tarafÄ± tamamen 0 oluyor(1-y). label = 0 ise sol taraf tamamen 0 oluyor. Yani aynÄ± anda sadece bir taraf aktif oluyor. Tahminimiz de sol taraf iÃ§in 1 olma olasÄ±lÄ±ÄŸÄ± saÄŸ taraf iÃ§in 0 olma olasÄ±lÄ±ÄŸÄ±. Tahminimiz label'dan ne kadar uzaksa hatayÄ± ona gÃ¶re buluyoruz..

![image](image/5.jpg)

### 2.hafta quizi

> quest": "2. hafta quizi

### soru 

> quest": "Merhaba. Classification: True vs. False and Positive vs. Negative kÄ±smÄ±nda, pozitif ve negatif durumlara gÃ¶re hikaye gÃ¶z Ã¶nÃ¼ne alÄ±ndÄ±ÄŸÄ±nda False positive(FP) ve False negative(FN) durumlarÄ±nÄ±n yer deÄŸiÅŸtirmesi gerekmez mi ?  TeÅŸekkÃ¼rler.",

> comments": 

1. ->  Burada negatiflik kafa karÄ±ÅŸtÄ±rÄ±yor olabilir. Kanser testi yaparken kanserli hÃ¼cre bulunursa sonuÃ§ Pozitif Ã§Ä±kar. Bulunmazsa Negatif Ã§Ä±kar. Bu Ã¶rnekten daha iyi anlaÅŸÄ±labilir anlamlar ğŸ™‚ DoÄŸru kanserli teÅŸhis : True Positive. Kanser olmayana Kanser TeÅŸhisi : False Positive. Kanser olup da Kanser deÄŸil teÅŸhisi : False Negative. Burada testin pozitif Ã§Ä±kmasÄ± gerekirken negatif Ã§Ä±kÄ±yor. Kanser olmayana da Kanser deÄŸil sonucu : True Negative. SonuÃ§ olarak : False Positive, normalde olmamasÄ± gereken ÅŸeyi olmuÅŸ gibi tahmin etmek. False Negative ise, olmasÄ± gereken ÅŸeyi olmamÄ±ÅŸ gibi tahmin etmek.Yerine gÃ¶re FP yerine gÃ¶re de FN'ler tehlikeli olabiliyor..",
2. ->  ->  TeÅŸekkÃ¼r ederim..",
3. ->  Confusion matrix oluÅŸturulurken modelin sonuÃ§larÄ± ile gerÃ§ek durumun uyumuna gÃ¶re Ã§Ä±ktÄ±lar isimlendirilir.Positive --> Wolf (Pozitif sÄ±nÄ±f)Negative --> No Wolf (Negatif sÄ±nÄ±f)True ve False etiketi de gerÃ§ek durumla modelin uyumuna gÃ¶re atanÄ±r. EÄŸer uyum varsa True yoksa False etiketi atanÄ±r. Shepherd(model) No Wolf dediÄŸinde Negative ve yanlÄ±ÅŸ karar olduÄŸu iÃ§in False yani False NegativeShepher Wolf dediÄŸinde Positive ve yanlÄ±ÅŸ karar olduÄŸu iÃ§in False yani False PositiveBu ÅŸekilde dÃ¼ÅŸÃ¼nmen Confusion matrisini doÄŸru bir ÅŸekilde oluÅŸturmana yardÄ±mcÄ± olabilir..",
4. ->  ->  Pozitiflik ve negatiflik durumu modelin sÃ¶ylediÄŸine mi baÄŸlÄ± yoksa reality'ye mi ?.",
5. ->  ->  ->  un cevabi yeterli oldu sanirim.",
6. ->  ->  Evet teÅŸekkÃ¼r ederim..",
7. -> Confusion matrix'te kendimize y=1 deÄŸeri seÃ§eriz bu da true olur. Ã–rneÄŸin y=1 deÄŸeri kurdun tehdidi (positive) olsun. y=0 kurdun tehdit etmiyor oluÅŸu (negative) olsun.EÄŸer kurt tehdit ediyorsa ve modelimiz bunu doÄŸru tahmin etmiÅŸse true positive olur. (gerÃ§ek deÄŸer y=1, tahmin edilen y=1)EÄŸer kurt tehdit etmiÅŸse ve modelimiz kurdun tehdit etmediÄŸini tahmin etmiÅŸse false negative. (gerÃ§ek deÄŸer y=1, tahmin edilen y=0. Negatif tahmin edlmÅŸ ama yanlÄ±ÅŸ)EÄŸer kurt tehdit etmiyorsa ve modelimiz bunu yanlÄ±ÅŸ tahmin edip kurdun tehdidini tahmin etmiÅŸse false positive olur. (gerÃ§ek y=0, tahmin edilen y=1. Positive tahmin edilmiÅŸ ama yanlÄ±ÅŸ )EÄŸer kurt tehdit etmiyorsa ve modelimiz bunu doÄŸru tahmin etmiÅŸse true negative olur. (gerÃ§ek deÄŸer y=0, tahmin edilen y=0)Yani y=1 olma durumu positive, y=0 olma durumu negative.Tahmin ile gerÃ§ek deÄŸerin eÅŸleÅŸme durumu true, tahmin ile gerÃ§ek durumun eÅŸleÅŸmeme durumu false olur.Ä°yi Ã§alÄ±ÅŸmalar.",
8. ->  ->  MantÄ±ÄŸÄ±nda yanlÄ±ÅŸlÄ±k yok ancak en son paragrafÄ±nda belirttiÄŸin \"Tahmin ile gerÃ§ek deÄŸerin eÅŸleÅŸme durumu positive, tahmin ile gerÃ§ek durumun eÅŸleÅŸmeme durumu negatif olur.\" Ã¶nermesi tam olarak doÄŸru deÄŸil Ã§Ã¼nkÃ¼ positive ve negative burada label ya da classlarÄ±mÄ±z oluyor. Tahmin ile eÅŸleÅŸip eÅŸleÅŸmeme durumuna gÃ¶re True veya False olarak adlandÄ±rÄ±lÄ±yor.Ä°yi Ã§alÄ±ÅŸmalar, kolay gelsin..",
9. ->  ->  DÃ¼zeltme iÃ§in teÅŸekkÃ¼rler, ilgili dÃ¼zeltmeleri yapÄ±yorum.Ä°yi Ã§alÄ±ÅŸmalar..",
10. ->  ->  EÄŸer kurt tehdit etmiÅŸse ve modelimiz kurdun tehdit etmediÄŸini tahmin etmiÅŸse false positive. demiÅŸsiniz ancak tabloda bu durum false negative olarak gÃ¶sterilmiÅŸ. Ben de sizin dediÄŸiniz gibi dÃ¼ÅŸÃ¼nmÃ¼ÅŸtÃ¼m. Galiba yanlÄ±ÅŸ dÃ¼ÅŸÃ¼nmÃ¼ÅŸÃ¼z..",
11. ->  ->  HayÄ±r tabloda yanlÄ±ÅŸlÄ±k yok. ÅÃ¶yle aÃ§Ä±klayayÄ±m:- shepherd kurt var derse positive, kurt yok derse negative.- shepherd kurt gerÃ§ekten varken kurt var derse true positive, kurt yok derse false negative.- shepherd kurt gerÃ§ekten yokken kurt var derse false positive, kurt yok derse true negative.Buradaki yanlÄ±ÅŸ anlaÅŸÄ±lmaya tabloya reality aÃ§Ä±sÄ±ndan bakmanÄ±z yol aÃ§Ä±yor. Reality deÄŸil shepherd'Ä±n sÃ¶ylediÄŸine gÃ¶re positive ve negative'i yerleÅŸtirmelisiniz..",
12. ->  ->  TeÅŸekkÃ¼r ederim. Åimdi anladÄ±m..",
13. ->  Buradaki yazÄ±yÄ± okuyabilirsiniz, yararlÄ± olacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum. [Link](https://medium.com/@sengul_krdrl/hata-matrisini-anlamak-7035b7921c0f)
"Hata Matrisini Anlamakmedium.comVeri aldÄ±ÄŸÄ±mÄ±zda Ã¶n iÅŸleme , veri temizleme ve kurulduktan sonra ilk adÄ±m onu bitmemiÅŸ bir modele beslemek ve tabii ki olasÄ±lÄ±klarda Ã§Ä±ktÄ±â€¦",

### soru

> quest: "Merhaba, tf.keras Linear Regression egzersizlerinin kodlamalarÄ±na Ã§alÄ±ÅŸÄ±rken bu hatayÄ± alÄ±yorum. Versiyonumu da kontrol ettim 2.1.  tf.keras.metrics'ler arasÄ±nda RootMeanSquaredError Ã§Ä±kmÄ±yor. Bu durumu nasÄ±l Ã§Ã¶zebilirim ? Bunun yanÄ±nda diÄŸer hatayÄ± da aÃ§Ä±klayabilirseniz sevinirim. Sayfadaki kodda da aynen bu ÅŸekilde yazÄ±yor. Åimdiden teÅŸekkÃ¼rler.",

> comments:
  
1. ->  Import ettiÄŸiniz paketlerinizi gÃ¶zden geÃ§irin muhtemelen importlarÄ±nÄ±zda bir hata olabilir.Edit: kodunuzu paylaÅŸÄ±rsanÄ±z daha saÄŸlÄ±klÄ± Ã§Ã¶zÃ¼m yolu sunulabilir..",
2. -> import pandas as pdimport tensorflow as tffrom matplotlib import pyplot as pltdef build_model(my_learning_rate):model= tf.keras.models.Sequential()model.add(tf.keras.layers.Dense(units=1, input_shape=(1,)))model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate), loss=\"mean_squared_error\", metrics=[tf.keras.metrics.RootMeanSquaredError()])return modeldef train_model(model,feature,label,epochs,batch_size):history=model.fit(x=feature, y=label, batch_size=None, epochs=epochs)trained_weight=model.get_weights()[0]trained_bias=model.get_weights()[1]epochs=history.epochhist=pd.DataFrame(history.history)rmse=hist[\"root_mean_squared_error\"]return trained_weight, trained_bias, epochs, rmseprint(\"Defined create_model and train_model\")def plot_the_model(trained_weight, trained_bias, feature, label):plt.xlabel(\"feature\")plt.ylabel(\"label\")plt.scatter(feature, label)x0=0y0= trained_biasx1=my_feature[-1]y1=trained_bias + (trained_weight*x1)plt.plot([x0,x1], [y0,y1], c='r')plt.show()def plot_the_loss_curve(epochs, rmse):plt.figure()plt.xlabel(\"Epoch\")plt.ylabel(\"Root Mean Squared Error\")plt.plot(epochs, rmse, label=\"Loss\")plt.legend()plt.ylim([rmse.min()*0.97, rmse.max()])plt.show()print(\"Defined the plot_the_model and plot_the_loss_curve functions.\")my_feature = ([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0])my_label = ([5.0, 8.8, 9.6, 14.2, 18.8, 19.5, 21.4, 26.8, 28.9, 32.0, 33.8, 38.2])learning_rate=0.01epochs=10my_batch_size=12my_model = build_model(learning_rate)trained_weight, trained_bias, epochs, rmse = train_model(my_model, my_feature,my_label, epochs,my_batch_size)plot_the_model(trained_weight, trained_bias, my_feature, my_label)plot_the_loss_curve(epochs, rmse).",
3. ->  ->  Kodunuz sorunsuz Ã§alÄ±ÅŸmakta, herhangi bir sÄ±kÄ±ntÄ± yok, paketlerinizi manuel kurmuÅŸ iseniz versiyon sorunu yaÅŸÄ±yor olabilirsiniz, paketlerinizi kaldÄ±rÄ±p yeniden kurmayÄ± deneyebilirsiniz..",
4. ->  ->  Ä°lginiz iÃ§in teÅŸekkÃ¼r ederim. Tensorflow 1.12'ydi onu 2.1 olarak da gÃ¼ncelledim ama sorunum Ã§Ã¶zÃ¼lmedi. KaldÄ±rmayÄ± tekrar denerim..",
5. ->  Pycharm kullaniyor iseniz , keras kÃ¼tÃ¼phanesini ayrÄ± yÃ¼klemeyi deneyin. Nedense tensorflow dan import edince saÃ§ma hatalarÄ± bende alÄ±yordum. AyrÄ± ayrÄ± kÃ¼tÃ¼phaneleri yÃ¼klenince ortadan kalktÄ±..",
6. ->  ->  merhaba , muhtemelen ben de bu problemi yasiyorum fakat pycharm da keras kutuphanesini nasil ayrica yukleyecegmi bilmiyorum. nasil yukleyebilirim? teÅŸekkurler.",
7. ->  BugÃ¼ne kadar Google Colab,Spyder(Anaconda Distributed) ve Jupyter Notebook (Anaconda Distributed) platformlarÄ±nda Ã§alÄ±ÅŸÄ±p bir hata ile karÅŸÄ±laÅŸmadÄ±m.Bu platformlardan birinde Ã§alÄ±ÅŸÄ±yorsanÄ±z ve tensorflow versiyonunuzda herhangi bi sÄ±kÄ±ntÄ± yok ise, [Link](https://keras.io/) sitesinden optimizer modÃ¼llerini inceleyip sorununuzu Ã§Ã¶zebilirsiniz.
    
### soru

> quest: "Merhaba ArkadaÅŸlar, Genel bir tekrar yaparken ekteki Ã¶rneÄŸi tam anlayamamÄ±ÅŸÄ±m. YardÄ±mlarÄ±nÄ±zÄ± rica ediyorum. TeÅŸekkÃ¼rler.",

> comments:
  
1. -> RegÃ¼larizasyonda deÄŸiÅŸkenlere atanan aÄŸÄ±rlÄ±klarÄ±n karelerinin toplamÄ±nÄ±n olabildiÄŸince dÃ¼ÅŸÃ¼k tutulmasÄ± hedeflenir. Ancak bunu yaparken aÄŸÄ±rlÄ±klarÄ± olmasÄ± gerektiÄŸinden fazlasÄ±yla dÃ¼ÅŸÃ¼rmek underfitting'e; olmasÄ± gerekenden az dÃ¼ÅŸÃ¼rmek (yani regÃ¼larisyonda kullanÄ±lan lambda deÄŸerini 0 veya 0'a yakÄ±n seÃ§mek) overfitting'e sebep olur. Bu Ã¶rnekte ilk ÅŸÄ±kta bir tane feature'Ä±n aÄŸÄ±rlÄ±ÄŸÄ±nÄ± bÃ¼yÃ¼k seÃ§mekten bahsediyor. YukarÄ±daki aÃ§Ä±klamama gÃ¶re bu istenmeyen bir durum. AyrÄ±ca diÄŸer feature'larÄ±n aÄŸÄ±rlÄ±klarÄ±nÄ± 0 deÄŸerine eÅŸitlemek onlarÄ± regresyon denkleminden Ã§Ä±kartmak anlamÄ±na gelir. Yani denklemimiz y = B0 + w1* b1 olmakla kalÄ±r ki bu da istemediÄŸimiz bir durum. DiÄŸer deÄŸiÅŸkenleri boÅŸuna denklemde kullanmamÄ±ÅŸtÄ±k. BÃ¶yle yaparak muhtemel bir underfitting'e sebep olduk. Ä°kinci ÅŸÄ±k da ilk ÅŸÄ±kka benzer. 1 feature yÃ¼ksek aÄŸÄ±rlÄ±ÄŸa sahipken diÄŸerlerinin aÄŸÄ±rlÄ±ÄŸÄ± 0'a yakÄ±nsak durumda. Tek farkÄ± feature'larÄ± direkt denklemden atmaktansa dÃ¼ÅŸÃ¼k aÄŸÄ±rlÄ±klar vererek model Ã¶ÄŸrenme kapasitesini sÄ±nÄ±rlandÄ±rmÄ±ÅŸ oluyoruz. Bu da yine bir underfitting ile karÅŸÄ±laÅŸmamÄ±zÄ± muhtemel kÄ±lÄ±yor.Genel manada dÃ¼ÅŸÃ¼nÃ¼rsek; anlamlÄ± bir regÃ¼larizasyon iÃ§in tek ve/veya birden fazla (ancak tÃ¼m featurelar deÄŸil) feature'a odaklanmak yeterli bir regÃ¼larisyon saÄŸlamÄ±yor. KÄ±sa bir Ã¶rnek ile bitireyim. Ä°lk ÅŸÄ±k iÃ§in 4 feature ile aÃ§Ä±kladÄ±ÄŸÄ±mÄ±z bir denklemimiz olsun ve ilkinin aÄŸÄ±rlÄ±ÄŸÄ± 5 iken diÄŸerleri 0 olsun. Kareler toplamÄ± 25 edecektir. 3. ÅŸÄ±k iÃ§in yine 4 feature'umuz olsun fakat aÄŸÄ±rlÄ±klarÄ± sÄ±rasÄ±yla 0.2, 0.5, 0.1 ve 0.2 olsun. Bu durumda kareler toplamÄ±mÄ±z yalnÄ±zca 0.34 edecektir. 3. ÅŸÄ±kkÄ±n doÄŸru olmasÄ±nÄ±n mantÄ±ÄŸÄ± da budur.,
2. -> Merhaba,Soruda bir modelimiz ve bu modelimizde birbirine karakteristik olarak benzeyen, korelasyonlu ama birinin kÃ¼Ã§Ã¼k miktarda rastgele noise iÃ§erdiÄŸi feature'Ä±mÄ±z olduÄŸunu sÃ¶ylemiÅŸ. EÄŸer bu modeli L2 regulazosyonu ile eÄŸitrsek bu iki feature'In weight deÄŸerleri ne olur demiÅŸ.1.ÅŸÄ±k iÃ§in: Bir feature bÃ¼yÃ¼k weight deÄŸerine sahip olurken diÄŸer feature'In weight'Ä° 0 olur demiÅŸ. Bu ÅŸu yÃ¼zden yanlÄ±ÅŸtÄ±r:L2 regularizasyonumuz aÄŸÄ±rlÄ±klarÄ± neredeyse 0'a yakÄ±nsamaya zorlar. Bu yÃ¼zden diÄŸer weight 0 olmaycakaÄŸÄ±ndan bu cevap elendi.2.ÅŸÄ±k iÃ§in: l2 regularizasyonumuz bÃ¼yÃ¼k weightleri kÃ¼Ã§Ã¼k weightlere gÃ¶re daha Ã§ok cezalandÄ±rÄ±r ve 0'a yakÄ±nsatÄ±r. [Link](http://community.globalaihub.com/community/status/1191-1191-1587125026/#comment.4315.4196.4196) linkindeki yorumumdaki resimde gradient descent formÃ¼lÃ¼ne bakarsanÄ±z thetaj ne kadar bÃ¼yÃ¼k olursa dÃ¼ÅŸÃ¼ÅŸÃ¼ o kadar fazla olur. (1-alpha rate*(lambda/m)) theta j ile Ã§arpÄ±lÄ±r thetaj ne kadar bÃ¼yÃ¼kse kÃ¼Ã§Ã¼lme o kadar fazla olur. Bu yÃ¼zden kÃ¼Ã§Ã¼k weight deÄŸerleriyle bÃ¼yÃ¼k weight deÄŸerlerinin sÄ±fÄ±ra yakÄ±nsadÄ±klarÄ± deÄŸerler arasÄ±nda uÃ§urum olmaz.3.ÅŸÄ±k iÃ§in: Bu sorunun cevabÄ±nÄ± 2.ÅŸÄ±kta verdim. BÃ¼yÃ¼k weight deÄŸerleri kÃ¼Ã§Ã¼k weight deÄŸerlerine gÃ¶re daha Ã§ok ezalandÄ±rÄ±lacaÄŸÄ± iÃ§in 0'a yakÄ±nsadÄ±klarÄ± deÄŸer aynÄ± olacak birbirine fazlasÄ±yla yakÄ±ndÄ±r.Ä°yi Ã§alÄ±ÅŸmalar.",
3. ->  Åimdi kavramlar net oldu bende arkadaÅŸlar Ã§ok teÅŸekkÃ¼rler ->  -> .",
    
### soru

> quest: "Bu denklemdeki log(x) in amacÄ± nedir yani iÃ§indeki deÄŸiÅŸkene ne yaptÄ±ÄŸÄ± iÃ§in Ã§ok fazla kullanÄ±yorlar. EÄŸer logaritmayla alakalÄ± bi ÅŸeyse logaritmanÄ±n machine learningdeki iÅŸlevinide kÄ±saca aÃ§Ä±klayabilir misiniz?. TeÅŸekkÃ¼rler.",

![image](image/6.jpg)

> comments:
  
1. ->  Merhaba,Burada log kullanmamÄ±zÄ±n sebebini aÅŸaÄŸÄ±daki resimdeki log loss fonksiyonlarÄ±mÄ±zÄ±n grafikte gÃ¶steriminden gÃ¶rebiliriz. Resmimizde kÄ±rmÄ±zÄ± ile altÄ±nÄ± Ã§izdiÄŸim kÄ±smÄ± alÄ±rsak y=1 ve y=0 iken neden cost function farklÄ±lÄ±ÄŸÄ± olduÄŸunu gÃ¶rebilriz. Lojistik regresyonda amacÄ±mÄ±z 1 ve 0 arasÄ± bir olasÄ±lÄ±k elde etmek olduÄŸu iÃ§in cost function'Ä±mÄ±zda da 0-1 arasÄ±ndaki logaritmik bir doÄŸru elde etmeliyiz.(0-1 Ã§Ã¼nkÃ¼ sigmoid fonksiyonumuz y ekseninde 0-1 arasÄ±nda ). Lojistik regresyonda y=1 iÃ§in sonucu iÃ§in h(x) sonucumuzun da 1 olmasÄ±nÄ± bekleriz yani tahmini doÄŸru gerÃ§ekleÅŸtirmesini bekleriz, eÄŸer h(x) 0 olursa costumuz -sonsuza yaklaÅŸÄ±r yani costumuz oldukÃ§a artar. Lojisik regresyon problemlerimizi lineer regresyonla Ã§Ã¶zemeyeceÄŸimiz iÃ§in farklÄ± bir yaklaÅŸÄ±m sergilememiz gerekti. AklÄ±nÄ±za takÄ±lan bir ÅŸey olursa sormaktan Ã§ekinmeyin.Ä°yi Ã§alÄ±ÅŸmalar.",

![image](image/7.jpg)

2. ->  ->  Merhaba, Niye squared loss oldugunu anlamadim.",
3. ->  ->  Merhaba,Squared loss derken nereyi kastettiniz? Sorunuzu tam anlayamadÄ±m. Loss function'da 0-1 arasÄ± bir Ã§Ä±ktÄ± Ã¼reteceÄŸimiz iÃ§in log kullanÄ±yoruz..",
4. -> Modelin tahmin etmesini istediÄŸimiz deÄŸerler 0 ve 1 olduÄŸu iÃ§in log loss kullanÄ±yoruz.Ã–rneÄŸin, bir input iÃ§in beklenen output 0 ise ve model 1 tahmininde bulunduysa, log loss'un bÃ¼yÃ¼k bir deÄŸer Ã¼retmesini bekliyoruz. (model kÃ¶tÃ¼ bir tahminde bulunmuÅŸ.)Bir input iÃ§in beklenen output 0 ise ve model 0 tahmininde bulunduysa, log loss'un kÃ¼Ã§Ã¼k bir deÄŸer Ã¼retmesini bekliyoruz. (model iyi bir tahminde bulunmuÅŸ.)Benzer ÅŸekilde, beklenen output 1 ise ve model 0.8 tahminini yaptÄ±ysa, log loss nispeten kÃ¼Ã§Ã¼k olacak ancak 1 tahmininde bulunsaydÄ± log loss daha da kÃ¼Ã§Ã¼k olacaktÄ±.",
5. -> Bunun ana temelini merak ediyorsan matematiksel olarak aynÄ± sonuca Ã§Ä±kmalarÄ±. Olay kÄ±saca ÅŸuModelinin tahmin ettiÄŸi deÄŸerlerin doÄŸruluÄŸunu Ã¶lÃ§men iÃ§in ÅŸÃ¶yle bir Ã¶rnek vereyimElinde kÄ±rmÄ±zÄ± ve mavi noktalar var. Bu noktalarÄ± bulunan bir dikdÃ¶rtgende mavi ve kÄ±rmÄ±zÄ± noktalara yerleÅŸtirmesini istiyorsun. Yani kÄ±z ve erkek var diyelim kÄ±zlarÄ± kÄ±zlarla gruplandÄ±rmak erkekleri erkeklerle gruplandÄ±rmak istiyorsun veya.Model 1 ve Model 2 aÅŸaÄŸÄ±da ki gibi tahminler Ã¼retiyor.( Tahmini Ã‡izgi olarak dÃ¼ÅŸÃ¼n kÄ±rmÄ±zÄ± ve mavi alanÄ± ayÄ±ran)Buna gÃ¶re kÄ±rmÄ±zÄ± noktalarÄ±n gerÃ§ekten kÄ±rmÄ±zÄ±da olma olasÄ±lÄ±ÄŸÄ± ve mavi noktalarÄ±n doÄŸru yerde olma olasÄ±klarÄ± verilmiÅŸ. Bu modelin doÄŸruluÄŸunu anlamak iÃ§in tÃ¼m olasÄ±lÄ±klarÄ± Ã§arpman ve Ã§Ä±kan sayÄ±ya bakman lazÄ±m. Ã–rneÄŸin saÄŸda ki modelde kÄ±rmÄ±zÄ± iki nokta iÃ§in kÄ±rmÄ±zÄ± alanda olma olasÄ±lklarÄ± , ve mavi noktalarÄ±n mavi alanda olma olasÄ±lÄ±klarÄ± verilmiÅŸ ( Bu model Ã§Ä±ktÄ±larÄ± olasÄ±lÄ±klarÄ±)Burda gÃ¶rdÃ¼ÄŸÃ¼n Ã¼zere daha dÃ¼zgÃ¼n modelde bu Ã§arpÄ±m daha yÃ¼ksek Ã§Ä±kÄ±yor , daha kÃ¶tÃ¼ tahmin eden modelde daha dÃ¼ÅŸÃ¼k. Eee hala niye log yapÄ±yoruz dersen olay ÅŸu ki burda 4 tane Ã¶rneÄŸimiz var ve bu Ã¶rnek normal bir model kat kat fazla ve bu Ã§arpÄ±m iÅŸlemi bilgisayarÄ± / iÅŸlem gÃ¼cÃ¼nÃ¼ gereksiz yorar. Bunun yerine matematiksel olarak aynÄ± iÅŸlemi veren log yapÄ±yoruz. Ã‡arpÄ±m iÅŸleriminin logunu alÄ±nca toplama iÅŸlemi olur ( Lise matematiÄŸi ğŸ™‚ ) ve bu iÅŸlemi Ã§arpmadan loga Ã§evirdiÄŸimizde logloss ve crossentropy loss gibi kavramlar ortaya Ã§Ä±kÄ±yor (cross entropide log loss'un binary classification dÄ±ÅŸÄ±nda kullanmak iÃ§in) Tabi olasÄ±lÄ±klar 1 ile 0 arasÄ±nda olduÄŸu iÃ§in bunlarÄ±n loglarÄ± - sayÄ±lar olucak malum log 1 = 0 log 0 = tanÄ±msÄ±z , log 1 ile log 0 arasÄ±nda ki deÄŸerler negatif deÄŸerler. Åimdi olasÄ±lÄ±klarÄ±n logunu alÄ±unca misal log(0.8) ( bunlar 10 tabanÄ±nda veya 2 tabanÄ±nda farketmiyor Ã§ok ben 10 diye dÃ¼ÅŸÃ¼nÃ¼yorum ÅŸuan)log (0.8) = -0.096log ( 0.2) = -0.69gÃ¶rdÃ¼ÄŸÃ¼n Ã¼zere sayÄ± deÄŸeri dÃ¼ÅŸÃ¼k olan log , gene daha kÃ¼Ã§Ã¼k Ã§Ä±kÄ±yor ( negatif sayÄ±larda - (sayÄ± bÃ¼yÃ¼dÃ¼kÃ§e - sonsuza yaklaÅŸÄ±r )bu sebeple bunlarÄ±n Ã§Ä±ktÄ±larÄ±nÄ± direk karÅŸÄ±laÅŸtÄ±rÄ±rmak zor oluyor negatiflerini alÄ±yoruz ve log'un negatifliÄŸinden kurtuluyoruz. Burdan da toplama yapÄ±lÄ±nca daha demin gÃ¶sterdiÄŸim Ã§arpma iÅŸleminin benzeri olayla Log sayÄ±larÄ±nÄ±n negatif alÄ±nmÄ±ÅŸ toplamÄ± bÃ¼yÃ¼k olanlar yÃ¼ksek Ã§Ä±kÄ±yor buda kÃ¶tÃ¼ demek yani . Misal log0.2 negatifi alÄ±nca 0.69 , bu tarz kÃ¶tÃ¼ tahminler sayÄ±yÄ± yÃ¼kseltip yÃ¼ksek bir loss yani fazla hata olmuÅŸ oluyorBiraz uzun oldu ama ğŸ™‚",

### soru 

> quest: "Quiz gayet gÃ¼zel ve seviyeli olmuÅŸ kod kÄ±smÄ±ndan ziyade mantÄ±k odaklÄ± olmuÅŸ ki iÅŸin en Ã¶nemli kÄ±smÄ± olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yorum. KodlarÄ±n arkadÄ±nda neler olduÄŸunu anlamak iÃ§in makine Ã¶ÄŸrenmesini matematiÄŸini anlamak adÄ±na YouTube da Ä°lker Birbil HocanÄ±n \"Makine Ã–ÄŸrenmesi\" dersleri var. Ã‡ok fayalÄ± olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yorum. Linkini burdan paylaÅŸÄ±yorum \"Google Machine Learning Crash Course\" beraber takip ederseniz Ã§ok faydalÄ± olacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum. Herkese iyi Ã§alÄ±ÅŸmalar diliyorum. [Link](https://www.youtube.com/watch?v=eKrnMr--bDY&amp;list=PLZcbvMjrj9DVU6g2A5e6voeigUtSMsAJH) 

> comments": 
    1. ->  Ã§ok teÅŸekkÃ¼rler, Ã§ok gÃ¼zel bir iÃ§erik..",
    2. ->  ->  iyi Ã§alÄ±ÅŸmalar.",
    3. ->  Kaynak iÃ§in teÅŸekkÃ¼r ederim, Ã§ok yararlÄ± bir paylaÅŸÄ±m olmuÅŸ..",
    4. ->  ->  iyi Ã§alÄ±ÅŸmalar.",
### soru 

> quest": "Merhabalar. Lojistik regresyonda  regularization un extrem Ã¶nemli olduÄŸu sÃ¶ylenmiÅŸ fakat Ã¶nemini kavrayamadÄ±m. \"Without regularization, the asymptotic nature of logistic regression would keep driving loss towards 0 in high dimensions. \" Åu cÃ¼mleyi matematiksel olarak aÃ§Ä±klayabilir misiniz?",

> comments":

1. ->  Merhaba,Lojistik regresyonda hipotez fonksiyonumuz lineer deÄŸil sigmoid bir fonksiyon olur. (Resimde gÃ¶rebilirsiniz.) Asimptode fonksiyon olan sigmoid fonksiyonumuz 1 ve 0'a yakÄ±nsayarak x ekseni boyunca sonsuza gider. Burada doÄŸasÄ± gereÄŸi yÃ¼ksek boyutlarda 0'a yaklaÅŸmaya devam eder dediÄŸi budur. YÃ¼ksek boyut dediÄŸi fazla feature olmasÄ±dÄ±r ve fazla feature demek weight deÄŸerlerinin fazla ve komplikeye yakÄ±n olmasÄ± demek. RegÃ¼larizasyonun weight deÄŸerlerini azalttÄ±ÄŸÄ±nÄ± biliyoruz bu yÃ¼zden kritik bir Ã¶neme sahiptir. [Link](http://community.globalaihub.com/community/status/1191-1191-1587125026/#comment.4315.4196.4196) linkindeki gradient descent fonksiyonu lojistik regresyon iÃ§in de geÃ§erlidir YalnÄ±z tek fark hipotez fonksiyonumuz artÄ±k 1/1+e^(-thetatranspose*X vector) yani sigmoid fonksiyonumuzdur.Ä°yi Ã§alÄ±ÅŸmalar.",
2. ->  ->  TeÅŸekkÃ¼r ederim. Ben yÃ¼ksek boyuttan 2 ve daha fazla featurelÄ± datalar yani uzayda Ã§ok boyutlu vektÃ¶rler oluÅŸturan datalar olduÄŸunu anlamÄ±ÅŸtÄ±m.",
3. ->  ->  Merhaba,AslÄ±nda orada demek istediÄŸim adet olarak yÃ¼ksek weight deÄŸerleriydi ama yanlÄ±ÅŸ anlaÅŸÄ±lmaya mahal vermemek iÃ§in dÃ¼zelttim. DÃ¼zeltme iÃ§in teÅŸekkÃ¼r ederim. YÃ¼ksek boyu tdediÄŸimiz fazla feature deÄŸerimiz buna baÄŸlÄ± olarak fazla ve yÃ¼ksek sayÄ±da weight deÄŸerlerimizin olmasÄ±dÄ±r..",
4. -> ->  high dimensions durumunda loss'un 0'a gitmesini engellemek icin regularization yapilmasinin onemli oldugu belirtiliyor. Training'in amaci loss'u minimize etmek iken (normalde loss'un 0'a yaklasmasini isterken), burada loss'un kontrolsuzce 0'a gitmesini istemiyoruz, cunku bu senaryoda loss 0'a giderken ogrenme yapilamiyor, diyebilir miyiz?.",
5. ->  -> Regularizasyon bizim modelimizin basitlik ile karmaÅŸÄ±klÄ±ÄŸÄ± arasÄ±ndaki dengeyi saÄŸlamalÄ±dÄ±r. Loss 0'a giderken Ã¶ÄŸrenme yapÄ±lÄ±rken overfit olur ve modelimiz eÄŸitim setini ezberler bÃ¶ylece artÄ±k test loss'umuz artmaya baÅŸlar.Ä°yi Ã§alÄ±ÅŸmalar..",

### soru 

> quest": "Regularization for Simplicity: Playground Exercise (L2 Regularization)'da bu sonuca nasÄ±l vardÄ±k?",

> comments": 

1. ->  Merhaba,Modeli eÄŸittikten sonra featurelar ile output arasÄ±ndaki baÄŸlantÄ±larÄ±n Ã¼zerine mouse ile gelirsen her bir feature iÃ§in weight deÄŸerini gÃ¶sterecektir. Verilen task 1'i Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±nda regularization kullanmÄ±yorsun, 500 epoch sonra her bir feature iÃ§in weight deÄŸerlerini bir yere not al. Task2'de regularization rate deÄŸeri 0.3 olarak verip 500 epoch sonrasÄ± weight deÄŸerlerini kontrol et. Weight deÄŸerlerinin task 1'e gÃ¶re 0'a yakÄ±n olarak konumlandÄ±ÄŸÄ±nÄ± gÃ¶receksin.Bunun sebebi L2 regularization iÅŸleminin modeldeki kompleksliÄŸi azaltmasÄ± yani weight deÄŸerlerini 0'a yaklaÅŸtÄ±rmasÄ±dÄ±r.Ä°yi Ã§alÄ±ÅŸmalar.",

### soru 

> quest": "Merhaba ArkadaÅŸlar,  Regularization for Simplicity: Playground Exercise bÃ¶lÃ¼mÃ¼nÃ¼n Task 3'Ã¼nÃ¼n cevabÄ±nda :  \"Given the randomness in the data set, it is impossible to predict which regularization rate produced the best results for you. For us, a regularization rate of either 0.3 or 1 generally produced the lowest Test loss.\" demiÅŸ.  Ama ben regularization rate'i 0.1 yaptÄ±ÄŸÄ±mda 0.3 ve 1'e gÃ¶re daha dÃ¼ÅŸÃ¼k test loss'u elde ettim. Ekte gÃ¶rebilirsiniz. Acaba ben mi bir yerlerde hata yaptÄ±m. YardÄ±mcÄ± olursanÄ±z sevinirim. Ã‡ok teÅŸekkÃ¼rler.",

> comments": 

1. ->  Merhaba,Bende de 0.1 lambda deÄŸeri en optimum test loss deÄŸerine sahip. Bir hata yaptÄ±ÄŸÄ±nÄ±zÄ± dÃ¼ÅŸÃ¼nmÃ¼yorum, Bunun kontrolÃ¼nÃ¼ ben de yaptÄ±m ve sanÄ±rÄ±m o kÄ±sma yanlÄ±ÅŸ yazÄ±lmÄ±ÅŸ. EÄŸer bunun bir hata olduÄŸunu dÃ¼ÅŸÃ¼nen varsa bizi dÃ¼zeltebilir.Ä°yi Ã§alÄ±ÅŸmalar..",
2. ->  Bende de Ã¶yle, KullandÄ±klarÄ± dataset ile ilgili olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yorum mesela sol Ã¼stteki dataset iÃ§in dedikleri doÄŸru.",
3. ->  tÄ±rnak iÃ§erisinde belirttiÄŸin ifadeden anlayabildiÄŸim kadarÄ±yla playground exerciselerda generate edilen herbir dataset iÃ§in belirli oranda bir rastgelelik sÃ¶zkonusu. o nedenle optimum parametre deÄŸerleri deÄŸiÅŸebiliyor. bende de 0.3 lambda deÄŸeri optimum sonucu veriyordu mesela..",
4. ->  Merhabalar, lamda deÄŸerini biraz daha kÃ¼Ã§Ã¼ltmen lazÄ±m, gÃ¶rselde farklÄ± lambda deÄŸerleri iÃ§in elde edilen sonuÃ§larÄ± ekledim,yeÅŸil olanlardan herhangi biri iyi sonuÃ§ veriyor,aradaki fark 0.01 civarÄ±nda.",


### soru  

> quest": "Merhaba. Regularization kÄ±smÄ±nda, lambda deÄŸerinin bÃ¼yÃ¼k olmasÄ± durumunda modelin underfit olmasÄ±nÄ±n ve tersi durumda overfit olmasÄ±nÄ±n sebebini kafamda oturtamadÄ±m. AÃ§Ä±klayabilir misiniz ? TeÅŸekkÃ¼rler.",

> comments": 

1. ->  Merhaba Furkan,Lambda deÄŸeri L2 regularization iÅŸleminin sonuca ne kadar fazla etki edeceÄŸini belirleyen hiperparametredir. Lambda deÄŸerini genellikle 0 ile 1 arasÄ±nda konumlandÄ±rÄ±yoruz. EÄŸer lambda deÄŸeri 0 olursa regularization uygulanmayacak demektir. Bizim regularization ile amacÄ±mÄ±z overfitting engellemek, dolayÄ±sÄ±yla Ã§ok dÃ¼ÅŸÃ¼k lambda deÄŸeri overfittingi engellemeyecektir. Ã‡ok yÃ¼ksek bir deÄŸer seÃ§ersek de bu sefer modeldeki Ã§oÄŸu weight hÄ±zlÄ±ca baskÄ±lanacaktÄ±r ve Ã¶ÄŸrenme tam anlamÄ±yla gerÃ§ekleÅŸemeyecektir, bundan dolayÄ± underfitting oluÅŸabilir.Ä°yi Ã§alÄ±ÅŸmalar.",
2. ->  ->  TeÅŸekkÃ¼r ederim..",
3. ->  anladÄ±ÄŸÄ±m kadarÄ± ile regularization iÃ§in loss ve complexity deÄŸerleri arasÄ±nda bir denge sÃ¶zkonusu. bu dengeyi lambda deÄŸeri ile saÄŸlamaya Ã§alÄ±ÅŸÄ±yoruz. lambda deÄŸerini yÃ¼ksek vermemiz durumunda model complexitysini azaltmaya odaklanÄ±yoruz ancak daha basit bir model tahmin deÄŸerlerinin istenilenden dÃ¼ÅŸÃ¼k olmasÄ±na (underfit) neden olabiliyor. aksi durumda, yani lambda deÄŸerini dÃ¼ÅŸÃ¼k verdiÄŸimiz durumda bu kez basit bir modelden ziyade daha doÄŸru tahmini veriler verebilecek bir modeli Ã¶nceliklendirmiÅŸ oluyoruz. bu da daha kompleks, overfitting nedeni ile test verileri ile daha uyumlu ancak yeni veriler ile tahminde muhtemelen daha baÅŸarÄ±sÄ±z olacak bir modele neden oluyor. bu nedenle lambda deÄŸerini optimize etmek gerekiyor diye anladÄ±m. yanlÄ±ÅŸ anladÄ±ysam dÃ¼zeltme gelirse sevinirim..",
4. ->  ->  TeÅŸekkÃ¼r ederim..",


### soru 

> quest": "Merhaba,  Regularization 'da playground exercise kÄ±smÄ±nda task2'de aÃ§Ä±klama kÄ±smÄ±nda cok fazla feature cross kullanmak eÄŸitim verisindeki gÃ¼rÃ¼ltÃ¼ye uyma fÄ±rsatÄ± olur buda testte kÃ¶tÃ¼ baÅŸarÄ±ya neden olur mu demek istiyor?Yani training yaparken training verisindeki gÃ¼rÃ¼ltÃ¼ye uymamasÄ± mÄ± lazÄ±m modelin?  TeÅŸekkÃ¼rler",

> comments": 

1. ->  Merhaba,Modelimiz ne kadar fazla feature iÃ§erirse o kadar weight iÃ§erir ve daha da komplike olur. Komplike oldukÃ§a hipotez fonksiyonumuz eÄŸitim setindeki noise datalarÄ± bile ezberler bÃ¶ylece eÄŸitim lossumuz Ã§ok dÃ¼ÅŸÃ¼k olur. YalnÄ±z bu eÄŸitim setimizi Ã§ok iyi ezberleyen ve karmaÅŸÄ±k olan modelimiz yeni gelen veri tahminini yapamayacaktÄ±r Ã§Ã¼nkÃ¼ sadece eÄŸitim verisini ezberleyip hipotez fonksiyonunu sadece eÄŸitim setini bilecek gibi oluÅŸturmuÅŸtur. (Grafikte eÄŸitim setini Ã§ok gÃ¼zel ve hatasÄ±z ÅŸekilde ayÄ±rmÄ±ÅŸtÄ±r ama yeni gelen veriyi grafikte konumlandÄ±rmakta ve analiz etmekte baÅŸarÄ±lÄ± olamayacaktÄ±r.)Ä°yi Ã§alÄ±ÅŸmalar.",
2. ->  ->  TeÅŸekkÃ¼rler:).",

> quest: "Regularization kÄ±smÄ±nda playgroundda regularization ratei arttÄ±rdÄ±ÄŸÄ±mda nedense test loss artmaya baÅŸladÄ±. Cevapta 0 dan 0.3 e Ã§ektiÄŸinde test lossda gÃ¶zle gÃ¶rÃ¼lÃ¼r bir azalma gÃ¶receksin diyor.",

> comments:

1. ->  Merhaba,Modeli her eÄŸittinizde aynÄ± training ve test loss deÄŸerlerini almazsÄ±nÄ±z. Muhtemelen tekrar eÄŸittiÄŸinizde bu sonucun deÄŸiÅŸtiÄŸini gÃ¶receksiniz. hger Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±ndaki test ve training loss deÄŸiÅŸiminin sebebi modelimizdeki verilerin test,train ve validation olarak ayrÄ±lmadan Ã¶nce shuffle edilmesidir.Regularization her gradient descent adÄ±mÄ±nda weight deÄŸerlerini daha da 0'a yakÄ±ndattÄ±ÄŸÄ± iÃ§in loss deÄŸerleri daha da dÃ¼ÅŸÃ¼klÃ¼k gÃ¶sterecektir.Ä°yi Ã§alÄ±ÅŸmalar.",
2. ->  Merhabalar,HatalÄ± deÄŸilsem training data size ve batch size gibi deÄŸerlerde deÄŸiÅŸiklik yaparak test etmiÅŸsiniz.Sonucunuzun beklenen ÅŸekilde olmayÄ±ÅŸÄ± bu parametrelerin hatalÄ± seÃ§iminden olabilir, varsayÄ±lan olarak gelen deÄŸerler ile testinizi yaparsanÄ±z azalma olduÄŸunu gÃ¶rebilirsiniz.Ä°yi Ã§alÄ±ÅŸmalar.,
3. ->  Merhaba,aÅŸaÄŸÄ±daki gÃ¶rsel ile lambda parametresini aÃ§Ä±klamaya Ã§alÄ±ÅŸtÄ±m.",
    

### soru 

> quest: "Merhaba ArkadaÅŸlar, Lower Learning rate (with early stopping), gÃ¼Ã§lÃ¼ L2 regularization ile aynÄ± etki yarattÄ±ÄŸÄ±nÄ± anladÄ±m. Ama eklediÄŸim 2 paragrafta tam ne anlatÄ±lmak isteniyor anlayamadÄ±m. YardÄ±m olabilirseniz Ã§ok sevinirim. Ã‡ok teÅŸekkÃ¼rler.",

> comments:

1. ->  Merhaba,Datasetine sÃ¼rekli olarak bir data akÄ±ÅŸÄ± varsa yani sÃ¼rekli yeni example'lar ekleniyorsa datanÄ±n trendi zamanla deÄŸiÅŸebileceÄŸi iÃ§in elinizdeki datayla hatayÄ± iyice dÃ¼ÅŸÃ¼recek (converge edecek) kadar train etmiyoruz, training i erken bitiriyoruz Ã§Ã¼nkÃ¼ yeni trendi anlayacak kadar elimizde data yok diyor. Bir de yeni gelen data iÃ§in daha genel bir modelimiz olmuÅŸ oluyor ve test loss azalÄ±yor.Ä°kinci sÃ¶ylediÄŸi de early stopping ve regularization rate benzer etkilere sahip. Siz optimum regularization rate i bulmak istiyorsanÄ±z early stopping etkisi olmamalÄ±, sadece regularization rate etkisi olmalÄ±. Bu yÃ¼zden iterasyon sayÄ±sÄ±nÄ± bÃ¼yÃ¼k seÃ§in ki early stopping olmasÄ±n sadece regularization rate in etkisini gÃ¶rÃ¼n diyor anladÄ±ÄŸÄ±m kadarÄ±yla ğŸ™‚",
2. -> Merhaba,Burada early stopping yani erken durdurmadan bahsetmiÅŸ. Erken durdurmak modelimiz eÄŸitilirken modelimiz tam yakÄ±nsamadan eÄŸitimi durdurmak demektir. YazdÄ±ÄŸÄ±nÄ±z gibi lower learning rate kullanÄ±p modelinizin eÄŸitmini tam yakÄ±nsamadan durdurursanÄ±z lambdanÄ±n oluÅŸturacaÄŸÄ± etkiyi oluÅŸturur. Nerede durduracaÄŸÄ±mÄ±zÄ± da ÅŸÃ¶yle bilebiliriz: validasyon setimizin loss oranÄ± artÄ±yorsa eÄŸitimi orada bitirirsiniz ki tahminleri optimum bir ÅŸekilde yapabilecek overfit olmayan bir model elde edebilelim.Lambda ile learning rate parametrelerinin etkilerini karÅŸÄ±laÅŸtÄ±rabilirsiniz. Bunu gÃ¶zlemleyebilmek iÃ§in ben ÅŸÃ¶yle bir ÅŸey yaptÄ±m(Her iki adÄ±mda da 1000 epoch ile eÄŸittim):1.Playground'da Regularization:None dedim ve learning rate deÄŸerini 0.1'e ayarlayarak eÄŸitim iÅŸlemini baÅŸlattÄ±m. Test ve Training loss deÄŸerleri Ã¶nce dÃ¼ÅŸmeye baÅŸladÄ± ama epoch sayÄ±sÄ± arttÄ±kÃ§a training loss deÄŸeri minimum deÄŸerde sabit kalÄ±yorken test loss deÄŸeri sÃ¼rekli artmaya baÅŸladÄ±. EÄŸer training loss en minimum deÄŸere gelmeden biraz Ã¶nce early stopping yapsaydÄ±k ve eÄŸitimi yarÄ±da kesseydik hem test hem de training loss deÄŸerleri optimum seviyede olacaktÄ±.2.Learning rate deÄŸerimi 0.1'den deÄŸiÅŸtirmeden regularization:L2 seÃ§tim ve regularization rate deÄŸerimizi 0.1 olarak ayarladÄ±m. EÄŸitimi baÅŸlatÄ±p beklediÄŸimde hem test hem training datanÄ±n deÄŸerlerinin 0'a olabildiÄŸince yakÄ±nsadÄ±ktan sonra minimum deÄŸerde kaldÄ±klarÄ±nÄ± ve 1.adÄ±mÄ±mÄ±n aksine test loss deÄŸerinin artmadÄ±ÄŸÄ±nÄ± gÃ¶zlemledim. Buradan Ã§Ä±karacaÄŸÄ±mÄ±z sonuÃ§ learning rate eÄŸer eÄŸitimi erken durdurursak lambda ile aynÄ± etkiyi oluÅŸturur.Ä°yi Ã§alÄ±ÅŸmalar.",
3. ->  Ã‡ok teÅŸekkÃ¼rler arkadaÅŸlar ->  ->  . Ä°yi Ã§alÄ±ÅŸmalar..",

### soru 

> quest: "Merhaba, ÅŸurada anlatÄ±lan aÃ§Ä±klamalarÄ± tam anlayamadÄ±m. YardÄ±mcÄ± olabilir misiniz?",

> comments:
  
1. ->  Merhaba,Burada bu model karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± iki ÅŸekilde ele aldÄ±ÄŸÄ±ndan bahsediyor.-Modelimizdeki weightler model karmaÅŸÄ±klÄ±ÄŸÄ±mÄ±zdÄ±r. Modelimizdeki weightlerin mutlak deÄŸeri ne kadar bÃ¼yÃ¼kse o kadar karmaÅŸÄ±ktÄ±r. Ã–rneÄŸin 25x1+7x2 olduÄŸunu varsayarsak x1 feature'Ä±mÄ±zÄ±n weight deÄŸeri x2 feature'Ä±mÄ±zÄ±n weight deÄŸerinden daha karmaÅŸÄ±ktÄ±r diyebiliriz.BaÅŸka bir Ã¶rnek olarak -150x1+77x2 dersek yine x1'in weight'i x2'nin weight deÄŸerine gÃ¶re daha karmaÅŸÄ±k olacaktÄ±r. Zaten regÃ¼larizasyon iÅŸlemimiz de karmaÅŸÄ±klÄ±ÄŸÄ± azaltmak yani weight deÄŸerlerini olabildiÄŸince 0'a yaklaÅŸtÄ±rmak. Weight ne kadar 0'a yaklaÅŸtÄ±rsa o kadar basit olur. (Fazla basit olursa underfitting, fazla komplike olursa overfitting olur.)-DiÄŸer karmaÅŸÄ±klÄ±k yaklaÅŸÄ±mÄ± ise sÄ±fÄ±rdan farklÄ± weight deÄŸerlerine sahip feature sayÄ±sÄ± modelimizin karmaÅŸÄ±klÄ±ÄŸÄ± olur.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 13 people like this.Like ReportReply",
2. ->  ->  TeÅŸekkÃ¼r ederim ÅŸimdi anladÄ±m..",
    
### soru 

> quest: "Bucket enlem ve boylarÄ±mÄ±zÄ± bÃ¶ldÃ¼ÄŸÃ¼mÃ¼z zaman binnning yaptÄ±ÄŸÄ±mÄ±zda karÅŸÄ±mÄ±za Ã§Ä±kan [0,0,0,1,0,0,0] grubunun adÄ± deÄŸil mi ya da bu iÅŸlemin adÄ±? Åu kÄ±smÄ± ben tam anlayamadÄ±m. Bucket ve Crosses Feature arasÄ±ndaki fark...  Bucket'te mi ayrÄ± bir yÃ¶ntem yani? UmarÄ±m derdimi anlatabilmiÅŸimdir. Åimdiden teÅŸekkÃ¼rler.",

> comments:
  
1. ->  Merhaba,Evet, bucket sizin yazdÄ±ÄŸÄ±nÄ±z her bir binary vectordÃ¼r. AralarÄ±ndaki farkÄ± [Link](http://community.globalaihub.com/community/status/519-519-1587052575/#comment.4259.4239.4239) linkinde bunu anlatmaya Ã§alÄ±ÅŸtÄ±m. Sorunuz olursa tekrar sorabilirsiniz.Ä°yi Ã§alÄ±ÅŸmalar..",
    
### soru 

> quest: "Merhaba ArkadaÅŸlar, Feature Crosses - Playground Exercises kÄ±smÄ±nda neden X1 ve X2 yerine X12 ve X22'yi seÃ§tiÄŸimizi anlayamadÄ±m. Ve X12 ve X22 neyi ifade ediyor tam anlayamadÄ±m.  DiÄŸer bir sorum :  \"If you enter a negative value for the feature cross, the model will separate the blue dots from the orange dots but the predictions will be completely wrong. \" ifadesinde neden negatif deÄŸer girersek tahminler yanlÄ±ÅŸ olur kÄ±smÄ± tam net oturmadÄ±.  Ã‡ok teÅŸekkÃ¼rler",

> comments:
  
1. -> Merhaba,Burada verimizin daÄŸÄ±lÄ±mÄ±na bakarsak bu problemimiz lineer regresyonla Ã§Ã¶zÃ¼lemez yani y=w0+w1x1+w2x2+...+wmxm tarzÄ±nda bir yaklaÅŸÄ±m kullanamayÄ±z. Peki bunun iÃ§in ne yapabiliriz? Elimizdeki feature deÄŸerlerindenm sentetik deÄŸerler Ã¼retmeyi deneyebiliriz veya elimizdeki feature deÄŸerlerini evaluate edebiliriz. Ama ben burada biraz matematiksel bir hileye kaÃ§acaÄŸÄ±m.(KaÃ§mayacaksam de elimdeki featurelar Ã¼zerinden yeni featurelar ve feature deÄŸerleri elde etmeye Ã§alÄ±ÅŸacaktÄ±m tabi bunu bir anda yapmayacak hangi feature verilerinin bu iÅŸlemlere gireceÄŸini analiz ile belirleyecektim.) Veri daÄŸÄ±lÄ±mlarÄ±nÄ± incelediÄŸimizde mavilerin ortada dairesel ÅŸekilde toplandÄ±ÄŸnÄ± ve turuncularÄ±n da Ã§evresinde toplandÄ±klarÄ±nÄ± gÃ¶rebiliyorum. AÅŸaÄŸÄ±daki resimde dairenin formÃ¼lÃ¼nÃ¼n x^2+y^2=r^2 olduÄŸunu biliyorum. Bu yÃ¼zden elde edeceÄŸim yeni feature deÄŸeri kareli bir deÄŸer olmalÄ±. Burada x12 x1'in karesi, x22 ise x2'nin karesi demek oluyor. Bu nedenle bizim de bu outputta dairesel bir Ã§Ä±ktÄ± elde edebilmemiz iÃ§in featurelarÄ±mÄ±zÄ±n karesini alÄ±p bu problemi linear regresyondan polynomial regression'a Ã§evirmemiz gerekiyor. Bu yÃ¼zden x1^2 ve x2^2 kullandÄ±k.\"If you enter a negative value for the feature cross, the model will separate the blue dots from the orange dots but the predictions will be completely wrong. \" kÄ±smÄ±nda ise ÅŸunu demek istemiÅŸ: Siz eÄŸer x1x2 feature'Ä±na negatif bir deÄŸer verirseniz verileriniz yine dÃ¼zgÃ¼n ayrÄ±lacaktÄ±r. Ama negatif deÄŸer verdiÄŸinz iÃ§in grafikte gÃ¶rÃ¼nen turuncu deÄŸerleri mavi deÄŸerler olarak, grafikte gÃ¶rdÃ¼ÄŸÃ¼nÃ¼z mavi deÄŸerleri de turuncu deÄŸer olarak tahmin edecektir.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 25 people like this.Like ReportReply",
2. ->  Ã‡ok teÅŸekkÃ¼rler ->  Ã§ok net anladÄ±m. Ä°yi Ã§alÄ±ÅŸmalar.",
    

### soru 

> quest: "Merhabalar, Feature Crosses : Playground Exercises : More Complex Feature Crosses : Task2 de cevabÄ±n neden \"Using both x1^2 and x2^2 as feature crosses. (Adding x1x2 as a feature cross doesn't appear to help.)\" olduÄŸunu anlayamadÄ±m. YardÄ±mcÄ± olabilirseniz sevinirim.",

> comments:
  
1. ->  Merhaba,[Link](http://community.globalaihub.com/community/status/1133-1133-1587160937/#comment.4376.4241.4241) linkinde bunu aÃ§Ä±klamaya Ã§alÄ±ÅŸtÄ±m. Sorunuz olursa sormaktan Ã§ekinmeyin.Ä°yi Ã§alÄ±ÅŸmalar..",
2. ->  ->  TeÅŸekkÃ¼rler, anlamama yardÄ±mcÄ± oldunuz..",
    

### soru 

> quest: "Merhaba.  Bu histogramÄ± tam olarak anlayamadÄ±m. Weight Frequency kavramÄ± ile ne temsil ediliyor ?",

> comments:
  
1. ->  Merhaba,Ã–ncelikle lambda'nÄ±n weight deÄŸerileri Ã¼zerine etkisini anlamak iÃ§in [Link](http://community.globalaihub.com/community/status/1191-1191-1587125026/#comment.4315.4196.4196) yorumunu okuyabilirsiniz.Lambda deÄŸeri ne kadar bÃ¼yÃ¼k olursa weight deÄŸerleri o kadar kÃ¼Ã§Ã¼lÃ¼r yani 0'a o kadar yaklaÅŸÄ±r. AÅŸaÄŸÄ±da kÃ¼Ã§Ã¼k bir kÄ±smÄ± Ã§Ä±kmÄ±ÅŸ resimde de lambda deÄŸerini kÃ¼Ã§Ã¼ltÃ¼rseniz histogramÄ±nÄ±z dikleÅŸmeye baÅŸlar Ã§Ã¼nkÃ¼ weight deÄŸerleriniz Ã§ok az bir kÃ¼Ã§Ã¼lme gÃ¶sterir yani 0'a Ã§ok az yaklaÅŸÄ±m gÃ¶sterir.Ä°yi Ã§alÄ±ÅŸmalar.,
2. -> Her Ã§ubuk belli bir deÄŸer aralÄ±ÄŸÄ±nÄ± (min_deÄŸer, max_deÄŸer) temsil ediyor. Ã‡ubuÄŸun uzunluÄŸu ise, weight'lerin kaÃ§ tanesinin o deÄŸer aralÄ±ÄŸÄ±nda olduÄŸunu ifade ediyor.,
3. ->  TeÅŸekkÃ¼r ederim..",

### soru 

> quest: "Merhaba ben feature crosses kÄ±smÄ±nÄ± tamamen anladÄ±ÄŸÄ±mÄ± dÃ¼ÅŸÃ¼nÃ¼yorum ama aklÄ±ma takÄ±lan bir konu var. Åu linkte [Link](https://developers.google.com/machine-learning/crash-course/feature-crosses/crossing-one-hot-vectors\) binned_latitude ve binned_longtitudede her ikisininde 5 elemanÄ± var. ve bunlarÄ±n cross productÄ±nÄ±n sonucu 25 elemanlÄ± bir vektÃ¶r olmuÅŸ oluyor cross product sonucunda normalde aynÄ± boyutta bir vektÃ¶r bulmamÄ±z gerekmezmiydi burda nasÄ±l bir istisna oluÅŸtu.",

> comments:
  
1. ->  a = [0,1,2,3,4]b = [0,1,2,3,4]a x b = [(0,0),(0,1),(0,2),(0,3),(0,4),(1,0), ... ,(1,4),..(4,0), ... ,(4,4)]Ã§arpÄ±m bu ÅŸekilde olduÄŸundan 25 elemanlÄ± vektÃ¶r oluÅŸuyor..",
2. ->  ->  VerdiÄŸim linkte ÅŸÃ¶yle bir ÅŸey geÃ§iyordu. The term cross comes from cross product. Ben aslÄ±nda bu yaptÄ±ÄŸÄ±mÄ±z iÅŸlem 3 boyutlu vektÃ¶rlerin cross productÄ±yla bir ilgisi olup olmadÄ±ÄŸÄ±nÄ± merak etmiÅŸtim. Ã‡Ã¼nkÃ¼ bildiÄŸim kadarÄ±yla 3 boyutlu vektÃ¶rÃ¼n Ã¶tesinde cross product alamÄ±yoruz ve iki vektÃ¶rÃ¼n cross productÄ± bize yine 3 boyutlu bu iki vektÃ¶re dik bir vektÃ¶r daha veriyordu..",
3. ->  The term cross comes from cross product ifadesinin geÃ§tiÄŸi yerin ss'ini gÃ¶nderebilirmisin ?.",
r. ->  YanlÄ±ÅŸ link yollamÄ±ÅŸÄ±m pardon. ["Feature Crosses: Encoding Nonlinearity Â |Â  Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course/feature-crosses/encoding-nonlinearity)
5. >  ->  Burada Ã¼Ã§Ã¼ncÃ¼ deÄŸiÅŸkenin ilk iki deÄŸiÅŸkenin cross product'Ä± ile elde edildiÄŸini sÃ¶ylÃ¼yor..",
6. ->  \"Ã‡Ã¼nkÃ¼ bildiÄŸim kadarÄ±yla 3 boyutlu vektÃ¶rÃ¼n Ã¶tesinde cross product alamÄ±yoruz \" kanÄ±sÄ±na nereden vardÄ±n..",
7. -> AslÄ±nda bin'ler arasÄ±ndaki iÅŸlem kartezyen Ã§arpÄ±m (cartesian product). Bence \"The term cross comes from cross product.\" ifadesindeki \"cross product\" referansÄ± yanÄ±ltÄ±cÄ± olmuÅŸ. Zira burada matematikte bildiÄŸimiz anlamÄ±yla \"cross product\" iÅŸlemi gerÃ§ekleÅŸmiyor..",

### soru {

> quest: "Merhaba, ÅŸu kÄ±smÄ± anlayamadÄ±m, neden binlere ayÄ±rÄ±yoruz ve neden o ÅŸekilde encode ediyoruz?",

> comments:
  
1. ->  Merhaba,[Link](http://community.globalaihub.com/community/status/875-875-1586778150/#comment.3974.3871.3871) bu yorumda binning'Ä° anlatmaya Ã§alÄ±ÅŸtÄ±m. AklÄ±nÄ±za hala soru takÄ±lÄ±rsa sorabilirsiniz.Ä°yi Ã§alÄ±ÅŸmalar.,
2. ->  ->  teÅŸekkÃ¼r ederim.",

### soru 

> quest: "Merhaba arkadaÅŸlar. Ben L2 Regularization ve Lambda kÄ±smÄ±nÄ± tam anladÄ±ÄŸÄ±mÄ± dÃ¼ÅŸÃ¼nmÃ¼yorum. YardÄ±mcÄ± olabilir misiniz? TeÅŸekkÃ¼rler ????",

> comments:
  
1. -> Merhaba,Ã–ncelikle regÃ¼larizasyon yapmamÄ±zÄ±n sebebi overfit durumunu Ã¶nlemek. Gradient descent algoritmamÄ±z her seferinde optimum deÄŸere yaklaÅŸmak iÃ§in eÄŸitim modelini validation modele gÃ¶re ayarlar (yani ilgili weight deÄŸerlerinin ayarlamasÄ±nÄ± yapar.) Burada regularizasyonun gÃ¶revi komplex modeli cezalandÄ±rmak.Kompleks model ne demek?Biz kompleks modelin iki tanÄ±mÄ±yla ilgileneceÄŸiz:1. Modeldeki tÃ¼m featurelarÄ±n aÄŸÄ±rlÄ±klarÄ±(weight deÄŸerleri)2. DeÄŸeri 0'dan farklÄ± olan feature sayÄ±sÄ±mÄ±z.Kompleks modelimizi nasÄ±l cezalandÄ±racaÄŸÄ±z?YukarÄ±daki kompleks model tanÄ±mÄ±ndan da anlayacaÄŸÄ±mÄ±z Ã¼zere burada weight deÄŸerlerini azaltarak modelin karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± azaltmaya Ã§alÄ±ÅŸacaÄŸÄ±z. Weight deÄŸeri yÃ¼ksek olan featurelar modeli daha da karmaÅŸÄ±klaÅŸtÄ±rÄ±r. Bu yÃ¼zden weight deÄŸerleri 0'a ne kadar yakÄ±nsa model o kadar az kompleks yani basittir. Ama burada ÅŸÃ¶yle bir husus var. Weight deÄŸerlerinin 0'a acayip yakÄ±n olmasÄ± y=w0+w1x1+w2x2+....+wmxm denkleminde tÃ¼m w deÄŸerlerini 0'a yakÄ±nsatacaÄŸÄ±ndan bu denklemi sadece y=w0 ele alÄ±rsak burada high bias durumu yani underfitting oluÅŸur. Tam tersi durumu dÃ¼ÅŸÃ¼nÃ¼rsek de weight deÄŸerleri training seti ezberleyecek kadar karmaÅŸÄ±k olacaÄŸÄ±ndan overfitting (high variance) olur yani tahmin iÃ§in yeni gelen datanÄ±n tahmininde baÅŸarÄ±sÄ±z olur.CezalandÄ±rma iÅŸlemi iÃ§in cost function denklemimize regularization term dediÄŸimiz denklemi ekliyoruz. Yani yeni cost function'Ä±mÄ±z resimdeki gibi oluyor.Burada her bir weight deÄŸerinin karelerinin toplamÄ±nÄ±n ortlamasÄ±nÄ± alÄ±p regularization parametremizle Ã§arpÄ±yoruz yalnÄ±z w0'Ä± eklemiyoruz Ã§Ã¼nkÃ¼ w0 deÄŸerimiz herhangi bir feature'a ait bir weight deÄŸil, bias deÄŸeri. Bu parametrenin Ã¶nemi gradient descent adÄ±mÄ±mÄ±za baktÄ±ÄŸÄ±mÄ±zda ortaya Ã§Ä±kÄ±yor. Burada hweight0 dÄ±ÅŸÄ±ndaki tÃ¼m weightlere regularization uygulanÄ±yor. EÄŸer yeÅŸil kutucuÄŸa aldÄ±ÄŸÄ±m yerde learning rate'i iÃ§eri daÄŸÄ±tÄ±p thetaj parantezine alÄ±rsanÄ±z thetaj'nin kaysayÄ±sÄ±nÄ±n (1-learningrate*(lambda/m)) olduÄŸunu gÃ¶rebilirsiniz. Burada regularization parametresi Ã§ok Ã¶nemli Ã§Ã¼nkÃ¼ thetaj'yi 0'a fazla yakÄ±n veya fazla uzak bir deÄŸer yaparsanÄ±z yukarÄ±da bahsettiÄŸim overfitting ve underfitting problemlerine kapÄ± aÃ§mÄ±ÅŸ olursunuz. O yÃ¼zden burada lambdayÄ± optimum seÃ§ebilmek Ã§ok Ã¶nemli.UmarÄ±m resim ve anlatÄ±mÄ±m aÃ§Ä±klayÄ±cÄ±dÄ±r :)Ä°yi Ã§alÄ±ÅŸmalar.,
    

### soru

> quest: "Bu koddaki -tf.feature_column.numeric_colum()- gibi fonksiyonlarÄ±n kullanÄ±mÄ±nÄ± ve mantÄ±ÄŸÄ±nÄ± bilmemiz ÅŸuanlÄ±k yeterli midir yoksa fonksiyonlarÄ± tamamen ezberleyip bu ÅŸekilde yazmamÄ±z mÄ± gereklidir. TeÅŸekkÃ¼rler.",

> comments:
  
1. ->  MantÄ±ÄŸÄ±nÄ± ve kullanÄ±mÄ±nÄ± bilmeniz ÅŸimdilik yeterli. Zamanla kullandÄ±kÃ§a mutlaka ezbere yapabileceksiniz..",
    
### soru 

> quest: "Merhaba, burada posta kodu nasÄ±l daha iyi bir feature oluyor? Arada linear iliÅŸki olmamasÄ±na raÄŸmen posta kodlarÄ±nÄ± kullanÄ±rsak linear bir iliÅŸki oluÅŸturmaz mÄ±yÄ±z?",

> comments:
  
1. -> Merhaba,AnladÄ±ÄŸÄ±m kadarÄ±yla biz latitude ve longitude deÄŸerlerinden spesifik bir koordinat Ã¼retmeye Ã§alÄ±ÅŸÄ±yoruz ama bu koordinat deÄŸerleri aslÄ±nda binlenmiÅŸ deÄŸerler ve Ã¶rnek anlamlarÄ± ÅŸu ÅŸekilde: 0<lat<60 ve 25<long<77 Yani iki feature'Ä± (latitude ve longitude) birbiri ile Ã§arptÄ±k ve yeni bir feature elde ettik. Yeni bir feature elde etmemiz demek yeni bir weight deÄŸeri elde etmemiz demek ve bu da modelimizin daha karmaÅŸÄ±k olmasÄ± demek. (Model kompleksitemiz weight sayÄ±sÄ± ve deÄŸerleriyle doÄŸru orantÄ±lÄ±dÄ±r.) EÄŸer siz aynÄ± iÅŸlevi gÃ¶recek ve binlenmeye (yani kategorize edilmeye) ihtiyaÃ§ duymayan numerik bir deÄŸer bulabilirseniz hem bu verileri binlemenize gerek kalmaz (ki bunun hem zaman hem space kompleksitesinden de kurtulmuÅŸ olursunuz) hem de model kompleksiteniz daha az olur. Neticede posta kodu her mahalle iÃ§in unique'tir. Burada posta kodu kullanacaksanÄ±z ve sizin eviniz iki sokaÄŸÄ±n kÃ¶ÅŸesindeyse multi-hot encoding yapÄ±p bu deÄŸerleri binary vector'e alabilme imkanÄ±nÄ±z vardÄ±r veya tek yerdeyse one hot encoding ile de binary vector feature deÄŸerleri elde edebilirsiniz. YalnÄ±z Ã¶nceki Ã¶rneÄŸe nazaran iki feature deÄŸeri Ã§arpÄ±p 3.bir feature elde edip bu iÅŸlemlerimi ona gÃ¶re yapmaktansa verisetimdeki posta kodu feature'Ä±nÄ± yaparak tÃ¼m bu iÅŸlemleri gerÃ§ekleÅŸtirebildim.Ä°yi Ã§alÄ±ÅŸmalar.",

### soru    

> quest: "Ben crossing one-hot vectors kÄ±smÄ±nda verilen Ã¶rneÄŸi anlayamadÄ±m. Feature Crosses kÄ±smÄ±nda biraz zorlandÄ±m galiba...   CevaplarÄ±nÄ±z iÃ§in ÅŸimdiden teÅŸekkÃ¼r ederim.",

> comments:
  
1. ->  binned_latitude ve binned_longitude deÄŸerleri belirli aralÄ±ktaki enlem ve boylamlarÄ± temsil ediyor. Bunlara feature cross uyguladÄ±ÄŸÄ±mÄ±zda ise, AND operatorÃ¼ uygulamÄ±ÅŸ oluyoruz. Yani fiyatÄ±nÄ± tahmin etmek istediÄŸimiz evimizin enlem deÄŸeri 15 derece ve boylam deÄŸeri 13 derece olsun. Feature cross kullanarak tÃ¼m olasÄ± enlem ve boylam aralÄ±klarÄ±nÄ± yazÄ±yoruz ve bizim Ã¶rneÄŸimizin iÃ§inde bulunduÄŸu aralÄ±ÄŸÄ± 1, diÄŸerlerini 0 yapÄ±yoruz. Ã–rneÄŸimiz; 10 < lat <=20 VE 0 < lon <=15 aralÄ±ÄŸÄ±nda bulunuyor. Bunu aynÄ± ÅŸekilde one-hot temsili ile gÃ¶sterip tahmin oranÄ±(predictive power) daha iyi bir feature oluÅŸturmuÅŸ oluyoruz.",
2. ->  AnladÄ±ÄŸÄ±m kadarÄ±yla Feature Crosses kÄ±smÄ±nda yapmaya Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z ÅŸey ÅŸuna benziyor; Ã¶rneÄŸin birinin boy ve kilo verisi var elimizde bu kiÅŸinin obezite olup olmadÄ±ÄŸÄ±nÄ± tahmin etmeye Ã§alÄ±sÄ±yoruz bunun iÃ§in direk boy ve kiloyu kullanarak oluÅŸturulcak model yerine bu 2 feature'Ä± kullanarak vÃ¼cut kitle indexi olan sentetikbir feature oluÅŸturup daha gÃ¼zel bir temsil yapmayÄ± istiyoruz. AynÄ± ÅŸekilde Feature Crosses kÄ±smÄ±nda da Ã¶rnek Ã¼zerinde latitude ve longitude tek tek kullanmak yerine crosslayÄ±p iÅŸlem yaparak daha iyi bir temsil yapmayÄ± amaÃ§lÄ±yoruz. Hatam varsa dÃ¼zeltirseniz sevinirm.",
3. -> Åimdi anladÄ±m cevaplar iÃ§in Ã§ok teÅŸekkÃ¼r ederim ğŸ™‚.",

### soru     

> quest: "Merhaba, Neden train ve validation loss egrilerinin birbirine cok yakin olmasini saglamamiz gerektigi konusunda bir yerde takiliyorum. Bana cok yakin olmamalari generalization icin daha iyi bir sey gibi geliyor. Yani loss farki fazlayda iki kumenin birbirine daha az benzedigi gibi bir dusuncem oluyor. Bu da generalization icin istenen birsey olamaz mi? Validation set dersindeki programlama egzersizinde train, val, test hatalarinin birbirine cok yakin oldugu bulunuyor. Bu saglanmasi gereken ve ideal bir durum mu?",

> comments:
  
1. ->  Merhaba. Modelimizi train veri kÃ¼mesi ile eÄŸitirken, validation ve test setlerinde test ediyoruz. EÄŸer train lossâ€™u dÃ¼ÅŸÃ¼k, validation lossâ€™u yÃ¼ksekse ve aralarÄ±nda Ã§ok fark varsa, modelimizin hiÃ§ gÃ¶rmediÄŸi bir veri kÃ¼mesinde kÃ¶tÃ¼ performans sergilediÄŸi iÃ§in overfit olduÄŸu ve kÃ¶tÃ¼ bir model olduÄŸunu gÃ¶rÃ¼rÃ¼z, test setinde test etmemize gerek kalmaz. AsÄ±l amaÃ§, modeli train ettikten sonra val ve train loss curvelerinin yakÄ±n olmasÄ±, ardÄ±ndan test loss curveâ€™nin diÄŸer iki curveâ€™e yakÄ±n olmasÄ±dÄ±r, generalizationda asÄ±l istediÄŸimiz de bu zaten, overfitting olmamasÄ±. Ä°yi Ã§alÄ±ÅŸmalar.",
2. ->  ->  tesekkurler.",

### soru 

> quest: "Herkese merhaba  Ben Representation with a Feature Crossda kod parÃ§acÄ±ÄŸÄ±na yazÄ±lan resolution_in_degrees deÄŸiÅŸkenini neden kullandÄ±ÄŸÄ±mÄ±zÄ± anlayamadÄ±m",

> comments:
  
1. ->  Merhaba,Binning yapma iÅŸlemi sÄ±rasÄ±nda verdiÄŸiniz boundaries listesine gÃ¶re numerik deÄŸerleri gruplandÄ±rma iÅŸlemi yapar. Ã–rneÄŸin elinizde yaÅŸlar verileri var ve bunlarÄ± binning ile gruplamak istiyorsunuz. Sizin boundaries listeniz: [10,20,30,40,50,60,70,80,90] olursa bu sÄ±nÄ±rlar iÃ§in gruplandÄ±rmalar yapar. Buna gÃ¶re 76 ile 77 aynÄ± grupta olacaktÄ±r. Bunun iÃ§in ise numpy'In arange metodu kullanÄ±lmÄ±ÅŸtÄ±r. np.arange(minimum deÄŸer, maksimum deÄŸer, minimumdan maksimuma giderken kaÃ§ar kaÃ§ar artacaÄŸÄ±) buradaki resolution_in_degrees deÄŸiÅŸkeni ise bu artÄ±ÅŸÄ±n kaÃ§ar olacaÄŸÄ±nÄ± belirlemek iÃ§in kullanÄ±lmÄ±ÅŸtÄ±r. VerdiÄŸim yaÅŸ Ã¶rneÄŸinde bu deÄŸer 10 iken, Representation with a Feature Cross Ã¶rneÄŸimizde 1'dir.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 12 people like this.Like ReportReply",
2. ->  ->  Ã§ok teÅŸekkÃ¼r ederim ğŸ˜€.",
3. -> ->  Merhaba, anlamadÄ±ÄŸÄ±m ÅŸey ÅŸu,Bu gruplara bucket denmiyor mu? Åu TASK 4'te takÄ±ldÄ±m. TeÅŸekkÃ¼rler ğŸ™‚.",
4. ->  Merhaba,SanÄ±rÄ±m burada bucket olarak bahsettiÄŸi ÅŸey iki feature'Ä±n ayrÄ± ayrÄ± binning yapÄ±lÄ±p oluÅŸturduÄŸu bucketlar yani binningden sonra oluÅŸan binary vectorler. (Longitude ve latitude featurelarÄ± ayrÄ± ayrÄ± binning yapÄ±ldÄ±lar.) Feature cross dediÄŸi ÅŸey ise longitude ve latitude iÃ§in bu ayrÄ± yapÄ±lan binning featurelarÄ±nÄ±n Ã§arpÄ±lmasÄ± ve ortaya Ã§Ä±kan yeni binary vector deÄŸeri. Burada sormak istediÄŸi ÅŸey ise siz bu featurelarÄ± Ã§arpmadan ikisini de binning yaparsanÄ±z performans ne olur (featurelar ayrÄ± weight deÄŸerlerine sahip olursa ne olur?), iki feature'Ä±n binninglerini Ã§arparsanÄ±z ne olur? (Ä°ki feature'Ä± Ã§arpÄ±p sentetik bir feature elde ederseniz ve tek bir weight deÄŸeriniz olursa performans ne olur?).UmarÄ±m aÃ§Ä±klayÄ±cÄ± olabilmiÅŸimdir :)Ä°yi Ã§alÄ±ÅŸmalar.",
5. -> ->  Ã‡okk teÅŸekkÃ¼r ederim Fethi bey....",
6. ->  -> Ben teÅŸekkÃ¼r ederim iyi Ã§alÄ±ÅŸmalar..",


### soru 

> quest: "Merhabalar , Representation kÄ±smÄ±nda one-hot encoding ile multi-hot encoding arasÄ±nda farkÄ± anlayamadÄ±.Bunun dÄ±ÅŸÄ±nda bir de mesela one hot encoding yaparken bÃ¼tÃ¼n streetleri sÄ±fÄ±r yapÄ±pÄ± sadece bizim kendi feature olarak seÃ§tiÄŸimiz street'i mi 1 yapÄ±yoruz mesela iki tane street verilirse iki tane mi 1 koyuyoruz?",

> comments:
  
1. -> Merhaba,Bunu bir Ã¶rnek Ã¼zerinden anlatmam gerekirse: Elimizde bir veriseti var ve verisetinde sokak isminde bir feature'Ä±mÄ±z var. Sokak isimlerimiz string yani kategorik bir veridir. Kategorik verileri modelimizin anlayabilmesi iÃ§in numerik veriye sokmamÄ±z gerekir. YalnÄ±z burada ÅŸuna dikkat etmeliyiz. EÄŸer iki tane sokak ismi iÃ§eren bir veri Ã¶rneÄŸimiz varsa? O zaman iÅŸin iÃ§ine Multi-Hot Encoding giriyor.SokaklarÄ±mÄ±zÄ±n hepsini One Hot encoding Ã§evirme yÃ¶ntemimizi kullanarak tekrar numerik veriye Ã§evirdiÄŸimizde bu sefer o sokak isimlerine karÅŸÄ±lÄ±k gelen feature alanlarÄ± 1 olmalÄ±dÄ±r. Multi Hot Encoding'de One-Hot Encoding'in aksine birden fazla feature deÄŸeri 1 olabilir. Yani bir kiÅŸinin evi aynÄ± anda iki sokakta da olabilir.Multi-Hot Encoding Ã–rneÄŸi(Tek bir kategori seti iÃ§in Ã¶rneÄŸin yaÅŸ aralÄ±klarÄ±):[1, 0, 0 , 1]One Hot Encoding'i ise ÅŸu Ã¶rnekle aÃ§Ä±klayabilirim: Elimizde bir veriseti var ve verisetinde yaÅŸ isimli bir feature'Ä±mÄ±z bu. Bu feature'Ä± binning kullanarak binary veri gruplarÄ±na binary vector ile grupladÄ±ÄŸÄ±mÄ±zÄ± dÃ¼ÅŸÃ¼nÃ¼n. Bu gruplamalarda yeni feature'Ä±mÄ±zÄ±n binary vector deÄŸerleri yalnÄ±zca 1 adet 1 deÄŸeri iÃ§erebilir Ã§Ã¼nkÃ¼ bir kiÅŸi aynÄ± anda iki yaÅŸ grubuna giremez.One Hot Encoding Ã–rneÄŸi (Tek bir kategori seti iÃ§in Ã¶rneÄŸin yaÅŸ aralÄ±klarÄ±): [0, 0, 0, 1]Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 12 people like this.Like ReportReply",
2. ->  teÅŸekkÃ¼r ederim.",
    

### soru 

> quest: "Merhaba, bu soruda [binned longitude x binned latitude] ve [binned roomsperPerson] ÅŸeklinde iki feature kullanmak doÄŸru cevaptan daha mÄ± kullanÄ±ÅŸlÄ± olurdu yoksa daha kullanÄ±ÅŸsÄ±z mÄ±?",

> comments:
  
1. -> Merhaba,[binned longitude x binned latitude] ve [binned roomsPerPerson] kullanmak daha kullanÄ±ÅŸsÄ±z olurdu. Ã‡Ã¼nkÃ¼ sizin istediÄŸiniz ÅŸey longitude, latitude ve roomsPerPerson deÄŸerlerinin her biri iÃ§in ihtimali featurelaÅŸtÄ±rÄ±p modelnize sokmak Ã§Ã¼nkÃ¼ hesaplanacak weight deÄŸerleri her ihtimal iÃ§in farklÄ± olacak. Ã–rneÄŸin sizin verdiÄŸiniz Ã¶rnek iÃ§in ([binned longitude x binned latitude] ve [binned roomsPerPerson]):Latitude x Longitude roomsPerPerson37.79 ve 76.51 3Bu durumda latitude x longitude iÃ§n ayrÄ± bir weight deÄŸeri, roomsPerPerson deÄŸeri iÃ§in ayrÄ± bir weight deÄŸeri hesaplanacaktÄ±r. Ama [binned longitude x binned latitude x binned roomsperPerson] kullanÄ±rsanÄ±z durum aÅŸaÄŸÄ±daki gibi olur:Latitude x Longitude x roomsPerPerson37.79 v3 76.51 ve 3Yani bu ihtimal iÃ§in tek bir weight deÄŸeri olur modelinizin hesaplayacaÄŸÄ± bu weight deÄŸeri diÄŸer ihtimale gÃ¶re daha tutarlÄ± olacaktÄ±r Ã§Ã¼nkÃ¼ bu ihtimal iÃ§in tek bir weight deÄŸeri varken aynÄ± ihtimale karÅŸÄ±lÄ±k gelen [binned longitude x binned latitude] ve [binned roomsperPerson] ihtimalinde 2 weight hesaplancaktÄ±r. (Bir tanesi [binned longitude x binned latitude] iÃ§in, diÄŸeri [binned roomsperPerson] iÃ§in.)Ä°yi Ã§alÄ±ÅŸmalar.",
2. ->  bin etmesek ne olur, neden bin ettik.",
3. ->  Fethi nin soyledigi gibi iki weights degeri hesaplanacaktir. Daha kullanisli olur mu sorusunun cevabi hayir daha kullanisli olmaz.Cunku daha fazla weights demek daha fazla hesaplama demektir,.Bu da daha uzun training sureci ve yuksek computational cost demektir..",
4. -> ->  yan.",
5. -> ->  ->  yani daha Ã§aba gerektiren ÅŸeyler olsada yinede doÄŸru bir yÃ¶ntem midir? KullanÄ±ÅŸlÄ± olmasa bile?.",
6. ->  -> Merhaba, hayÄ±r deÄŸildir Ã§Ã¼nkÃ¼ bu durumda daha fazla weight sayÄ±mÄ±z olacak ve modelimizin karmaÅŸÄ±klÄ±ÄŸÄ± daha da artacak, bu da modelimizi overfitting olmaya daha da yaklaÅŸtÄ±racaktÄ±r. Burada bu argÃ¼manÄ± sunmamÄ±n sebebi bu 3 feature'Ä±n ayrÄ± ayrÄ± korelasyonu ile oluÅŸacak yeni sentetik verinin korelasyonu arasÄ±nda performans farkÄ± vardÄ±r. Bu yÃ¼zden siz bu 3 feature'I Ã§arpÄ±p tek bir sentetik feature elde edip buna baÄŸlÄ± olarak tek bir weight deÄŸeri elde edebilliyorken 3 tame farklÄ± feature kullanmanÄ±z hem performans aÃ§Ä±sÄ±ndan modelin training sÃ¼resi ve costunu uzatacaktÄ±r hem de tahminleriniz label ile bu featurelar arasÄ±ndaki korelasyonun daha az olmasÄ± sebebiyle daha da az performanslÄ± oluÅŸacaktÄ±r.Ä°yi Ã§alÄ±ÅŸmalar..",


### soru 

> quest: "One-Hot Encoding kÄ±smÄ±nÄ± anladÄ±m fakat burada anlatÄ±lan Sparse Representation kÄ±smÄ±nda 0 olan verilerin alÄ±nmamasÄ±nÄ± nasÄ±l saÄŸlayacaÄŸÄ±z ve verisetinde bu iÅŸlem nasÄ±l bir etkiyle gÃ¶zÃ¼kecek ? Veri setine tablo ÅŸeklinde baktÄ±ÄŸÄ±mÄ±zda da 0 yerine boÅŸluklar ya da \"Nan\" vb. ÅŸeyler mi gÃ¶receÄŸiz. Daha Ã¶nce sorulduysa gÃ¶rmedim kusura bakmayÄ±n  iyi gÃ¼nler",

> comments:

1. -> Merhaba arkadaÅŸlar,Sparse representation kÄ±saca ÅŸu demek oluyor. One hot encoding bildiÄŸiniz Ã¼zere elimizdeki veriyi bir sÃ¶zlÃ¼ÄŸe gÃ¶re indeksleme iÅŸlemi ÅŸeklinde dÃ¼ÅŸÃ¼nebilirsiniz.Burada nasÄ±l oluyordu mesela \"Ben bugÃ¼n Ã§alÄ±ÅŸÄ±yorum\" cÃ¼mlesi iÃ§in \"Ben\" kelimesini kodlamam iÃ§in (SÃ¶zlÃ¼ÄŸÃ¼mÃ¼zÃ¼n boyutu -kelime hacmi- 42000 kelime olduÄŸunu varsayarsak). Sadece \"Ben\" kelimesini gÃ¶sterim iÃ§inSÃ¶zlÃ¼k boyutunda bir tane dizi tanÄ±mlamam lazÄ±m ve bu dizininde sadece \"Ben\" kelimesine karÅŸÄ±lÄ±k gelen indeks deÄŸerinin 1 diÄŸerlerinin 0 olduÄŸu bir dizi oluÅŸturmuÅŸ olacaÄŸÄ±z.DiÄŸer 2 kelime iÃ§inde aynÄ± iÅŸlemi yaptÄ±ÄŸÄ±mÄ±zÄ± dÃ¼ÅŸÃ¼rsek. Dikkat ettiÄŸiniz Ã¼zere her bir kelime iÃ§in sÃ¶zlÃ¼k boyutu kadar diziler oluÅŸturuyoruz ve bu dizilerin bÃ¼yÃ¼k bir kÄ±smÄ± 0, boÅŸ, null veya ne derseniz artÄ±k.BÃ¶yle matrixlere sparse matrix denir. Bu hem hafÄ±z hemde iÅŸletim aÃ§Ä±sÄ±ndan zaman alacaÄŸÄ±ndan bu matriksleri daha az hafÄ±za alanÄ± kaplayan matriksler olara gÃ¶sterebiliriz.Yine aynÄ± cÃ¼mle Ã¼zerinden gidecek olursak Ben sÃ¶zlÃ¼ÄŸÃ¼n 140. bugÃ¼n 885. ve Ã§alÄ±ÅŸÄ±yorum 1987. kelimeleri olduÄŸunu dÃ¼ÅŸÃ¼nelim.O zaman bu cÃ¼mleyi kÄ±saca [140, 885, 1987] ÅŸeklinde tanÄ±mlayabiliriz. Bu ÅŸekilde 42000 x 3 byte yerine sadece 3 byte hafÄ±za alanÄ± ile aynÄ± gÃ¶sterimi saÄŸlamÄ±ÅŸ olduk.Ek olarak burada bir aÃ§Ä±klamayÄ± faydalÄ± gÃ¶rÃ¼yorum. Bu yeni indeksler her ne kadar sayÄ± olsalarda aralarÄ±nda bÃ¼yÃ¼klÃ¼k kÃ¼Ã§Ã¼klÃ¼k vb. matematiksel ifadelerin kullanÄ±lmamasÄ± gerekir.Ã‡Ã¼nkÃ¼ bunlar pointer deÄŸerleridir. Kategorik verileridir. Her ne kadar sayÄ± olsalarda sayÄ±sal veriler deÄŸildirler..",
2. ->  ->  TeÅŸekkÃ¼r ederim.",
3. ->  ->  Buradan yola Ã§Ä±karsak her durumda one hot encoding kullanmak yerine sparse representation kullanmak Ã§ok daha mantÄ±klÄ±dÄ±r diyebilir miyiz? DoÄŸru mu anladÄ±m teyit etmek istedim..",
4. ->  ->  Benim anladÄ±ÄŸÄ±m kadarÄ±yla veri kÃ¼mesi aÅŸÄ±rÄ± bÃ¼yÃ¼k deÄŸilse One-Hot Encoding yeterli olarak gÃ¶rÃ¼lÃ¼yor ama veri kÃ¼mesi bÃ¼yÃ¼k ise Sparse Representation yapÄ±yoruz ki hafÄ±za alanÄ±ndan tasarruf edebilelim..",
5. -> ->  ->  One hot encoding yerine sparse kullanabilirsiniz.Bunun bir sakÄ±ncasÄ± yok genel olarak kullanÄ±m ÅŸÃ¶yle oluyor diyebiliriz.Encoding iÅŸlemi yapÄ±lacak olan Ã¶zellik bir Ã§ok deÄŸer alÄ±yorsa bunun bu Ã¶zelliÄŸi sparse representation olarak kullanmak daha mantÄ±klÄ± oluyor.Bir Ã¶rnek ile kÄ±saca aÃ§Ä±klayacak olursak 2 Ã¶zelliÄŸimiz olsun bunlar il ve sokak. Ä°llerde de sadece istanbul Ankara ve Ä°zmir geÃ§tiÄŸini dÃ¼ÅŸÃ¼nelim.Sokak isimleri ile bu 3 ÅŸehirin sokak isimleri olacaÄŸÄ±ndan bunu ÅŸehir Ã¶zelliÄŸi iÃ§in one-hot encoding yaparken ÅŸehir isimleri iÃ§in sparse daha uygun olabilmektedir.Sparse'Ä±n bir dezavantajÄ± ÅŸu oluyor ilgili indeksin neye referans ettiÄŸini bir yerde saklamanÄ±z gerekiyor. Ama one-hot encoding iÃ§in yeni Ã¶zellikler (feature'lar) oluÅŸturduÄŸunuz iÃ§in verinize baÅŸka bir look-up table benzeri bir ÅŸeye ihtiyaÃ§Ä±nÄ±z yok..",
6. ->  ->  anladÄ±m teÅŸekkÃ¼rler.",
7. ->  ->  Merhabalar. Tekrar yaparken bu konu hakkÄ±nda size bir ÅŸey danÄ±ÅŸmak istedim. Ã–nceki yorumlarda Ã¶rneÄŸin ÅŸehir kÃ¼mesini one-hot yaptÄ±ÄŸÄ±mÄ±zda her ÅŸehir ismi bir feature oluyor ve bunu,is_istanbul is_bursa is_antalya1 0 0ÅŸeklinde gÃ¶steriyoruz. Tablodan dÃ¼ÅŸÃ¼nÃ¼rsek sparse vektÃ¶re Ã§evirince sizindediÄŸinize gÃ¶re yalnÄ±zca Ä°stanbulun indeksi tutuluyor. Peki bu Ã¼stte verdiÄŸim Ã¶rnekteki ÅŸekilde tabloya gÃ¶rsel olarak etki ediyor mu? Yoksa sparse olayÄ± sadece arka planda verinin tutulma ÅŸekliyle mi ilgili?.",
8. ->  ->  Merhaba aÃ§Ä±klama iÃ§in teÅŸekkÃ¼rler fakat son kÄ±sÄ±mdaki ifadenizi anlayamadÄ±m --\" Bu yeni indeksler her ne kadar sayÄ± olsalarda aralarÄ±nda bÃ¼yÃ¼klÃ¼k kÃ¼Ã§Ã¼klÃ¼k vb. matematiksel ifadelerin kullanÄ±lmamasÄ± gerekir. Her ne kadar sayÄ± olsalarda sayÄ±sal veriler deÄŸildirler.\"-- biraz daha aÃ§Ä±klayabilirmisiniz bu sayÄ±larÄ±n indexleri arasÄ±nda bÃ¼yÃ¼klÃ¼k kÃ¼Ã§Ã¼klÃ¼k iliÅŸkisi kurmayacaksak bilgisayara nasÄ±l o indexte bulunduklarÄ±nÄ± anlatÄ±cak yani bu indexte bulunan veri aynÄ± zamanda baÅŸka bir featurun 1532. indexi ile korelasyon halinde oldugunu biliyoruz ve bu iliÅŸkiyi kaybetmemeleri iÃ§in index numaralarÄ±nÄ± kullanmamÄ±z gerekirse ne yapmamÄ±z gerekir ?.",
9. ->  Merhabalar -> ,Bir Ã¶rnek ile aÃ§Ä±klayacak olursam ÅŸÃ¶yle sÃ¶ylÃ¼yebiliriz. Ã–rneÄŸin Meslek adÄ±nda bir Ã¶zelliÄŸimiz olsun. Ve bu bilgi karakter olarak tutuluyor. (MÃ¼hendis, Doktor, Ã–ÄŸretmen, Avukat vb.)Bu bilgileri sparse encoding ÅŸeklinde kodladÄ±ÄŸÄ±mÄ±zda MÃ¼hendis iÃ§in 1, Doktor iÃ§in 2, Ã–ÄŸretmen iÃ§in 3 ve Avukat iÃ§in de 4 numaralÄ± indeksler ile ifade etmiÅŸ olduÄŸumuzu dÃ¼ÅŸÃ¼nelim.Burada ( 4 > 1) Avukat MÃ¼hendis'ten bÃ¼yÃ¼k deÄŸildir. Elimizdeki deÄŸerler nÃ¼merik ama bunlar arasÄ±nda matematiksel iÅŸlemler yapÄ±lmamalÄ±..",
    

### soru 
"question_isim": 1. -> uploaded 1 photo",
> quest: "Sparse gÃ¶steriminde, one hot encoding yaptÄ±ktan sonra oluÅŸan ve Ã§oÄŸunluÄŸu 0'larla dolu vektÃ¶rÃ¼ kullanÄ±rken, sadece dolu kÄ±sÄ±mlarÄ±nÄ± ele alan bir representation'dan bahsedilmiÅŸ. Bu gÃ¶sterimde (saÄŸdaki tabloda yani) dolu olan kutunun indexi bulunan sÃ¼tunu feature sÃ¼tununa mÄ± ekliyoruz? EÄŸer Ã¶yle yapÄ±yorsak modelimizi kÃ¶tÃ¼ etkilemez mi? Bu kÄ±smÄ± tam anlamadÄ±m. Åimdiden teÅŸekkÃ¼r ederim",

> comments:
  
1. -> BurasÄ± benim de kafamÄ± karÄ±ÅŸtÄ±rdÄ±. Åu ÅŸekilde yorumladÄ±m; Sparse representation 0 harici deÄŸerleri indisleriyle birlikte tutuyor, bunu da vektÃ¶r Ã§arpÄ±mÄ± vb. iÅŸlemlerde hÄ±z kazanmak iÃ§in yapÄ±yor (boÅŸuna 0 olan elemanlar ile Ã§arpma yapmamak iÃ§in) Ancak bunu feature olarak kullanmak istediÄŸimizde tekrardan \"dense\" haline Ã§evrilmesi gerekiyor. Bkz: [TensorFlow Core v2.1.0](https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensortf.sparse.SparseTensor)
2. -> -> Feature matrisindeki sÃ¼tun sayÄ±mÄ±z deÄŸiÅŸmiyor ve elimizdeki sparse tablosu featurelardan ayrÄ±ca bulunan bir bilgi, onu sadece iÅŸlem yaparken kolaylÄ±k olsun diye kullanÄ±yoruz . DoÄŸru anlamÄ±ÅŸ mÄ±yÄ±m?.",
3. -> -> Evet, en azÄ±ndan ben bu ÅŸekilde anladÄ±m. Mentor arkadaÅŸlarÄ±mÄ±z da yorumlarsa daha net bilgi edinmiÅŸ oluruz..",
4. -> -> TamamdÄ±r teÅŸekkÃ¼r ederim.",
5. ->  Merhabalar aynÄ± soru olduÄŸundan ÅŸurada cevaplamaya Ã§alÄ±ÅŸtÄ±m.[Link](http://community.globalaihub.com/community/status/918-918-1587034561/#comment.4209.4144.4144)
6. -> ->  AÃ§Ä±klayÄ±cÄ± olmuÅŸ teÅŸekkÃ¼rler.",
    
### soru 
j
> quest: "Merhaba,  Feature Crosses Programming Exercise kÄ±smÄ±nda aÅŸaÄŸÄ±daki parametrenin iÅŸlevini anlayamadÄ±m;  --------------------------------------- # Create a feature cross of latitude and longitude. latitude_x_longitude = tf.feature_column.crossed_column([latitude, longitude], hash_bucket_size=100) ---------------------------------------  Burada \"hash_bucket_size\" parametresi tam olarak neyi ifade ediyor ve deÄŸeri neye gÃ¶re belirleniyor?  TeÅŸekkÃ¼rler ÅŸimdiden.",

> comments:
  
1. ->  Merhaba,Feature Crossing yaptÄ±ÄŸnÄ±z anda ortaya Ã§Ä±kacak yeni binary vector'daki eleman sayÄ±sÄ±nÄ± temsil etmektedir. Ã–rneÄŸin elinizde resimdeki gibi bir feature crossing output'u olsun. Burada binary vector listesindeki(bu listedeki binary vectorlerin her biri yeni bir feature deÄŸeridir Ã§Ã¼nkÃ¼ biz iki feature'Ä± Ã§arptÄ±ÄŸÄ±mÄ±zda yeni featurelar elde ederiz.) her bir binary vector hash bucket, her bir hash bucket iÃ§indeki eleman sayÄ±sÄ± hash_bucket_size olur. Peki bu deÄŸeri az verirsek ne olur?EÄŸer hash_bucket_size'Ä± 100 deÄŸil de 10 verseydik kategorilenmiÅŸ verilerimizin Ã§arpÄ±m sonuÃ§ verktÃ¶rÃ¼nÃ¼n daha kÃ¼Ã§Ã¼k bir binary vector'de toplanmasÄ±nÄ± zorlayacaktÄ±k. Bu da birbiri ile alakasÄ±z kategorilerin aynÄ± alanda maplenmesine yol aÃ§abilirdi. Bu yÃ¼zden de modelimiz bu iki alakasÄ±z veriyi aynÄ± kategoriden sayacaktÄ±.Ä°yi Ã§alÄ±ÅŸmalar.",

![image](image/8.jpg)

2. ->  ->  CevabÄ±nÄ±z iÃ§in Ã§ok teÅŸekkÃ¼rler. Peki bu deÄŸerin parametre olarak kullanÄ±cÄ± tarafÄ±ndan girilmesinin spesifik bir sebebi var mÄ±? Yani tf.feature_column.crossed_column() fonksiyonuna latitude ve longtitude feature'larÄ±nÄ± verdiÄŸimizde bu \"hash_bucket_size\" deÄŸeri kullanÄ±cÄ±ya bÄ±rakÄ±lmadan da hesaplanabilirdi diye dÃ¼ÅŸÃ¼nÃ¼yorum. Tekrardan teÅŸekkÃ¼rler..",
3. ->  ->  Merhaba,AnladÄ±ÄŸÄ±m kadarÄ±yla feature crossing verdiÄŸimiz orjinal featurelarÄ± alÄ±p onlarÄ± Ã§arpar ve berlirlediÄŸimiz hash_bucket_size kadar bucketlar iÃ§ine bu Ã§arpÄ±lan deÄŸerleri yerleÅŸtirir.hash_bucket_size deÄŸerini vermemiz, bÃ¼tÃ¼n ihtimal dahilinde kalan indis sayÄ±sÄ±nÄ± (featurelar Ã§arpÄ±ldÄ±ktan sonra) bilmeden Ã¶nce, modelimizi kayÄ±p verme riski olsa dahi oluÅŸturmamÄ±za yaramaktadÄ±r. Kaynak: [what TensorFlow hash_bucket_size matters](https://stackoverflow.com/a/45219489/6139104) Ä°yi Ã§alÄ±ÅŸmalar.",
4. ->  ->  TeÅŸekkÃ¼rler..",
5. ->  10 buckets for latitude.10 buckets for longitude. OlduÄŸu iÃ§in hash_bucket_size=100 oluyor. YanlÄ±ÅŸÄ±m varsa dÃ¼zeltirseniz sevinirim.,
6. ->  ->  DoÄŸru, 10x10 feature deÄŸeri size 100 feature deÄŸeri verir yani feature crossing yaptÄ±ÄŸÄ±nÄ±zda 100 elemanlÄ± yeni bir binary vector elde edersiniz. Benim resimde verdiÄŸim Ã¶rnek longitude ve latitufe deÄŸerleri iÃ§in deÄŸil, sadece bucket'Ä± gÃ¶sterebilmek adÄ±na baÅŸka bir Ã¶rnekti. AÃ§Ä±klamanÄ±z iÃ§in teÅŸekkÃ¼rler, iyi Ã§alÄ±ÅŸmalar..",
7. ->  ->  Ben teÅŸekkÃ¼r ederim. Ä°yi Ã§alÄ±ÅŸmalar dilerim..",
8. ->  ->  CevabÄ±nÄ±z iÃ§in teÅŸekkÃ¼rler..",
    
### soru 

> quest: "Merhabalar, log ve min fonksiyonlarÄ± tam olarak ne iÅŸlev yaptÄ±ÄŸÄ± iÃ§in grafikler deÄŸiÅŸti ve neden 1.kodda( total_room/population+1) yani neden +1 dedik, 2.kodda  (total_room/population, 4) dedik ,4 Ã¼n iÅŸlevi nedir. TeÅŸekkÃ¼r ederim.",

![image](image/9.jpg)

> comments:
  
1. ->  Merhabalar,Log fonksiyonu verisetindeki her roomsPerPerson verisinin logaritmasÄ±nÄ± alÄ±yor. LogaritmasÄ± alÄ±nan deÄŸerler kÃ¼Ã§Ã¼lÃ¼yor ve kÃ¼Ã§Ã¼len bu yeni deÄŸerlerle yeni bir grafik oluÅŸturulduÄŸunda bile hala outlier yani diÄŸer verilerden Ã§ok uzakta verilerin olduÄŸu gÃ¶rÃ¼nÃ¼yor. Bunun nedeni ise roomsPerPerson feature deÄŸerleri normalde 3-4-5 gibi deÄŸerler iken bizim outlier deÄŸerimiz 50 ve 5 ile 50'nin logaritmasÄ± alÄ±nsa bile aralarÄ±nda yine bir aÃ§Ä±klÄ±k olacaktÄ±r.Bizim istediÄŸimiz verisetimizdeki bu outlier sorununu gidermek. Bunun iÃ§in ise yapabileceÄŸimiz ÅŸey roomsPerPerson iÃ§in kendimiz bir maksimum deÄŸer belirlemek (Ã¶rneÄŸin 4 belirlemiÅŸ olalÄ±m) ve o maksimum deÄŸerden bÃ¼yÃ¼k her deÄŸeri (Ã¶rneÄŸin outlier deÄŸerimiz 50) belirlediÄŸimiz maksimum deÄŸere eÅŸitleyelim.min fonksiyonu ise totalRooms/population iÅŸlemini yapÄ±yor ama bu deÄŸer 4'ten bÃ¼yÃ¼k ise 4 deÄŸerini alÄ±yor.Ä°yi Ã§alÄ±ÅŸmalar..",
2. -> ->  ama sonuÃ§ta 4 deÄŸeri normal deÄŸerlerden yÃ¼ksek deÄŸil mi yinede.. YANÄ°, daÄŸÄ±lÄ±mdan uzakta... Burada onun seÃ§ilmesinin nedeni nedir?.",
3. ->  -> ->  'nÄ±n paylaÅŸtÄ±ÄŸÄ± resme bakarsanÄ±z burada deÄŸer daÄŸÄ±lÄ±mlarÄ±nÄ±n 4'Ã¼ de kapsadÄ±ÄŸÄ±nÄ± ve 4'Ã¼n outlier deÄŸer olmadÄ±ÄŸÄ±nÄ± gÃ¶rebilirsiniz. Siz sanÄ±rÄ±m logaritma alÄ±ndÄ±ktan sonraki grafik iÃ§in konuÅŸuyorsunuz. Burada logaritma alÄ±p bu iÅŸin iÃ§inde Ã§Ä±kacaÄŸÄ±nÄ±zÄ± dÃ¼ÅŸÃ¼nebilirsiniz ama bu ÅŸekilde de outlier sorununu Ã§Ã¶zemediniz, o yÃ¼zden logaritma alma yaklaÅŸÄ±mÄ±na girmeden cap veya clip yÃ¶ntemini kullanabilirsiniz denmiÅŸ. 4 seÃ§ilmesinin belli bir nedeni yok, bu deÄŸerin ne olacaÄŸÄ± tamamen size kalmÄ±ÅŸ 5 de alabilirdik 3 de 6 da..",
4. ->  aykÄ±rÄ±lÄ± deÄŸerleri onlemek adÄ±na 4 den bÃ¼yÃ¼k deÄŸerler alÄ±rsa bu deÄŸerler 4 olarak sabitleniyor diye anladÄ±m ben..",
5. -> +1 denmesinin sebebi \"log\" fonksiyonunun 0 deÄŸeri iÃ§in tanÄ±msÄ±z olmasÄ±ndan kaynaklanÄ±yor. (totalRooms/population) = 0 olmasÄ± durumunda roomsPerPerson hesaplanabilmesi iÃ§in +1 deÄŸeri eklenmiÅŸ, +1 yerine +0.00001 de eklenebilirdi..",
6. ->  -> Merhaba, bu durum iÃ§in +0.00001 deÄŸeri eklenmesi muhtemelen doÄŸru olmazdÄ± Ã§Ã¼nkÃ¼ log fonksiyonunda 0-1 arasÄ± deÄŸerler negatif deÄŸerler vereceÄŸinden tablomuz gerÃ§ekten uzaklaÅŸmÄ±ÅŸ olurdu diye dÃ¼ÅŸÃ¼nÃ¼yorum..",
7. -> ->  Evet +1 bu Ã¶rnek iÃ§in en doÄŸrusu. Ä°lgili feature'Ä±n negatif deÄŸer almasÄ± bir anlam ifade etmiyor. (0,+] aralÄ±ÄŸÄ±nda normalize olmasÄ± dediÄŸiniz gibi daha uygun..",
    
### soru 

> quest: "Ã–ncelikle merhabalar, representation-qualities of good features kÄ±smÄ±nda bu ifadeyi tam olarak anlayamadÄ±m. Bu kÄ±sÄ±m ile ilgili bir aÃ§Ä±klama yapabilir misiniz? TeÅŸekkÃ¼r ederim.

![image](image/10.jpg)

> comments:
  
1. ->  Merhaba,Az Ã¶nce bu kÄ±sÄ±mlarÄ± [Link](http://community.globalaihub.com/community/status/190-190-1586982868/#comment.4163.4048.4048) linkindeki yorumumda aÃ§Ä±klamaya Ã§alÄ±ÅŸtÄ±m ğŸ™‚ AklÄ±nÄ±za bir ÅŸey takÄ±lÄ±rsa tekrardan cevaplayabilirim.Ä°yi Ã§alÄ±ÅŸmalar..",
2. ->  ->  gayet anlaÅŸÄ±labilir bir yorum olmuÅŸ, aÃ§Ä±klamanÄ±z iÃ§in teÅŸekkÃ¼r ediyorum ğŸ™‚.",
    
### soru 

> quest: "Merhaba,  Resimdeki kÄ±smÄ± genel olarak anlayamadÄ±m.Burada tam olarak ne demek istiyor acaba?  TeÅŸekkÃ¼rler.

![image](image/11.jpg)

> comments:
  
1. -> Merhaba,Bu kÄ±sÄ±mda demek istediÄŸini resimedki Ã¶rnek Ã¼zerinden anlatayÄ±m.Elinizde bir verisetin var ve verisetinde quality_rating isimli bir feature var. Bu feature'Ä±n deÄŸerinini girilmediÄŸi veri Ã¶rnekleriniz olabilir. Siz burada ÅŸÃ¶yle bir yaklaÅŸÄ±mda bulunabilirsiniz:EÄŸer quality_rating isimli feature'Ä±nÄ±zÄ±n verisi girilmemiÅŸ ise siz el ile -1 atayabilirsiniz ve -1 olan quality_rating feature'Ä±nÄ±n aslÄ±nda verisi girilmemiÅŸtir diyebilirsiniz. Ama bu yanlÄ±ÅŸtÄ±r Ã§Ã¼nkÃ¼ siz -1 koyarak quality_rating feature'nÄ±n varsayÄ±lan aralÄ±ÄŸÄ± olan 0-1 arasÄ±ndaki deÄŸerlerden farklÄ± bri deÄŸere girdiniz. Bu aynÄ± zamanda modelinizin Ã¶ÄŸrenme sÄ±rasÄ±nda da performansÄ± dÃ¼ÅŸÃ¼recek ve hatalÄ± tahminlere yol aÃ§acaktÄ±r. Bunun Ã¶nÃ¼ne ÅŸÃ¶yle geÃ§ebilirsiniz:Bool tipinde (0 veya 1 alan) bir feature oluÅŸturursunuz ve bu feature deÄŸeriniz sizin quality_rating feature'Ä±nÄ±zÄ±n deÄŸerinin girilip girilmediÄŸi bilgisini tutar. quality_rating girilmiÅŸse yeni bool feature'Ä±nÄ±za 1, girilmemiÅŸse 0 verdiÄŸinizi varsayalÄ±m. Peki iÅŸimiz bitti mi? HayÄ±r ama Ã§ok az kaldÄ± :)EÄŸer sizin quality_rating deÄŸeriniz discrete bir deÄŸer ise yani alabileceÄŸi deÄŸerler sÄ±nÄ±rlÄ±ysa: feature deÄŸerinin kayÄ±p olduÄŸunu belli eden bir deÄŸer ekleyin (Ã¶rneÄŸin elinizde sadece 0,1 deÄŸerleri var ise 2 deÄŸerini ekleyip bu 2'nin sadece girilmemiÅŸ deÄŸerler iÃ§in kullanÄ±ldÄ±ÄŸÄ±nÄ± belirtebilrisiniz. resimdeki Ã¶rnekte quality_rating continuos bir deÄŸer olduÄŸu iÃ§in bu yÃ¶ntem orada iÅŸe yaramaz.).EÄŸer sizin quality_rating deÄŸeriniz continuous bir deÄŸer ise: bu kayÄ±p deÄŸerlerin modeli etkilememesi iÃ§in quality_rating feature datalarÄ±nÄ±n ortalama deÄŸerlerini girilmemiÅŸ kÄ±sÄ±mlara yazÄ±n.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 13 people like this.Like ReportReply",
2. ->  ->  feature deÄŸerlerimizin continuous veya discrete olmasÄ±, problemimizin classification veya regression olduÄŸunu belirlemiyor diye biliyorum, yazdÄ±ÄŸÄ±nÄ±zdan Ã¶yle anlaÅŸÄ±lÄ±yor ya da ben mi yanlÄ±ÅŸ anladÄ±m ? Ya da siz quality_rating'i bizim tahmin etmek istediÄŸimiz deÄŸer olarak aldÄ±nÄ±z.",
3. ->  ->  Merhaba, anlÄ±k kafa karÄ±ÅŸÄ±klÄ±ÄŸÄ±yla quality_rating'i label olarak almÄ±ÅŸÄ±m. DÃ¼zeltme iÃ§in teÅŸekkÃ¼rler ğŸ™‚",
4. ->  ->  is_quality_rating_defined bool feature yarattÄ±ÄŸÄ±mÄ±z yeterli deÄŸil mi? Continuous deÄŸerlerde ortalama ile deÄŸiÅŸtirmeye gerek yok diye dÃ¼ÅŸÃ¼nÃ¼yorum. Bu feature'i iÅŸlerken oluÅŸturduÄŸumuz bool feature bakarak bu boÅŸ deÄŸerlere goz ardi edebiliriz. Neyi etkiler bu eÄŸer deÄŸiÅŸtirmezsek?.",
5. ->  ->  BildiÄŸim kadarÄ±yla belli featurelarÄ± gÃ¶z ardÄ± etme diye bir ÅŸey yok, sadece o feature'Ä±n mensup olduÄŸu veri Ã¶rneÄŸini gÃ¶z ardÄ± edebilirsiniz ama ya iki feature'Ä±nÄ±z var ise ve biri boÅŸ biri doluysa o zaman bu veri Ã¶rneÄŸini gÃ¶z ardÄ± etmekten sÃ¶z edemeyiz. Bu yÃ¼zden de bu veri Ã¶rneÄŸini alabilmek ama alÄ±rken de boÅŸ olan feature deÄŸerinin feature ortalamasÄ±na etki etmemesi iÃ§in ortalamayÄ± feature deÄŸeri olarak verebiliriz..",
6. ->  ->  Genel tekrar yaparken aklÄ±ma bir ÅŸey takÄ±ldÄ± sormak istedim. Continuous ise ortalama alÄ±yoruz. Discrete ise o deÄŸerin yazÄ±lmadÄ±ÄŸÄ±nÄ± belli eden bir sÄ±nÄ±f oluÅŸturuyoruz. is_quality_rating diye ekstra Ã¶zellik aÃ§manÄ±n gerekliliÄŸi nedir? Buradan modelin quality belirlenenlere daha yÃ¼ksek bir aÄŸÄ±rlÄ±k verdiÄŸi mi anlaÅŸÄ±lmalÄ±?.",
7. ->  ->  Merhaba,[Makine Ã–ÄŸrenmesiâ€™nde Ham Veriâ€™den Ã–znitelik](https://medium.com/@ftfethi/makine-%C3%B6%C4%9Frenmesinde-ham-veri-den-%C3%B6znitelik-%C3%A7%C4%B1karmak-8a6e234ada46) linkindeki yazÄ±mÄ±n 3.maddesinde bu konuya detaylÄ± deÄŸinmeye Ã§alÄ±ÅŸtÄ±m. EÄŸer aklÄ±nÄ±za takÄ±lan bir ÅŸey olursa sormaktan Ã§ekinmeyin.Ä°yi Ã§alÄ±ÅŸmalar.",
8. ->  ->  TeÅŸekkÃ¼r ederim okuyacaÄŸÄ±m..",
    
### soru 

> quest: "Merhaba,  Representation kÄ±smÄ±nda kategorik deÄŸerler iÃ§in one-hot-encoding kullanÄ±ldÄ±ÄŸÄ±nÄ± anlatÄ±yor.Bu kullanÄ±mda feature iÃ§in tek bir aÄŸÄ±rlÄ±k var deÄŸil mi ?Bu aÄŸÄ±rlÄ±k bu binary vector ile Ã§arpÄ±lÄ±nca mesela [0,0,5.0] yada [5,0,0,0] oluyor ikisi iÃ§inde 5 deÄŸerimi toplanacak?  Birde seyrek temsilden bahsediliyor.Bunu nasÄ±l kullanacaÄŸÄ±mÄ±zÄ± anlamadÄ±m.Her bir kategorik deÄŸer iÃ§in sayÄ±sal deÄŸer atÄ±caz fakat her biri iÃ§in farklÄ± aÄŸÄ±rlÄ±klar elde edicez olarak anladÄ±m ,ama peki nasÄ±l her biri iÃ§in farklÄ± aÄŸÄ±rlÄ±k elde edilcek?  TeÅŸekkÃ¼rler",

> comments:
  
1. -> Merhaba Buse,One-Hot-Encoding yaptÄ±ÄŸÄ±nda bahsettiÄŸin vektÃ¶rdeki her bir deÄŸer ayrÄ± bir feature oluyor ve farklÄ± weight deÄŸerleri alÄ±yorlar. Ã–rneÄŸin elindeki datasette ÅŸehir adlarÄ±nÄ±n olduÄŸu bir feature var ve iÃ§erisinde [\"Ä°stanbul\", \"Ankara\", \"Ä°zmir\", \"Bursa\"] kategorik deÄŸerleri var. One-Hot-Encoding yaptÄ±ÄŸÄ±n zaman bu deÄŸerler datasete kolon olarak eklenirler. [\"Ä°stanbul\", \"Ankara\", \"Ä°zmir\", \"Bursa\"] kolon adlarÄ± olmak Ã¼zere eÄŸer satÄ±rda bu deÄŸerler geÃ§iyorsa 1, geÃ§miyorsa 0 olur. Mesela ilgili satÄ±rda \"Ankara\" var ise [0,1,0,0] olur. Bu deÄŸerleri feature olarak eklediÄŸimiz iÃ§in her birinin weight deÄŸeri farklÄ± olacaktÄ±r, Ã§Ã¼nkÃ¼ normal ÅŸartlarda her bir ÅŸehir adÄ±nÄ±n sÄ±nÄ±flandÄ±rma sonucuna etkisi farklÄ± Ã§Ä±kmalÄ±dÄ±r.Seyrek temsil olarak bahsettiÄŸin yani sparse represantation iÃ§in ise yukarÄ±da verdiÄŸim Ã¶rneÄŸe ek olarak tÃ¼m dÃ¼nya ÅŸehirlerini kullandÄ±ÄŸÄ±mÄ±zÄ± dÃ¼ÅŸÃ¼nelim. DÃ¼nya Ã¼zerinde yaklaÅŸÄ±k 2.5 milyon ÅŸehir var ve her biri iÃ§in bir kolon oluÅŸturup sadece ismi geÃ§en ÅŸehri 1 ile iÅŸaretleyip diÄŸerlerini 0 yapmak pek mantÄ±klÄ± deÄŸil.Bu gibi durumlarda kullanÄ±lÄ±yor ve sadece 1 olan yani ilgili satÄ±rda geÃ§en kategorik deÄŸerler gÃ¶steriliyor..",
2. ->  ->  Sparse representationÄ±n ne olduÄŸunu tam olarak anlayamadÄ±m sadece kelime sayÄ±sÄ± milyonlarÄ± bulduÄŸunda one hot encodinging yetersiz kaldÄ±ÄŸÄ± durumlarda kullanÄ±lÄ±yor diye anladÄ±m sparse repin kullanÄ±mÄ± aklÄ±mda pek canlanmadÄ±. Ä°nternettede baya karmaÅŸÄ±k formÃ¼ller var yanlÄ±ÅŸ anlamadÄ±ysam sparse rep. konusu sÃ¶zlÃ¼ olarak anlatmaya pek mÃ¼sait deÄŸil?.",
3. ->  ->  Seyrek temsil iÃ§in verdiÄŸiniz Ã¶rnekten gidecek olursak sadece Ankara ÅŸehir kolonunda 1 olan bir Ã¶rnek iÃ§in sadece \"Ankara\" feature'Ä± mÄ± tutuluyor? Geri kalan kolonlara 0 deÄŸerleri feature engineering adÄ±mlarÄ±nda mÄ± ekleniyor?.",
4. ->  ->  Seyrek gÃ¶sterimi (Sparse representation) ÅŸu ÅŸekilde aÃ§Ä±klamaya Ã§alÄ±ÅŸayÄ±m. Seyrek gÃ¶sterim veri setinde sadece sÄ±fÄ±r olmayan Ã¶zelliklerin (feature) gÃ¶sterildiÄŸi Ã¶zellikle bÃ¼yÃ¼k (big data) veri setlerinde kullanÄ±lan bir gÃ¶sterim ÅŸeklidir. GÃ¶rsel ile aÃ§Ä±klamaya Ã§alÄ±ÅŸtÄ±m.",
5. ->  ->  TeÅŸekkÃ¼rler.Peki sparse representation 'da 1000 kategorik deÄŸer varsa 1000 feature eklemiyo muyum yani?Bu kÄ±smÄ± gene anlayamadÄ±m..",
6. ->  ->  Ama her Ã¶rnek iÃ§in O olmayan deÄŸer deÄŸiÅŸecek.Mesela ÅŸehir bir Ã¶rnekte Ankara,diÄŸerinde Ä°zmir?Gene hepsi iÃ§in feature olmasÄ± lazÄ±m yoksa her example iÃ§in aynÄ± feature mÄ± olacak yani?.",
7. -> ->  evet yine 1000 feature ekleniyor ancak sparse matrix olarak ekleniyorlar. Tensorflow Ã¼zerinde Ã§alÄ±ÅŸÄ±rken bunun ile ilgili metodlar var.BildiÄŸin gibi bir yazÄ±lÄ±m dilinde(Python iÃ§in konuÅŸalÄ±m) variable iÃ§ine matris tanÄ±mlarsan (Numpy ile) onun uzunluÄŸu kadar hafÄ±zada yer kaplayacaktÄ±r. EÄŸer elimizde bahsettiÄŸimiz Ã¶lÃ§Ã¼de bÃ¼yÃ¼k bir matris var ise memory Ã¼zerine yazÄ±lamaz Ã§Ã¼nkÃ¼ matris iÃ§erisindeki 0'lar da yer kaplar. Bu noktada sparse matrixler kullanÄ±lÄ±r, bu matrisler farklÄ± mapping teknikleri ile 0 olan verileri boÅŸ olarak alÄ±r, sadece deÄŸer iÃ§eren veriler matris iÃ§erisinde depolanÄ±r. DolayÄ±sÄ±yla memory problemi oluÅŸmaz. Sparse matrixleri kullanmak iÃ§in Python'da Scipy kÃ¼tÃ¼phanesini kullanabilirsin.AÅŸaÄŸÄ±da bu konu ile ilgili yazÄ±larÄ± bulabilirsin ancak Machine Learning iÃ§in ÅŸimdilik bu konularÄ±n detaylarÄ±nÄ± bilmek zorunda deÄŸilsin, merak ettiÄŸin iÃ§in paylaÅŸÄ±yorum :)FarklÄ± Sparse Matrix tÃ¼rleri:[Link](https://matteding.github.io/2019/04/25/sparse-matrices/)
8. -> One hot encoding yaptÄ±ÄŸÄ±mÄ±zda bir nitelikten, nitelikte bulunan dÃ¼zey sayÄ±sÄ± kadar yeni nitelik elde ederiz. Ã–rneÄŸin ÅŸehir niteliÄŸimizde Ä°stanbul,Ankara ve Ä°zmir dÃ¼zeyleri olsun. Åehir niteliÄŸine one-hot encoding yaptÄ±ÄŸÄ±mÄ±zda is_Ä°stanbul, is_Ankara , is_Ä°zmir ÅŸeklinde yeni nitelikler elde ederiz.Ã–rnek olarak ÅŸÃ¶yle bir verimiz olsunbuyukluk (m2), ÅŸehir, oda_sayisi, fiyat135 , Ä°zmir, 3 , 270000buna one-hot encoding uyguladÄ±ÄŸÄ±mÄ±zda verimizdeki nitelikler ve deÄŸerleribuyukluk (m2), is_Ä°stanbul, is_Ankara, is_Ä°zmir, oda_sayisi, fiyat135 , 0, 0 , 1, 3, 270000e dÃ¶nÃ¼ÅŸÃ¼r. ArtÄ±k modele girecek veri gÃ¶sterimi son elde ettiÄŸimiz gÃ¶sterim. Yani her bir nitelik iÃ§in ayrÄ± bir aÄŸÄ±rlÄ±ÄŸa sahip olacaÄŸÄ±z. DolayÄ±sÄ±yla is_Ä°stanbul, is_Ankara ve is_Ä°zmir niteliklerinin aÄŸÄ±rlÄ±klarÄ± birbirinden farklÄ± olacak.",
9. ->  Fatih Bey'in Ã¶rneÄŸinden devam ederek anlatayÄ±m, farkettiyseniz burada sayÄ± ile Ã¶lÃ§Ã¼lemeyen Ã¶zelliÄŸimiz \"ÅŸehir bilgisi\". One hot encoding ile ÅŸehir Ã§eÅŸidi kadar yeni Ã¶zelliÄŸi (yani sÃ¼tunu) tablomuza eklediÄŸimizi dÃ¼ÅŸÃ¼nÃ¼n, yani her bir ÅŸehir ismi iÃ§in tabloya bir sÃ¼tun daha ekliyoruz, bunlar Ä°stanbul, Ankara ve Ä°zmir iÃ§in birer yeni sÃ¼tun oluyor Ã¶rnekte. Bizim gÃ¶zlemimizdeki (yani satÄ±rÄ±mÄ±zdaki) ev hangi ÅŸehirde ise o sÃ¼tunumuz 1, diÄŸerleri 0 oluyor. Bu ÅŸekilde gÃ¶zlemimizin o Ã¶zelliÄŸini kodlamÄ±ÅŸ oluyoruz. Ben en basit haliyle bu ÅŸekilde kullanÄ±yorum. UmarÄ±m anlatabilmiÅŸimdir.",
    
### soru 

> quest: "ArkadaÅŸlar merhaba. Ben \"Feature Crosses\" bÃ¶lÃ¼mÃ¼nÃ¼ etkinliklere raÄŸmen genel olarak anlayamadÄ±m. Ä°nternet Ã¼zerinde faydalÄ± bir site veya video ÅŸeklinde bir kaynak bulamadÄ±m. Bu konuyla ilgili bir site ya da herhangi bir kaynak bilgisi olan var mÄ±? Ä°yi Ã§alÄ±ÅŸmalar ğŸ™‚",

> comments:
  
1. ->  Merhaba,[Link](http://community.globalaihub.com/community/status/774-774-1586937745/#comment.4123.4009.4009) linkinde Feature Cross'u genel hatlarÄ±yla kabaca anlatmaya Ã§alÄ±ÅŸtÄ±m. EÄŸer bu kÄ±sÄ±mda sorularÄ±nÄ±z eksik gÃ¶rdÃ¼ÄŸÃ¼nÃ¼z veya anamadÄ±ÄŸÄ±nÄ±z yer olursa bu post altÄ±ndan daha aÃ§Ä±klamalÄ± halini yazmaya Ã§alÄ±ÅŸabilirim. AyrÄ±ca Andrew Ng'nin Coursera'daki Machine Learning kursununda da bunun aÃ§Ä±klamasÄ± mevcut, o kursu da Ã¶nerebilirim.Ä°yi Ã§alÄ±ÅŸmalar.",
2. ->  Ã‡ok teÅŸekkÃ¼r ederim..",
3. ->  Ufak bir sorum daha olacak : Feature Crosses bÃ¶lÃ¼mÃ¼nÃ¼n Playground Exercise kÄ±smÄ±ndaki Task 1'de learning rate'den bahsedilmiÅŸ, orada \"non-linear\" model'de learning rate'in yakÄ±nsama deÄŸerine etkili olmadÄ±ÄŸÄ± mÄ± anlatÄ±lmaya Ã§alÄ±ÅŸÄ±lmÄ±ÅŸ?.",
4. ->  ->  Merhaba,-> 'nÃ¼n de dediÄŸi gibi lineer modelleme bu verisetini efektif bir ÅŸekilde modelleyemiyor. Learning rate deÄŸerini deÄŸiÅŸtirmemiz lossumuzu yine azaltacaktÄ±r yani etkileyecektir ama en kadar azaltÄ±rsa azaltsÄ±n loss halen kabul edilemez dÃ¼zeyde yÃ¼ksek bir deÄŸere yakÄ±nsar, optimum deÄŸere yakÄ±nsayamaz. Yani learning rate yakÄ±nsamamÄ±zÄ± etkiler ama yeterli dÃ¼zeyde etkilemez.Ä°yi Ã§alÄ±ÅŸmalar..",
5. ->  Merhaba Nil HanÄ±m, bahsettiÄŸiniz egzersizin \"Task 1\" bÃ¶lÃ¼mÃ¼nde linear modeli verilen ÅŸekliyle Ã§alÄ±ÅŸtÄ±rÄ±lmasÄ± istenmiÅŸ. VerildiÄŸi ÅŸekliyle de \"feature\" olarak sadece x1 ve x2 var yani feature cross olmadan verilen data seti linear olarak modelleyebilir miyiz'in cevabÄ±nÄ± sorgulamamÄ±z isteniyor. Learning rate loss'u azaltsa da verilen data setten linear bir model Ã§Ä±karmamÄ±z sÃ¶z konusu deÄŸil anladÄ±ÄŸÄ±m kadarÄ±yla..",
    
### soru 

> quest: "Merhaba, Representation: Cleaning Data bÃ¶lÃ¼mÃ¼ndeki, Scaling feature values baÅŸlÄ±ÄŸÄ±ndaki maddeleri ve floating-point teriminin ne olduÄŸunu anlayamadÄ±m, yardÄ±mlarÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederim."

![image](image/12.jpg)

> comments:
  
1. -> Merhaba,1- Siz bir feature alanÄ±nÄ± scale ettiÄŸinizde gradient descent algoritmasÄ±, feature deÄŸeri daha da kÃ¼Ã§Ã¼ldÃ¼ÄŸÃ¼nden dolayÄ± daha hÄ±zlÄ± optimum deÄŸere yakÄ±nsar.2-Scale etmek NaN tuzaÄŸÄ±nÄ± engellemenize yarayacaktÄ±r. NaN tuzaÄŸÄ± kavramÄ± ÅŸudur, EÄŸer sizin verisetinizde NaN (gerÃ§ek hayatta sayÄ±lar sonsuzdur ama bilgisayar donanÄ±mÄ±nÄ±n kÄ±sÄ±tladÄ±ÄŸÄ± bir sayÄ± sÄ±nÄ±rÄ± varÄ±dr. Bunu aÅŸmasÄ± durumunda NaN olacaktÄ±r. Peki nasÄ±l aÅŸabilir? BÃ¼yÃ¼k sayÄ±larla matematik iÅŸlemleri yaparsa bu sayÄ± NaN olabilir. O bÃ¼yÃ¼k sayÄ±yÄ± kÃ¼Ã§Ã¼ltmek ve belli bir range'e sokmak iÃ§in scale yapÄ±labilir.) bir veri var ise modeldeki diÄŸer sayÄ±larÄ±mÄ±zda eninde sonunda NaN olacaktÄ±r.3-Scale etmeniz modelinizin her bir feature'Ä±nÄ±z iÃ§in ilgili weight deÄŸerlerini Ã¶ÄŸrenmesi konusunda yardÄ±mcÄ± olacaktÄ±r Ã§Ã¼nkÃ¼ scale edilmemiÅŸ geniÅŸ aralÄ±ÄŸa sahip verilerde model weighr deÄŸerini Ã¶ÄŸrenmek iÃ§in daha Ã§ok kaynak ve zaman harcayacaktÄ±r.Floating point kavramÄ± aslÄ±nda reel sayÄ±larÄ±n bilgisayar alanÄ±ndaki adÄ±dÄ±r. Bu kavrama reel deÄŸil de floating-point denmesinin sebebi ise sayÄ± iÃ§erisindeki ondalÄ±k noktasÄ±nÄ±n kayabilme Ã¶zelliÄŸinden dolayÄ±dÄ±r. GerÃ§ek dÃ¼nyada sayÄ±lar sonsuza kadar giderken, bilgisayar ortamÄ±nda bilgisayar donanÄ±mÄ±nÄ±n getirdiÄŸi sÄ±nÄ±rlamalardan dolayÄ± bÃ¼tÃ¼n sayÄ±larÄ±n gÃ¶sterilmesi mÃ¼mkÃ¼n deÄŸildir. Bununla birlikte gerÃ§ekte sonsuza kadar giden birtakÄ±m deÄŸerler bilgisayar ortamÄ±nda ortamÄ±n kapasitesine baÄŸlÄ± olarak yaklaÅŸÄ±k deÄŸerlerle temsil edilirler. Bu sÄ±nÄ±rlamalarÄ±n etkisini en aza indiren, sayÄ±larÄ±n maksimum miktarda ve gerÃ§eÄŸe en yakÄ±n ÅŸekilde temsilini saÄŸlayan sisteme \"Kayan-NoktalÄ± SayÄ±lar\" sistemi denir. Kaynak ve daha fazlasÄ± iÃ§in: [Kayan-Nokta](https://tr.wikipedia.org/wiki/Kayan_nokta) adresini inceleyebilirsiniz.Ä°yi Ã§alÄ±ÅŸmalar.
2. ->  ->  AÃ§Ä±klamanÄ±z iÃ§in teÅŸekkÃ¼r ediyorum ğŸ™‚.",
3. ->  ->  peki scale iÅŸlemini nasÄ±l yapÄ±yoruz yani tam olarak neyi scale ettiÄŸimizi ve neye gÃ¶re sÄ±nÄ±rlarÄ± belirlediÄŸimiz anlayamadÄ±m.",
4. ->  ->  Feature olarak kullanacaÄŸÄ±mÄ±z veri aralÄ±klarÄ±na bakÄ±yoruz. Zaten tek bir feature'Ä±mÄ±z var ise scale etmemiz gerekmiyor, birden fazla feature'Ä±mÄ±z var ise deÄŸer aralÄ±klarÄ±nÄ± karÅŸÄ±laÅŸtÄ±rabiliriz. Ã–rneÄŸin ev metrekaresi ve oda sayÄ±sÄ± featurelarÄ± deÄŸer aralÄ±ÄŸÄ± olarak aynÄ± dÃ¼zlemde olmayacaktÄ±r. (ev metrekaresi 50-300 arasÄ± skalada diyelim, oda sayÄ±sÄ± ise en fazla 10 olsun diyelim.) Bu durumda gradient descent fonksiyonumuzun daha hÄ±zlÄ± Ã§alÄ±ÅŸmasÄ± iÃ§in bu iki feature'Ä± benzer deÄŸer aralÄ±klarÄ±na sokmamÄ±z performansÄ± arttÄ±racaktÄ±r. Benzer dememin sebebi Ã¶rneÄŸin ev metrekaresi feature'Ä±nÄ± scale edip 50-300 aralÄ±ÄŸÄ±ndan -3Ã–zellik Ã–lÃ§ekleme ve NormalleÅŸtirme (Feature Scaling andÂ Normalization)",
5. ->  ->  TeÅŸekkÃ¼r ediyorum Ã§ok gÃ¼zel aÃ§Ä±klÄ±yorsunuz ????galiba yarÄ±sÄ± silinmiÅŸ yazÄ±nÄ±n.",
6. ->  ->  Merhaba, yorumunuz iÃ§in teÅŸekkÃ¼r ederim ğŸ™‚ evet edit diyince yazÄ±nÄ±n tamamÄ± geliyor ama save diyince yarÄ±sÄ± gidiyor teknik bir problem var sanÄ±rÄ±m ğŸ™‚ Sizin iÃ§in ÅŸÃ¶yle bir ÅŸey yapabilirim ama, edit dediÄŸimde Ã§Ä±kan yazÄ±nÄ±n tamamÄ±nÄ± ekran gÃ¶rÃ¼ntÃ¼sÃ¼ alÄ±p atÄ±yorum. GÃ¶zlerinizden ÅŸimdiden Ã¶zÃ¼r diliyorum, iyi Ã§alÄ±ÅŸmalar diliyorum ğŸ™‚.",
7. ->  ->  olur mu Ã¶yle ÅŸey ğŸ™‚ saolun kafamdaki soru iÅŸaretlerini giderdiÄŸiniz iÃ§in, kolay gelsin..",
    
### soru 

> quest: "Merhabalar. Regularization bÃ¶lÃ¼mÃ¼nÃ¼n son kÄ±smÄ±nda check your understanding 2. sorusunda sÄ±kÄ±ntÄ± yaÅŸadÄ±m. Cevap olarak 3 . ÅŸÄ±kkÄ± seÃ§tim verilen bir feature iÃ§inde noise olduÄŸu iÃ§in. Anlatabilecek birisi varsa Ã§ok sevinirim.",

> comments:
  
1. ->  Merhaba Mehmet,Regularization ile kastedilen modelin karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± azaltmaktÄ±r. Burada bahsedilen L2 ve daha sonra karÅŸÄ±laÅŸacaÄŸÄ±n L1 regularization ile modeldeki weight deÄŸerleri mÃ¼mkÃ¼n olduÄŸunca azaltÄ±lÄ±r. L2 regularization formÃ¼lÃ¼ gereÄŸi en yÃ¼ksek weight deÄŸerini hÄ±zlÄ±, dÃ¼ÅŸÃ¼k weight deÄŸerini ise yavaÅŸ ÅŸekilde 0'a yaklaÅŸtÄ±rÄ±r ancak tam olarak 0'a eÅŸitlemez. Ä°leride gÃ¶receÄŸin L1 regularization ise bazÄ± weightleri 0 yaparak model kompleksliÄŸini azaltÄ±r.\"One feature will have a large weight; the other will have a weight of almost 0.0.\" seÃ§tiÄŸin ÅŸÄ±kta bir feature'Ä±n yÃ¼ksek weight deÄŸerine sahip olacaÄŸÄ± diÄŸerinin ise 0'a yakÄ±nsayacaÄŸÄ±nÄ± sÃ¶ylÃ¼yor. Ancak L2 regularization yukarÄ±da da aÃ§Ä±kladÄ±ÄŸÄ±m gibi yÃ¼ksek weight deÄŸerini daha hÄ±zlÄ± bir ÅŸekilde azaltÄ±r ve modelde yÃ¼ksek weight deÄŸeri kalmaz Ã§Ã¼nkÃ¼ yÃ¼ksek weight deÄŸeri modelin karmaÅŸÄ±klÄ±ÄŸÄ±na en Ã§ok katkÄ± yapandÄ±r.",
    
### soru 

> quest: "Herkese merhaba. Crossing One-Hot Vectors kÄ±smÄ±nÄ± tam oturtamadÄ±m yardÄ±mcÄ± olursanÄ±z sevinirim ğŸ™‚",

> comments:
  
1. -> Merhaba,Ã–ncelikle Feature Cross yapmamÄ±zÄ±n sebebi modelimizin verileri tek bir lineer Ã§izgiyle ayÄ±ramamasÄ±dÄ±r. Bu yÃ¶ntemle yeni bir feature elde edip bu yeni feature modelimizin eÄŸitim sÄ±rasÄ±nda verileri daha etkili ayÄ±rÄ±p daha etkili bir hipotez fonksiyonu elde etmesinde yardÄ±mcÄ± oluyor. Ã–rneÄŸin elinizde \"dil\" ve \"Ã¼lke\" kategorik featurelarÄ± olsun.Ã–rneÄŸin dil feature deÄŸerleri: \"TÃ¼rkÃ§e, Ä°ngilizce, Japonca\"Ãœlke deÄŸerleri de: \"TÃ¼rkiye, Ä°spanya, Kanada\" olsun.Bu iki kategorik veriyi One Hot Encoding kullanarak binary vector'e Ã§evirdiniz ki modelimiz numerik veri Ã¼zerinde Ã§alÄ±ÅŸabilsin.EÄŸer siz bu iki feature'Ä± yani iki binary vector deÄŸerini Ã§arparsanÄ±z elinizde 9 elemanlÄ± bir binary vector olur. Bu binary vector deÄŸerlerinden her biri bir ihtimali temsil eder. Ã–rneÄŸin:[TÃ¼rkÃ§e ve TÃ¼rkiye,TÃ¼rkÃ§e ve Ä°spanya,TÃ¼rkÃ§e ve Kanada, Ä°ngilizce ve TÃ¼rkÃ§e,.......] gibi.Siz ilgili ihtimalin olduÄŸu indeksteki deÄŸere 1 koyduÄŸunuz anda artÄ±k o eÄŸitim Ã¶rneÄŸi iÃ§in o deÄŸer geÃ§erlidir. Ã–rneÄŸin [1,0,0,0,0,0,0,0,0] yaptÄ±ÄŸÄ±nÄ±zda artÄ±k TÃ¼rkÃ§e ve TÃ¼rkiye deÄŸerini o eÄŸitim Ã¶rneÄŸi iÃ§in deÄŸer belirlemiÅŸ olursunuz. Buradaki amaÃ§ featurelarÄ±n tek tek tahmine katkÄ±sÄ±ndan daha Ã§ok katkÄ± saÄŸlamalarÄ±nÄ± saÄŸlayabilmek. Ã–rneÄŸin dil ve Ã¼lke featurelarÄ± kend baÅŸlarÄ±na feature olarak katkÄ± saÄŸlarlar ama iki feature'Ä± Ã§arpÄ±p elde ettiÄŸimiz yeni feature tahminde daha Ã§ok katkÄ± saÄŸlayacaktÄ±r.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 19 people like this.Like ReportReply",
2. ->  ->  DoÄŸru anlÄ±yor muyum? Dil Ã¼lke Ã¶rneÄŸi ile modelimizin verileri lineer olarak ayÄ±ramadÄ±ÄŸÄ± durumda, featurelar Ã§arpÄ±ldÄ± ve yeni bir Ã§Ä±ktÄ± elde ettik(binary vektÃ¶r). DaÄŸÄ±nÄ±k halde olan verileri daha dÃ¼zgÃ¼n bir hale getirip tekrar bir doÄŸru ile ayÄ±rÄ±p ayÄ±ramadÄ±ÄŸÄ±mÄ±za bakÄ±yoruz bu ÅŸekilde. Peki bu yeni feature'Ä±mÄ±z mÄ± oldu yani diÄŸer featurelarla birlikte nasÄ±l deÄŸerlendiriyoruz bu durumu?.",
3. ->  ->  Evet, bu Ã§arpÄ±lan feature sizin yeni feature'Ä±nÄ±z oldu. x3 feature'Ä± olduÄŸunu dÃ¼ÅŸÃ¼nelim. x3=x1 (x) x2 olsun. Yani x1 ve x2 feature'Ä±mÄ±zÄ±n Ã§arpÄ±mÄ± ile x3 sentetik feature'Ä±mÄ±zÄ± elde edelim. Bu durumda y=w0+w1x1+w2x2 olan hipotez fonksiyonumuz artÄ±k y=w0+w1x1+w2x2+w3x3 olacak ve bu hipoetizimin doÄŸru olarak gÃ¶sterimi de bize verileri daha tutarlÄ± ayÄ±rmÄ±ÅŸ olacak. [Feature Crosses: Playground Exercises ](https://developers.google.com/machine-learning/crash-course/feature-crosses/playground-exercises) playground'Ä±nda w1 ve w2 aÄŸÄ±rlÄ±klarÄ±mÄ±zÄ± 0, w3'Ã¼mÃ¼zÃ¼ 1 olarak aldÄ±ÄŸÄ±mÄ±zda aslÄ±nda yeni oluÅŸturduÄŸumuz feature'Ä±n tek baÅŸÄ±na gÃ¼zel bir veri ayÄ±rmasÄ± yaptÄ±ÄŸÄ±nÄ± gÃ¶rebiliyoruz. Bu da yeni oluÅŸturduÄŸumuz feature x3'Ã¼n, x1 ve x2 featurelarÄ±ndan daha efektif Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶steriyor.",
4. ->  ->  teÅŸekkÃ¼r ettim, Ã§ok iyi aÃ§Ä±klÄ±yorsun..",
5. ->  ->  teÅŸekkÃ¼r ederim ğŸ™‚.",
    
### soru 

> quest: "Herkese merhabalar. Feature crosses bolumundeki en son sorulan soruda (Check your understanding kisminda) neden one feature crossu diger featurelarinin binned halini alarak olusturduk. Binned hali olmadan alsak nasil bir sonuc dogurur? Binning konusunun uygulamasi kafamda tam oturmadi acikcasi. Bu konuda yardimci olursaniz cok sevinirim. Tesekkurler.",

> comments:
  
1. ->  Merhaba, bir ÅŸehirdeki boylam derecemiz 30 olsun ve kiÅŸi baÅŸÄ±na dÃ¼ÅŸen oda sayÄ±sÄ± da 1 olsun. DiÄŸer ÅŸehirde de boylam derecesi 20 ve kiÅŸi baÅŸÄ±na dÃ¼ÅŸen oda sayÄ±sÄ± yine 1. Åimdi bunlarÄ± binning yapmadan feature crossing yaparsak, derece ne kadar yÃ¼ksekse biz ona daha Ã§ok deÄŸer biÃ§miÅŸ oluyoruz. Binning yaptÄ±ÄŸÄ±mÄ±zda, sadece ÅŸehrin bulunduÄŸu boylamÄ± 1, diÄŸerlerini 0 ÅŸeklinde ifade ettiÄŸimiz iÃ§in, boylamÄ±n derecesine gÃ¶re karar vermemiÅŸ oluyoruz.",
1. ->  ->  Ben de rooms per person Ã¶zelliÄŸinin neden bin yapÄ±ldÄ±ÄŸÄ±nÄ± anlamadÄ±m. Enlem ve boylam da gerekliliÄŸini anlatÄ±yor. Rooms per person diÄŸer iki Ã¶zelliÄŸe gÃ¶re daha stabil ve gÃ¼venilir. Bu kÄ±smÄ±nda 50 gibi bir outlier deÄŸer vardÄ± onun etkisini kÄ±rmak iÃ§in mi yine bin yapmamÄ±z gerekti ?.",
1. ->  ->  SanÄ±rÄ±m o outlier deÄŸerlerini bu iÅŸleme gelmeden temizlemiÅŸ oluyoruz. DediÄŸiniz gibi rooms per person bin iÅŸlemi diÄŸerleri kadar net gÃ¶rÃ¼lemiyor. Bin yapÄ±lmayÄ±p normal deÄŸerleri ile kullanÄ±lsaydÄ±, roomsperperson = 1 ve roomsperperson = 2 deÄŸerleri iÃ§in; 2 olan deÄŸere 2 kat Ã¶nem vermiÅŸ oluyoruz ve ister istemez w deÄŸerine mÃ¼dahele etmiÅŸ oluyoruz. Belki de fiyat olarak aralarÄ±nda net olarak 2 kat fark yok. Onu modelin vereceÄŸi aÄŸÄ±rlÄ±klar ve hesaplayacaÄŸÄ± hata ile kendisi tespit etmesini istiyoruz. AÄŸÄ±rlÄ±ÄŸa mÃ¼dahale etmemiz bizi doÄŸruluktan uzaklaÅŸtÄ±rabilir diye dÃ¼ÅŸÃ¼nÃ¼yorum.",
1. ->  ->  teÅŸekkÃ¼rler benim iÃ§in faydalÄ± oldu aÃ§Ä±klama ğŸ™‚.",

### soru 

> quest: "Herkese Merhaba, umarÄ±m dolu dolu bir machine learning crash course haftasÄ± geÃ§irirsiniz. Ben tam olarak Representation kÄ±smÄ±ndaki \"Account for upstream instability\" kÄ±smÄ±nÄ± anlamadÄ±m. YardÄ±mcÄ± olursanÄ±z sevinirim.iyi akÅŸamlar.",

> comments:
  
1. ->  Merhaba,Burada demek istediÄŸi feature'Ä±nÄ±zÄ±n deÄŸeri zaman iÃ§erisinde deÄŸiÅŸiklik gÃ¶stermemelidir yani Stationary durumda olmalÄ±dÄ±r. Ã–rneÄŸin siz her ÅŸehirdeki oy oranÄ±na bakacaksÄ±nÄ±z ve her ÅŸehir iÃ§n o ÅŸehri tanÄ±mlayacak bir belirleyici feature'a ihtiyacÄ±nÄ±z var. Bu feature ismine sehir_id dediniz ve 1234567 deÄŸerini atadÄ±nÄ±z. Bu deÄŸer ilerleyen zamanlar deÄŸiÅŸkenlik gÃ¶sterme potansiyeline sahip. Ã–rneÄŸin verisetinize yeni ÅŸehir eklendiÄŸinde veya Ã§Ä±kartÄ±ldÄ±ÄŸÄ±nda. Bunu yerine sehir_id feature deÄŸerinizi \"tr/istanbul\" yaparsanÄ±z bu deÄŸerin deÄŸiÅŸmeyeceÄŸi neredeyse kesindir (biri kalkÄ±p da ÅŸehrin adÄ±nÄ± deÄŸiÅŸtirmezse).Ä°yi Ã§alÄ±ÅŸmalar.",
2. ->  ->  anladÄ±m teÅŸekkÃ¼rler. iyi Ã§alÄ±ÅŸmalar..",
    
###Â 1. hafta sÄ±navÄ± 
  
    
### soru 

> quest: "Merhaba ArkadaÅŸlar,  Representation: Feature Engineering bÃ¶lÃ¼mÃ¼nde kategorik deÄŸerlerimize sayÄ±sal deÄŸerler tanÄ±mlayÄ±p doÄŸrudan modelimize dahil ettiÄŸimizde sorunlu olabilecek bazÄ± kÄ±sÄ±tlamalar olduÄŸundan bahsedilmiÅŸ. Buna istinaden eklediÄŸim iki maddeyi tam olarak anlayamadÄ±m. YardÄ±mcÄ± olursanÄ±z Ã§ok sevinirim. TeÅŸekkÃ¼rler"

![image](image/13.jpg)

> comments:
  
1. -> Merhaba,1.Ã–rneÄŸin sizin sokak featureÄ±nÄ±z var ve string deÄŸerinde yani kategorik bir veri. Siz dediniz ki ben her bir sokak ismi iÃ§in bir index kullanacaÄŸÄ±m yani ilk sokak iÃ§in 0, ikinci sokak iÃ§in 1 diye bÃ¶yle gidecek. 10 sokaÄŸÄ±nÄ±z var ise son indexi 9 olur bu durumda. Burada ilk maddede diyor ki gÃ¼zel index kullandÄ±n ama Ã¶rneÄŸin siz o feature deÄŸeri iÃ§in ilgili weight'i 6 buldunuz bu sefer durum ÅŸÃ¶yle olacak 1.eÄŸitim Ã¶rneÄŸi iÃ§in 6x0 2. eÄŸitim Ã¶rneÄŸi iÃ§in 6x1......... 10.eÄŸitim Ã¶rneÄŸi iÃ§in 6x9 (lineer regresyon formÃ¼lÃ¼ndeki w (x) x kÄ±smÄ±ndan). Burada sizin her sokak iÃ§in bir weight deÄŸeri Ã¶ÄŸrenmeniz gerektiÄŸinden bahsediyor Ã§Ã¼nkÃ¼ sokaklarÄ±n hepsinin labelÄ±mÄ±za farklÄ± bir etkisi olur ama siz az Ã¶nceki ÅŸekilde yaparsanÄ±z bÃ¼tÃ¼n sokaklar iÃ§in aynÄ± weight bulmuÅŸ olur ve sokaklarÄ±n labela etkisini gÃ¶zlemleyemezsiniz. Buradaki indeksleme yÃ¶ntemi her katgorik deÄŸeri bir int deÄŸere maplemekti. One Hot Encoding veya Multi-Hot Encoding kullanÄ±rsak bÃ¼tÃ¼n bu ihtimalleri featurelara ayÄ±rÄ±rÄ±z ve bu featurelardan her birinin deÄŸeri binary bir vector olur.2.YukarÄ±da sokak isimleri labelÄ±mÄ±z tek bir sokak ismi alyÄ±yormuÅŸ gibi dÃ¼ÅŸÃ¼ndÃ¼k ve ona gÃ¶re indeksledik. Bazen sokak featureÄ±mÄ±z string tipinde iki tane sokak ismi alabilir.(Ã–rneÄŸin evimiz iki sokaÄŸÄ±n kÃ¶ÅŸesindeyse.) EÄŸer siz yukarÄ±daki gibi bunlar iÃ§in de indeks kullanÄ±rsanÄ±z bu veriyi encode edemeyeceÄŸimizden bahsediyor.Ä°yi Ã§alÄ±ÅŸmalar.",
2. ->  Ã‡ok teÅŸekkÃ¼rler ->  ÅŸimdi daha iyi anladÄ±m. Ä°yi Ã§alÄ±ÅŸmalar.",
    
### soru 

> quest: "Merhaba, Tensorflow'u pip ile yÃ¼klemek istediÄŸimde bÃ¶yle bir hata alÄ±yorum. Ã‡ok yanlÄ±ÅŸ bir ÅŸey mi deniyorum? Numpy ve Pandas'Ä± bu ÅŸekilde yÃ¼klemiÅŸtim. Pip sÃ¼rÃ¼mÃ¼m gÃ¼nceldir.  YardÄ±mcÄ± olabilir misiniz? TeÅŸekkÃ¼rler,",

> comments:
  
1. ->  sanÄ±rÄ±m versiyon sÃ¶ylemenizi istiyor.pip install tensorflow==2.0.0.",
2. -> eÄŸer versiyon tanÄ±mÄ± sorunu Ã§Ã¶zmez ise bunlara bakabilirsiniz python versionunuz nedir acaba? python 3.5 veya 3.7 versiyonlu olmasÄ± gerekiyor. Åurada bir aÃ§Ä±klamasÄ± var. [Link](https://www.tensorflow.org/install) ayrÄ±ca eÄŸer bu versiyonlarÄ± kullanÄ±yorsanÄ±z \"pip3 install tensorflow\" olarak da bir dener misiniz? Bir de python2 kullanmayÄ± tercih ediyorsanÄ±z ([Link](https://www.tensorflow.org/install/pip) ÅŸu link'te olduÄŸu gibi tensorflow versiyonunu seÃ§meniz gerekiyor. AyrÄ±ca ÅŸu siteden python3 indirebilirsiniz [Link](https://www.python.org/downloads/windows)
3. ->  TeÅŸekkÃ¼r derim Python 3.8.2 kullanÄ±yordum o yÃ¼zden olmadÄ± sanÄ±rÄ±m. Åimdi 3.7.7 indirdim ve pip ile versiyon belirtmeden yÃ¼kleme yapabildim.Ã‡ok teÅŸekkÃ¼r derim,.",
4. ->  Anaconda kullanmak yeni baÅŸlayanlar iÃ§in en iyisi. Kendisi paketler arasÄ±nda uyumluluklarÄ± hallediyor ve gereklilikleri kuruyor..",
    
### soru 

> quest: "Merhaba arkadaÅŸlar,  GeÃ§en haftanÄ±n konusu ile ilgili bir yerde takÄ±ldÄ±m. TecrÃ¼besi olanlar yardÄ±mcÄ± olabilir mi?  Elimdeki bir veri setine eÄŸitim gerÃ§ekleÅŸtiriyorum ancak bir tÃ¼rlÃ¼ loss deÄŸerinde sÃ¼rekli azalmayÄ± yakalayamadÄ±m(converged olmuyor). AÅŸaÄŸÄ±da denediklerimden 3 Ã¶rnek gÃ¶rseli paylaÅŸÄ±yorum. Ã‡ok daha fazla denemem oldu. GeÃ§tiÄŸimiz haftadan nasÄ±l yapmam gerektiÄŸini tam anlayamadÄ±ÄŸÄ±mÄ± fark ettim. Ã–ÄŸrenme oranÄ±nÄ± dÃ¼ÅŸÃ¼rdÃ¼m, epoch sayÄ±sÄ±nÄ± artÄ±rdÄ±m ve batch size Ä± azalttÄ±m. Grafik hep tÄ±rtÄ±klÄ± ÅŸekilde Ã§Ä±kÄ±yor. Bunlardan kurtulmak iÃ§in anladÄ±ÄŸÄ±m kadarÄ±yla kesin geÃ§erli bir yol yok. Parametre ayarlamalarÄ±nÄ± yaparken bildiÄŸiniz dikkat edilmesi gereken baÅŸka noktalar nelerdir? TeÅŸekkÃ¼rler.

![image](image/14.jpg)
![image](image/15.jpg)
![image](image/16.jpg)

> comments:
  
1. ->  Batch-size'Ä± dÃ¼ÅŸÃ¼rmek osilasyon yapmasÄ±na yol aÃ§abilir. Stochastic gradient descent yani batch-size=1 aldÄ±ÄŸÄ±nÄ±zda daha fazla osilasyon yapacaÄŸÄ±nÄ± tahmini ediyorum. 128-256 gibi sayÄ±lar denediniz mi ?.",
2. ->  ->  MantÄ±klÄ± geldi dediÄŸiniz. Batch size bÃ¼yÃ¼dÃ¼kÃ§e daha az tahmin gerÃ§ekleÅŸtirecek. Ama yine de olmuyor..",
3. ->  ->  SÃ¼rekli azalmasÄ±ndan ziyade, hatanÄ±n dÃ¼ÅŸÃ¼k olmasÄ± daha Ã¶nemli deÄŸil mi ? Hata miktarÄ± yeterince dÃ¼ÅŸÃ¼k gibi geldi bana. AzalÄ±p artmasÄ±ndan Ã§ok, en son ulaÅŸtÄ±ÄŸÄ± noktada ne kadar az hata deÄŸerine ulaÅŸtÄ±ÄŸÄ± daha Ã¶nemli diye biliyorum. Pratik konusunda daha tecrÃ¼beli arkadaÅŸlar belki daha iyi yanÄ±tlayabilir, her zaman teorik bilgi ile pratik baÄŸdaÅŸmÄ±yor. Belki sizin istediÄŸiniz gibi daha iyi bir sonuÃ§ elde edilebilir ğŸ™‚.",
4. ->  ->  Åurada sÃ¼rekli azalmalÄ± diyor ama.",
5. ->  ->  Bence orada demek istediÄŸi genel olarak azalan bir grafiÄŸe sahip olmasÄ±, sizin grafik iÃ§in konuÅŸacak olursak 0.04 e gelip sonra 0.08 e tekrar atlÄ±yorsa o zaman sorun var demektir. Ama 0.0310 dan 0.312 ye Ã§Ä±karsa, bunda bir sorun yok diye dÃ¼ÅŸÃ¼nÃ¼yorum. Sizin Ã§izdirdiÄŸiniz grafiÄŸin Ã¶lÃ§eÄŸi de bÃ¶yle gÃ¶zÃ¼kmesine sebep oluyor. HatayÄ± 0-100 arasÄ± Ã§izdirirseniz bÃ¼yÃ¼k ihtimal bu titreÅŸimler hiÃ§ gÃ¶zÃ¼kmeyecektir. Siz baÅŸka kaynaklarda gÃ¶rdÃ¼ÄŸÃ¼nÃ¼z sÃ¼rekli azalan grafikleri Ã¶lÃ§eÄŸi 0 - 0.10 aralÄ±ÄŸÄ±na dÃ¼ÅŸÃ¼rÃ¼p incelerseniz bÃ¼yÃ¼k ihtimal onlarda da bu tarz dalgalanmalar olacaktÄ±r..",
6. ->  ->  steadily kelimesini sÃ¼rekli olarak deÄŸil de yavaÅŸ yavaÅŸ ve dÃ¼zenli bir ÅŸekilde olarak Ã§evirebilirsin..",
7. ->  Modelinizin eÄŸitiminde herhangi bir sorun gÃ¶rÃ¼nmÃ¼yor. Bu kadarcÄ±k sizin deyiminizle tÄ±rtÄ±klÄ± olmasÄ± Ã§ok normal. Epoch sayÄ±sÄ± arttÄ±kÃ§a azalma gerÃ§ekleÅŸmiÅŸ ancak belli bir yerden sonra adÄ±mlar arasÄ± fark o kadar az ki grafikte net bir ÅŸekilde belli olmuyor. Bu azalÄ±ÅŸÄ± net bir ÅŸekilde gÃ¶rmek istersen Ã¶zellikle 0.04 deÄŸerinden dÃ¼ÅŸÃ¼k deÄŸerler iÃ§in y ekseninde ki noktalara Ã§ok yakÄ±ndan bakabilirsin (yanlÄ±ÅŸ hatÄ±rlamÄ±yorsam matplotlib'de ticker fonksiyonu ile yapabilirsin )..",
8. ->  Evet bence de bazen daha kÃ¶tÃ¼ sonuÃ§lara izin vermesi gerekir ki lokal minimumlardan kurtulabilsin. Ã–rnekteki grafik sÃ¼rekli azalan ÅŸeklinde olunca sormak istedim. TeÅŸekkÃ¼rler cevaplar iÃ§in. Biraz araÅŸtÄ±rÄ±nca ÅŸu linke denk geldim. Ã‡ok faydalÄ± oldu sizinle de paylaÅŸayÄ±m: [Link](https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/)
    
### soru 

> quest: "Merhaba.Representation kÄ±smÄ±nda verileri one hot encoding yÃ¶ntemi ile kullanÄ±yoruz fakat weight Ã¶zelliÄŸini nasÄ±l kullanacaÄŸÄ±mÄ±zÄ± anlayamadÄ±m.",

> comments:
  
1. ->  One hot encoding kullandÄ±ÄŸÄ±mÄ±zda Ã¶rnekte verilen evin bulunduÄŸu sokak deÄŸeri 1 oluyor, kalan sokaklar 0 oluyor. [0 0 0 1 0 0] ÅŸeklinde bir vektÃ¶r oluÅŸmuÅŸ oluyor (boyutlarÄ± rasgele yazdÄ±m). Ve weight deÄŸerimizle Ã§arparken sadece tahmin etmek istediÄŸimiz evin bulunduÄŸu sokak hesaba katÄ±lmÄ±ÅŸ oluyor. 0 olan diÄŸer sokaklarÄ± deÄŸerlendirmeye katmamÄ±ÅŸ oluyoruz (w * 0 = 0 olacaÄŸÄ±ndan). UmarÄ±m soruyu doÄŸru anladÄ±m ğŸ™‚",
2. ->  ->  evet doÄŸru anlamÄ±ÅŸsÄ±nÄ±z :). fakat bu deÄŸerleri sayÄ±sal olarak nasÄ±l kullanÄ±yoruz ?.",
3. ->  ->  evin fiyatÄ± Ã¶rneÄŸi iÃ§in linear regression kullandÄ±ÄŸÄ±mÄ±zda, y' = w1*x1 + w2*x2 + .... + wn * xn + b ÅŸeklinde bir formulÃ¼mÃ¼z vardÄ± (n = feature sayÄ±sÄ±). Bizim sokak ismi feature'Ä±mÄ±z x2 olsun. (x2 * w2) -> sadece istediÄŸimiz sokak iÃ§in sayÄ±sal bir deÄŸer Ã¼retecektir. w2 deÄŸerimiz 5 ise oradan elde ettiÄŸimiz deÄŸer yukarÄ±da yazdÄ±ÄŸÄ±m formÃ¼lde sadece o sokak iÃ§in katkÄ± saÄŸlayÄ±p modelin o sokaÄŸÄ±n ev fiyatÄ±nÄ± tahmin ederken ne kadar etkili olduÄŸunu anlamasÄ±nÄ± saÄŸlayacaktÄ±r. weight deÄŸerleri ilk olarak 0 veya random olarak belirleniyor. model training kÄ±smÄ±nda evin gerÃ§ek fiyatÄ±nÄ± gÃ¶rÃ¼p hatayÄ± hesaplÄ±yor. weight deÄŸerlerini hatanÄ±n azalmasÄ± iÃ§in gradient descent kullanarak gÃ¼ncelliyor. Biz belirlemiyoruz weight deÄŸerlerini. Son kÄ±sÄ±mlarÄ± bÃ¼tÃ¼nlÃ¼k oluÅŸturmasÄ± aÃ§Ä±sÄ±ndan yazdÄ±m, diÄŸer arkadaÅŸlar okurken daha faydalÄ± olabilir.,
4. -> ->  GÃ¼zel aÃ§Ä±klama teÅŸekkÃ¼rler. Ã‡ok ufak bir ekleme yapayÄ±m. EÄŸer bir ev 2 sokaÄŸÄ±n kesiÅŸiminde (2 sokaÄŸÄ±n kesiÅŸtiÄŸi kÃ¶ÅŸede) bulunuyor ise vektÃ¶rÃ¼mÃ¼zde bahsi geÃ§en 2 sokaÄŸÄ±n deÄŸeri de 1 oluyor. VektÃ¶r de Ã¶rneÄŸin [ 0 0 0 0 1 0 1 0 0] gibi bir ÅŸey oluyor. Ana regresyon denklemimizde de 2 farklÄ± katsayÄ±nÄ±n etkisini dikkate alÄ±yoruz.,
5. ->  ->  teÅŸekkÃ¼r ederim gayet iyi aÃ§Ä±klamÄ±ÅŸsÄ±nÄ±z ğŸ™‚.",
6. ->  Merhaba, benim anladÄ±ÄŸÄ±m kadarÄ±yla; one-hot encoding yÃ¶ntemi sayÄ±sal olmayan raw data larÄ± feature a Ã§evirip eÄŸitimde Ã¶ÄŸrenilen weight ile Ã§arpabilmek iÃ§in kullanÄ±lan bir yÃ¶ntem. Yani aslÄ±nda Ã¶nce verileri feature a Ã§evirip ki bunu yaparken one-hot encoding yÃ¶ntemi de kullanÄ±lÄ±yor sonra eÄŸitim esnasÄ±nda weight leri buluyoruz. UmarÄ±m bende doÄŸru anlamÄ±ÅŸÄ±mdÄ±r..",
7. ->  Ã‡alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z kÄ±sÄ±mda anlatÄ±lan, model weightlerinin anlamlÄ± olmasÄ± iÃ§in neden kategorik deÄŸiÅŸkenlerde one-hot encoding yÃ¶ntemini kullanmamÄ±z gerektiÄŸi. Bu anlayÄ±ÅŸla o kÄ±sma tekrar bakarsanÄ±z net bir ÅŸekilde anlayacaÄŸÄ±nÄ±zÄ± dÃ¼ÅŸÃ¼nÃ¼yorum..",
    
### soru 

> quest: "Merhabalar herkese, keyifli ve verimli haftalar ???????? Ben sparse representation Ä± tam olarak anlamadÄ±m. Ã‡ok fazla farklÄ± deÄŸer olan kategorik featurelarda multi-hot encoding yaparsak Ã§ok bÃ¼yÃ¼k bir vektÃ¶rde Ã§oÄŸu 0, birkaÃ§ elemanÄ± 1 olan bir gÃ¶sterimin pek doÄŸru olmayacaÄŸÄ±nÄ±, bunun iÃ§in sparse representation yapÄ±labileceÄŸi sÃ¶yleniyor. Bunun iÃ§in vocabularydeki her deÄŸeri indexliyor ve 1 milyon eleman tutmak yerine deÄŸeri 0 dan farklÄ± elemanlarÄ±n deÄŸerlerini ve bu elemanlarÄ±n index ini tutuyor.  Benim anlamadÄ±ÄŸÄ±m index bilgisini training iÅŸleminde nasÄ±l uyguluyor? Index iÃ§in de ayrÄ± bir weight mi kullanÄ±lÄ±yor?  TeÅŸekkÃ¼rler ????",

> comments:
  
1. ->  Merhabalar,DoÄŸru anlamÄ±ÅŸsÄ±nÄ±z. Yeniden bir indexleme yapÄ±lmÄ±yor. Sadece elimizde tutacaÄŸÄ±mÄ±z datalarÄ± indexleri ile birlikte alÄ±nÄ±yor. Ancak index bilgisi benzersiz olmasÄ± sebebi ile ML iÃ§in kullanÄ±lamamaktadÄ±r. EÄŸitime katkÄ± saÄŸlamamasÄ± sebebiyle veriden eÄŸitim aÅŸamasÄ±na gelmeden Ã§Ä±kartÄ±lÄ±r diye biliyorum.Ä°yi Ã§alÄ±ÅŸmalar. ğŸ™‚",
2. ->  Bu gÃ¶sterimin teorik temeli seyrek matrisler (sparse matrices ). [Sparse matrix](https://en.wikipedia.org/wiki/Sparse_matrix) linkinden ekstra inceleme yapabilirsiniz.",
3. ->  TeÅŸekkÃ¼rler ğŸ™‚ ->  -> .",

### soru 

> quest: "Merhaba,  \"There's a Goldilocks learning rate for every regression problem. \" Goldilocks ile learning rate baglantisini, Goldilocks learning rate kavramini biraz acabilir misiniz?",

> comments:
  
1. ->  Merhaba,Goldilocks kavramÄ± ve learning rate'in rolÃ¼ [Link](http://community.globalaihub.com/community/status/1043-1043-1586253928/) postunun altÄ±nda aÃ§Ä±klanmÄ±ÅŸtÄ±. Oradan bulabilirsiniz.Ä°yi Ã§alÄ±ÅŸmalar dilerim..",
2. -> gozden kacirmisim, tesekkurler..",
    

    
### soru 

> quest: "Merhaba. Binning ile feature'Ä± belirli sÄ±nÄ±rlara bÃ¶lÃ¼p, bu sÄ±nÄ±r sayÄ±sÄ± kadar yeni feature elde edip, bu featurelarÄ± da binary vectorler ile mi ifade ediyoruz?",

> comments:
  
1. -> Merhaba,Bunu basit bir Ã¶rnekle anlatabilirim. Ã–rneÄŸin sizin elinizde yaÅŸlarÄ± farklÄ± 10 tane insan olsun. Bu insanlarÄ±n yaÅŸlarÄ± numerik veridir ve siz binningde bunu kategorik veriye Ã§evirirsiniz ki feature ile label arasÄ±nda lineer bir baÄŸÄ±ntÄ± oluÅŸabilsin. Ã–rneÄŸin bu insanlarÄ±n yaÅŸlarÄ±na gÃ¶re diyabet olup olmadÄ±klarÄ±nÄ± tahmin etmek istiyorsunuz bunun iÃ§in ise elinizde her yaÅŸ grubu iÃ§in belli diyabet risk deÄŸerleri var Ã¶rmeÄŸin 50-60 arasÄ± riskli siyabet 40-50 arasÄ± az riskli diyabet gibi. Burada yapmanÄ±z gereken ÅŸey bu yaÅŸlarÄ± kategorik veriye Ã§evirmek. Bunun iÃ§in Elinizde 10 tane insan var ise bu insanlarÄ±n yaÅŸ aralÄ±klarÄ±nÄ± bulup bunlarÄ± kategorik veriye Ã§evirirsiniz (Ã¶rneÄŸin 19 yaÅŸ iÃ§in 10lar, 28 yaÅŸ iÃ§in 20ler.... gibi) Burada sÄ±nÄ±r sayÄ±sÄ± kadar yani bÃ¶ldÃ¼ÄŸÃ¼mÃ¼z kategorik veri sayÄ±sÄ± kadar feature'Ä±mÄ±z oldu. Bu featurelar binary vectorler ile ifade edilir Ã¶rneÄŸin 10lar feature'Ä±mÄ±zÄ±n value'sÄ± binary vectordÃ¼r ve karÅŸÄ±lÄ±ÄŸÄ± sÄ±rasÄ±yla [10lar,20ÅŸer,30lar,40lar,50ler,60lar,70ler,80ler,90lar] olacaktÄ±r. EÄŸer biz 19 yaÅŸÄ±ndaki bir insanÄ± bu binary vectÃ¶r ile ifade edeceksek [1,0,0,0,0,0,0,0,0] olarak yapmalÄ±yÄ±z ki bu insanÄ±n hangi kategoride olduÄŸunu belli edebilelim. (10- yaÅŸ arasÄ±nda). UmarÄ±m aÃ§Ä±klayÄ±cÄ± olmuÅŸtur eÄŸer olmamÄ±ÅŸsa ekstra olarak ÅŸu linki de inceleyebilirsiniz: [Link](https://www.youtube.com/watch?v=iv_ec0EfXcE&t=204s) . EksiÄŸim veya hatam varsa dÃ¼zeltilmelere aÃ§Ä±ÄŸÄ±m ğŸ™‚Machine Learning Tutorial 10 - Binning Datawww.youtube.comBest Machine Learning book: [Link](https://amzn.to/2MilWH0) (Fundamentals Of Machine Learning for Predictive Data Analytics). Machine Learning and Predictive Analyti...",
2. -> ->  NiÃ§in yaÅŸ gruplarÄ±nÄ± 10-19, 20-29 vs. gibi gruplara ayÄ±rÄ±yoruz. Ã–rneÄŸin; 10-14, 15-19, 20-24 vs. gibi ayÄ±rsak ne olurdu. Buna sezgisel mi karar veriyoruz?.",
3. ->  -> Merhaba, buna sezgisel karar verebilirsiniz. Ã–rneÄŸin yeni bir hastalÄ±k tipi beÅŸerli yaÅŸ gruplarÄ± iÃ§in deÄŸiiklik gÃ¶steriyorsa bunun iÃ§in yaÅŸlarÄ± beÅŸerli gruplara ayÄ±rabilirsiniz..",
4. -> ->  O halde bir soru daha sorayÄ±m. EÄŸer bu aralÄ±klarÄ±mÄ±zÄ±n sabit olduÄŸunu (yani asimetri var) dÃ¼ÅŸÃ¼nmÃ¼yorsak yani 10-19, 20-29 gibi gruplar yapÄ±yorken belli bir yaÅŸtan sonra (Ã–rneÄŸin 60 yaÅŸÄ±ndan sonra gruplarÄ± 60-64, 65-69 ÅŸeklinde yapmamÄ±z gerekiyor olsun) bu gruplarÄ±n daralmasÄ± gerektiÄŸini dÃ¼ÅŸÃ¼nÃ¼yorsak nasÄ±l bir yol izlemeliyiz..",
5. ->  -> Merhaba, [Link](https://medium.com/hacktive-devs/feature-engineering-in-machine-learning-part-1-a3904769cd93) linkinde 3 ÅŸekilde binning yapabileceÄŸimizden bahsediyor. Benim yukarÄ±da bahsettiÄŸim binning Ã§eÅŸidi Fixed-Width Binning Ã§eÅŸididir. Yani binning aralÄ±klalarÄ± arasÄ±nda sabit bir katsayÄ± vardÄ±r. Sizin dediÄŸiniz yÃ¶ntem de gerÃ§ekleÅŸtirilebilir buna Binning By Instinct(Ä°Ã§gÃ¼dÃ¼yle binning) denir. Burada bin range aralÄ±klarÄ±nÄ± siz belirliyorsunuz. Toparlamam gerekirse, dediÄŸiniz yÃ¶ntem iÃ§in Binning By Instinct kullanabilirsiniz.",
"Feature Engineering in Machine Learning (Part 1)medium.comHandling Simple Numeric Data with Binning.",
6. -> buraya ek olarak bir ÅŸey sormak isterim, Ã§ok saÃ§ma olabilir ama kusura bakmayÄ±n lÃ¼tfen, peki bunlarÄ± bir sokakta yaÅŸayan, yaÅŸ aralÄ±klarÄ±nÄ±, diyabet durumlarÄ±nÄ±(az riskli, Ã§ok riskli, risksiz) ve yaÅŸadÄ±klarÄ± yerleri(latitude cinsinden) barÄ±ndÄ±ran bir raw values olarak dÃ¼ÅŸÃ¼nÃ¼rsek, yaÅŸ aralÄ±klarÄ±nÄ± ve yaÅŸadÄ±klarÄ± yerleri binning ile diyabet olma durumlarÄ±nÄ± ise on-hot-encodingle kategorileÅŸtirip hepsi iÃ§in yeni feature'lar (binary vectorler) elde ederek, bu sayede train modeli daha iyi tahmin verileri Ã§Ä±karsÄ±n diye mi eÄŸitiyoruz? Yoksa bunlar tamamen bu Ã¶rnekten farklÄ±, ayrÄ± ayrÄ± konular mÄ±?1 month ago Like Reply Edit",
7. -> -> Makine Ã¶ÄŸrenme algoritmalarÄ± doÄŸrudan kategorik veriler Ã¼zerinde Ã§alÄ±ÅŸmamaktadÄ±r bu yÃ¼zden verilerimizin sayÄ±sal verilere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi gerekmektedir.Ã–ncelikle binning feature ile numerik verimizi kategorik karÅŸÄ±lÄ±klarÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yoruz. Binning kullanarak yaÅŸlarÄ±mÄ±zÄ± 10-20,40-50 gibi kategorilere ayÄ±rÄ±yoruz ki amacÄ±mÄ±z verideki gÃ¼rÃ¼ltÃ¼yÃ¼ ve non-linearity durumunu azaltÄ±p modelimizin generalization oranÄ±nÄ± arttÄ±rmak. YaÅŸ iÃ§in konuÅŸursak ÅŸu an elimizde 10-20,21-30.. kategorilerine karÅŸÄ±lÄ±k gelen booelan featurelarÄ± oldu. Yani bir kiÅŸi 18 yaÅŸÄ±nda ise 10-20 yaÅŸ aralÄ±ÄŸÄ± feature'Ä± 1, diÄŸerleri 0'dÄ±r. Bir eÄŸitim Ã¶rneÄŸi iÃ§in bu yaÅŸ kategorilerinden aynÄ± anda ikisi de 1 olamaz. Ã–rneÄŸin bir kiÅŸi hem 27 hem de 37 yaÅŸÄ±nda olamaz. Bu yÃ¼zden bu One Hot Encoding olarak geÃ§er.YaÅŸadÄ±klarÄ± yer iÃ§in de tahminime gÃ¶re bu deÄŸerleri de binning ile kategorik verilere sokup labelÄ±mÄ±zÄ± bu kategorileÅŸmiÅŸ veriler Ã¼zerinden yapmamÄ±z, yani regression problemimizi classification problemine Ã§evirmemiz gerekiyor.Diyabet olma durumunu ise evet One Hot Encoding ile kategorileÅŸtirip bunu da numerik gÃ¶sterime sÄ±ÄŸdÄ±rabilmek iÃ§in binary vector elde ederiz ve tÃ¼m bu iÅŸlemlerimizin amacÄ± kategorik verileri numerik veriye sokmak ve generalization'Ä± yani veri tahminini arttÄ±rmaktÄ±r. GÃ¶zden kaÃ§Ä±rdÄ±ÄŸÄ±m veya eksik noktam varsa dÃ¼zeltmekten eklemekten Ã§ekinmeyin ğŸ™‚ Ä°yi Ã§alÄ±ÅŸmalar.,
8. -> ->  Ã§ok teÅŸekkÃ¼r ederim,
    
### soru 

> quest: "Merhabalar, Validation and Test sets kÄ±smÄ±nda, loss eÄŸrileri arasÄ±ndaki farkÄ± azaltmak iÃ§in, veri setini shuffle etmemiz gerektiÄŸi anlatÄ±lmÄ±ÅŸtÄ±(longtitude a gÃ¶re azalan indekslendiÄŸi iÃ§in, split ederken train ve validasyon setinin iÃ§eriÄŸi benzer olmuyor, bundan dolayÄ± shuffle etmemiz gerekiyor), shuffle ettikten sonra da eÄŸrilerin birbirine yakÄ±n konumlandÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼yoruz. Ancak, shuffle edilmemiÅŸ kÄ±sÄ±mda validation_split i 0.4 e Ã§ekerek de aradaki farkÄ± azaltabiliyoruz. Bu tamamen elimizdeki veri setine gÃ¶re gerÃ§ekleÅŸen rastlantÄ±sal bir durum mudur? Ä°ki yÃ¶ntemin birbirinden farkÄ± nedir teknik olarak? validasyona ayÄ±rdÄ±ÄŸÄ±mÄ±z veri miktarÄ±nÄ±n yÃ¼zdesini artÄ±rmak genel olarak tercih edilmemesi gereken bir yol mudur? TeÅŸekkÃ¼r ederim ÅŸimdiden yorumlar iÃ§in.",

> comments:
  
1. -> Merhaba,Shuffle edilmemiÅŸ veride calidation boyutunu deÄŸitirerek loss eÄŸrilerini birbirine yakÄ±nlaÅŸtÄ±rabiliyoruz. Ä°lk durumda train loss 70, validation loss 90 olsun, validation setin boyutunu arttÄ±rdÄ±kÃ§a, train'in loss deÄŸeri artacak, validation'un azalacak yani 80 civarlarÄ±nda bu iki eÄŸri yaklaÅŸÄ±k olarak birbirlerinin aynÄ±sÄ± olacak. Ki bu durum loss da azalma yapmamakta aksine artÄ±ÅŸa sebep olmakta. Bu yÃ¼zden validation seti optimum boyutta tutarak, train seti olabildiÄŸince bÃ¼yÃ¼k tutmayÄ± amaÃ§lÄ±yoruz.SÄ±ralÄ± veri setinden rastgele Ã¶rnek Ã§ekmiÅŸ olsak bile sÄ±ralÄ± veri Ã§ekmiÅŸ oluruz. Bu durumda da Ã§ekmiÅŸ olduÄŸumuz Ã¶rnek ile train setimizi saÄŸlÄ±klÄ± bir ÅŸekilde ifade edemeyiz.(Train ve Test setleri aynÄ± daÄŸÄ±lÄ±mdan seÃ§ilmeli - Generalization Assumption 3). Bu sebeple veri setimizi karÄ±ÅŸtÄ±rÄ±yor sonrasÄ±nda Ã¶rneklem Ã§ekiyoruz. BÃ¶ylece verimizi genelleyebileceÄŸimiz bir Ã¶rnek Ã§ekebilme ihtimalimiz sÄ±ralÄ± veride olduÄŸundan daha fazla olacaktÄ±r.Loss EÄŸrilerinin grafiÄŸini inceleyerek bahsettiÄŸim durumlarÄ± gÃ¶zlemleyebilirsiniz.Ä°yi Ã§alÄ±ÅŸmalar..",
2. ->  Validation ve train datasetleri icin shuffle = True dedigimizde randomization saglar ve modelin ezberlemesinin onune gecilmesine yardim eder.Tabiki ezberlemeyi yani overfitting i sadece shuffle = True diyerek engelleyemeyiz ve overfitting ortaya ciktiginda validation loss ile test loss arasindaki fark buyuk egriler uzak olur.Validation ve test loss egrilerini birbirine yaklastirmak demek validation sirasinda modelimizi check ederken aldigimiz iyi sonuclari(umarim iyi sonuclardir) test sirasinda da elde etmek, parallel sonuclara sahip olmak demektir.Yani bir anlamda overfittingi onlemek demektir.Iyi generalization demektir.Bunu yapmanin yolu validation setini buyutmek train setini kucultmek filan degildir..",
    
### soru 

> quest: "Merhaba arkadaÅŸlar,  Ã–ncelikle umarÄ±m herkesin sÄ±navÄ± verimli olmuÅŸtur, yeni hafta iÃ§in de ÅŸimdiden iyi Ã§alÄ±ÅŸmalar :)  Correlation matrix Ã¼zerine biraz dÃ¼ÅŸÃ¼ndÃ¼m de, output ile yÃ¼ksek corr. deÄŸerine sahip olanlar Ã§ok Ã¶nemli onlarÄ± kesinlikle traininge dahil etmeliyiz ama hem output hem de diÄŸer featureâ€™lar ile 0a yakÄ±n corr deÄŸerine sahip olan bir featureâ€™Ä± traininge dahil etmeye gerÃ§ekten gerek var mÄ± sorusu kafamÄ± kurcaladÄ±.  Ama sonuÃ§ta corr matrix bize aralarÄ±ndaki bÃ¼tÃ¼n iliÅŸkiyi vermiyordu sadece artÄ±ÅŸ-azalÄ±ÅŸ iliÅŸkisi ile ilgili bir bilgi alÄ±yorduk bu da featureâ€™lar arasÄ±ndaki farklÄ± bir iliÅŸkinin outputu etkileme ihtimalinin bu matrix ile keÅŸfedilememe olasÄ±lÄ±ÄŸÄ±nÄ± ortaya Ã§Ä±kartÄ±yordu.  Bunu bir Ã¶rnekle aÃ§Ä±klamam gerekirse mesela a b c featurelarÄ±mÄ±z ve y output olsun, (a-b)+câ€™nin outputa eÅŸit olmasÄ± gibi bir durumda a ya da bâ€™nin bÃ¼tÃ¼n corr deÄŸerleri 0 olsa bile kendi aralarÄ±ndaki farkÄ±n outputa etkisi olduÄŸunu gÃ¶rebiliyoruz, yani corr matrix bir iÅŸimize yaramÄ±yor. Peki bu gibi durumlarda hangi featureâ€™larÄ±n elenmesi hangilerinin traininge dahil edilmesine nasÄ±l karar vermeliyiz?  Zaman ayÄ±rdÄ±ÄŸÄ±nÄ±z iÃ§in Ã§ok teÅŸekkÃ¼r ederim.

> comments:
  
1. -> Overfit'i engellemenin yollarÄ±ndan birisi \"removing useless/irrelevant features\". Ä°lgisiz Ã¶zelliklerin modelde kullanÄ±lmasÄ± modelin verimini dÃ¼ÅŸÃ¼rebilir. Bu feature'lar ya veri setinden dÃ¼ÅŸÃ¼rÃ¼lÃ¼yor ya da daha iliÅŸkili olabilecek hale dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor.google crash course'da california housing data'yla Ã§alÄ±ÅŸÄ±rken toplam oda sayÄ±sÄ±nÄ± nÃ¼fusa bÃ¶lerek \"kiÅŸi baÅŸÄ±na dÃ¼ÅŸen oda sayÄ±sÄ±\" feature'Ä±nÄ± oluÅŸturduÄŸumuzda bunu yaptÄ±k. EÄŸer modeli tek yerine Ã§ok sayÄ±da Ã¶zellik kullanarak eÄŸitiyor olsaydÄ±k, \"evin kapÄ±sÄ±nÄ±n rengi\"(mesela) gibi bir kolonu model dÄ±ÅŸÄ±nda bÄ±rakmamÄ±z gerekirdi.DolayÄ±sÄ±yla, yanlÄ±ÅŸ yorumlamÄ±yorsam, bu Ã¼zerine Ã§alÄ±ÅŸÄ±lan alanÄ± iyi bilmemizi gerektiriyor. Ã‡Ã¼nkÃ¼, belki de kapÄ±nÄ±n rengi bu bÃ¶lge iÃ§in zenginlik/lÃ¼ks belirtisidir:Ã–r.Afrika'da birkaÃ§ sene Ã¶nce yoksul hanelere yapÄ±lacak yardÄ±mlarÄ±n doÄŸru kiÅŸilere ulaÅŸmasÄ±nÄ± saÄŸlamak iÃ§in bir derin Ã¶ÄŸrenme Ã§alÄ±ÅŸmasÄ± yapÄ±ldÄ±. Uydu fotoÄŸraflarÄ± yorumlanarak yardÄ±ma talip bÃ¶lgedeki evlerin ne kadarÄ±nÄ±n metal Ã§atÄ±lara sahip olduÄŸu ayÄ±rt edildi. BÃ¶ylece bu bÃ¶lgenin diÄŸer bÃ¶lgelere kÄ±yasla ne kadar fakir/zengin olduÄŸu ayÄ±rt edildi. [Link](https://www.liebertpub.com/doi/pdf/10.1089/big.2014.0061) [Link](https://www.liebertpub.com/doi/pdf/10.1089/big.2014.0061www.liebertpub.com)
2. ->  Soruya detaylÄ± bir yanÄ±t veremeyeceÄŸim fakat ufak bir ekleme yapayÄ±m; feature'lar arasÄ±ndaki correlation Ã§ok yÃ¼ksekse bunun tahminimiz Ã¼zerinde ekstra bilgi taÅŸÄ±madÄ±ÄŸÄ±nÄ± ve bu feature'larÄ±n elenmesi gerektiÄŸini biliyorum. Mesela bir feature diÄŸerinin 2 katÄ± ise, correlation deÄŸeri 1 olur ve bir tanesini silmek verimlilik aÃ§Ä±sÄ±ndan faydalÄ± oluyor..",
3. ->  ->  Bence de corr deÄŸeri 1 ise o feature'lardan birini silmek gayet mantÄ±klÄ± bir karar olur sadece ufak bir ekleme yapmak istiyorum, anladÄ±ÄŸÄ±m kadarÄ±yla corr deÄŸeri bize artÄ±ÅŸ/azalÄ±ÅŸ katsayÄ±sÄ±nÄ± deÄŸil, olasÄ±lÄ±ÄŸÄ±nÄ± veriyor.(verdiÄŸiniz Ã¶rnekte bu yanlÄ±ÅŸ anlaÅŸÄ±lmalara yol aÃ§abilir diye eklemek istedim).",
4. ->  Merhabalar,Bu konu ile alakalÄ± yakÄ±n bir geÃ§miÅŸte araÅŸtÄ±rma yapmak fÄ±rsatÄ±m oldu. KarÅŸÄ±laÅŸtÄ±ÄŸÄ±m yÃ¶ntemlerin bÃ¼yÃ¼k Ã§oÄŸunluÄŸu deneyerek buna karar vermekte. DiÄŸer kÄ±smÄ± ise modelde kimin kalacaÄŸÄ±na istatistiksel testler yaparak karar verip sonrasÄ±nda elde ettikleri modelleri deneyerek etkinlikliklerini Ã¶lÃ§mekte.Sorunuza cevap verecek olursam: Deneyerek karar verebilirsiniz..",
5. ->  Herkese cevaplarÄ± iÃ§in Ã§ok teÅŸekkÃ¼r ederim, ÅŸu ana kadar yapÄ±lan yorumlardan elde ettiÄŸim Ã§Ä±karÄ±mlar; Ã¼zerine Ã§alÄ±ÅŸÄ±lan alana gÃ¶re bilgi sahibi olmak gerekebiliyor ya da deneyerek Ã¶nemli/Ã¶nemsiz feature'larÄ± tespit etmek. Ben aynÄ± zamanda ÅŸunu da merak ediyordum acaba bunlarÄ± tespit etmek iÃ§in belirli algoritma veya matematiksel yaklaÅŸÄ±mlar var mÄ±?.",
6. ->  ->  Istatistiki yaklasimlar var.kisa cevap: Sormus oldugun sorunun temeli Multiple Regression Analysis. Bu isimle google'laya bilirsin ya da talep edersen sana link gonderebilirim.Konuya ne kadar hakimsin bilemiyorum ama oncelikle sunu vurgu yapmak gerekiyor, verdigin ornek ve uyguladigin correlation matrix multiple regression konusunun ogeleri, yani coklu aciklayici degisken ile bir bagimli degiskenin tahmini. Cok degiskenli regresyonlarda regresyonun tahmin gucu ana konudur. Bunun da olcutu R-Squared denen bir parametre. Yalniz regresyona her buldugun degiskeni atma sansin yok ne yazik ki; kurgulanmasinda kistaslar bulunuyor. Ornegin aciklayici degiskenler arasinda dogrusal bir iliski bulunmamali (collinearity). Bu tarz degiskenlerden sadece birini denkleme katabilirsin ya da degiskenleri arindirdiktan sonra kullanabilirsin..",
7. ->  ->  Multiple Regression Analysis ile ilgili daha detaylÄ± araÅŸtÄ±rma yapacaÄŸÄ±m. R-squared parametresi yukarÄ±da anlattÄ±ÄŸÄ±nÄ±za gÃ¶re RMSE ile aynÄ± gÃ¶revi gÃ¶rÃ¼yor yani tahmin gÃ¼cÃ¼nÃ¼ anlamamÄ±za yarÄ±yor, bir farkÄ± var mÄ±dÄ±r acaba soruyorum Ã§Ã¼nkÃ¼ eÄŸer pek bir farkÄ± yoksa Ã¼zerinde durmanÄ±zÄ±n ve RMSE yerine onu kullanmanÄ±zÄ±n sebebini tam anlayamadÄ±m, teÅŸekkÃ¼rler..",
8. ->  ->  Fark var. RMSE mevcut durumu acikliyor. Verilen degerlere bagli olarak su kadar ya da bu kadar basarili demek icin var. R-squared dagilimin aciklayicilik gucu var. Yani (dagilimda bir degisiklik olmadigi surece) modelin yeni verileri de ne kadar aciklayabildigini ifade etmek icin kullaniliyor. Su soylediklerim birbirinin aynisi ya da ayni seyin laciverti gibi geliyor kulaga belki ama degil. Ikisi de modelin gucuyle mi alakali, evet. Ayni seyler mi veya ayni amaca mi hizmet ediyorlar, hayir. Yazilim gecmisinden geldigini varsayarak, su soylediklerimi icsellestirebilmek sanirim istatistik ile biraz hasir nesir olmayi gerektiriyor, onu da sana ben veremiyor olabilirim. Suraya iki link birakayim, benim anlattiklarimdan daha faydali olurlar sanirim.RMSE: [R-squared](https://www.statisticshowto.com/rmse/R-squared) [Coefficient-of-Detetmination](https://www.statisticshowto.com/probability-and-statistics/coefficient-of-determination-r-squared/)
9. ->  [Feature Selection](https://scikit-learn.org/stable/modules/feature_selection.html) [1.13. Feature selection â€” scikit-learn 0.22.2](https://scikit-learn.org/stable/modules/feature_selection.html)
10. ->  Charles Wheelan'Ä±n Ã§Ä±plak istatistik kitabÄ±nda bu gibi durumlar iÃ§in Regresyon Analizini(diÄŸer tÃ¼m deÄŸiÅŸkenlerin aynÄ± ÅŸartlar altÄ±nda sabit tutularak, elimizdeki deÄŸiÅŸkenin(feature) etkisini Ã¶lÃ§meyi) Ã¶neriyordu. Ä°yice araÅŸtÄ±rmak gerekiyor sonuÃ§ olarak \"etkisi olabilir de olmayabilir de\" diye bir sonuca varÄ±yorsunuz ğŸ™‚ Yine domain hakkÄ±nda bilgi sahibi birisine danÄ±ÅŸmak da hÄ±zlÄ± bir Ã§Ã¶zÃ¼m olabilir diye Ã¶neriyordu..",
11. ->  ->  teÅŸekkÃ¼rler, denemek ya da domain hakkÄ±nda bilgi gerekliliÄŸi sorunun popÃ¼ler cevaplarÄ± ğŸ™‚.",
12. ->  ->  Yani elimizde birden fazla sayÄ±da ve farklÄ± modeller iÃ§in farklÄ± optimal feature selection algoritmalarÄ± var gibi gÃ¶rÃ¼nÃ¼yor. MÃ¼sait bir zamanÄ±mda tabloda adÄ± geÃ§en algoritmalara bi gÃ¶z atÄ±cam, teÅŸekkÃ¼r ederim..",
13. ->  ->  Evet dogru.Rica ederim..",
14. ->  Merhaba, Ã§oklu regresyon analizinde yeni bir baÄŸÄ±msÄ±z deÄŸiÅŸken(Ã¶zellik) modele dahil olursa R^2 ya aynÄ± kalÄ±r ya da artar. Ancak bu modelimizin daha iyi aÃ§Ä±klama oranÄ±na sahip olduÄŸu anlamÄ±na gelmez. AÃ§Ä±klayÄ±cÄ±lÄ±ÄŸÄ±n artÄ±p artmadÄ±ÄŸÄ±na bakmak iÃ§in R^2 adjusted deÄŸerine bakmamÄ±z gerekir. R^2 adjusted modele yeni bir Ã¶zellik eklendiÄŸinde modeldeki parametre sayÄ±sÄ±nÄ± ve Ã¶rneklem sayÄ±sÄ±nÄ± dikkate alarak RÂ² Ã¼zerinde ayarlama yapar. Modele yeni parametre ekledikÃ§e RÂ² deÄŸeri yÃ¼kselir ancak modelin karmaÅŸÄ±klÄ±ÄŸÄ±nÄ±n azaltÄ±lmasÄ± iÃ§in modelin en az deÄŸiÅŸken ile aÃ§Ä±klanmasÄ± beklenir. Bu nedenle modele yeni deÄŸiÅŸkenler eklendiÄŸinde gereksiz eklenen deÄŸiÅŸkenleri cezalandÄ±ran R_adjÂ² kullanÄ±lmasÄ± gereklidir. Åurada daha detaylÄ± gÃ¶stermeye Ã§alÄ±ÅŸmÄ±ÅŸtÄ±m: [Kategorik Veriler ile Ã‡oklu Regresyon Analizi](https://medium.com/@cerden/kategorik-veriler-ile-%C3%A7oklu-regresyon-analizi-minitab-uygulamas%C4%B1-e30f74a9b73d)
    
### soru 

> quest: "Selamlar, Bu soruyu yanlÄ±ÅŸ yaptÄ±m aÃ§Ä±klamasÄ± mevcut mu, teÅŸekkÃ¼rler.  Which of the following is prevent overfitting ? 1 - Cross-validation 2- Training with more data 3- Removing features 4- Ensembling",

> comments:
  
1. ->  [Link](https://elitedatascience.com/overfitting-in-machine-learning)Bu adreste oldukÃ§a iyi aÃ§Ä±klanmÄ±ÅŸ.",
2. -> Merhabalar,Overfit durumuna dÃ¼ÅŸmemek iÃ§in alÄ±nabilecek Ã¶nlemleri sorulmuÅŸ, 4 maddede bu Ã¶nlemler arasÄ±nda mevcut.Her birini kÄ±saca aÃ§Ä±klamaya Ã§alÄ±ÅŸacaÄŸÄ±m.1. Cross Validation: Veri setini k tane parÃ§aya ayÄ±rarak eÄŸitimi yapar, bu k parÃ§adan 1 parÃ§ayÄ± test iÃ§in kullanÄ±r, bu parÃ§a her seferinde bir Ã¶nceki iterasyondan farklÄ± olur, bu yÃ¼zden modelimiz sÃ¼rekli yeni test seti ile test edilmiÅŸ olur.2. Training with more data: Ã–rnek sayÄ±mÄ±zÄ± artÄ±rmak verimizdeki target ile feature arasÄ±nda ki iliÅŸkiyi daha rahat anlamamÄ±zÄ± saÄŸlamayabilmekte.3. Removin Features: Feature setimizden alakasÄ±z featur'larÄ± Ã§Ä±kartarak target-feature iliÅŸkisini daha net bir hale getirebilmekteyiz.4. Ensembling : Birbirinden ayrÄ± modelleri bir arada kullanmamÄ±za olanak saÄŸlayan ML metodudur. BÃ¶ylece modelimiz daha karmaÅŸÄ±k yapÄ±lÄ± Ã¶rnekler ile overfit olmadan Ã§alÄ±ÅŸabilir.KÄ±saca Ã¶zetlemeye Ã§alÄ±ÅŸtÄ±m daha ayrÄ±ntÄ±lÄ± bir ÅŸekilde : [Link](https://elitedatascience.com/overfitting-in-machine-learning) adresinden inceleyebilirsin.Ä°yi akÅŸamlar.",
3. ->  ->  hocam ÅŸu soruma bakar mÄ±sÄ±nÄ±z rica etsem bir kaÃ§ saat Ã¶nce post attÄ±m. ben de bu 4 adet ÅŸeyi seÃ§tim ama yanlÄ±ÅŸ cevap dedi.[Link](http://community.globalaihub.com/community/status/1468-1468-1586718659/) [Link](https://www.quora.com/Can-early-stopping-of-machine-learning-algorithms-lead-to-overfitting-of-validation-data)
4. ->  ->  Ä°lk olarak VermiÅŸ olduÄŸunuz link Ã§alÄ±ÅŸmamakta.Edit: Bahsi geÃ§en soruda .Early stopping, .Regularization seÃ§enekleri de bulunmaktaydÄ±. Bunlarda overfit'i Ã¶nlemek iÃ§in alÄ±nabilecek Ã¶nlemler arasÄ±nda bulunmaktalar. Yani O soru iÃ§in hepsi doÄŸru olmalÄ±ydÄ±. Sadece bu postta bahsi geÃ§miÅŸ olan 4 yÃ¶ntem deÄŸil..",
5. ->  ->  profilime tÄ±klar mÄ±sÄ±nÄ±z orada gÃ¶zÃ¼kÃ¼yor hocam.",
6. ->  ->  Maalesef gÃ¶rebildiÄŸim bir post yok profilinizde ğŸ™.",
7. ->  ->  sorum ÅŸuydu hocam:Overfit i Ã¶nlemek iÃ§in eÄŸitimin erken durdurulmasÄ± doÄŸru kabul edilmiÅŸ fakat internette ÅŸÃ¶yle bir yazÄ±ya rastladÄ±m. Ä°ki bilgi Ã§eliÅŸir gibi geldi..",
8. ->  ->  GÃ¶rdÃ¼m ÅŸimdi, Renklendirerek paylaÅŸmÄ±ÅŸ olduÄŸun cevabÄ± eÄŸer yanlÄ±ÅŸ anlamadÄ±ysam sadece ilk paragrafÄ±nda soru ile alakalÄ± renklendirdiÄŸin kÄ±sÄ±m var cevabÄ±n kalanÄ±nÄ±n daha Ã§ok veri kalitesi train- test verisinin dengesi (generalization) Ã¼zerine olduÄŸunu gÃ¶rÃ¼yorum. Yani bu yazÄ± ile bu yÃ¶ntemler kesinlikle yanlÄ±ÅŸtÄ±r diyemeyiz. DevamÄ±nda bulunan 2. cevabÄ± okursan eÄŸer durumu daha iyi anlayacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum.Edit: Burada bahsi geÃ§en yÃ¶ntemlerin yanlÄ±ÅŸ kullanÄ±mÄ± halinde de yine overfit gibi bir durumla ya da daha farklÄ± problemlerle karÅŸÄ±laÅŸabiliriz. AlÄ±nabilecek Ã¶nlemler olarak kabul edilmiÅŸ yÃ¶ntem olmalarÄ± bu yÃ¶ntemleri kullanmamÄ±z halinde \"oldu tamam ben artÄ±k overfit problemini aÅŸtÄ±m\" diyerek arkamÄ±za yaslanabileceÄŸiz anlamÄ±na gelmiyor tabi ğŸ™‚Ä°yi Ã§alÄ±ÅŸmalar..",
9. ->  ->  teÅŸekkÃ¼rnederim hocam ğŸ™‚.",
    
### soru 

> quest: "Bu konuda Ã§ok kafa karÄ±ÅŸÄ±klÄ±ÄŸÄ± var o yÃ¼zden buraya bir post yazayÄ±m dedim. Veriye validation set eklemezsek ne olur'la baksak Ã§ok daha iyi olacak.  Siz bir model geliÅŸtiriyorsunuz, training ve test seti ayÄ±rdÄ±nÄ±z, 100 Ã¶rnekten 80'i training 20'si test. Ev fiyatlarÄ±nÄ± tahminlemeye Ã§alÄ±ÅŸÄ±yorsunuz. Bir regresyon modeli train ettiniz, sonra iÃ§ine test verisinden 4 odalÄ± ve iki banyolu bir ev koydunuz o da size bu evin fiyatÄ±nÄ±n 100 bin lira olmasÄ± gerektiÄŸini sÃ¶yledi, ama gerÃ§ekte o ev (test verisindeki ev fiyatÄ± kolonu) 120 bin lira, buna gÃ¶re hatanÄ±za baktÄ±nÄ±z, parametrelerinizi deÄŸiÅŸtirip yeniden train ettiniz. Zamanla kendinizi bu test verisinden aldÄ±ÄŸÄ±nÄ±z hatalara gÃ¶re adapte ediyorsunuz, yani test verisine overfit ediyorsunuz. Farkettiyseniz test verisiyle hem parametreleri deÄŸiÅŸtiriyoruz hem de test ediyoruz, bu yanlÄ±ÅŸ, bu yÃ¼zden validation set ekliyoruz, hataya bakÄ±p parametre deÄŸiÅŸtirme iÅŸlemini validation set'te yapÄ±yoruz, ardÄ±ndan yeni Ã§Ä±kan modeli test verisiyle test ediyoruz, bÃ¶ylece modelin gerÃ§ekten iyi bir performans sergileyip sergilemediÄŸini gÃ¶rebiliyoruz.",

> comments:
  
1. ->  Merve Hanim, diger post altinda da sormaya calismistim ama sorumu yeterince izah edemedim sanirim. Benim anladigim;\"burada train edilmis model icin test datasini bir sekilde modelin tekrar guncellemesi icin kullanildigini soyluyorsunuz. Bu durum, kullandigimiz takdirde validation verisi icin de gecerli.\"Demek ki bir \"update rule\" kullanimi var. Bu \"update rule\" nasil yapilandiriliyor (matematiksel olarak)?Bana bununla ilgili bir aciklama ya da kaynak gostermeniz mumkun mu acaba? Benim bildigim tek update rule backpropagation ve bu sizin soylediginiz test verisine \"tune\" olma probleminin onune gecmek adina validation verisi kullanildigi kurs programinda da bahsediliyor lakin ben bunun nasil oldugunu henuz kavrayabilmis degili..",
2. ->  Son bir ekleme daha yapabilir miyim;parametreler dedikleriniz \"agirliklar ve bias'lar\" mi yoksa \"learning rate, batch size, epochs\" mu?.",
3. ->  ->  tabiki de \"learning rate, batch size, epochs\" ... ÅŸunu demek istemiÅŸ anladÄ±ÄŸÄ±m kadarÄ±yla bu parametreleri sÃ¼rekli deÄŸiÅŸtirip iyiye yÃ¶nelmek isterken test verisini overfitting yapÄ±yorsunuz yani networku ezberletmiÅŸ oluyorsunuz bunu validation verisi ile test verisini doÄŸrulatarak modeli eÄŸitmenin daha doÄŸru olduÄŸunu sÃ¶ylemiÅŸ..",
4. ->  Evrim bence guzel soru sordun cunku anlam karmasasi yasiyoruz gercekten parametreler konusunda. zaman zaman dinlerken.Gradients denileni weights and biases olarak algiliyorum.Leraning rate, epoch, batch_size ise hyper parametrelerdir.Ancak konusmacilar weights ve biases icin parametreler ifadesini kullanabiliyor..",
5. ->  ->  weight ve bias parametrelerine siz mÃ¼dehale etmiyorsunuz model katmanÄ±ndaki optimizasyon algoritmasÄ±(Ã–rneÄŸin: Stochastic Gradient Descent, Adam...) bu gÃ¼ncellemeyi yapar, deÄŸiÅŸtirir. YanlÄ±ÅŸsam biri beni dÃ¼zeltsin..",
6. ->  ->  Eger dediginiz gibi ise sunu aciklarmisiniz: diyelim ki model = vgg16(pretrained) ve for param in model.features.parameters()...param.requires_grad= False dersem ben neyi freeze etmis oluyorum?.",
7. ->  ->  Benim kafami karistiran terminoloji oldu. Sayet parametreden kastimiz sizin dediginiz gibi \"learning rate, batch size, epochs\" ise benim sorularim anlamsizlasiyor, cunku guncelleme metodu gerektiren seyler \"weights and biases\".Ilaveten Senay'a katilmak durumundayim, benim terminoloji bilgim su sekilde:hyperparamaters: \"learning rate, batch size, epochs\"parameters: \"weights and biases\".",
7. ->  ->  Ibrahim weights ve biases lere tabiki biz mudahale etmiyoruz biz sadece weightsleri optimizer.step() function kullanarak update ediyoruz.Bu konuda hemfikiriz..",
9. ->  ->  Eywallah gÃ¼ncelleme gerektiren yerler weight ve bias ... diyelim ki siz modeli eÄŸitiniz sonuÃ§lar kÃ¶tÃ¼ loss azaltÄ±p accuracy deÄŸerini arttÄ±rmak iÃ§in ne yapmanÄ±z gerekecek learning rate, batch size ve epoch deÄŸerlerini hatta optimizer da deÄŸiÅŸtirerek en iyi sonucu bulmaya Ã§alÄ±ÅŸacaksÄ±nÄ±z bu denemeleri yaparken test veriniz overfitting olabilir.Bu yÃ¼zden veriyi 3 e ayÄ±rÄ±p validation set ve test seti kÄ±yaslamak gerekecek.",
10. -> -> :Ã–ncelikle terminoloji ile alakalÄ± sizinle aynÄ± fikirdeyim eÄŸer daha burada hata yapÄ±yorsak aydÄ±nlatÄ±lÄ±rsa Ã§ok iyi olur.hyperparamaters: \"learning rate, batch size, epochs\"parameters: \"weights and biases\"Bu soruda; \"The regressor might overfit to test set if we don't use validation sets. \"KafanÄ±za takÄ±lanÄ±n bu olduÄŸunu sÃ¶ylemiÅŸsiniz;Evet hatirliyorum. Benim sormaya calistigim, validation verisi kullanmak overfitting'i nasil onluyor? Nasil bir mekanik (bir gunceleme kurali ya da metodu) kullanilarak overfitting onleniliyor?Ve yanlÄ±ÅŸ anlamadÄ±ysam net olarak sormak istediÄŸiniz validation set iÅŸlemi iÃ§in farklÄ± bir matematiksel iÅŸlem olup olmadÄ±ÄŸÄ±.Benim anladÄ±ÄŸÄ±m validation set ile test set arasÄ±nda setlerin kendi Ã§alÄ±ÅŸma mantÄ±ÄŸÄ±nda hiÃ§bir fark yok, yani ikisinde de amaÃ§ aslÄ±nda test etmek. Ancak validation sette test ettikten sonra parametreleri gÃ¼ncelliyoruz(weights ve bias). AsÄ±l Test setinde ise sadece bu ayarlarÄ±n nasÄ±l sonuÃ§ verdiÄŸine bakÄ±yoruz. (parametreler Ã¶nceden validation sette ayarlandÄ±). EÄŸer bunu validation sette yapmayÄ±p test sette yaparsak test set hem parametreleri ayarlamak iÃ§in modele kendinden veri verecek, model bu verileri Ã¶ÄŸrenecek, sonra tekrar test setinde bu veriler test iÃ§in kullanÄ±lÄ±p \"overfitting\" olacak. Overfitting olacaksada validation sette olsun ki nasÄ±l olsa test sette modelin hiÃ§ gÃ¶rmediÄŸi verilerle modeli son kez test edeceÄŸiz. Ä°ÅŸlemler sonunda Training loss ve Test loss deÄŸerlerine bakarak modelin tahmin gÃ¼cÃ¼nÃ¼ anlÄ±yoruz.Test setteki parametre ayarlama matematiksel iÅŸlemlerini Validation sette yaptÄ±k.DoÄŸru anlamadÄ±ysam yÃ¼zÃ¼me vurun ğŸ™‚.",
11. -> ->  ilk basta sizin anlattiginiz gibi algiladim; yani validation veya test set uzerinden \"weights and biases\" icin bir update rule uyguluyoruz. Yalniz Ibrahim Ayaz kavram sorumun uzerine beni duzeltti. Bu durumda, yukurida da belirttigim uzere, benim sormaya calistigim sorular anlamsizlasiyor, cunku ben \"weights and biases\" icin bir guncelleme yaptigimizi saniyordum. Oysaki validation veya test seti \"learning rate, batch size, epochs\" uzerinde degisiklik yapmak icin kullanmaktan bahsediyormusuz. Bunlar bir \"update rule\"a bagli olmayan bizim elimizle girip degistirdigimiz degerler. Dolayisiyla validation set'in butun amaci bizim *training* sonuclarina bakarak kendimizce degisiklikler yapip modeli guclendirme amacimiza hizmet ediyor. Ki bu elimizle yaptigimiz degisiklikler de neticede bir cesit *tuning* olmasi sebebiyle test set uzerinde yapilirsa modelin genellenebilirligini zedeleyen bir unsura donusuyor, cunku model genel bir veri gurubu yerine test set verilerine duyarli hale geliyor, o yuzden de bunu validation set diye ayirdigimiz bir veri gurubu uzerinde yapmak daha mantikli.Kisa yorum: validation veya test set'in \"weights and biases\" ile dogrudan bir iliskisi yok. Amaci bizim gozlem (deneme-yanilma) yoluyla modelin gucune katki vermemize olanak tanimasi.Benim icin faydali bir tartisma oldu. Validation set'in islevi konusunda muglak fikirlerim vardi ve kavram tam olarak zihnimde yer etmemisti. Simdi tam olarak oturdu. Katki veren herkese tesekkur ederim.",
12. -> Merhabalar,->  Ã–ncelikle paylaÅŸÄ±mÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederim. Ancak bazÄ± noktalarda eksikleriniz bulunmakta.Ã–rneÄŸimiz Ev FiyatlarÄ±nÄ±n Tahmin Edilmesi (Regresyon Problemi), Hedef: Evin FiyatÄ±, Feature(DeÄŸiÅŸken): Oda SayÄ±sÄ± . Ã–rnek BÃ¼yÃ¼klÃ¼ÄŸÃ¼ 100, Train/Test bÃ¼yÃ¼klÃ¼ÄŸÃ¼: 80/20 <- Sizin Ã¶rneÄŸiniz Ã¼zerinden aÃ§Ä±klamaya Ã§alÄ±ÅŸacaÄŸÄ±m.EÄŸitime baÅŸladÄ±ktan itibaren, her bir iterasyon sonunda bir Regresyon modeli tahmin edilir(Ã¶rneÄŸin: ev_fiyatÄ± = 45.000(bias) + 1250(weight) * oda_sayÄ±sÄ±). Bu model Test Setinin TamamÄ± ile(AyrÄ±lmÄ±ÅŸ olan 20 Ã¶rneÄŸin hepsi ile ) test edilir, Ã§Ä±kan sonuca gÃ¶re katsayÄ±lar(weight(1250), bias(45.000)), belirlemiÅŸ olduÄŸumuz learning rate'ye gÃ¶re gÃ¼ncellenir(Batch Size verinin nasÄ±l parÃ§alanÄ±p iÅŸleneceÄŸini(batch_size'nin bÃ¼yÃ¼klÃ¼ÄŸÃ¼ iterasyon sayÄ±sÄ±nÄ± belirler.), Epoch ise verinin bir bÃ¼tÃ¼n olarak kaÃ§ defa eÄŸitime tabii tutulacaÄŸÄ±nÄ± belirtir.). Sonraki iterasyon ile devam edilir. Belirlenen epoch sayÄ±sÄ±na ulaÅŸÄ±lÄ±ncaya kadar bu iÅŸlem bÃ¶yle devam eder. Ancak burada Test Set Ã¼zerine modelimizi overfit etmiÅŸ olmuyoruz. Modelimizin overfit olma olasÄ±lÄ±ÄŸÄ± var. BÃ¶yle bir durumu sadece test set ile Ã§alÄ±ÅŸarak gÃ¶zlemlememiz mÃ¼mkÃ¼n olamamakta. Bu yÃ¼zden 3. bir set oluÅŸturuyoruz: validation set olarak. BÃ¶ylece eÄŸitim boyunca bÃ¼tÃ¼n testleri validation set Ã¼zerinden yapacak ve eÄŸitim bittikten sonra test setimiz ile 2. defa modelimizi test edecek ve eÄŸitim sonuÃ§larÄ± ile tutarlÄ±lÄ±ÄŸÄ±nÄ± gÃ¶zlemleyebileceÄŸiz. EÄŸer eÄŸitim oranlarÄ± en son yapmÄ±ÅŸ olduÄŸumuz test oranlarÄ±ndan Ã§ok bÃ¼yÃ¼k ise eÄŸitim sÄ±rasÄ±nda overfit olmuÅŸ diyebiliriz, ve buna gÃ¶re modelimizi tekrar gÃ¶zden geÃ§irmek suretiyle gerekli deÄŸiÅŸiklikleri yapabiliriz.->  DediÄŸiniz gibi validation seti bÃ¼tÃ¼n eÄŸitim boyunca kullandÄ±ÄŸÄ±mÄ±z iÃ§in modelimiz validation set'e de overfit olabilmekte ancak en son Test Set'imizle yapmÄ±ÅŸ olduÄŸumuz deneme ile bu durumu tespit edebilmekteyiz.Ä°yi geceler, iyi Ã§alÄ±ÅŸmalar..",
13. ->  ->  Bilgilendirmeniz iÃ§in teÅŸekkÃ¼r ederim. Ben de bu alana yeni baÅŸlayan biri olarak bir dÃ¼ÅŸÃ¼ncemi belirtmek istiyorum. YazÄ±larda ifade edilen terimler bazen olaylarÄ± kafamda farklÄ± ÅŸekillendirmeme sebep olabiliyor. Bundan dolayÄ± bu terimler kullanÄ±lÄ±rken daha hassas olunursa anlam karmaÅŸÄ±klÄ±ÄŸÄ±nÄ±n Ã¶nÃ¼ne geÃ§ileceÄŸini dÃ¼ÅŸÃ¼nmekteyim.Terminolojiyi takip etmek isteyenler iÃ§in;[Link]((https://developers.google.com/machine-learning/glossary)
"Machine Learning Glossary Â |Â  Google Developersdevelopers.google.comCompilation of key machine-learning and TensorFlow terms, with beginner-friendly definitions..",
    
### soru 

> quest: "SorularÄ±n hepsini doÄŸru yaptÄ±ÄŸÄ±mÄ± belirterek kendimce nasÄ±l yaptÄ±ÄŸÄ±mÄ± tek tek anlatacaÄŸÄ±m. YararlÄ± olmasÄ±nÄ± umuyorum ve yorumlarÄ±nÄ±zÄ± bekliyorum. YazÄ±m hatalarÄ± olabilir hÄ±zlÄ±ca yazdÄ±m kusuruma bakmayÄ±n. Hepsini yorum olarak paylaÅŸacaÄŸÄ±m.",

> comments:
  
1. ->  Q1: Soruda validation setini kullanma sebebimizi soruyordu.1.1: Regressor ifadesi bana regresyon modelini Ã§aÄŸrÄ±ÅŸtÄ±rdÄ±.Train setinde eÄŸittiÄŸimiz verilerdeki hiperparametreleri test setine gÃ¶re yaparsak model test setindeki verileri verdiÄŸimizde iyi sonuÃ§ verip bizi yanÄ±ltabilir.Bu sebeple validation ile parametre ayarlayÄ±p test setiyle overfitting'in oluÅŸup oluÅŸmadÄ±ÄŸÄ±nÄ± kontrol ediyoruz. 2 aÅŸamalÄ± deÄŸerlendirmeden sonra bunlarÄ±n loss deÄŸerleri birbirine Ã§ok yakÄ±n ise overfitting oluÅŸmadÄ±ÄŸÄ±na kanaat getiriyoruz.DolayÄ±sÄ±yla validation set kullanmaz isek \"test setine\" overfit olabilir.1.2: Validation setin modelin fit performansÄ±nÄ±na etkisi yoktur. Sadece test setine overfitting olmasÄ±nÄ± Ã¶nlemek iÃ§in ara aÅŸama.1.3: Modelin overfit veya underfit olmasÄ±nÄ± kontrol eden ÅŸey test setidir. Validation set sadece test setine olan overfiti denetler..",
2. ->  Q2: 6 resmin eÅŸleÅŸtirilmesini istiyordu.1.resimde overfit durumu gÃ¶rÃ¼yoruz. DolayÄ±sÄ±yla train setin kaybÄ± dÃ¼ÅŸÃ¼k, test setinin kaybÄ± yÃ¼ksek olmalÄ±.Bu nedenle B ÅŸeklindeki son duruma baktÄ±ÄŸÄ±mÄ±zda test setin kaybÄ± train sete gÃ¶re oldukÃ§a fazla.2.resimde optimal modeli gÃ¶rÃ¼yoruz. Ne 1 gibi Ã§ok karmaÅŸÄ±k bir model ne de 3 gibi Ã§ok basit.DolayÄ±sÄ±yla eÄŸitim performansÄ± iyi olmalÄ±, test performansÄ±da ona yakÄ±n olmalÄ±.3.resimde ise model Ã§ok basit. Verilere Ã§ok iyi uymuyor. DolayÄ±sÄ± ile eÄŸitim performansÄ± dÃ¼ÅŸÃ¼k olmalÄ±.Bu nedenle eÄŸitim performansÄ± diÄŸerlerinden daha dÃ¼ÅŸÃ¼k olan A ÅŸekliyle eÅŸleÅŸir. SonuÃ§: 1-B/2-C/3-A.",
3. ->  Q3: Modelin kaÃ§ kez gÃ¼ncelleneceÄŸini soruyordu.250 Ã¶rneÄŸimiz var. 80/20 oranÄ±nda parÃ§alarsak train set 200 Ã¶rneÄŸe sahip oluyor. Batch size ise 32.200'e tam bÃ¶lÃ¼nmÃ¼yor. 200 iÃ§inde 6 tane batch var ve bunlarÄ± Ã§Ä±karÄ±nda 8 Ã¶rnek kalÄ±yor. DolayÄ±sÄ± ile bunlarÄ±n 7 iterasyon olacaÄŸÄ±nÄ± sÃ¶yleyebiliriz.Buradaki dÃ¼ÅŸÃ¼ncem kÃ¼sÃ¼rat olamayacaÄŸÄ± yÃ¶nÃ¼nde Ã§Ã¼nkÃ¼ iterasyon tam sayÄ±lardan olmalÄ± yarÄ±m iterasyon gibi bir ÅŸey mantÄ±ksÄ±z olacaktÄ±r.Batch 32 olduÄŸundan kafa karÄ±ÅŸtÄ±rabilir ama ben o yeterince veri yoksa elindeki veriler kadar yapacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum.DolayÄ±sÄ±yla cevaba 7*1000(epoch sayÄ±sÄ±) = 7000 dedim..",
4. ->  ->  Bu sorunun net olmadÄ±ÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum. Batch size 32 iken 8 Ã¶rnek ile train etmek ne kadar doÄŸrudur? Mevcut algoritmalar nasÄ±l davranÄ±yor bilmiyorum, bu konuda bilgisi olan varsa aÃ§Ä±klayabilirse Ã§ok iyi olur.Ben de 200 / 32 = 6.25 Ã§Ä±kÄ±yor ve batch size Ä±mÄ±z 32 i olduÄŸu iÃ§in 8 sample ile train edilmeyeceÄŸini dÃ¼ÅŸÃ¼ndÃ¼m ve 1 epoch da 6 iterasyon olur, 1000 epoch iÃ§in 1000*6 = 6000 iterasyon gerekir diye dÃ¼ÅŸÃ¼ndÃ¼m. TamsayÄ± Ã§Ä±kan bir deÄŸer sorulsaydÄ± daha aÃ§Ä±k ve net bir soru olurdu sanÄ±rÄ±m.,
5. ->  ->  Batch 32 diye 32 Ã¶rneÄŸe ihtiyacÄ±mÄ±z olmamasÄ± daha mantÄ±ksÄ±z deÄŸil mi? ÅÃ¶yle dÃ¼ÅŸÃ¼nÃ¼n batchte amacÄ±mÄ±z verileri parÃ§alamak biz diyoruz ki aynÄ± anda en fazla 100 veri iÅŸleyebiliriz. 8 veri gelmesi sizce mantÄ±ksÄ±z mÄ± olur? BÃ¶yle dÃ¼ÅŸÃ¼nmekte fayda var..",
6. ->  ->  AyrÄ±ca ÅŸunu belirtmeyi unutmuÅŸum 8 Ã¶rneÄŸi dÄ±ÅŸarÄ±da bÄ±raktÄ±ÄŸÄ±nÄ±zda tÃ¼m verisetini eÄŸitimden geÃ§irmemiÅŸ oluyorsunuz. DolayÄ±sÄ±yla bununla da Ã§eliÅŸiyor dediÄŸiniz yÃ¶ntem..",
7. -> ->  elimizdeki veri sayÄ±sÄ± batch size'a gÃ¶re bÃ¶lÃ¼ndÃ¼kten sonra batch size'dan daha az sayÄ±da kalan veriler ne kadar olursa olsun son iterasyon olarak training'e katÄ±lÄ±yor. bu neden bu Ã¶rnek iÃ§in 6 iterasyon 32 veri ile, 7. iterasyon ise kalan 8 veri ile gerÃ§ekleÅŸiyor. tam sayÄ± Ã§Ä±kmamasÄ± aslÄ±nda sorunun ufak bir trick'i olmuÅŸ.,
8. -> -> ->  Merhaba, yorumlar iÃ§in teÅŸekkÃ¼rler. Ben 8 Ã¶rnek ile update etmenin problem olabileceÄŸini dÃ¼ÅŸÃ¼ndÃ¼m, Ã§Ã¼nkÃ¼ kalan 8 Ã¶rnekten 4 tanesi iki kÃ¼menin tam sÄ±nÄ±rÄ±nda kalan veya yanlÄ±ÅŸ tarafta olan Ã¶rnekler olursa az sayÄ±da Ã¶rnekten dolayÄ± dÃ¼zgÃ¼n bir update iÅŸlemi olmayabilir, bu yÃ¼zden batch size a bir limit koyuyoruz, 32 lik datayla daha genel bir update iÅŸlemi oluyor.8 Ã¶rneÄŸi bir epochda dahil etmemek Ã§ok bÃ¼yÃ¼k bir problem deÄŸil. Zaten siz datasetteki bÃ¼tÃ¼n datalarla Ã¶ÄŸrenme iÅŸlemi yapmÄ±yorsunuz. Training ve test set olarak ayrÄ±lmamÄ±ÅŸ tek bir dataset varsa yaklaÅŸÄ±k yÃ¼zde 80 ini training e, yÃ¼zde 20 sini teste ayÄ±rÄ±yorsunuz ve sadece training datasÄ± ile update yapÄ±yorsunuz.Genelde her epochda datalarÄ±mÄ±zÄ± random olarak seÃ§tiÄŸimiz iÃ§in bir epochda kalan 8 Ã¶rnek diÄŸer epochda kullanÄ±labilir, her epochda kalan 8 Ã¶rnek aynÄ± olmayacaktÄ±r.Bu yÃ¼zden son 8 Ã¶rneÄŸi almamanÄ±n, alÄ±nacaksa da o epochda kullanÄ±lan datalardan random 24 tane daha datayÄ± dahil etmenin daha uygun olacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum.MentorlarÄ±mÄ±zdan biri de konuyla ilgili aÃ§Ä±klama yaparsa sÃ¼per olur.Kolay gelsin...",
9. ->  ->  Teknik olarak algoritma son kalan 8 Ã¶rneÄŸi yeni bir batch olarak deÄŸerlendirip 8 Ã¶rnekle gÃ¼ncelleme yapÄ±yor. Bu tip durumlarda dediÄŸiniz gibi yÃ¶ntemlere baÅŸvurulabilir mi ? Ä°sterseniz bu fazlalÄ±klarÄ± veri setinizden Ã§Ä±karabilirsiniz veya random 24 tane veride verisetinden ekleyebilirsiniz (Ezberci eÄŸitime karÅŸÄ±yÄ±z ğŸ™‚ ). Bunlar ek Ã§Ã¶zÃ¼mler olur. Soruda sorulmak istenen algoritmanÄ±n nasÄ±l davranacaÄŸÄ±. Ã‡Ã¶zÃ¼m Enes beyin ifade ettiÄŸi gibi. Ancak sizin de ifade ettiÄŸiniz gibi Ã§ok Ã§ok aÅŸÄ±rÄ± farklÄ±lÄ±klar yaratmayacaktÄ±r..",
10. ->  Q4: Ev fiyatÄ± iÃ§in hangisinin iyi bir Ã¶zellik olmayacaÄŸÄ±nÄ± soruyordu.Ã–nceki sahibinin cinsiyeti iyi bir Ã¶zellik olamazdÄ±..",
11. ->  Q5: Soruda learning rate'i optimal seÃ§memekten dolayÄ± oluÅŸan problemlerden olmayanÄ± soruyordu.DolayÄ±sÄ±yla Ã¶ÄŸrendiklerimizi dÃ¼ÅŸÃ¼nÃ¼rsek kÃ¶tÃ¼ learning rate in 2 etkisi vardÄ±: hÄ±zlÄ± adÄ±m atÄ±p minimumu kaÃ§Ä±rma veya Ã§ok yavaÅŸ adÄ±m atÄ±p uzun sÃ¼rede minimuma ulaÅŸma. BaktÄ±ÄŸÄ±mÄ±zda 1.ÅŸÄ±k ve 2.ÅŸÄ±k bunlarÄ± saÄŸlÄ±yor.3.ÅŸÄ±kka baktÄ±ÄŸÄ±mÄ±zda ise kayÄ±p eÄŸrisinde minimuma gitmek yerine test yÃ¶ne hareket ettiÄŸi yazÄ±yor. Bunun sebebinin gradyan hesaplarken yapÄ±lan hata olduÄŸunu dÃ¼ÅŸÃ¼nerek bu cevabÄ± seÃ§tim..",
12. ->  Q6: Hangisinin lineer regresyon problemi olduÄŸunu soruyordu soruda.SÄ±nÄ±flandÄ±rma ile aralarÄ±ndaki temel fark ise regresyondaki output sayÄ±sal yani sÃ¼rekli bir deÄŸer, sÄ±nÄ±flandÄ±rma ise kategorik deÄŸerdir. DolayÄ±sÄ±yla (negatif-pozitif, kadÄ±n-erkek, yazar) sÄ±nÄ±flandÄ±rma problemi oluyor. SatÄ±ÅŸ tahmin etmek ise regresyon problemidir..",
13. ->  Q7: Korelasyon matrisi hakkÄ±nda doÄŸru olanÄ± soruyordu.Bu tensorflow colabÄ±nda geÃ§iyordu. Her Ã¶zelliÄŸin ham deÄŸerinin diÄŸerlerinin ham deÄŸeri ile iliÅŸkisini veren deÄŸerlerimiz vardÄ±.Bir de doÄŸru hatÄ±rladÄ±ÄŸÄ±mÄ± kesinleÅŸtirmek iÃ§in ÅŸÃ¶yle dÃ¼ÅŸÃ¼ndÃ¼m, Neden her Ã¶zellik Ã¶zellik deÄŸeri diÄŸerlerinin ham deÄŸeriyle iliÅŸkili olsun ki?.",
14. -> Q8: Hangilerinin overfittingi Ã¶nlediÄŸini soruyordu.1.deki cross-validation'a validation'Ä± Ã¶ÄŸrenmiÅŸtik ve bu da validation'un bir Ã§eÅŸidi gibi gÃ¶rÃ¼ndÃ¼ÄŸÃ¼nden dolayÄ± doÄŸru dedim.2.deki daha fazla veriyle eÄŸitim yapmanÄ±n veri miktarÄ± ne kadar uzun olursa overfit olmanÄ±n o kadar uzun sÃ¼receÄŸini dÃ¼ÅŸÃ¼ndÃ¼m. Overfittingi kafamda ezberleme olarak kodlamÄ±ÅŸtÄ±m. Bir yerdeki insan sayÄ±sÄ± artarsa onlarÄ±n hepsinin ismini ezberlemeniz daha uzun sÃ¼rer mantÄ±ÄŸÄ±yla.3.de Ã¶zellik Ã§Ä±karmaya doÄŸru dedim Ã§Ã¼nkÃ¼ aÄŸÄ±rlÄ±k eksilmesi modelimizin karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± azaltÄ±yor. Buna ÅŸÃ¶yle bir Ã¶rnek versem saÃ§ma olur mu bilemiyorum. Kalem verisetimiz olduÄŸunu dÃ¼ÅŸÃ¼nelim. KÄ±rmÄ±zÄ± kalem Ã¶rneÄŸi Ã§ok olduÄŸundan iyi tahmin ediyor ancak mavi kalem Ã¶rneÄŸi az o kadar iyi deÄŸil. Her boydan yeterince kalem olduÄŸundan dolayÄ± 100% tahmin etsin. Renk Ã¶zelliÄŸini Ã§Ä±karÄ±rsak boylara gÃ¶re tahminimiz yÃ¼ksek olduÄŸundan test setimizin doÄŸruluÄŸu artÄ±yor. Overfitting dÃ¼ÅŸÃ¼yor.4.de erken bitirme olayÄ± overfit olmadan Ã¶nce en iyi seviyede modelin eÄŸitimini bitirebileceÄŸimizi dÃ¼ÅŸÃ¼nÃ¼rsek doÄŸru geliyor.5.de regular kelimesinin dÃ¼zenli anlamÄ±na geldiÄŸini biliyordum ve bundan yola Ã§Ä±ktÄ±m. Verisetini eÄŸitim iÃ§in dÃ¼zenleÅŸtireceÄŸini dÃ¼ÅŸÃ¼nerek overfittingi azaltabileceÄŸini dÃ¼ÅŸÃ¼ndÃ¼m ama buna pek gerek kalmadÄ±.1,2,3 ve 4 Ã¼n olduÄŸu tek ÅŸÄ±k vardÄ± o da son ÅŸÄ±k olan hepsiydi..",
15. ->  ->  Overfitting Ã¶nleme ile ilgili kursun hangi bÃ¶lÃ¼mÃ¼nde anlatÄ±yor? Ben bunlara bakmamÄ±ÅŸÄ±m.",
16. ->  ->  Validation set kÄ±smÄ±nda anlatÄ±lÄ±yor..",
17. ->  Q9: Uyumu test etmek iÃ§in test metadolojisi uygulanÄ±rken hangisi gereksizdir diye soruyordu.1.ÅŸÄ±kta olan Ã¶rneklerin setten baÄŸÄ±msÄ±z ve aynÄ± ÅŸekilde Ã§ekilmesi kesinlikle lazÄ±m.2.ÅŸÄ±kta olan daÄŸÄ±lÄ±mÄ±n deÄŸiÅŸmez olmasÄ± sonradan veri eklenmemesi gerekiyor. Ã‡Ã¼nkÃ¼ Ã¶rneÄŸin kedi kÃ¶pek sÄ±nÄ±flayan bir modelimiz var. Bunu eÄŸitirken kÃ¶pek sayÄ±sÄ± azsa yani kÃ¶peÄŸi tahmin etmesini geliÅŸtirmek iÃ§in yeterince Ã¶rnek yoksa ve biz sonradan abartÄ±rsak 10.000 kÃ¶pek verisi eklersem tahmin oranÄ± Ã§ok dÃ¼ÅŸer.3.ÅŸÄ±kta Ã¶rnekleri seÃ§erken rastgele seÃ§memiz gerektiÄŸinden bahsediyor ve kesinlikle doÄŸru.4.ÅŸÄ±kta model test seti Ã¼zerinde eÄŸitilmelidir diyor ve bu kesinlikle yanlÄ±ÅŸ. Model train seti Ã¼zerinde eÄŸitilir. Test seti Ã¼zerinde deÄŸerlendirilir.DolayÄ±sÄ±yla cevabÄ± 4.ÅŸÄ±k iÅŸaretledim..",
18. ->  Q10: Nispeten diÄŸerlerine gÃ¶re kolaydÄ±.Elbette atlamalarÄ±n sebebi Ã¶ÄŸrenme oranÄ±nÄ±n yÃ¼ksek olmasÄ±..",
    
### soru 

> quest: "Ä°yi akÅŸamlar arkadaÅŸlar ğŸ™‚  Ã–ncelikle sÄ±nav sorularÄ±ndan bir tanesini sormak istiyorum. Belki Ã§ok basittir ama anlayamadÄ±m. \"The regressor might overfit to test set if we don't use validation sets. \" buradaki ifadeyi aÃ§Ä±klarmÄ±sÄ±nÄ±z?",

> comments:
  
1. ->  Bu soruyu ben yazdÄ±m. EÄŸer ekstra bir validation set kullanmazsak regressor overfit eder test setine demek. Bunun hangi kÄ±smÄ±nÄ± anlamadÄ±ÄŸÄ±nÄ±zÄ± sÃ¶ylerseniz aÃ§Ä±klayabilirim..",
2. ->  ->  Devam niteliginde bir sorum olacak. Validation set'in islevi konusunda yerine oturtamadigim bir durum var. Yanlissam duzeltin;agirliklarin guncellenmesi icin sadece training verisinden gelen ciktinin label verisi ile karsilastirmasindan yararlaniliyor. Bu durumda validation verisi sadece gorsel bir karsilastirma yapmak icin var. O zaman overfit'i onleme processini nasil gerceklestiriyor? tam olarak yaptigi sey nedir?.",
3. ->  Merve Hanim ifadenzide hata oldugunu dusunuyorum. Oncelikle regressor un test setine overfit etme ifadesine dogru diyemeyiz..Test sirasinda overfitting probleminin ortaya cikabilecegini soyleyebilirsiniz.Ancak bu problem de validation kullanilmadigi icin ortaya cikmaz..",
4. ->  ->  bununla ilgili bir post yazdÄ±m..",
5. ->  ->  overfit olayÄ± olunca illa ekstra validation set eklememize gerek yokki baÅŸka yollarla da overfitting Ã¶nlenebilir , bide benim eÄŸitimden de anladÄ±ÄŸÄ±m validation set testten once modeli anlamak iÃ§in kullanÄ±lÄ±yor..",
6. ->  ->  overfitting'i regularisation'la engelliyoruz, validation seti eklemek ve ayrÄ± bir test seti kullanmak bizim overfit edip etmediÄŸimize bakmamÄ±zÄ± saÄŸlÄ±yor..",
7. ->  Overfitting oneleme nasil olur sorusunun cevabi sinavin iceriginde mevcuttu hatirlarsaniz;Cross-validation, early stopping, train with more data, remove features ,regularization, dropout..",
8. ->  ->  Overfitting nasil onlenir sorusunun cevabi sinav sorularindan biriydi.Hatirlarsaniz, cross-validation, remove features, train with more data, regularization, early stopping, dropout...",
9. ->  ->  hmm simdi anladÄ±m ğŸ˜€ teÅŸekkÃ¼r ederÄ±m oturmamÄ±ÅŸ bu konu bende ğŸ™‚.",
10. ->  ->  Evet hatirliyorum. Benim sormaya calistigim, validation verisi kullanmak overfitting'i nasil onluyor? Nasil bir mekanik (bir gunceleme kurali ya da metodu) kullanilarak overfitting onleniliyor?.",
11. ->  ->  Overfitting engelleme ile ilgili kÄ±sÄ±mlar eÄŸitim serisi iÃ§inde nerede acaba? GÃ¶zden kaÃ§Ä±rdÄ±m sanÄ±rÄ±m..",
12. ->  RegresÃ¶r regresyon yapan modele dendiÄŸini dÃ¼ÅŸÃ¼ndÃ¼m ben yaparken. EÄŸitimde de gÃ¶rdÃ¼k ki validation kullanma amacÄ±mÄ±z test setine overfitting oluÅŸmamasÄ±. DolayÄ±sÄ±yla kullanmaz isek test setine overfit oluÅŸabilir..",
13. ->  AklÄ±mda check ve evaluate kavramlarÄ± kaldÄ±ÄŸÄ±ndan ben soruyu yanlÄ±ÅŸ cevapladÄ±m..",
14. ->  Validation kullanmazsan test sirasinda overfitting problemi ortaya cikar diye bir kural yok.Ortaya cikabilir.Validatin kullanmamizin sebebi modelimizi check edip karar vermek, teste hazir olup olmadigina..",
15. ->  ->  DÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼mÃ¼ aktaramamÄ±ÅŸÄ±m kesinlikle Ã¶yle oluÅŸmamasÄ± iÃ§in bir Ã¶nlem validation..",
16. ->  Aslinda daha onemlisi su: Validation set kullanmadigin icin overfitting problemi ortaya cikmiyor, validation set kullanmak, test surecinden once modeli degerlendirmeni saglar.Dolayisiyla Merve Hanim ifadenizin dogrulugundan supheliyim..",
17. ->  ->  might diyor orada zaten.",
18. ->  ->  might diyor ama eger validation kullanmazsak diyor.Yanlis hatirlamiyorsam bu dogru yanitti.Ve test sirasinda ortaya cikabilecek olan overfiiting probleminin validation set kullanmamaya baglanmasina dogru diyemeyiz..",
19. ->  Bununla ilgili bir post yazdÄ±m..",
20. -> Soruda herhangi bir hata gÃ¶rmedim, ancak burada yazÄ±lanlar biraz fazla terimsel olduÄŸu iÃ§in konunun anlaÅŸÄ±lmasÄ±nÄ± engelliyor olabilir.Herhalde ÅŸunu biraz aÃ§mak bu meselenin anlaÅŸÄ±lmasÄ±nÄ± kolaylaÅŸtÄ±rabilir:Ä°ki parÃ§alÄ± veriyle(train+test) Ã§alÄ±ÅŸÄ±rken Ã¼rettiÄŸimiz modelin ne kadar baÅŸarÄ±lÄ± olduÄŸunu gÃ¶rmek iÃ§in model Ã¼zerinde deÄŸiÅŸiklikler yapÄ±yoruz. yaptÄ±ÄŸÄ±mÄ±z her deÄŸiÅŸiklik modelin \"kullandÄ±ÄŸÄ±mÄ±z test seti iÃ§in\" dÃ¼zenlenmesine sebep oluyor. Yani bir sÃ¼re sonra bu sisteme overfit olmaya baÅŸlayabilir. Bu da gerÃ§ek datayla Ã§alÄ±ÅŸmaya baÅŸladÄ±ÄŸÄ±mÄ±zda hata miktarÄ±nÄ±n Ã¶ngÃ¶remediÄŸimiz ÅŸekilde artmasÄ±na sebep olabilir.Bunu engellemek (yani tarafsÄ±zlÄ±ÄŸÄ±mÄ±zÄ± korumak) adÄ±na yapabileceÄŸimiz bir ÅŸey araya bir validation set ekleyip (train+validation+test) modeli validation set Ã¼zerinde elde ettiÄŸimiz sonuÃ§lara bakarak dÃ¼zeltmek. Modelle iÅŸimiz bittikten sonra performansÄ±nÄ± test sete bakarak belirleriz. BÃ¶ylece tarafsÄ±zlÄ±ÄŸÄ±mÄ±zÄ± daha iyi korumuÅŸ, Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z veriye overfit olma riskini de azaltmÄ±ÅŸ oluruz.",
21. ->  ->  ÅÃ¶yle bir Ã¶rnek daha net anlaÅŸÄ±lmasÄ±nÄ± saÄŸlayabilir belki. BoksÃ¶r olduÄŸumuzu dÃ¼ÅŸÃ¼nelim. GÃ¼Ã§lÃ¼ biriyle (test) turnuva maÃ§Ä±na Ã§Ä±kacaÄŸÄ±z. Antrenman yapÄ±p (train) direkt adamÄ±n karÅŸÄ±sÄ±na Ã§Ä±kmak yerine Ã¶ncesinde orta seviye biriyle (validation) maÃ§ yapÄ±p gÃ¼cÃ¼mÃ¼zÃ¼ test ediyoruz. Bu karÅŸÄ±laÅŸmaya gÃ¶re daha iyi hazÄ±rlanÄ±p turnuvadaki maÃ§Ä±mÄ±za (test) gidiyoruz. Orta seviye adama gÃ¶re Ã§alÄ±ÅŸmaya Ã§ok fazla odaklanÄ±rsak (overfitting) turnuvada Ã§ok fena dayak yiyebiliriz ğŸ™‚",
22. ->  ->  Harika! Bu Ã¶rneÄŸe bir dÃ¼zeltme; rakip boksÃ¶rlerin ne kadar gÃ¼Ã§lÃ¼ olduÄŸunu bilmiyor olmalÄ±yÄ±z. Aksi takdirde tarafsÄ±zlÄ±ÄŸÄ±mÄ±zÄ± kaybetmiÅŸ ve gene overfit riskiyle karÅŸÄ±laÅŸmÄ±ÅŸ oluruz..",
23. ->  ->  DoÄŸrudur o zaman ikisinide bilmediÄŸimizi ama birbirlerinden farklÄ± olduklarÄ±nÄ± dÃ¼ÅŸÃ¼nebiliriz sanÄ±rÄ±m..",
24. ->  Overfitting, training esnasinda cok iyi sonuclar alip, test/validation sirasinda poor sonuclarin olusmasidir.Modeliniz training sirasinda ogrenmekten ziyade ezberlemistir..Dolayisiyla modelinize ezberledigi training dataset disinda farkli bir dataseti verdiginizde sonuclar icacici olmamistir,Peki neden olmustur bu? Yani overfittingin sebebi nedir? Kucuk bir dataseti ile cok katmanli complex bir model kullanmissinizdir.Nasil onleriz? Dropout, regularization, remove features, cross-validation, early stopping, train with more data.(Bazi yontemlerin ayni anda kullanilmasi tavsiye olunmaz).",
    
### soru 

> quest: "Veri setinden veri setine deÄŸiÅŸtiÄŸini bilmekle beraber en iyi epoch, learning rate ve batch size kombinasyonu (iÅŸlem hÄ±zÄ±nÄ± da gÃ¶zeterek) learning rate ve batch size'Ä± mÃ¼mkÃ¼n mertebe dÃ¼ÅŸÃ¼k tutup epoch sayÄ±sÄ±nÄ± yÃ¼ksek tutmak mÄ±dÄ±r? Ã‡Ã¼nkÃ¼ anladÄ±ÄŸÄ±m kadarÄ±yla batch sayÄ±sÄ±nÄ± ne kadar kÃ¼Ã§Ã¼ltÃ¼rsek ana Ã¶rneklemimizi o denli kÃ¼Ã§Ã¼k parÃ§alara ayÄ±rÄ±yor ve her seferinde learning rate'i kullanarak aÄŸÄ±rlÄ±klarÄ± update ediyor. Bu durum da iÅŸimize gelmeli.  Epoch tarafÄ±ndan bakacak olursak da, 1 epoch sanÄ±yorum ki tÃ¼m mini batchlerimizin iÅŸlenmesi anlamÄ±na geliyor (Yani ana verideki Ã¶rneklem sayÄ±sÄ±/mini batchteki Ã¶rneklem sayÄ±sÄ± kadar iterasyon). Bu sayÄ±yÄ± ne kadar yÃ¼ksek tutarsak da defalarca kez veriyi iÅŸleriz ve sonucunda dÃ¼ÅŸÃ¼k bir MSE deÄŸerine ulaÅŸÄ±rÄ±z.  First Step with TF dersinin 'Linear Regression with a Real Dataset' egzersizinde learning rate'i dÃ¼ÅŸÃ¼rÃ¼rken epoch ve batch size'Ä± bÃ¼yÃ¼tmenin Ã§oÄŸunlukla en iyi kombinasyon olduÄŸu yazÄ±yor ancak ben batch size kÄ±smÄ±na katÄ±lmÄ±yorum.

> comments:
  
1. -> Merhaba,Batch size'Ä± Ã§ok kÃ¼Ã§Ã¼k bir deÄŸere ayarlamak kararsÄ±zlÄ±ÄŸa neden olabilir. Ã–ncelikle batch size'Ä± bÃ¼yÃ¼k bir deÄŸere ayarlayÄ±p azalmayÄ± gÃ¶rene kadar ufak ufak kÃ¼Ã§Ã¼ltmeniz daha iyi olacaktÄ±r. Batch size'Ä± bÃ¼yÃ¼k bir deÄŸer almamÄ±zdaki dezavantaj memoryde kaplayacaÄŸÄ± yer ve zaman karmaÅŸÄ±klÄ±ÄŸÄ±dÄ±r(complexity.) AvantajÄ± ise bÃ¼yÃ¼k bir batch size'da daha doÄŸru ve tutarlÄ± eÄŸimler elde edersiniz Ã§Ã¼nkÃ¼ daha bÃ¼yÃ¼k bir veri grubu (batch sayÄ±sÄ± kadar veri) iÃ§indeki kaybÄ±mÄ±zÄ± optimize ediyoruz. Yani batch size'Ä±nÄ±z dÃ¼ÅŸÃ¼kken daha sÄ±k gÃ¼ncelleme yapÄ±yor olsanÄ±z da bu sÄ±klÄ±k optimizasyonun daha iyi yapÄ±lacaÄŸÄ± anlamÄ±na gelmez. Bunu bir Ã§ok kÃ¶tÃ¼ gÃ¼ncelleme vs Ã§ok az iyi gÃ¼ncelleme olarak dÃ¼ÅŸÃ¼nebilirsiniz. En ekstrem Ã¶rnekte zaten batch_size training size'a eÅŸit olacak kadar bÃ¼yÃ¼ktÃ¼r. Kaynak olarak: [Link](https://forums.fast.ai/t/disadvantages-of-using-very-large-batch-size/29177/3) linkini verebilirim. Ä°yi Ã§alÄ±ÅŸmalar dilerim ğŸ™‚",

### soru 

> quest: "Merhabalar,  Validation and Test Sets Collab kÄ±smÄ±nda task2 de train ve validation setindeki verilere yeterince benzemiyor diyor ve head ile incelenmesini sÃ¶ylÃ¼yor.Tam olarak benzememeden kastÄ± ne ve de bu sette bunu nasÄ±l gÃ¶zlemleyip evet benzemiyor diyebilirim?  TeÅŸekkÃ¼rler:)",

> comments:
  
1. ->  dataframe ismi ile birlikte .head(1000) diyerek kullanÄ±rsan ilk 1000 veri geliyor Ã¶rneÄŸin. Burada verilerin hepsinin farklÄ± olduÄŸunu gÃ¶zlemliyoruz hepsi bu ğŸ™‚.",
" -> Merhaba Buse,Ã‡Ã¶zÃ¼m kÄ±smÄ±na baktÄ±ÄŸÄ±nda, 0-4 ile 25-29 arasÄ±ndaki deÄŸerleri incelemeni sÃ¶ylÃ¼yor. Kodu yazÄ±p baktÄ±ÄŸÄ±mÄ±zda, bazÄ± farklÄ± ve aÅŸÄ±rÄ± deÄŸerler gÃ¶rebiliriz. Birisi 1000-7000 arasÄ± deÄŸiÅŸirken, diÄŸeri 700-2000 arasÄ± deÄŸiÅŸmekte.",
" -> Merhaba, sanÄ±rÄ±m \"validation seti train setine yeterince benzemiyor yani rastgele daÄŸÄ±lmamÄ±ÅŸ\" bunu keÅŸfetmemizi bekliyor Task 2. Longitude deÄŸerine bakarsak verinin sÄ±ralandÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼yoruz.",
1. ->  SanÄ±rÄ±m keÅŸfetmemizi istediÄŸi ÅŸey train setindeki verilerin longitude deÄŸerlerine gÃ¶re sÄ±ralÄ± olmasÄ±. Bu durum veri setini train ve validation olarak ayÄ±rÄ±rken, validation setinin sadece belirli bir aralÄ±ktaki longitude deÄŸerlerine iÃ§ermesine sebep oluyor. Bu durumun problem olmasÄ±nÄ±n asÄ±l sebebi de longitude deÄŸerinin median_house_value deÄŸerini etkilemesi olduÄŸunu sÃ¶ylÃ¼yor colab'deki aÃ§Ä±klama. Bu etkiyi yani feature'larÄ±n birbirleri arasÄ±ndaki iliÅŸkinin derecesini bir Ã¶nceki exercise'larda correlation matrix ile gÃ¶rebileceÄŸimizi Ã¶ÄŸrenmiÅŸtik fakat corr matrisine gÃ¶re aralarÄ±nda(median_house_value ve longitude) bir iliÅŸki olmamasÄ± gerekiyor. TeÄŸit etmek iÃ§in datayÄ± incelediÄŸimde de aralarÄ±nda bir iliÅŸki gÃ¶remiyorum. Bu durumun sebebini anlayamadÄ±m, birisi aydÄ±nlatabilirse sevinirim, ÅŸimdiden teÅŸekkÃ¼rler..",
    
### soru 

> quest: "Son aÅŸamada (Validation Set)  Åimdi ilk Ã¶nce training set ile veri eÄŸitiliyor, ilk epoch sonunda test ediliyor deÄŸil mi? eÄŸer iyi bir tahmin yoksa, ikinci epoch'a geÃ§iyor sonra test set ile yine test ediliyor. Bu yÃ¼zden overfitting olmamasÄ± iÃ§in Validation Set kullanÄ±yoruz. Buraya kadar doÄŸru anlamÄ±ÅŸ mÄ±yÄ±m? Bir diÄŸer sorumda Training Set iÃ§inde Test Set verileri yok, ayrÄ± yani bu veriler, overfitting nasÄ±l oluyor? BurayÄ± tam anlayamadÄ±m. TeÅŸekkÃ¼rler:)",

> comments:
  
1. ->  Benim anladÄ±ÄŸÄ±m training setinden verilerimizi eÄŸittikten sonra her aÅŸamada test setteki veriler ile test edince modelimiz verileri ezberlemesi duruma overfitting oldu deniliyor. Modelimiz overfitting olduÄŸunda ise yeni bir veri eklediÄŸinde dÃ¼zgÃ¼n bir ÅŸekilde Ã§alÄ±ÅŸamÄ±yabiliyor. Bu yÃ¼zden bu durumu engelleyebilmek iÃ§in modelimizi eÄŸitirken validation seti kullanarak hyperparameterleri ayarlÄ±yoruz ve modelimizin hazÄ±r olduÄŸuna karar verdiÄŸimizde son aÅŸama olan test iÃ§in ayÄ±rdÄ±ÄŸÄ±mÄ±z test seti ile modelimizi test ediyoruz.",
1. ->  yani modelimizi overfitting olmamasÄ± iÃ§in validation seti kullanarak test ediyoruz en son aÅŸamada test seti kullanarak modelimizin iyi olup olmadÄ±ÄŸÄ±nÄ± belirliyoruz. UmarÄ±m daha Ã§ok kafanÄ± karÄ±ÅŸtÄ±rmamÄ±ÅŸÄ±mdÄ±r.",
" ->  Merhaba, [Link](https://medium.com/data-science-tr/overfitting-underfitting-cross-validation-b47dfda0cf4e) bu sitede overfitting durumu Ã§ok basit bir dille anlatÄ±lmÄ±ÅŸ belki faydasÄ± olabilir",
"Makine Ã–ÄŸrenmesi Dersleri 8: Cross Validationmedium.comOverfitting (High Variance)",
1. -> Ã‡ok teÅŸekkÃ¼r ederim cevaplarÄ±nÄ±z iÃ§in.",
1. ->  ÅÃ¶yle ki eÄŸitim setinde test verileri bulunmuyor ama eÄŸitme iÅŸleminde hiperparametreleri kullanarak test setindeki verilerin doÄŸruluÄŸunu iyileÅŸtirmek iÃ§in kullandÄ±ÄŸÄ±mÄ±zdan dolayÄ± model sadece test verileri iÃ§in iyi deÄŸer vermiÅŸ oluyor. Yeni veri gelince patlÄ±yor..",
1. ->  Verini Ã¼Ã§e bÃ¶lÃ¼yorsun, eÄŸitim, deÄŸerlendirme ve test. DeÄŸerlendirme de aslÄ±nda bir test seti. Verini batch'ler halinde eÄŸittin, her batch'te deÄŸerlendirme setindeki verilerle hata hesaplayÄ±p hiperparametrelerini gÃ¼ncelliyorsun. Yani bu her epoch sonu deÄŸil her batch sonu olan bir ÅŸey. Verini eÄŸittikten sonra hiperparametrelerini gÃ¼ncellediÄŸin deÄŸerlendirme setiyle kontrol edersen modelinin Ã§ok iyi bir performans sergilediÄŸini gÃ¶rÃ¼rsÃ¼n, ama aslÄ±nda modelin kendi hatasÄ±na baka baka deÄŸerlendirme setini ezberlemiÅŸtir, biz buna overfitting diyoruz, yani modelin Ã§ok iyi gibi gÃ¶zÃ¼kÃ¼yor da aslÄ±nda deÄŸil. O yÃ¼zden ikinci bir test seti kullanÄ±yoruz test etmek iÃ§in.",
1. -> Cevaplar iÃ§in Ã§ok teÅŸekkÃ¼r ederim. Åimdi Ã§ok daha iyi anladÄ±mmm...",
    
### soru 

> quest: "Merhaba. Benim bir sorum olacaktÄ±. Åimdi biz veri setini kÃ¼Ã§Ã¼k gruplara ayÄ±rarak Ã¶ÄŸrenme iÅŸlemini bu kÃ¼Ã§Ã¼k gruplar yani mini-batchler Ã¼zerinden devam ettiriyoruz. Peki bu mini-batchler Ã¼zerinden giderek bulduÄŸumuz cost function'Ä± ve bu cost'u minimize etmek iÃ§in kullandÄ±ÄŸÄ±mÄ±z gradient descent batchlere gÃ¶re deÄŸiÅŸiklik mi gÃ¶steriyor. Yani her bir batch iÃ§in ayrÄ± bir cost function mÄ± buluyoruz o kÄ±smÄ± tam anlamadÄ±m. AnlamadÄ±ÄŸÄ±m iÃ§in de karÄ±ÅŸtÄ±rmÄ±ÅŸ olabilirim ???? DÃ¼zeltilmeye aÃ§Ä±ÄŸÄ±m, vereceÄŸiniz cevaplar iÃ§in ÅŸimdiden teÅŸekkÃ¼r ediyorum. ????",

> comments:
  
1. ->  Merhaba, evet mini-batch iÃ§in belirlediÄŸimiz sayÄ±da Ã¶rneÄŸi kullanarak loss'u (yani gerÃ§ek sonuÃ§lardan ne kadar uzak olduÄŸumuzu) hesaplÄ±yoruz ve parametrelerimizi (W, b) mini-batch Ã¼zerinde bulduÄŸumuz loss'a gÃ¶re gÃ¼ncelliyoruz. SeÃ§tiÄŸimiz farklÄ± Ã¶rnekler, farklÄ± feature deÄŸerlerine sahip olduÄŸu iÃ§in, mini-batch'lerimizin loss'larÄ± da doÄŸal olarak farklÄ± olacaktÄ±r. UmarÄ±m doÄŸru anladÄ±m soruyu ğŸ˜€",
2. ->  TeÅŸekkÃ¼rler Mert cevabÄ±n iÃ§in. Peki genel olarak modelden dÃ¶necek olan weight ve bias, mini-batchlerden hesaplanan weight ve biaslarÄ±n ortalamasÄ± olarak mÄ± olur? Yani nasÄ±l formÃ¼lize edilir? Bunun da yanÄ±tÄ±nÄ± verebilirsen Ã§ok iyi olur ğŸ™‚.",
3. -> Sorunu tam olarak anlamadÄ±m ama baÅŸtan itibaren kendimce mantÄ±ÄŸÄ±nÄ± aÃ§Ä±klamaya Ã§alÄ±ÅŸayÄ±m. Linear Regression Ã¼zerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±zÄ± dÃ¼ÅŸÃ¼nelim. Ä°lk olarak w ve b deÄŸerlerimizi 0'a eÅŸitliyoruz. y'(tahminimiz) = w.x + b gibi bir formÃ¼lle ifade ediliyor. X ise feature vektÃ¶rÃ¼mÃ¼z, yani ev fiyatÄ± tahmin etmek istiyorsak feature'larÄ±mÄ±z x = [oda sayÄ±sÄ±, metrekare, evin yaÅŸÄ±, vb.] , ardÄ±ndan bu y' deÄŸerimizi hesapladÄ±ÄŸÄ±mÄ±zda fotoÄŸrafta olduÄŸu gibi bir doÄŸru tahmin etmiÅŸ oluyoruz. DoÄŸrumuzun Ã¶rneklerimizin bulunduÄŸu noktalara gÃ¶re olan uzaklÄ±ÄŸÄ± loss deÄŸerimizi ifade ediyor. Ã–rneÄŸin mini-batch-size=5 iÃ§in kullandÄ±ÄŸÄ±mÄ±z Ã¶rneklerin rastgele Ã§ok lÃ¼ks evlerden denk geldiÄŸini dÃ¼ÅŸÃ¼nelim. Fakat ortalama olarak o mahalledeki evler, lÃ¼ks evler kadar pahalÄ± olmayacaÄŸÄ±ndan Ã§izgimiz noktalarÄ±mÄ±zla alakasÄ±z Ã§Ä±kacak ve loss yÃ¼ksek Ã§Ä±kacak. Sonraki 5 Ã¶rneÄŸimize geÃ§tiÄŸimizde ise ortalama fiyatlara sahip evler geldiÄŸini dÃ¼ÅŸÃ¼nelim. Bu sefer bu evler iÃ§in yaptÄ±ÄŸÄ±mÄ±z tahminler gerÃ§ek sonuÃ§larÄ±mÄ±za yakÄ±n olduÄŸundan Ã§izgiyi verilerimize daha uygun ÅŸekilde Ã§izebileceÄŸiz. Bu ÅŸekilde mini-batch'ler Ã¼zerinde iÅŸlem yaparak Ã§izgimizi, noktalardan en az uzak olacak ÅŸekilde Ã§izmeye Ã§alÄ±ÅŸÄ±yoruz. Bu kursta bahsedilmemiÅŸ terimler kullandÄ±ysam ve anlaÅŸÄ±lmadÄ±ysa Ã¼zgÃ¼nÃ¼m, aÃ§Ä±klamaya Ã§alÄ±ÅŸtÄ±m, umarÄ±m faydasÄ± olur :)",
4. ->  ->  AklÄ±ma cevabÄ±nÄ±zÄ± okuyunca bir soru geldi. Batch'in alacaÄŸÄ± veriler rastgele seÃ§iliyor dediÄŸiniz gibi. Bu rasgelelik seÃ§ilen Ã¶ÄŸenin bir daha seÃ§ilmemesi Ã¼zerine mi yoksa rastgele veri Ã§ektiÄŸimiz havuza her zaman veriseti iÃ§erisindeki tÃ¼m veriler dahil oluyor mu?.",
5. ->  ->  Bizim ÅŸu ana kadar kursta ilerlediÄŸimiz kadarÄ±yla epoch kavramÄ±nÄ±n aÃ§Ä±klanÄ±ÅŸÄ± ve genel olarak bilinen yÃ¶ntem, seÃ§ilen Ã¶rneÄŸin tekrar seÃ§ilmemesi diye biliyorum. Fakat yapay sinir aÄŸlarÄ± uygulamalarÄ±nda seÃ§ilen Ã¶rneÄŸin tekrar havuza geri atÄ±lmasÄ± kullanÄ±lÄ±yormuÅŸ. With replacement - without replacement ÅŸeklinde geÃ§iyor. AttÄ±ÄŸÄ±m linkte bahsettiÄŸin durum ile alakalÄ± bir deÄŸerlendirme var.[Should training samples randomly drawn for mini-batch](https://stats.stackexchange.com/questions/235844/should-training-samples-randomly-drawn-for-mini-batch-training-neural-nets-be-dr)
6. ->  ->  AnladÄ±m teÅŸekkÃ¼r ederim..",
7.   ->  ->  Her mini-batch iÃ§in bir y' tahmin ediyoruz. yani Ã¶rneklere en az uzak olucak sekilde Ã§izgi Ã§iziyoruz. nihai Ã§izgiyi, nasÄ±l elde ediyoruz? elimizde bir Ã§ok y' olucak. mesela arasÄ±ndaki en iyisini mi alÄ±yoruz? yoksa bÃ¼tÃ¼n y' alÄ±p ortalamasÄ±nÄ± alarak en iyi tahmin edecek modeli mi elde ediyoruz? yada baÅŸka birÅŸey mi.",
8. ->  ebubekir ceylan y' dediÄŸimiz ÅŸeyler tahmin ettiÄŸimiz deÄŸerler bunun modeli Ã§izmekle dolaylÄ± bir iliÅŸkisi var. Modelin doÄŸruluÄŸunu Ã¶lÃ§mek iÃ§in Cost Functiondan kayÄ±p deÄŸeri hesaplamamÄ±za yarÄ±yor. Bizim batchler sonunda elde ettiklerimiz bias ve weight deÄŸerleri. Ki bu da birden fazla olmuyor bir denklemdeki aÄŸÄ±rlÄ±klarÄ± deÄŸiÅŸtirerek kaybÄ± azaltmaya Ã§alÄ±ÅŸÄ±yoruz. Ama tek bir denklem var elimizde. Ortalama vs sÃ¶z konusu deÄŸil..",
9. ->  ebubekir ceylan Nihai Ã§izgi, en son elde ettiÄŸimiz weight ve bias deÄŸerlerini kullanarak Ã§izdiÄŸimiz Ã§izgi oluyor. Ã–nceki Ã§izgileri sadece hatamÄ±zÄ± hesaplayÄ±p w ve bias deÄŸerlerimizi gÃ¼ncellemek iÃ§in kullanÄ±yoruz. Zaten mini-batch sayÄ±sÄ± Ã§ok Ã§ok kÃ¼Ã§Ã¼k belirlemediysek, her adÄ±mÄ±mÄ±zda daha iyi bir Ã§izgi Ã§izmemiz yani daha az cost'a sahip olmamÄ±z beklenir..",
    
### soru 

> quest: "Validation Set kÄ±smÄ±nda oluÅŸan yeni iÅŸ akÄ±ÅŸÄ±nda validation ile en iyi modeli seÃ§in sonrasÄ±nda test setine gÃ¶re 2 kez kontrol edin diyor neden iki kez?Birde bu iÅŸ akÄ±ÅŸÄ±nÄ±n test setine daha az exposures oluÅŸturur derken ne demek istiyor anlayamadÄ±m?  TeÅŸekkÃ¼rler:)",

> comments:
  
1. -> SanÄ±rÄ±m ingilizce olmasÄ±ndan Ã¶tÃ¼rÃ¼ farklÄ± anlaÅŸÄ±lÄ±yor ????Ben ÅŸÃ¶yle anlamÄ±ÅŸtÄ±m, burada bir validation set Ã¼zerinde en uygun yaklaÅŸÄ±mÄ± aldÄ±k. Bu bizim iÃ§in, Ã¶ÄŸrenim sonrasÄ±nda validation setâ€™e gÃ¶re en iyi sonuÃ§ veren yapÄ±. Bunu, test setinin Ã¼zerinde tekrar kontrol ederek, validation setâ€™e overfit olup olmadÄ±ÄŸÄ±nÄ± kontrol ediyoruz. Yani ilk check, validation set Ã¼zerinde, ikinci check ise test seti Ã¼zerinde. Double checkâ€™i bÃ¶yle anladÄ±m ben.",
2. -> Exposure'dan kastÄ± da ÅŸÃ¶yle ki, Verimizi \"train-validation-test\" olarak bÃ¶lmek ile \"train-test\" ÅŸeklinde bÃ¶lmenin kÄ±yasÄ±nÄ± yapÄ±yor anladÄ±ÄŸÄ±m kadarÄ±yla. BÃ¶ylece, test Ã¼zerinde ustalaÅŸmayan yapÄ±nÄ±n doÄŸruluÄŸun, gÃ¶rseldeki yolla daha iyi gÃ¶rebiliyoruz..",
3. ->  Merhaba,AnladÄ±ÄŸÄ±m kadarÄ±yla oradaki double check demesinin sebebi veriyi daha Ã¶nceden validation set ile kontrol etmemizdi yani oradaki double, test setini iki kez kontrol et demek deÄŸil ikinci kez test verisinde kontorle t demek. Az exposure kÄ±smÄ± iÃ§in validation set'i iÅŸin iÃ§ine sokmamÄ±zÄ±n amacÄ± ise, validation setin olmadÄ±ÄŸÄ± iÅŸ akÄ±ÅŸÄ±nda modeli optimize ÅŸekle ayarlamak iÃ§in model eÄŸitildikten sonra test setimizi deneyerek o anki optimumluk deÄŸerine gÃ¶re bu workflow dÃ¶ngÃ¼sÃ¼nÃ¼ sÃ¼rdÃ¼rÃ¼yordu. Validation set ise training set iÃ§inden seÃ§ileceÄŸi iÃ§in test ve train datasÄ±nÄ± ayÄ±rarak training sonrasÄ± test datasÄ±nÄ±n unseen data olarak kalmasÄ±nÄ± saÄŸlar. Yani test datasÄ±nÄ±n exposure'luÄŸu Ã¶nlenmiÅŸ olur.Ä°yi Ã§alÄ±ÅŸmalar.",
4. ->  OÄŸuzhan ve Fethi'nin dediÄŸi gibi validation datasÄ± ile yapÄ±lan teste ek olarak test datasÄ±yla da test edilmesi double check olmuÅŸ oluyor.Burada datamÄ±zÄ± Ã¼Ã§ farklÄ± parÃ§aya bÃ¶lmemizdeki amaÃ§ ÅŸu, train datasÄ± ile eÄŸittik ve validation datasÄ± hiperparametrelerimizi ayarladÄ±k ve en iyi modelimizi seÃ§tik. Peki bu ayarlamadan sonra ya modelimiz validation datasÄ±na overfit olduysa? Ä°ÅŸte burada test datasÄ± devreye giriyor ve bir kez daha modelimizi test etmiÅŸ oluyoruz.",

### soru 

> quest: "Merhaba,   AnladÄ±ÄŸÄ±m kadarÄ±yla Epoch, learning rate ve batch kavramlarÄ±nÄ± gÃ¶stermeye Ã§alÄ±ÅŸtÄ±m. Sizden talebim, hatalarÄ±mÄ± dÃ¼zeltmeniz Ã§Ã¼nkÃ¼ sebebini bilmediÄŸim bir ÅŸekilde anlamakta zorlandÄ±ÄŸÄ±mÄ± dÃ¼ÅŸÃ¼nÃ¼yorum.  Veri setimizi, tÃ¼m veriyi tek seferde iÅŸlemek zorunda kalmasÄ±n diye batch'lere ayÄ±rÄ±yoruz. Burada veri setimiz 10, batch boyutumuz ise 2.   10 veriyi, 2'li parÃ§alara ayÄ±rdÄ±ÄŸÄ±mÄ±z iÃ§in, toplam 5 kez (her seferinde 2 veri olacak ÅŸekilde) veriyi alÄ±yor ve kendisini eÄŸitiyor. bu iÅŸlemi 5 kez yaptÄ±ktan sonra yani tÃ¼m seti parÃ§a parÃ§a aldÄ±k bÃ¶ylece bir epoch bitti. Bu epoch'un sonucunun, feature'u ve bias'Ä± ne kadar deÄŸiÅŸtireceÄŸi de bizim learning rate'imize baÄŸlÄ±.  0,5 veya 1'se bu sonuÃ§ fazla etkileyecekken, 0.001 gibi bir deÄŸerse etkisi Ã§ok az olacaktÄ±r.  Burada bir hata var mÄ±? Åimdiden teÅŸekkÃ¼r ederim.",

> comments:
  
1. ->  DoÄŸru anlamÄ±ÅŸsÄ±n. Her batch'ten sonra modelin weight'leri ve bias'larÄ± gÃ¼ncelleniyor, senin Ã¶rneÄŸine gÃ¶re her epoch'ta 5 kez gÃ¼ncelleme yapÄ±lÄ±yor, yani parametre gÃ¼ncellemesi her epoch sonunda yapÄ±lmÄ±yor, batch bitince yapÄ±lÄ±yor. Ama epoch sayÄ±sÄ±nÄ± istediÄŸin kadar belirleyebilirsin bunlardan baÄŸÄ±msÄ±z olarak. Senin modelin veri setine epoch sayÄ±sÄ± kadar defa maruz kalÄ±r. UmarÄ±m aÃ§Ä±klayabilmiÅŸimdir.1 month ago 18 people like this.Like ReportReply",
2. -> ->  Ã‡ok teÅŸekkÃ¼r ederim, gayet iyi aÃ§Ä±kladÄ±nÄ±z..",
3. ->  ->  Epoch sayÄ±sÄ±nÄ±n Ã§ok fazla yaptÄ±ÄŸÄ±mÄ±zda overfitting oluÅŸmuyor mu acaba ?.",
4. ->  ->  learning rate'in ve parametrelerin yeterince dÃ¼ÅŸÃ¼kse overfitting'e yol aÃ§maz, aynÄ± ÅŸekilde regularizasyonla da bunun Ã¶nÃ¼ne geÃ§ebilirsin, ama evet, mantÄ±ken overfitting'e mÃ¼sait bir yapÄ± varsa epoch sayÄ±sÄ±nÄ± arttÄ±rmak overfitting'i arttÄ±rÄ±r.",
5. ->  ->  TeÅŸekkÃ¼rler. Learning rate'in overfitting ile ilgili olduÄŸunu bilmiyordum. Ama nasÄ±l bir ilgisi var onu anlayamadÄ±m..",
6. ->  ->  demeye Ã§alÄ±ÅŸtÄ±ÄŸÄ±m ÅŸey eÄŸer learning rateâ€™in ve parametrelerin dÃ¼ÅŸÃ¼kse overfitting olmasÄ± iÃ§in Ã§ok fazla epoch olmasÄ± gerek, yani Ã§ok kÃ¼Ã§Ã¼k adÄ±mlar atÄ±yorsun sonuÃ§ta gibi dÃ¼ÅŸÃ¼nebilirsin. dÃ¼ÅŸÃ¼k learning rate de overfittingâ€™e yol aÃ§abiliyor bazen, burada aÃ§Ä±klamasÄ± var learning rateâ€™ini probleme gÃ¶re nasÄ±l seÃ§men gerektiÄŸinin [Link](https://mlexplained.com/2018/01/29/learning-rate-tuning-in-deep-learning-a-practical-guide/)
7. ->  ->  Ä°nceliyorum teÅŸekkÃ¼r ederim..",
8. ->  \"tÃ¼m veriyi tek seferde iÅŸlemek zorunda kalmasÄ±n diye\" yerine \"tek bir parametre gÃ¼ncellemesi(weight update(iteration)) iÃ§in bÃ¼tÃ¼n sample'larÄ±n Ã¼zerinden geÃ§mesini bekleyerek zaman kaybetmemek amacÄ±yla\" olarak gÃ¼ncelleyebiliriz sanÄ±rÄ±m..",
9. ->  First Steps with TF bÃ¶lÃ¼mÃ¼ndeki Linear Regression with Synthetic Data kÄ±smÄ±nÄ±n 5. gÃ¶revinde sorduÄŸun sorunun cevabÄ± var ->  kÄ±saca gÃ¼zel aÃ§Ä±klamÄ±ÅŸ..",
10. -> Batch (kÃ¼me) lere ayÄ±rmak istememizin nedenlerinden biri de dataset Ã§ok bÃ¼yÃ¼k olduÄŸunda tek seferde bu kadar datayÄ± tutarak iÅŸlem yapabilecek memory mizin olmayacaÄŸÄ±ndan dolayÄ±. AyrÄ±ca tek seferde ne kadar Ã§ok data olursa bu hesaplamalar matris Ã§arpÄ±mlarÄ±na dayalÄ± olduÄŸu iÃ§in matrisin satÄ±r sayÄ±sÄ± artmÄ±ÅŸ oluyor ve iÅŸlem sÃ¼resi de baya artÄ±yor.Bir tane data alÄ±p loss hesaplayarak parametreleri gÃ¼ncellerseniz hÄ±zlÄ± iÅŸlem yapÄ±yorsunuz fakat kÃ¼meden Ã§ok farklÄ± noktalar seÃ§erek updatelediÄŸiniz iÃ§in stabil olmayan bir Ã¶ÄŸrenme gerÃ§ekleÅŸiyor. Ã–rneÄŸin ders iÃ§eriklerinde Ã¶rnek verilen sick-healthy trees datasetinde healthy lerin iÃ§inde bir tane bulunan sick Ã¶rneÄŸi ile train ederken model parametreleri sapabilir. Bu yÃ¼zden daha fazla Ã¶rneÄŸi kapsayan bir gÃ¼ncelleme daha doÄŸru sonuÃ§ veriyor.Ã‡Ã¶zÃ¼m olarak da imkan verdiÄŸince yÃ¼ksek batch size ile baÅŸlayÄ±n, hÄ±zlanmak ve daha hÄ±zlÄ± train edebilmek adÄ±na yavaÅŸ yavaÅŸ batch size Ä± dÃ¼ÅŸÃ¼rÃ¼n, sonuÃ§lar bozulup loss zigzag Ã§izene kadar batch size Ä± azaltabilirsiniz Ã¶neriliyor.",
11. ->  Bu ayrÄ±mÄ± yapmakta Ã§ok zorlanÄ±yordum. Ã‡ok aÃ§Ä±k ve faydalÄ± bir anlatÄ±m olmuÅŸ. Destekleriniz iÃ§in Ã§ok teÅŸekkÃ¼rler..",
12. -> ->  Rica ederim, ben de uzun uÄŸraÅŸlar sonucu da oturtabilmiÅŸtim, size faydasÄ± olduysa ne mutlu ğŸ™‚.",
    
### soru 

> quest: "Merhaba,   Validation &amp; Test Sets Programming Exercise kÄ±smÄ±nda veri train ve validation olarak 2'ye ayrÄ±lÄ±yor. 3'e ayÄ±rÄ±p test seti kesinlikle train iÃ§inde kullanmamamÄ±z gerekiyor diye anlamÄ±ÅŸtÄ±m. Exercise'da en son problemleri Ã§Ã¶zdÃ¼kten sonra test set kullanÄ±lÄ±yor. Bu durum modeli baÅŸarÄ±lÄ± yorumlamamÄ±za sebep olmaz mÄ± ?   Birde bu exercise'da veriyi karÄ±ÅŸtÄ±rararak, yeni index atayarak sanÄ±rÄ±m problemi Ã§Ã¶zmeye Ã§alÄ±ÅŸÄ±yor. MantÄ±ÄŸÄ± anlayamadÄ±m. KÄ±saca bahsedebilirseniz Ã§ok sevinirim .   TeÅŸekkÃ¼rler ğŸ™‚",

> comments:
  
1. -> Bu Ã¶rnekte yanlÄ±ÅŸ hatÄ±rlamÄ±yor isem,verilerimizi okuyup scale ederken zaten test verimizi ayÄ±rÄ±yorduk.Ancak anlatÄ±mda da bahsedildiÄŸi Ã¼zere,test verilerini modelin eÄŸitimi sÄ±rasÄ±nda validation iÃ§in bile kullanmamÄ±z modeli etkileyecektir.Bu yÃ¼zden,train setin iÃ§inden bir validation set ayÄ±rÄ±p eÄŸitimimizi Ã¶yle gerÃ§ekleÅŸtiriyoruz.Ve evet modelin tahmin yeteneÄŸini arttÄ±rÄ±r bu iÅŸlem.Ä°kinci sorunuza istinaden,train set iÃ§erisinden validation setlerini ayÄ±rÄ±rken 0.8-0.2 oranÄ±nÄ± kullanÄ±yoruz.Yani datanÄ±n ilk %80 lik kÄ±smÄ± (100 satÄ±r iÃ§inden ilk 80 satÄ±r gibi) train,%20 (son 20 satÄ±r gibi) validation iÃ§in kullanÄ±lÄ±yor.Ancak verilerimiz,ilk kolona gÃ¶re sÄ±ralÄ± olduÄŸu iÃ§in,modelimiz eÄŸitim aÅŸamasÄ±nda yeteri kadar farklÄ± Ã¶rnek gÃ¶remiyor.Bu yÃ¼zden,indexleri karÄ±ÅŸtÄ±rarak,yani veri setinin kÃ¼Ã§Ã¼kten bÃ¼yÃ¼ÄŸe olan sÄ±ralamasÄ± rastgele hale getirerek,elimizdeki veri Ã§eÅŸidini daha farklÄ± Ã¶rneklere kavuÅŸturuyoruz mantÄ±ÄŸÄ± bu.Kod yapÄ±sÄ± iÃ§in pandas dÃ¶kÃ¼mantasyonunu incelemenizi tavsiye ederim.Eksik veya yanlÄ±ÅŸ sÃ¶ylediÄŸim bir ÅŸey varsa dÃ¼zeltin lÃ¼tfen ğŸ™‚",
2. ->  ->  Ã§ok teÅŸekkÃ¼rler bazÄ± kÄ±sÄ±mlarÄ± kaÃ§Ä±rmÄ±ÅŸÄ±m ğŸ™‚.",
3. ->  Merhaba,En baÅŸta internetten aldÄ±ÄŸÄ±mÄ±z 2 tane csv var. Bunlardan bir tanesi test iÃ§in. DiÄŸeri de training ve validation'Ä± barÄ±ndÄ±ran csv. Yani test verisi training-validation verisi iÃ§inde yer almÄ±yor.DiÄŸer sorunuza gelince de ÅŸÃ¶yle Ã¶rnek vereyim;- Elinizde bir veri var ve o veri bir sÃ¼tuna gÃ¶re sÄ±ralanmÄ±ÅŸ ve siz bÃ¶lmek istiyorsunuz. Peki bÃ¶ldÃ¼ÄŸÃ¼nÃ¼zde elmalar bir tarafta armutlar bir tarafta kalÄ±rsa ne olur? Sadece elmalara gÃ¶re eÄŸitmiÅŸ olursunuz modelinizi ve armut gÃ¶rÃ¼nce sapÄ±tÄ±r. Bu yÃ¼zden sÄ±ralama olmadan karÄ±ÅŸÄ±k bir ÅŸekilde bÃ¶lme yapÄ±lÄ±rsa daha anlamlÄ± bir daÄŸÄ±lÄ±m elde etme ÅŸansÄ± artar. UmarÄ±m yardÄ±mcÄ± olmuÅŸumdur..",
4. ->   ->  teÅŸekkÃ¼r ederim.",
5. -> Merhabalar,Ä°lk sorun iÃ§in, 3 sete ayÄ±rmamÄ±zÄ±n sebebi aslÄ±nda Ã¶zet olarak Validation Set: Check Your Intuition baÅŸlÄ±ÄŸÄ± altÄ±nda bulunmakta, kÄ±saca Ã¶zetleyecek olursam:test setimizi her iterasyonda modelin verimliliÄŸini test iÃ§in kullanmamÄ±z halinde modelimiz test setimizin iÃ§ermekte olduÄŸu ya da olabileceÄŸi kendine has durumlara adapte olmasÄ±na sebep olabilmekte.(modelin test sete aÅŸÄ±rÄ± uyumu/ overfitting).Bunun yerine bir valiadation set ile her eÄŸitim sonunda model etkinliÄŸini test edip, nihai modele karar verdikten sonra test seti ile test ederek, modelimizin etkinliÄŸini daha saÄŸlÄ±klÄ± bir ÅŸekilde gÃ¶zlemleyebiliriz. Bu ÅŸekilde modelimizin validation setimize aÅŸÄ±rÄ± uyum saÄŸlayÄ±p saÄŸlamadÄ±ÄŸÄ±nÄ± tespit edebilir ve devam eden aÅŸamalara daha saÄŸlÄ±klÄ± karar verebiliriz.Veriyi karÄ±ÅŸtÄ±rmasÄ±nÄ±n sebebi ise elimizde bulunan verinin longitude alanÄ±na gÃ¶re kÃ¼Ã§Ã¼kten bÃ¼yÃ¼ÄŸe sÄ±ralanmÄ±ÅŸ olmasÄ±, bu durum her ne kadar veriden rastgele seÃ§im yapsakta sÄ±ralÄ± veri seÃ§memize sebep olmakta ve sonuÃ§lara baktÄ±ÄŸÄ±mÄ±z zaman train ve validation loss deÄŸerleri arasÄ±nda ki farkÄ±n fazla olduÄŸunu gÃ¶rmekteyiz. Verinin sÄ±ralÄ± olmasÄ± yapÄ±lan ayrÄ±m sonucunda train ve validation setlerinin daÄŸÄ±lÄ±mlarÄ±nÄ±n birbirlerine yakÄ±n olmadÄ±ÄŸÄ±nÄ± gÃ¶stermekte. Bunu dÃ¼zeltebilmek iÃ§in sÄ±ralÄ± olan veriyi setini, karÄ±ÅŸtÄ±rmayÄ± Ã§Ã¶zÃ¼m yolu olarak Ã¶neriyor ve uygulayarak sonuÃ§larÄ± gÃ¶zlemliyor.Ä°yi Ã§alÄ±ÅŸmalar ...",
    
### soru 

> quest: "Merhaba epoch batch size ve iteration kavramlarÄ±nÄ± kafamda pek oturtamadÄ±m bunlarÄ± biz neden kullanÄ±yoruz?",

> comments:
  
1. ->  iteration: yineleme demek ya TÃ¼rkÃ§esi ordan bakarsak olaya, modelin bir kere iÅŸlemesi (tabi diÄŸer deÄŸiÅŸkenlere gÃ¶re) 1 iteration oluyor anladÄ±ÄŸÄ±m kadarÄ±yla. Batch size ise kaÃ§ Ã¶rnekte bir iteration yani modeli baÅŸtan Ã§alÄ±ÅŸtÄ±racak onun sayÄ±sÄ±. Ã–rneÄŸin 12 Ã¶rnekli bir datasetinde batch size 6 ise burdaki 1 epoch ta 2 yineleme (iteration) olacak demektir. Bilmem anlatabildim mi? ğŸ™‚.",
2. -> Batch size: Bir kerede iÅŸlenen veri sayÄ±sÄ±.Iteration: TÃ¼m verileri iÅŸlemek iÃ§in gereken batch size sayÄ±sÄ±.Epoch: TÃ¼m verisetinin iyileÅŸtirme aÅŸamasÄ±ndan kaÃ§ kez geÃ§irileceÄŸi.Ä°terasyonlarÄ± oluÅŸturma yani batch size ayarlama sebebimiz tÃ¼m verilerin aynÄ± anda iÅŸlenmesinin maliyetli olmasÄ± ve daha uzun zaman almasÄ±. Ã‡ok fazla epoch olmasÄ± durumunda hem eÄŸitim sÃ¼resi Ã§ok uzuyoor hem de overfitting sorunu baÅŸ gÃ¶steriyor.AnladÄ±klarÄ±mÄ± kabaca bir senaryoya dÃ¶keyim. 10.000 verimiz var ve batch size 200, tÃ¼m bu verileri iÅŸlemek iÃ§in 50 iterasyona ihtiyacÄ±mÄ±z var. 1.epochun 1.iterasyonunda 200 veri geliyor modelimizin ilk parametrelerini oluÅŸturuyoruz. Ve cost functiona sokarak kaybÄ± hesaplÄ±yor. 2.iterasyonda ise bu kayÄ±p deÄŸerini azaltmak iÃ§in parametrelerde deÄŸiÅŸiklikler yapÄ±yor yeniden cost functiona sokarak kaybÄ± hesaplÄ±yor. 1.epoch sonunda tÃ¼m verileri iÅŸleyerek elde ettiÄŸimiz bir modele sahip oluyoruz. 2.epochta amaÃ§ yine tÃ¼m verileri iterasyonlara bÃ¶lerek yeniden iÅŸleyerek modeli daha da iyleÅŸtirmek..",
3. ->  EÄŸitmenlerimizden senaryonun doÄŸruluÄŸu hakkÄ±nda onay almak gÃ¼zel olacaktÄ±r ğŸ™‚.",
4. ->  1000 verimizin olduÄŸunu dÃ¼ÅŸÃ¼nelim. Modele vereceÄŸimiz her BÄ°R veri \"iterasyon\"dur.TÃ¼m iterasyonlar tamamlandÄ±ÄŸÄ±nda yani 1000 verimiz tamamen modele verilip, loss deÄŸerlerinin hesaplanmasÄ±, BÄ°R \"epoch\"tur.Batch-size ise bu loss deÄŸerlerimizin iÅŸleme alÄ±nÄ±p, aÄŸÄ±rlÄ±klarÄ±n gÃ¼ncellemesinin sÄ±klÄ±ÄŸÄ±nÄ± ifade eder.Yani Batch-size =100 yaparsak; her 100 iterasyonda (her 100 verinin iÅŸlenmesinde) modelin aÄŸÄ±rlÄ±klarÄ± gÃ¼ncellenecektir.",
5. ->  ->  SanÄ±rÄ±m iteration tam olarak bu deÄŸil. AnladÄ±ÄŸÄ±m kadarÄ±yla iteration parametre gÃ¼ncellemesi anlamÄ±na geliyor. Yani her weight update bir iteration'dÄ±r diyebiliriz. Bu durumda eÄŸer 1000 sample varsa eÄŸer SGD iÃ§in iteration sayÄ±mÄ±z bir epoch iÃ§in 1000 olacaktÄ±r ama mini-batch(batch-size=100) tercih edersek bu kez bir epoch iÃ§in iteration sayÄ±mÄ±z 10 olacaktÄ±r..",
6. ->  ->  HaklÄ±sÄ±n. Yinelemenin tam tanÄ±mÄ±nÄ± ÅŸÃ¶ylede dÃ¼ÅŸÃ¼nebiliriz; \"Yineleme, bir epoch tamamlamak iÃ§in gereken batch sayÄ±sÄ±dÄ±r\". BÃ¶ylelikle 1 epoch yani toplamda 1000 veriyi 100'er veri iÃ§eren partilerle tamamlamak iÃ§in 10 yineleme yapmamÄ±z gerektiÄŸi ortaya Ã§Ä±kÄ±yor..",
7. ->  ->  \"iterasyon\" dÃ¼zeltmesi iÃ§in teÅŸekkÃ¼rler. Ben de ÅŸunu dÃ¼zelteyim Ã¶rneÄŸinizde; SGD random seÃ§tiÄŸi bir Ã¶rnek Ã¼zerinden gÃ¼ncelleme yapar. Yani 1000 Ã¶rneÄŸimiz iÃ§in bir epochta 1 gÃ¼ncelleme olur, \"iterasyon\" sayÄ±mÄ±z da 1 oluyor haliyle. EÄŸer GD yapsaydÄ±k o zaman 1000 Ã¶rnek iÃ§in bir epochta 1000 gÃ¼ncelleme olacaÄŸÄ±ndan, \"iterasyon\" sayÄ±mÄ±z da 1000 olacaktÄ±r. KÄ±saca GD-SGD farkÄ±na deÄŸinmek istedim ????.",
8. ->  teÅŸekkÃ¼rler.",
9. -> ArkadaÅŸlar merhaba,Burada kÃ¼Ã§Ã¼k bir karÄ±ÅŸÄ±klÄ±k sezdim, onun iÃ§in ek bir aÃ§Ä±klama yapmak istiyorum :)Ä°terasyon dediÄŸimiz ÅŸey iÅŸlem sayÄ±sÄ±dÄ±r, ML konularÄ±nda bu iÅŸlem weight update'dir. Yani modelimizde bulunan weight ve bias'Ä±n kaÃ§ kere gÃ¼ncellendiÄŸidir.Epoch, modelinizin tÃ¼m data ile kaÃ§ kere eÄŸitileceÄŸidir. EÄŸer elinizde 10.000 adet veriniz varsa, modeliniz bir epoch sonunda tÃ¼m datayÄ± gÃ¶rmÃ¼ÅŸ olur.Batch ise Ã§ok yÃ¼ksek sayÄ±da veriyi aynÄ± anda modele vermemek ve bu sayede oluÅŸabilecek memory sorunlarÄ±na Ã¶nlem olarak kullanÄ±lan, bir iterasyonda kullanacaÄŸÄ±nÄ±z veri miktarÄ±dÄ±r. Ã–rneÄŸin batch_size 1000 alÄ±nÄ±rsa, 10.000 adet verinin iÃ§inden 1000 adet veri alÄ±nÄ±r, 1 kez weight update yapÄ±lÄ±r, ardÄ±ndan diÄŸer veriler 1000er 1000er modele verilir ve her biri ile yine weight update yapÄ±lÄ±r. 10.000 verinin tamamÄ± verildiÄŸinde 1 epoch tamamlanmÄ±ÅŸ ve veriniz 10 kere gÃ¼ncellenmiÅŸ olur..",
    
### soru 

> quest: "Validation test kÄ±smÄ±ndaki check your intuition bÃ¶lÃ¼mÃ¼nÃ¼ tam anlayamadÄ±m.ÅÃ¶yle anladÄ±m,modeli eÄŸitim setiyle eÄŸiticez bu eÄŸitim kÄ±smÄ±nda hiperparametreleri dÃ¼zenleyeceÄŸiz.En son test setiyle deÄŸerlendireceÄŸiz.Yani her iterasyonda eÄŸitim olur ama test en sonda olur.DoÄŸru mu anladÄ±m?",

> comments:
  
1. ->  Benim anladÄ±ÄŸÄ±m kadarÄ±yla ÅŸÃ¶yle bir ÅŸeyden bahsediyor orada -ki cevapla da Ã¶rtÃ¼ÅŸÃ¼yor-- Bir training set ve bir test set var elimizde,- Her bir Ã§evrimde Ã¶nce train edip sonra test sete uyumuna bakÄ±yor,- Haliyle aslÄ±nda test setini de bir bakÄ±ma training set olarak kullanÄ±yor ve overfitting oluÅŸuyor..",
2. ->  Merhabalar, KÄ±saca Ã¶zetleyecek olursam, umarÄ±m yanlÄ±ÅŸ anlamamÄ±ÅŸÄ±mdÄ±r :)Ana baÅŸlÄ±ÄŸa gÃ¶re:Modelimizi her bir iterasyonda eÄŸitiyoruz ve her eÄŸitimin sonunda test setimiz ile Ã¶lÃ§Ã¼mlerimizi yapÄ±yoruz. Elde ettiÄŸimiz sonuÃ§lara gÃ¶re parametrelerimizde deÄŸiÅŸiklik yapÄ±p yapmayacaÄŸÄ±mÄ±za karar veriyoruz.Burada ki problemimiz: Her bir iterasyonda test setimizi bir Ã¶lÃ§Ã¼m seti olarak kullandÄ±ÄŸÄ±mÄ±z iÃ§in, modelimizin test setinde oluÅŸabilecek garipliklere uyum saÄŸlayarak bizi aldatabilecek sonuÃ§lar elde etmemize sebep olabilmekte.Bu sebepten Ã¶tÃ¼rÃ¼ de setimizi 3'e bÃ¶lerek bir de validation_set oluÅŸturuyoruz. BÃ¶ylece BÃ¼tÃ¼n eÄŸitim sonunda elde ettiÄŸimiz modelimizi test seti ile gÃ¶zlemleyerek modelimizin validation_set'imize aÅŸÄ±rÄ± uyum saÄŸlayÄ±p saÄŸlamadÄ±ÄŸÄ±nÄ± gÃ¶zlemleyebilmekteyiz.Ä°yi Ã§alÄ±ÅŸmalar.",
3. ->  eÄŸitim setiyle belirlediÄŸimiz en uygun parametreleri test setinde tahmin edeceÄŸiz diye biliyorum..",
4. -> Merhaba, benim anladÄ±ÄŸÄ±m kadarÄ±yla amaÃ§ overfitting'i azaltmak ve modelin kalitesini deÄŸerlendirmek. Bu nedenle Ã¶nce training setin bir kÄ±smÄ±nÄ± split ederek validation_set'i oluÅŸturuyor. EÄŸitim aÅŸamasÄ±ndan sonra sonuÃ§larÄ± deÄŸerlendirmek iÃ§in doÄŸrulama setini kullanÄ±yor, doÄŸrulama bittikten sonra test seti Ã¼zerinde test ediyor..",
5. ->  EÄŸitim verisetini eÄŸittiÄŸimizde model kendi baÅŸÄ±na overfitting oluÅŸtururken, test seti iÅŸin iÃ§ine girdiÄŸinde, test setinde kaybÄ± dÃ¼ÅŸÃ¼rmek iÃ§in yaptÄ±ÄŸÄ±mÄ±z mÃ¼dahaleler sonucunda overfitting oluÅŸuyor diye dÃ¼ÅŸÃ¼nÃ¼yorum. YanlÄ±ÅŸ mÄ± dÃ¼ÅŸÃ¼nÃ¼yorum acaba?.",
6. ->  Merhaba, modelimiz eÄŸitilirken her bir Ã§evrimde test seti ile karÅŸÄ±laÅŸtÄ±rma yapÄ±lÄ±yor. Burdan Loss alÄ±nÄ±p model eÄŸitiliyor. Bu durumda test setindeki veriler eÄŸitimde kullanÄ±lmÄ±ÅŸ oluyor. Daha sonra test aÅŸamasÄ±nda bu deÄŸerler eÄŸitimde kullanÄ±ldÄ±ÄŸÄ±ndan dolayÄ± overfitting ihtimali artÄ±yor. Bu nedenle eÄŸitim verilerimizi eÄŸitim ve validation olarak ikiye bÃ¶lÃ¼yoruz. ArtÄ±k modelimiz eÄŸitilirken validasyon datalarÄ± ile karÅŸÄ±laÅŸtÄ±rma yapÄ±yor. BÃ¶ylece test aÅŸamasÄ±nda test datalarÄ±mÄ±z eÄŸitimde kullanÄ±lmadÄ±ÄŸÄ± iÃ§in daha Ã¶nce karÅŸÄ±laÅŸmadÄ±ÄŸÄ± datalarla modeli test etmiÅŸ oluyoruz. Hem overfitting azalÄ±yor hem de daha doÄŸru bir test yapmÄ±ÅŸ oluyoruz diye anladÄ±m ben. YanlÄ±ÅŸÄ±m varsa mentÃ¶r hocalarÄ±mÄ±z dÃ¼zeltsinler lÃ¼tfen. Ä°yi Ã§alÄ±ÅŸmalar dilerim.",
7. ->  ->  Merhaba, buradan anladÄ±ÄŸÄ±m kadarÄ±yla ilk baÅŸta eÄŸitim setimizi eÄŸitim ve validation set olarak ayÄ±rÄ±yoruz. Modelimizi eÄŸitim seti ile eÄŸitip validation datalarÄ± ile karÅŸÄ±laÅŸtÄ±rma yapÄ±yoruz. Validation datalarÄ±mÄ±z ile karÅŸÄ±laÅŸtÄ±rma yaparken modelimizin daha doÄŸru Ã§alÄ±ÅŸmasÄ± iÃ§in parametrelerimizi en doÄŸru sonuca ulaÅŸana kadar tekrar tekrar deÄŸiÅŸtirip validation datalarÄ±mÄ±z ile test ediyoruz (Bu kÄ±sÄ±m doÄŸru mudur?). En sonunda da test datalarÄ±mÄ±zÄ± modelimizde kullanÄ±p karÅŸÄ±laÅŸtÄ±rma yapÄ±yoruz. Ã–zet olarak sormak istediÄŸim eÄŸitim setimizi bÃ¶ldÃ¼kten sonra modelimizi eÄŸitim setiyle eÄŸitip en uygun sonuca ulaÅŸana kadar parametreleri deÄŸiÅŸtirip tekrar tekrar validation datalarÄ±mÄ±z ile mi karÅŸÄ±laÅŸtÄ±rÄ±yorz? YanlÄ±ÅŸ anlamÄ±ÅŸ olabilirim dÃ¼zeltebilirseniz sevinirim. TeÅŸekkÃ¼r ederim..",
8. ->   ->  ben de sizin gibi dÃ¼ÅŸÃ¼nÃ¼yorum. Ancak kursta Ã¶ÄŸrenciyim yanlÄ±ÅŸ bir bilgi verip kafa karÄ±ÅŸtÄ±rmak istemiyorum. AÅŸaÄŸÄ±da paylaÅŸtÄ±ÄŸÄ±m linkte validation set kÄ±smÄ±ndaki aÃ§Ä±klama ile de Ã¶rtÃ¼ÅŸÃ¼yor dediklerimiz. Ek olarak eÄŸer validation set olmasa bu iÅŸlemde test seti kullanÄ±lacak. BÃ¶ylece modelimiz test setindeki verilerle Ã§alÄ±ÅŸmÄ±ÅŸ olacak. Modeli en son test ettiÄŸimizde modelin daha Ã¶nce gÃ¶rmediÄŸi verilerle test etmemiz bize daha doÄŸru sonuÃ§lar verecektir. Bir yanlÄ±ÅŸlÄ±k varsa mentÃ¶r hocalarÄ±mÄ±z yardÄ±m etsinler lÃ¼tfen. Ä°yi Ã§alÄ±ÅŸmalar dilerim.["About Train, Validation and Test Sets in Machine](https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7)
9. ->  ->  TeÅŸekkÃ¼r ederim bilgiler iÃ§in. Ä°yi Ã§alÄ±ÅŸmalar..",
10. ->  Modelimizi training data Ã¼zerinden eÄŸitirken test ile de modelin genelleme yeteneÄŸini ve ne kadar iyi Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± test ediyoruz. Ancak burada ÅŸundan bahsetmiÅŸ, peki train datasÄ± Ã¼zerinde eÄŸitim yaparken test sonuÃ§larÄ±na bakarak learning rate gibi parametreleri daha iyi bir model oluÅŸturmak iÃ§in deÄŸiÅŸtirebilir miyiz? Cevap olarak ise bu da test datasÄ±nda iyi bir sonuÃ§ alÄ±nabilir ama bu seferde seÃ§ilen test verilerine Ã¶zgÃ¼ bir modelleme olur ve genelleme yeteneÄŸi dÃ¼ÅŸÃ¼k olur..",
    
### soru 

> quest: "Merhaba, Generalization kÄ±smÄ±nda ki ML Fine Print altÄ±nda anlatÄ±lanÄ± anlayamadÄ±m.Tam olarak ne demek istiyor acaba?  TeÅŸekkÃ¼rler",

> comments:
  
1. -> Merhaba,Burada Generalization yani modelimizin daha Ã¶nce gÃ¶rÃ¼lmemiÅŸ bir veriyi tahmin etme yeteneÄŸine rehberlik ve etki eden 3 varsayÄ±mdan bahsetmiÅŸ:1.(Independently and Identically): Burada verilerinizi random olarak almanÄ±z gerektiÄŸinden bahsediyor. Ã–rneÄŸin elinizde insanlarÄ±n yaÅŸ, boy, kilo, cinsiyet ve Ã¼lke bilgilerini iÃ§eren bir veriseti var. Burada Ã¼lke sizin labelÄ±nÄ±z, diÄŸer alanlar ise featurelarÄ±nÄ±z olsun. EÄŸer verisetinizi eÄŸitime sokarken random olarak almazsanÄ±z eÄŸitim-test bÃ¶lme iÅŸleminde eÄŸitim verisinde sadece tek bir Ã¼lkeye ait veriler gelmiÅŸ olabilir. (Ã–rneÄŸin elinizde TR-US-FR Ã¼lkeleri olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼n. EÄŸitim setinde sadece TR verileri olursa modelimiz FR ve US verilerini tahmin etmekte efektif Ã§alÄ±ÅŸmayacaktÄ±r.)2. (Stationary): Burada da verilerimizin daÄŸÄ±tÄ±mÄ±nÄ±n sabit olduÄŸundan bahseder. Ã–rneÄŸin verisetinizde bir ÅŸemsiye ÅŸirketinin satÄ±ÅŸ listesi olsun. Åemsiye satÄ±ÅŸlarÄ± mevsimsel olarak farklÄ±lÄ±k gÃ¶stereceÄŸinden bu daÄŸÄ±tÄ±m sabitliÄŸini ihlal eder.3. Bu kÄ±smÄ± tam anlayamamakla birlikte anladÄ±ÄŸÄ±m kadarÄ±yla Ã¶rneklerimizi aynÄ± daÄŸÄ±tÄ±mÄ±n iÃ§indeki bÃ¶lÃ¼mlerden Ã§iziyoruz bunu nedeni test ve eÄŸitim verilerimizi birbirinden farklÄ± distributionlarda olursa test loss'umuzun fazla olacaÄŸÄ± yani tahminleri doÄŸru yapamayacaÄŸÄ±dÄ±r.Ä°yi Ã§alÄ±ÅŸmalar.",
2. ->  ->  3. KÄ±sÄ±m DaÄŸÄ±lÄ±mlarÄ±n aynÄ± olmasÄ±n bahsetmektedir. Ã‡Ã¼nkÃ¼ daÄŸÄ±lÄ±mÄ±n deÄŸiÅŸmesi ile verinin karakteristiÄŸi deÄŸiÅŸir, ve elinde iki farklÄ± veri seti olmuÅŸ olur. (Her daÄŸÄ±lÄ±mÄ±n kendisine has olan Ã§Ã¶zÃ¼m yÃ¶netim vardÄ±r.) Bu durumda biri ile eÄŸitim yaparak diÄŸeri ile test etmen saÄŸlÄ±klÄ± sonuÃ§lar vermeyecektir.,
3. ->  ->  AÃ§Ä±klama iÃ§in teÅŸekkÃ¼r ederim ğŸ™‚ Ä°yi Ã§alÄ±ÅŸmalar dilerim..",
4. -> ->  Stationary'den kastÄ±mÄ±z verinin ortalamasÄ±nÄ±n, varyansÄ±nÄ±n ve kovaryansÄ±nÄ±n sabit olmasÄ± deÄŸil midir?.",
5. ->  -> Evet, ortalama, kovasyans ve varyans deÄŸerleri Stationary'de sabittir. Bu konu ile alakalÄ± [Link](http://people.duke.edu/~rnau/411diff.htm) linkinde yazÄ±lmÄ±ÅŸ Ã§ok gÃ¼zel bir yazÄ± mevcut, okumanÄ±zÄ± tavsiye ederim ğŸ™‚.",
6. ->  Ã‡ok teÅŸekkÃ¼rler ÅŸimdi daha iyi anladÄ±m:).",
    
### soru 

> quest: "Merhabalar. BazÄ± terimleri TÃ¼rkÃ§e nasÄ±l aÃ§Ä±klayacaÄŸÄ±mÄ± bulamÄ±yorum. Ã–rneÄŸin tuning ve fit ifadelerinin bu iÅŸin iÃ§inde Ã§alÄ±ÅŸanlar nasÄ±l TÃ¼rkÃ§eleÅŸtiriyor? Fit iÃ§in \"uydurma\" Tuning iÃ§in \"ayarlama\" ifadesini kullanmak anlamÄ±nÄ±n kaybolmasÄ±na yol aÃ§Ä±yormuÅŸ gibi geliyor. Mediumda yazÄ± yazmak gibi bir hedefim var. Ã–ÄŸrendiklerimi en iyi ÅŸekilde aÃ§Ä±klamak istiyorum.  Bir de \"offset\" tam olarak nedir?",

> comments:
  
1. ->  tuning final modeli oluyor fit etmek train verilerini eÄŸitmek oluyor diye biliyorum..",
2. ->  Bence her ÅŸeyi TÃ¼rkÃ§e olarak yazmak zorunda deÄŸilsiniz. EÄŸer kelimeyi TÃ¼rkÃ§e yazdÄ±ÄŸÄ±nÄ±zda daha zor anlaÅŸÄ±lacaksa, TÃ¼rkÃ§e yazmaya Ã§alÄ±ÅŸmanÄ±n Ã§ok da bir anlamÄ± yok. BazÄ± kavramlar oturmuÅŸ ve sÃ¼rekli Ä°ngilizce karÅŸÄ±lÄ±klarÄ± karÅŸÄ±mÄ±za Ã§Ä±kÄ±yor. AyrÄ±ca bazÄ± kelimelerin de tam karÅŸÄ±lÄ±klarÄ± yok. Tabii bu konuda net bir doÄŸru yok, dilimize oturmasÄ± iÃ§in sÃ¼rekli TÃ¼rkÃ§e yazÄ±lmasÄ± daha iyi olur diyenler de olabilir. En azÄ±ndan 2020 yÄ±lÄ±nda tamamen TÃ¼rkÃ§e iÃ§erik yazmak zor olabilir ğŸ™‚ Belki 10 yÄ±l sonra dilimizde tam karÅŸÄ±lÄ±klarÄ± olur ve insanlar TÃ¼rkÃ§e olarak bu kavramlara aÅŸina olur.",
3. ->  ->  AnladÄ±m. O zaman olduÄŸu gibi kullanmak dediÄŸiniz gibi en mantÄ±klÄ±sÄ± olacaktÄ±r. TeÅŸekkÃ¼rler..",
4. ->  [Link](https://github.com/deeplearningturkiye/turkce-yapay-zeka-terimleri/blob/master/ingilizce-turkce.md) BurayÄ± kullanabilirsin. Ethem AlpaydÄ±n Yapay Ã–ÄŸrenme kitabÄ±nda kullandÄ±ÄŸÄ± TÃ¼rkÃ§e karÅŸÄ±lÄ±klar oldukÃ§a deÄŸerli. TÃ¼rkÃ§e anlaÅŸabilmemiz bu kavramlarÄ± TÃ¼rkÃ§eleÅŸtirebilmenin her bilim dalÄ±nda olduÄŸu gibi Ã§ok Ã¶nemli olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yorum. Ian Goodfellow, Yoshua Bengio ve Aaron Courville'nin Deep Learning kitabÄ±nÄ±n BuzdaÄŸÄ± YayÄ±nevinden Ã§Ä±kan Ã§evirisinde Ã§eviri ekibinin kullandÄ±ÄŸÄ± terimleri de mutlaka kullanmalÄ±..",
5. ->  ->  DediÄŸiniz kaynaÄŸa bakÄ±yorum kafama takÄ±lan bir ÅŸey olunca. Ama fit yerine \"uydurma\" kelimesini kullanmak biraz zorlama gibi durduÄŸu iÃ§in acaba kullanÄ±lÄ±yor mu diye Ã¶ÄŸrenmek istemiÅŸtim. TeÅŸekkÃ¼r ederim..",
6. ->  Ben de TÃ¼rkÃ§e kullanmaya gayret eden biriyim. EÄŸer TÃ¼rkÃ§e karÅŸÄ±lÄ±k olarak tam ifade eden kelime yoksa Ä°ngilizce kullanmakta sakÄ±nca olmayacaktÄ±r. Bu durumu da yazÄ±nÄ±zÄ±n sonunda bir dipnot ÅŸeklinde belirtebilirsiniz yazarlar genelde Ã¶yle yapÄ±yor",
7. ->  ->  DediÄŸiniz gibi mini bir sÃ¶zlÃ¼k eklemeyi dÃ¼ÅŸÃ¼nÃ¼yorum yazdÄ±ÄŸÄ±mda. TeÅŸekkÃ¼r ederim..",
8. ->  Fit kelimesinin karÅŸÄ±lÄ±ÄŸÄ± olarak uyarlama kullanÄ±labilir..",
    
### soru 

> quest: "Merhaba, Scale iÅŸleminin tam olarak ne yaptÄ±ÄŸÄ±nÄ± anlayamadÄ±m. Biraz basit bir soru oldu galiba, Ã¶zÃ¼r dilerim.",

> comments:
  
1. ->  Scale iÅŸlemi genelde verileri yorumlamayÄ± kolaylaÅŸtÄ±rÄ±yor. Ã–rneÄŸin nÃ¼fusun yaÅŸa gÃ¶re daÄŸÄ±lÄ±m verilerimiz var. 25 yaÅŸ birey sayÄ±sÄ±nÄ± toplam sayÄ±ya bÃ¶lerek 0 ve 1 arasÄ±na yani olasÄ±lÄ±ksal yorumlanmasÄ± iÃ§in gerekli aralÄ±ÄŸa dÃ¼ÅŸÃ¼rmÃ¼ÅŸ oluyoruz. Ã–te yandan grafik Ã§izerken bazÄ± deÄŸerlerin 100000 lerde olduÄŸunu (Ã¶rneÄŸin ev fiyatÄ±) bazÄ±larÄ±nÄ±n ise 10 lardan daha kÃ¼Ã§Ã¼k olduÄŸunu (Ã¶rneÄŸin oda sayÄ±sÄ±) dÃ¼ÅŸÃ¼n. GÃ¶rselleÅŸirmek zor olacaktÄ±r. EÄŸitmenlerimizden gerekli dÃ¼zeltmeleri bekliyorum.",
2. -> Andrew NG de bu ÅŸekilde aÃ§Ä±klÄ±yor. Ã–zetleyecek olursak convex ÅŸeklin daha dÃ¼zgÃ¼n oluÅŸmasÄ± iÃ§in scaling yapÄ±yoruz. Daha dÃ¼zgÃ¼n oluÅŸmasÄ± ise ÅŸekilde gÃ¶rÃ¼ldÃ¼ÄŸÃ¼ Ã¼zere daha az ve doÄŸru yÃ¶nden sapmayan adÄ±mlarla global minimuma ulaÅŸmamÄ±zÄ± saÄŸlar..",
" -> Yani anladÄ±ÄŸÄ±m kadarÄ±yla, kÄ±yasÄ±n daha doÄŸru yapÄ±labilmesi iÃ§in, deÄŸeri belirli bir sayÄ±yla Ã§arpÄ±yor veya bÃ¶lÃ¼yoruz. BÃ¶ylece gÃ¶rselleÅŸtirme olsun, bizim modelin gidiÅŸatÄ±nÄ± anlamamÄ±z olsun bu konularda yararlÄ± oluyor..",
3. ->   -> Aynen Ã¶yle..",
4. -> ->  Ã‡ok teÅŸekkÃ¼r ederim..",
5. ->   -> evet Ã¶lÃ§eklendirme yapÄ±yoruz..",
6. ->  Verilerimizi Ã¶lÃ§eklememiz featurelar arasÄ±ndaki uÃ§urumu azaltacaktÄ±r. Andrew Ng'den alÄ±nan -> 'Ä±n paylaÅŸatÄ±ÄŸÄ± grafiÄŸe bakarsanÄ±z elimizde ev boyutu ve evdeki lavabo sayÄ±sÄ± adlÄ± featurelarÄ±mÄ±z var. Bu featurelarÄ±n deÄŸer aralÄ±klarÄ± ev boyutu iÃ§in (0-2000), lavabo asyÄ±sÄ± iÃ§in (1-5). Bu deÄŸer aralÄ±klarÄ±nÄ±n Ã§ok farklÄ± olmasÄ± gradient descent fonksiyonumuzun yavaÅŸ Ã§alÄ±ÅŸmasÄ±na neden olacaktÄ±r Ã§Ã¼nkÃ¼ resimdeki soldaki garafiÄŸimizde optimum deÄŸer olan en iÃ§ deÄŸere yaklaÅŸmasÄ± uzun sÃ¼recektir. Bu problemi Ã§Ã¶zmek iÃ§in feature scaling yapabilirsiniz. Feature scaling aslÄ±nda tÃ¼m featurelarÄ±nÄ±zÄ±n belli bir deÄŸer aralÄ±ÄŸÄ±na alÄ±nmasÄ±dÄ±r. En optimum deÄŸer aralÄ±ÄŸÄ± diye bir ÅŸey yoktur ama olabilrdiÄŸinde birbrine yakÄ±n kÃ¼Ã§Ã¼k deÄŸerler arasÄ±na alÄ±nmaya Ã§alÄ±ÅŸÄ±labilir. Ã–rneÄŸin -1About Feature Scaling and Normalizationsebastianraschka.comSections",
7. ->  ArkadaÅŸlarÄ±n teknik olarak aÃ§Ä±klamasÄ±nÄ±n yanÄ±nda bana hitap eden kÄ±smÄ± ÅŸÃ¶yle. GÃ¶rselleÅŸtirme ve grafiklerde Ã§ok bÃ¼yÃ¼k rakamlar bu mantÄ±kla bin ya da milyon Ã¶lÃ§eÄŸinde gÃ¶sterilir ki veri okumasÄ± kolay olsun, gÃ¶rsel Ã§irkin gÃ¶zÃ¼kmesin. En basit haliyle model yazmaya baÅŸlamadan Ã¶nce define gibi komutlarla veriye genel bir bakÄ±ÅŸ aÃ§Ä±sÄ± ile baktÄ±ÄŸÄ±nÄ±zda, her bir feature milyon seviyesinde olursa okumasÄ± bakan kiÅŸiyi yoracaktÄ±r ve tek bir sayfaya sÄ±ÄŸmasÄ±nÄ± zorlaÅŸtÄ±racaktÄ±r. Veri Biliminde en Ã¶nemli ÅŸeylerden birisinin de kodunuzun okunabilir olmasÄ±. Ã‡alÄ±ÅŸmanÄ±za bakan diÄŸer insanlarÄ± dÃ¼ÅŸÃ¼nerek en sade ve yalÄ±n ÅŸekilde olmasÄ± Ã¶nemli. Bu nedenle tekniÄŸin de Ã¶tesinde bu sebeplerle Ã¶lÃ§eklendirme Ã¶nemli bence..",
8. ->  Verileri aynÄ± dÃ¼nyaya indirgeme iÅŸlemidir. BÃ¶ylece modelimiz daha iyi ve hÄ±zlÄ± Ã¶ÄŸrenir. Yapay zeka da yÄ±ÄŸÄ±n normalizasyonu denilen iÅŸlem vardÄ±r. Veriler bir sonraki katamana gÃ¶nderilmeden Ã¶nce aÃ§Ä±k bir ÅŸekilde normalize edilir. Ã‡Ã¼nkÃ¼ sonraki katman, daha Ã¶nce bu katmana gÃ¶nderilen daÄŸÄ±lÄ±ma benzeyen bir veri yÄ±ÄŸÄ±nÄ± beklemektedir..",
9. ->  Scale yani Ã¶lÃ§eklendirme iÅŸlemi biraz daha okunaklÄ± hale getirmek iÃ§in kullanÄ±lmÄ±ÅŸ. Yani 1000 e bÃ¶lÃ¼yor ev fiyatlarÄ±nÄ± daha okunaklÄ± bir deÄŸer ortaya Ã§Ä±kÄ±yor. \"/=\" ifadesi zaten pythonda aynÄ± deÄŸeri yani median_house_value deÄŸerlerini 1000 e bÃ¶l ve tekrar eÅŸitle anlamÄ±nda..",
    
### soru 

> quest: "Merhabalar, teorik olarak anladÄ±ÄŸÄ±mÄ± dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼m ÅŸeylerin Playground Exercise lar esnasÄ±nda yerine oturmadÄ±ÄŸÄ±nÄ± fark ediyorum. Ã–rneÄŸin Training and Test Sets: Playground Exercise kÄ±smÄ±nda taskleri yerine getirip, gÃ¶zlem yapsam da bazÄ± neden sonuÃ§ iliÅŸkilerini kuramÄ±yorum. Task 2 ve 3 teki  \"Is the delta between Test loss and Training loss lower or higher with this new Learning rate? What happens if you modify both Learning rate and batch size?\" ve \"Does altering the training data percentage change the optimal learning settings that you discovered in Task 2? If so, why?\" sorularÄ±nÄ±n cevaplayamadÄ±m.  YardÄ±mcÄ± olabilirseniz sevinirim ve aynÄ± zamanda kafamda daha iyi oturtabilmek adÄ±na gelebilecek tavsiyelere de aÃ§Ä±ÄŸÄ±m. TeÅŸekkÃ¼rler.",

> comments:
  
1. -> Task 1â€™de modeli eÄŸittiÄŸimizde overfitting(test loss >> training loss) olduÄŸunu gÃ¶rÃ¼yoruz. Yani modelimiz eÄŸitim verilerine Ã§ok iyi uyuyor, ancak yeni bir veri geldiÄŸinde veriyi doÄŸru ÅŸekilde genelleÅŸtiremiyor.Task 2â€™de learning rateâ€™i azalttÄ±ÄŸÄ±mÄ±zda, test loss deÄŸerinin training loss deÄŸerine yaklaÅŸtÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼yoruz. Batch sizeâ€™Ä± arttÄ±rdÄ±ÄŸÄ±mÄ±zda, test loss deÄŸerinin traning loss deÄŸerinin birazcÄ±k altÄ±na dÃ¼ÅŸtÃ¼ÄŸÃ¼nÃ¼ gÃ¶rÃ¼yoruz. Peki bunu niye yapÄ±yoruz? AmaÃ§ burda perfect fittingâ€™i(test loss ~ training loss) yakalamak. Yani her iki deÄŸerin de kabaca aynÄ± veya birbirine yakÄ±n deÄŸerler olmasÄ±nÄ± istiyoruz. Task 3â€™te ise training data percentage oranÄ±nÄ± %10 olarak ayarladÄ±ÄŸÄ±mÄ±zda, verilerin %10â€™u training set iÃ§in, kalan %90â€™Ä± test set iÃ§in kullanÄ±lÄ±yor. Training setindeki veri yÃ¼zdesini bu kadar azaltmak veri noktalarÄ±nÄ±n sayÄ±sÄ±nÄ± bÃ¼yÃ¼k bir oranda azaltÄ±yor. Ã‡Ã¼nkÃ¼ eskiye gÃ¶re daha az veriyle eÄŸitim saÄŸlamÄ±ÅŸ oluyoruz. Learning rate ve batch sizeâ€™a yÃ¼ksek bir deÄŸer verdiÄŸimizde, eÄŸitim modelindeki dÃ¼zensiz atlamalarÄ± gÃ¶rÃ¼yoruz. Loss curve deki minimum pointe asla ulaÅŸamÄ±yor, tekrar tekrar Ã¼stÃ¼nden atlÄ±yor. Ä°yi bir model iÃ§in yeterli Ã¶lÃ§Ã¼deki bir training sete ihtiyacÄ±mÄ±z var. Ben Ã¶ÄŸrendiklerimle bu ÅŸekilde yorumladÄ±m, yanlÄ±ÅŸÄ±m varsa arkadaÅŸlar dÃ¼zeltirse sevinirim.", 
2. ->  ->  SanÄ±rÄ±m Task1'de overfitting gerÃ§ekleÅŸmiyor aksine learning rate Ã§ok yÃ¼ksek olduÄŸu iÃ§in modelimiz training loss'u yeterince dÃ¼ÅŸÃ¼remiyor yani yeterince iyi Ã¶ÄŸrenemiyor ve bu da delta'nÄ±n (test loss - training loss) yÃ¼ksek olmasÄ±na sebep oluyor Ã§Ã¼nkÃ¼ iyi Ã¶ÄŸrenememesi sebebiyle yeni gelen test datasÄ±nda iyi tahmin gerÃ§ekleÅŸtiremiyor. Yani Ã§ok iyi Ã¶ÄŸrendiÄŸi(overfit) iÃ§in deÄŸil yeterince iyi Ã¶ÄŸrenemediÄŸi iÃ§in (test loss >> training loss).",
3. ->  ->  DÃ¼zelttiÄŸiniz iÃ§in teÅŸekkÃ¼r ederim, ben de doÄŸrusunu Ã¶ÄŸrenmiÅŸ oldum bÃ¶ylece..",
4. ->  TeÅŸekkÃ¼r ederim ÅŸimdi daha iyi anladÄ±m..",
    
### soru 

> quest: "Merhabalar. Ã–ncelikle yardÄ±mlarÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederim. SorularÄ±mÄ± Ã§alÄ±ÅŸmam bittikten sonra teker teker sormak istedim. Gradient Descent optimizasyonunu Ã¶nceden tek seferde sÃ¼rekli yineleme yaparak optimum deÄŸerleri buluyor gibi dÃ¼ÅŸÃ¼nÃ¼yordum. Ama epoch kavramÄ± iÅŸin iÃ§ine girdi ve kafam biraz karÄ±ÅŸtÄ±. Tek veya birden fazla epoch arasÄ±nda ne fark var anlayamadÄ±m. Batch_size olarak verileri rastgele almadÄ±ÄŸÄ±mÄ±zÄ±, tÃ¼m veriseti aldÄ±ÄŸÄ±mÄ±zÄ± dÃ¼ÅŸÃ¼nÃ¼rsek sÃ¼rekli aynÄ± sonucu Ã¼retmez mi? Epochlarda ne oluyor ki deÄŸerlerimizi sÃ¼rekli optimize edebiliyoruz? Bir de diyelim ki her epochda ikiÅŸer iterasyonumuz var. Resimde gÃ¶rdÃ¼ÄŸÃ¼mÃ¼z ÅŸekilde 1. epochta 2 nokta ilerleyip ikincisinde kaldÄ±ÄŸÄ±mÄ±z noktadan devam etmiÅŸ mi oluyoruz? Epochlar arasÄ± geÃ§iÅŸlerde elimizde olanlarÄ± kafamda tam olarak  oturtamadÄ±m.",

> comments:
  
1. ->  Benim de burada oturtamadÄ±ÄŸÄ±m ÅŸeyler vardÄ±. Bu linkte tartÄ±ÅŸmÄ±ÅŸtÄ±k kafandaki soru iÅŸaretleri gidecektir. Ä°yi Ã§alÄ±ÅŸmalar dilerim. [Link](http://community.globalaihub.com/community/status/1377-1377-1586334163/?t=1586558632#comment.2492.2559.2585.2606)
2. ->  ->  Hala gitmedi maalesef. Epoch artÄ±nca belirli bir seviyeye kadar maliyet azalÄ±yor konuÅŸmalardan sadece bunu Ã§Ä±karabiliyorum ki zaten eÄŸitimde bundan bahsediliyor oradan biliyorum ancak Ã¶ÄŸrenmek istediÄŸim tam olarak bu deÄŸil..",
3. ->  ->  1 epoch'ta bÃ¼tÃ¼n weightler 1 kere gÃ¼ncelleniyor. 10 epoch yaparsan bÃ¼tÃ¼n hepsini 10 kere gÃ¼ncellemiÅŸ olursun. Yani daha fazla yakÄ±nsarsÄ±n..",
4. ->  ->  Her epochun iÃ§inde aÄŸÄ±rlÄ±klar iterasyon baÅŸÄ±na gÃ¼ncelleniyor..",
5. -> ->  aÄŸÄ±rlÄ±k iterasyon baÅŸÄ±na gÃ¼ncelleniyor diye biliyorum hocam.",
6. ->  Elinde 200 sayfalÄ±k bir kitap var diye dÃ¼ÅŸÃ¼n. AmacÄ±n bu kitapta yazÄ±lanlarÄ± Ã¶ÄŸrenmek. Bunun iÃ§in bir strateji belirledin kendine. Dedin ki ben bunu 5 sayfalÄ±k parÃ§alara ayÄ±rÄ±p her bir parÃ§ayÄ± Ã§alÄ±ÅŸtÄ±ktan sonra bir sonraki kÄ±sÄ±ma geÃ§eceÄŸim.Batch size dediÄŸimiz ÅŸey modelin parametrelerini gÃ¼ncellemeden Ã¶nce Ã¼zerinde Ã§alÄ±ÅŸÄ±lacak eÄŸitim verisi sayÄ±sÄ±. Yani kitap Ã¶rneÄŸinde bu sayÄ± 5. Modelin y = w.x + b olduÄŸunu kabul edelim.Ä°lk olarak w ve b parametrelerine rasgele deÄŸerler veriyoruz. Sen 5. sayfayÄ± okuduktan sonra w ve b parametrelerini gÃ¼ncelliyorsun. KitabÄ± bitirmen iÃ§in 200/5 = 40 adet batch'in mevcut. Yani model parametreleri 40 kere gÃ¼ncellendi ve kitabÄ± tamamladÄ±n. Epoch tÃ¼m kitabÄ±n tamamlanma sayÄ±sÄ±. Yani ÅŸu ana kadar 1 epoch tamamlanmÄ±ÅŸ oldu. KitabÄ± kaÃ§ kere okuyacaÄŸÄ±mÄ±z bize kalmÄ±ÅŸ. 100 kere okursak kitabÄ± 100 epoch'a ihtiyacÄ±mÄ±z var.",
7. ->  ->  Epochu tamamlayÄ±p 2. epocha geÃ§tiÄŸimde kitaptan 1.epochta Ã¶ÄŸrendiklerimi pekiÅŸtirerek devam ediyorum diyebilir miyiz? 2.Epocha geÃ§erken birinciden elde ettiÄŸimiz modele gÃ¶re loss belirleyip her epochta bunu tekrar mÄ± ediyoruz? Ve 2 nokta atlama olayÄ± hakkÄ±nda bir fikir verebilir misiniz acaba? Bu ÅŸuna mÄ± benziyor bir kitabÄ± bir gÃ¼n okuyup bitirmek yerine bugÃ¼n 2 kez yani iter 5er sayfa okuyup devamÄ±nÄ± ertesi gÃ¼n yani 2.epochta okumak?.",
8. ->  ->  Birinci sorunun cevabÄ± evet. 2. Epocha geÃ§erken birinciden elde ettiÄŸimiz modele gÃ¶re loss belirleme ifadesi yerine ÅŸÃ¶yle diyelim: Loss fonksiyonu en baÅŸta tanÄ±mlanÄ±r. Ã–rneÄŸin regresyon problemi iÃ§in ortalama kare hata Ã§ok kullanÄ±lan bir loss fonksiyonudur. Bunu en baÅŸta belirlersin. DolayÄ±sÄ±yla her epoch'ta aynÄ± loss fonksiyonu kullanÄ±lÄ±r. Loss fonksiyonunun deÄŸerlerine gÃ¶re modelin parametreleri gÃ¼ncellenir. Bu gÃ¼ncelleme her bir batch_size tamamlandÄ±ÄŸÄ±nda gerÃ§ekleÅŸir. Kitap Ã¶rneÄŸinde senin ifadenle nokta atlama 5 sayfalÄ±k dilimi tamalayÄ±p diÄŸer 5 sayfaya geÃ§tiÄŸinde oluyor. 1 epoch kitabÄ± bir kere bitirmek demek..",
9. ->  Kitap Ã¶rneÄŸinin doÄŸru bir Ã¶rnek olabilmesi iÃ§in tabii ki bilgilerin Ã¼st Ã¼ste giden bilgiler olmadÄ±ÄŸÄ±nÄ± da belirtmem lazÄ±m..",
10. ->  peki epoch sayÄ±sÄ±nÄ± Ã§ok fazla artÄ±rÄ±nca ne olur? sanÄ±rÄ±m loss deÄŸeri artÄ±yor ama nedenini anlayamadÄ±m?.",
11. ->  ->  Epoch sayÄ±sÄ±nÄ± Ã§ok fazla artÄ±rÄ±rsanÄ±z mutlak sÄ±fÄ±ra yakÄ±nsarsÄ±nÄ±z. EÄŸer loss deÄŸeriniz artÄ±yorsa learning_rate deÄŸerinizi Ã§ok bÃ¼yÃ¼k seÃ§miÅŸsinizdir. DolayÄ±sÄ±yla learning_rate deÄŸerinizi kÃ¼Ã§Ã¼ltmeniz gerektiÄŸini anlayabilirsiniz bÃ¶yle bir durumla karÅŸÄ±laÅŸÄ±rsanÄ±z.,
12. ->  Kurs iÃ§erisinde de ÅŸÃ¶yle bir ifade geÃ§iyordu: \"Epoch sayÄ±sÄ±nÄ± ve batch size arttÄ±rÄ±rken learning rate azaltmak genelde iyidir.\".",
13. ->  ->  cevap icin tesekkur ederim, simdi daha iyi anladim..",
14. -> Merhabalar,[Link](http://community.globalaihub.com/community/status/190-190-1586531975/?t=1586595736#comment.2872.2860.2900.2877) Burada makina Ã¶ÄŸreniminin rastgeleliÄŸi ile alakalÄ± bir paylaÅŸÄ±m olmuÅŸtu. Bu postu iÅŸaret etmemin sebebibu rastgelelik 1 epoch iÃ§in de geÃ§erli 100000 epoch iÃ§inde. Epoch kavramÄ±nÄ± basitÃ§e tanÄ±mlamak gerekirse: elinde bulunan veri seti'ni epoch olarak dÃ¼ÅŸÃ¼nebilirsin. batch_size ise elinde ki veri setini nasÄ±l alt kÃ¼melere ayÄ±racaÄŸÄ±na karar verdiÄŸin deÄŸer, iterasyon ise basitce veri setinini bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼n batch_size ye oranÄ±. Yani elinde bulunan verinin bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼ 1000 olduÄŸunu varsayalÄ±m, batch_size deÄŸerini de 100 bu durumda 10 kÃ¼me elde edebilirsin. Bu 10'da senin iterasyon boyutun oluyor.Ancak epoch, batch_size ve iteration_size Ã¼Ã§lÃ¼sÃ¼ rastgelelikle alakalÄ± kavramlar deÄŸiller. Bu kavramlarÄ± nasÄ±l deÄŸiÅŸtirirsen deÄŸiÅŸtir rastgelelik ortadan kalkmayacaktÄ±r. SonuÃ§larÄ±n her denemede farklÄ± olmasÄ±nÄ±n sebebi kullanÄ±lan yÃ¶ntemin \"Stochastic\" olmasÄ±.Stochastic Gradient Descent' in son cÃ¼mlesi: \"The term \"stochastic\" indicates that the one example comprising each batch is chosen at random.\" ÅŸeklindeydi. Mini-Batch SGD iÃ§in bu cÃ¼mleyi one example kÄ±smÄ±nÄ± batch_size olarak dÃ¼ÅŸÃ¼nebilirsin.Bir eÄŸitim sÃ¼resince bÃ¼tÃ¼n epoclar birbiri ile baÄŸlantÄ±lÄ± olarak iÅŸleyecektir. Yani bir epoch'un Ã§Ä±kÄ±ÅŸ deÄŸeri diÄŸer epoch iÃ§in giriÅŸ deÄŸeri olmaktadÄ±r. Bu ÅŸekilde optimal loss deÄŸerine ulaÅŸana kadar iÅŸlemlere devam edilmektedir.Ä°yi Ã§alÄ±ÅŸmalar.",
15. ->  ->  ->  Ã‡ok teÅŸekkÃ¼r ederim kafamdaki tÃ¼m sorulara cevap buldum sayenizde..",
    
### soru 

> quest: "Merhaba, First Step with TF da yapÄ±lan araÅŸtÄ±rmayÄ± yaptÄ±ÄŸÄ±mda ÅŸÃ¶yle bir sonuÃ§ gÃ¶rdÃ¼m.  Batch Size deÄŸiÅŸtirdiÄŸimde bir farklÄ±lÄ±k gÃ¶remedim. Epoch sayÄ±sÄ±nÄ± arttÄ±rÄ±nca ve learnin rate arttÄ±rÄ±nca  rmse azalma oldu. Genelde hep bu ÅŸekilde mi sonuÃ§lanÄ±yor yoksa bu Ã¶rneÄŸe istisna bir ÅŸey miydi? Bu konuda yardÄ±mcÄ± olabilir misiniz?",

> comments:
  
1. -> yapÄ±lan aÅŸamalarÄ± sonda Ã¶zetlemeye Ã§alÄ±ÅŸmÄ±ÅŸ.",
2. ->  bu konuda ben de merak edip farklÄ± denemeler yaptÄ±m ama gÃ¶rdÃ¼ÄŸÃ¼m kadarÄ±yla yalnÄ±zca eÄŸitim hÄ±zÄ±na etki eden bir parametre gibi , ama tabiki kesin bir ÅŸey sÃ¶ylemem .. Daha deneyimli birinden Ã¶ÄŸrenmek daha saÄŸlÄ±klÄ± olur.",
3. -> Merhabalar. Ã–ncelikle Modellerde bir genelleme yapmak Ã§ok fazla sÃ¶z konusu deÄŸil. Hiper parametrelerin hangisinde nasÄ±l bir ayarlama yapacaÄŸÄ±nÄ±z, elinizdeki veri setine gÃ¶re deÄŸiÅŸiklik gÃ¶sterebiliyor. Ã–zellikle batch-size ayarlamalarÄ±, Ã§ok bÃ¼yÃ¼k boyutlarda veri setiniz olduÄŸunda size lazÄ±m olacaktÄ±r. KÃ¼Ã§Ã¼k tuttuÄŸunuzda Ã§ok fazla zaman alacak ve bu da size maliyet anlamÄ±na gelecektir. Gelelim learning rate durumuna. Learning rate iÃ§in de deÄŸer ayarlama Ã¶nemlidir. Ã‡ok kÃ¼Ã§Ã¼k tuttuÄŸunuzda modeliniz Ã¶ÄŸrenmesi iÃ§in Ã§ok fazla epoch gerekebilir hatta Ã¶ÄŸrenmeyebilir. Ã‡ok bÃ¼yÃ¼k tuttuÄŸunuzda da aradan kaÃ§Ä±rabileceÄŸiniz deÄŸerler olabilir bu da Ã¶ÄŸrenme grafiÄŸinizde dalgalanmalara sebep olabilir. Epoch deÄŸeri ise yine verisetine gÃ¶re deÄŸiÅŸebilir. Gereksiz Ã§ok uzun tutulan epoch sayÄ±sÄ± size zaman maliyetine sebep olacaktÄ±r. Hatta buna ek olarak bir sÃ¼re sonra loss deÄŸerinizin artmasÄ±na da sebep olabilir. TÃ¼m bunlardan, aslÄ±nda bir ÅŸÃ¶yle bir Ã§Ä±karÄ±m yapmak gerekiyor. Burada genelleme yapmayÄ±p, her bir parametrenin iÅŸlevinin ne olduÄŸunu kavramaya Ã§alÄ±ÅŸmak gerekiyor. Hepimize iyi kurslar diliyorum.",
4. ->  ->  teÅŸekkÃ¼r ederim Serkan Bey.",
5. ->  Merhaba, bu konuyla alakalÄ± Linear Regression with Synthetic Data kÄ±smÄ±nÄ±n sonunda seÃ§enekler Summary of hyperparameter tuning kÄ±smÄ±nda Ã¶zetlenmiÅŸ durumda. Buradaki aslÄ±nda pÃ¼k nokta hyperparametre Ã¼zerindeki deÄŸiÅŸikliklerin ya da etkilerin grafikler Ã¼zerinden okunmasÄ±. Grafikler, hangi parametre Ã¼zerinde ihtiyaÃ§ ya da deÄŸiÅŸikliÄŸe gitmemiz konusunda ipuÃ§larÄ± veriyor..",
    
### soru 

> quest: "1- Kodlama PratiÄŸi kÄ±smÄ±nda gerÃ§ek veriler bÃ¶lÃ¼mÃ¼nde (Regression with a Real Dataset ) en son TASK,  Ne yaptÄ±ysam, gerÃ§ek deÄŸerlere yakÄ±n bir tahmin Ã¼rettiremedim. Yapanlar var mÄ±?  2- Bias KavramÄ±nÄ±da tam kafamda oturtmuÅŸ deÄŸilim. Neden acaba? Bu tanÄ±m olarak anlÄ±yorum biasta eÄŸitime giriyor, yani aslÄ±nda bias mantÄ±ÄŸÄ±yla hatalarÄ± Ã¶ÄŸretmek ve onlardan kaÃ§Ä±nmak iÃ§in mi? binevi hatalardan ders Ã§Ä±kar mantÄ±ÄŸÄ±?  3- Birde epoach ile iterasyon arasÄ±ndaki fark nedir? mini batch deÄŸeri 30 olduÄŸunda 1. iterasyonda 30 kÃ¼meyi parÃ§a parÃ§a iÅŸliyor anlamÄ±nda mÄ±? Sonra 2. iterasyonu istersen yine 30 kere Ã¶ÄŸrenmeye devam ediyor.  4- GRAFÄ°KLÄ° ÅEKÄ°LDE, \"some fraction of the gradient's magnitude\" ile kastetiiÄŸi ÅŸey nedir? EklediÄŸi ÅŸeyi anlayamadÄ±m. Terimlere uzaÄŸÄ±z galiba baÄŸdaÅŸtÄ±ramadÄ±m.  Åimdiden Ã§ok teÅŸekkÃ¼r ederim cevaplarÄ±nÄ±z iÃ§in..",

> comments:

1. ->  2 - Bias Linear Regression da doÄŸrumuzun (modelimiz) y - ekseni Ã¼zerindeki konumunu ayarlamada yardÄ±mcÄ±dÄ±r. EÄŸer bias deÄŸeri vermezsek modelimiz originden geÃ§mek zorunda kalacaktÄ±r ve bu Ã§oÄŸu veri setinde muhtemelen kÃ¶tÃ¼ sonuÃ§lar elde etmemize neden olacak ve modelimize zarar verecektir. 3 -epoch - iteration - batch size arasÄ±ndaki baÄŸlantÄ± iÃ§in Ã¶rnek: 12 verilik veri setimizde batch size = 12 olsun, bu durumda bir epoch 1 iterasyon ile sonlanacak, bir de batch size = 6 iken deneyelim, bu durumda bir epoch 2 iterasyonda sonlanacaktÄ±r. 4 - belirlediÄŸimiz learning rate sayesinde bulduÄŸumuz sÄ±Ã§rama mesafesi ile eÄŸrimiz Ã¼zerinde sÄ±radaki konumumuzu belirliyoruz, eÄŸri Ã¼zerinde bu ÅŸekilde gezinerek modelimize vermemiz gereken optimum aÄŸÄ±rlÄ±k deÄŸerlerini arÄ±yoruz. Eksik veya yanlÄ±ÅŸ bir bilgi varsa lÃ¼tfen bilgilendirin. Ä°yi Ã§alÄ±ÅŸmalar..",
2. ->  ->  Peki o zaman Epoch sayÄ±sÄ±nÄ± arttÄ±rdÄ±ÄŸÄ±mÄ±zda nasÄ±l oluyor? Yine bir Ã¶rnekle aÃ§Ä±klama imkanÄ±n olur mu rica etsem? Sonucunu biliyorum, mantÄ±ÄŸÄ±nÄ± anlamaya Ã§alÄ±ÅŸÄ±yorum ezber olmamasÄ± iÃ§in ğŸ™‚.",
" ->  -> Batch_size'Ä± sabit tutarak, elimizdeki veri seti 10 epoch ile underfitting, 50 ile optimum , 100 ile overfitting modeller oluÅŸturabilir. Burada iterasyon sayÄ±sÄ± aynÄ± Ã§Ã¼nkÃ¼ batch deÄŸiÅŸmiyor. Overfitting ve underfitting konularÄ±nÄ± biraz daha araÅŸtÄ±rÄ±p, batch, epoch sayÄ±larÄ±nÄ± da Ã§ok yÃ¼ksek veya dÃ¼ÅŸÃ¼k deÄŸerler ile model Ã¼zerinde denediÄŸinde konunun netleÅŸeceÄŸini dÃ¼ÅŸÃ¼nÃ¼yorum..",
3. ->  ->  Ã‡ok teÅŸekkÃ¼r ediyorum, tavsiyeni dikkate alacaÄŸÄ±m...",
4. ->  1-predict_house_values fonksiyonunda hata olduÄŸunu baÅŸka bir postta yazmÄ±ÅŸlardÄ±. O yÃ¼zden print ettiÄŸiniz feature value, label value deÄŸerleri predicted value deÄŸerlerinin gerÃ§ek deÄŸerleri deÄŸil. Ben predict_house_values fonksiyonunda ÅŸu kÄ±smÄ± deÄŸiÅŸtirdim:print (\"%5.0f %6.0f %15.0f\" % (training_df[feature][10000+i],training_df[label][10000+i],predicted_values[i][0] ))Sonra sizin yazdÄ±ÄŸÄ±z deÄŸerler ile eÄŸittim modeli. Loss function zaten nerdeyse deÄŸiÅŸmiyor yani zaten olabilecek en iyi score bulmuÅŸsunuz gibi gÃ¶zÃ¼kÃ¼yor. Root_mean_square 83 civarÄ± ve sonuÃ§lar da ona uygun. Tek Ã¶zellik ile tahmin yapÄ±ldÄ±ÄŸÄ±nÄ± gÃ¶z Ã¶nÃ¼ne alÄ±nca Ã§ok iyi bir score beklemek doÄŸru deÄŸil zaten..",
5. -> ->  Ã‡ok teÅŸekkÃ¼r ederimm..",
6. ->  4-\"some fraction of the gradient's magnitude\" dediÄŸi resimdeki kÄ±rmÄ±zÄ± ok. w parametresi gÃ¼ncellenirken w:=w-learning rate*(Loss fonksiyonunun w parametresine gÃ¶re kÄ±smi tÃ¼revi). \"Loss fonksiyonunun w parametresine gÃ¶re kÄ±smi tÃ¼revi\" kÄ±smÄ± gradyantÄ±n genliÄŸi oluyor. some kelimesini kullanmasÄ±nÄ±n nedeni learning rate faktÃ¶rÃ¼nden kaynaklÄ± olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yorum. Ã‡Ã¼nkÃ¼ parametreyi gÃ¼ncellerken genliÄŸi learning rate ile Ã§arptÄ±ÄŸÄ±n iÃ§in scale etmiÅŸ oluyorsun. kÄ±rmÄ±zÄ± ok learnin rate*magnitude oluyor yani. bu deÄŸer sonra w deÄŸerinin o anki olduÄŸu konumunun Ã¼zerine gradyanÄ±n negatif yÃ¶nÃ¼nde(loss functionun azalmasÄ± iÃ§in) ekleniyor ve yeni w deÄŸeri bulunuyor. Biraz karmaÅŸÄ±k oldu sanÄ±rÄ±m ama parametre gÃ¼ncelleme ile ilgili gÃ¶rsel ekledim daha aÃ§Ä±klayÄ±cÄ± olabilir..",
    
### soru 

> quest: "Merhabalar,  Linear Regression with a Real Dataset kÄ±smÄ±nda aklÄ±ma takÄ±lan bir kÄ±smÄ± sormak istiyorum. Batch deÄŸerleri n e baÄŸlÄ± olarak training_df 'in o aralÄ±ktaki deÄŸerlerinden oluÅŸuyorken ve bu deÄŸerleri  alÄ±p prediction iÅŸlemi gerÃ§ekleÅŸtiriliyorken aÅŸaÄŸÄ±da for iÃ§erisinde indexi direkt olarak i kabul etmiÅŸ.Burada olmasÄ± gereken 10000+i deÄŸil midir(Sadece training_df  iÃ§in )? Yoksa ben mi bir ÅŸeyleri kaÃ§Ä±rdÄ±m.",

> comments:
  
1. ->  Merhabalar,Evet dediÄŸiniz gibi olmalÄ±, tahmin iÃ§in kullandÄ±ÄŸÄ± deÄŸerler yerine veri setinin ilk deÄŸerlerini almÄ±ÅŸ. YazÄ±m sÄ±rasÄ±nda gÃ¶zden kaÃ§Ä±rÄ±lmÄ±ÅŸ olmalÄ±.Ä°yi Ã§alÄ±ÅŸmalar.,
    
### soru 

> quest: "Merhaba benim sorum NumPy Ultraquick tutorial ile  alakalÄ±. \"np.random.random([6])\" bu kod satÄ±rÄ± bize 0'la 1 arasÄ±ndaki  random floating deÄŸerlerini buluyor.Peki -2 ile +2 arasÄ±ndaki floating deÄŸerlerini nasÄ±l bulacaÄŸÄ±z?",
> comments:


1. ->  0 ile 1 arasÄ±nda dÃ¶dÃ¼ÄŸÃ¼ iÃ§in (np.random.random() * 4) - 2 yapÄ±lacak. ÅÃ¶yle dÃ¼ÅŸÃ¼n en kÃ¼Ã§Ã¼k deÄŸer 0 olabilir ve bizim yazdÄ±ÄŸÄ±mÄ±z denklemde 0*4 - 2 = -2 oluyor . En bÃ¼yÃ¼k deÄŸer iÃ§in ise 1 olabilir, 1 ise 1*4 - 2 = 2 olabilir. Bu ÅŸekilde dÃ¼ÅŸÃ¼nmemiz gerekiyor. Bu denklemi nasÄ±l elde ediyoruz dersen hiÃ§ araÅŸtÄ±rmadÄ±m ama mantÄ±ÄŸÄ±m ÅŸu yÃ¶nde. en kÃ¼Ã§Ã¼k sÄ±fÄ±r gelceÄŸi iÃ§in aralÄ±ktaki en kÃ¼Ã§Ã¼k sayÄ±yÄ± + olarak yazmak ve istenilen fark ile Ã§arpmak. Ã‡arpmak dediÄŸim yukarÄ±da gÃ¶sterdiÄŸim ÅŸekilde tÃ¼m terimi deÄŸil..", 1. ->  yada ÅŸu ÅŸekilde bir kÄ±sayolu var : np.random.randint(low = -2, high =2, size=(6)) -2 ve 2 arasÄ±nda 6 deÄŸer atar.",
2. ->  ->  Ama bu sadece bize tam sayÄ±larÄ± veriyor, bize ondalÄ±klÄ± sayÄ±lar lazÄ±m..",
3. ->  teÅŸekkÃ¼rler.",
4. ->  np.random.uniform(low=-2, high=2).",
5. ->  import numpy as np4*np.random.random_sample((5,))-2.",
6. ->  ->  Bu konu aralÄ±k aritmetiÄŸi (interval arithmetic) ile alakalÄ±. BildiÄŸimiz aritmetik iÅŸlemler aralÄ±klar Ã¼zerinde de geÃ§erli. AslÄ±nda ÅŸÃ¶yle bir denklem kuruyoruz x.(0,1) + y = (-2,2) . Burada (0,1) 0 1 aralÄ±ÄŸÄ±nÄ± gÃ¶steriyor.Denklemin Ã§Ã¶zÃ¼mÃ¼x.0 + y = -2x.1 + y = 2den x =4 y=-2 olarak bulunuyor. DolayÄ±sÄ±yla (np.random.random() * 4) - 2 iÅŸlemi bize istediÄŸimiz aralÄ±ÄŸÄ± veriyor.",

### soru 

> quest: "Merhabalar,  Linear Regression with Synthetic Data Ã§alÄ±ÅŸma kodunda Task 2 'de epoch sayÄ±sÄ±nÄ± artÄ±rma yapÄ±lmasÄ± isteniyor.Ben 200 olarak yaptÄ±ÄŸÄ±mda her Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±mda farklÄ± grafikler elde ediyorum.Yani aynÄ± parametreler ile modeli eÄŸitirken her run edildiÄŸinde farklÄ± sonuÃ§ Ã§Ä±kabiliyor mu?O zaman bir model iÃ§in optimum value leri nasÄ±l saptayacaÄŸÄ±z?Epoch 200 iken model converge oladabiliyor,olmayadabiliyor.  TeÅŸekkÃ¼rler",

> comments:

1. -> Merhaba,Makina Ã–ÄŸrenimi algoritmalarÄ± kararsÄ±z yapÄ±lar olmasÄ± sebebiyle her yeni baÅŸlangÄ±Ã§ta farklÄ± sonuÃ§lara ulaÅŸmaktadÄ±r. Bunun sebebi de rassallÄ±ktan(randomness) dolayÄ± olmaktadÄ±r. Yani algoritmamÄ±z her ne kadar aynÄ± data ile Ã§alÄ±ÅŸÄ±yor olsa bile datanÄ±n sÄ±ralamasÄ±ndaki deÄŸiÅŸim sonuÃ§larÄ± etkilemektedir. EÄŸer her seferinde aynÄ± sonuÃ§larÄ± almak istiyorsanÄ±z random seed deÄŸeri verebilirsiniz. Bu deÄŸer her seferinde aynÄ± deÄŸeri Ã¼retmek iÃ§in sabitlenmektedir. EÄŸer bu deÄŸere sabit bir sayÄ± tanÄ±mlamamÄ±ÅŸsak varsayÄ±lan olarak sistem zamanÄ±nÄ± kullanÄ±r. Bu yÃ¼zden her seferinde farklÄ± sonuÃ§lar elde etmemize sebep olmaktadÄ±r.import numpy as npnp.random.seed(42)tf.random.set_seed(42)YukarÄ±daki satÄ±rlarÄ± kodunuza eklerseniz her seferinde tutarlÄ± bir ÅŸekilde aynÄ± sonuÃ§larÄ± alabilirsiniz.42 olarak belirttiÄŸim deÄŸer keyfi olarak seÃ§ilebilir, sabit kaldÄ±ÄŸÄ± sÃ¼rece sonuÃ§lar deÄŸiÅŸmeyecektir.Ä°yi Ã§alÄ±ÅŸmalar.",
2. ->  ->  Ã‡ok teÅŸekkÃ¼rler:).",
3. -> Merhaba,model.fit metodunu incelediÄŸimde model.fit metodunun shuffle isminde bir parametre aldÄ±ÄŸÄ±nÄ± ve bu parametre deÄŸerinin default olarak TRUE olduÄŸunu gÃ¶rdÃ¼m. Bu parametrenin aÃ§Ä±klamasÄ± ise :\"Shuffle the training data on each epoch\" yani her epochta eÄŸitim datasÄ±nÄ± karÄ±ÅŸtÄ±rÄ±r bu yÃ¼zden veriler karÄ±ÅŸtÄ±ÄŸÄ± iÃ§in her algoritma Ã§alÄ±ÅŸmasÄ±nda aynÄ± sonucu elde edemeyiz. AraÅŸtÄ±rdÄ±ÄŸÄ±m kadarÄ±yla Keras'Ä±n model.compile() metodu otomatik olarak bu shuffle deÄŸerini true yapmaktadÄ±r. [Link](https://github.com/keras-team/keras/blob/7a39b6c62d43c25472b2c2476bd2a8983ae4f682/keras/engine/training.py#L1584) linkinden inceleyebilirsiniz.). Bu shuffle'Ä± False yapabilmek iÃ§in Ã¶nerilenler arasÄ±nda Keras'tan Ã¶nce numpy kÃ¼tÃ¼phanesini import etmek ve ederken de seed metodunu Ã§aÄŸÄ±rmak var. Yani;\"import numpy as npnp.random.seed(1337)from keras.models import Sequential\"tarzÄ±nda bir yaklaÅŸÄ±mda bulunmak. Buradaki seed metodu her Ã§aÄŸrÄ±ldÄ±ÄŸÄ±nda aynÄ± random sayÄ±larÄ± dÃ¶ner. Yine araÅŸtÄ±rdÄ±ÄŸÄ±ma gÃ¶re Keras'ta bu shuffle randomness'Ä± kullanabilmenin yolu numpy kÃ¼tÃ¼phanesindeki random.seed metodunu kullanmak. EksiÄŸim var ise eklemelere aÃ§Ä±ÄŸÄ±m ğŸ™‚ iyi Ã§alÄ±ÅŸmalar.",
4. ->  ->  Merhaba,Her ne kadar shuffle parametresini False yapsak ve np.random.seed(1337), bir deÄŸere sabitlesek bile, tensorflow iÃ§in random seed'i set etmez isek yeterli olmamakta. (tf.random.set_seed(1337)) ile tutarlÄ±lÄ±k saÄŸlanmakta.Edit: Hatta sadece tf.random.set_seed(1337), model.fit() fonksiyonunun shuffle parametresinin True ya da False olmasÄ±na bakÄ±lmasÄ±zÄ±n tutarlÄ±lÄ±ÄŸÄ± saÄŸlamakta, ÅŸimdi test ederek sonuÃ§larÄ± inceledim.",
5. ->  ->  Merhaba,CevabÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederim. Evet, bu shuffle deÄŸerini model.compile metodunda kendisi eziyorYukarÄ±da verdiÄŸim bilgi kaynaklarÄ±nÄ± ÅŸÃ¶yle paylaÅŸabilirim.[Each time I run the Keras, I get different result](https://github.com/keras-team/keras/issues/2479#issuecomment-213892402) - [Link](https://github.com/keras-team/keras/issues/2743#issuecomment-219777627). Burada numpy seed'inin randomness'Ä±n kalkmasÄ± iÃ§in yeterli olduÄŸundan bahsediliyor. EÄŸer bu bilgiler hatalÄ± veya eksikse ekleme ve bilgilendirme iÃ§in teÅŸekkÃ¼r ederim, iyi Ã§alÄ±ÅŸmalar dilerim.",
6. ->  ->  tensorflow'un da numpy random seed'i eziyor olmasÄ± ya da hiÃ§ gÃ¶rmÃ¼yor olmasÄ± muhtemel, bahsettiÄŸiniz kaynaÄŸÄ± ben de inceledim ancak test ettiÄŸim zaman tutarlÄ±lÄ±ÄŸÄ± saÄŸlamadÄ±ÄŸÄ±nÄ± farkettim. SonrasÄ±nda[Keras LSTM - why different results with \"same\" model & same weights](https://stackoverflow.com/questions/46119435/keras-lstm-why-different-results-with-same-model-same-weights)burada tensorflow iÃ§in de seeed deÄŸeri atandÄ±ÄŸÄ±nÄ± gÃ¶rdÃ¼m. DenediÄŸim zaman sorunsuz tutarlÄ±lÄ±k saÄŸlandÄ±.Kaynak iÃ§in teÅŸekkÃ¼rler. iyi Ã§alÄ±ÅŸmalar ğŸ™‚",
7. ->  ->  KaynaÄŸÄ±nÄ±zÄ± inceledim, bilgilendirme ve ekleme iÃ§in tekrar teÅŸekkÃ¼rler iyi Ã§alÄ±ÅŸmalar ğŸ™‚.",
    
### soru 

> quest: "Merhaba, iÅŸaretlediÄŸim kÄ±smÄ± anlamakta sorun yaÅŸÄ±yorum. \"smooth out noisy gradients\"  derken ne demeye Ã§alÄ±ÅŸÄ±yor ve Noisy Gradient kavramÄ± nedir?",

> comments:
  
1. ->  Merhaba,Noisy data verisetimizdeki anlamsÄ±z verilere denir. Bu anlamsÄ±z veriler tahminleri olumsuz etkiler. Ã–rneÄŸin modelimizi eÄŸitirken oda sayÄ±sÄ± 100 olan bir ev veri Ã¶rneÄŸi soktuÄŸumuzda Ã§Ä±kacak olan lineer grafiÄŸimiz (lineer olduÄŸunu varsayÄ±yorum) olmasÄ± gerekenden daha az performanslÄ± olacaktÄ±r Ã§Ã¼nkÃ¼ diÄŸer oda sayÄ±sÄ± deÄŸerleri muhtemelen 1-10 arasÄ±nda olacaktÄ±r. AnladÄ±ÄŸÄ±m kadarÄ±yla burada demek istediÄŸi redundancy i batch size arttÄ±ÄŸÄ±nda artan bir ÅŸey olarak tanÄ±mlamÄ±ÅŸ ve batch size'Ä±nÄ±z arttÄ±kÃ§a bu artÄ±ÅŸ noisy (gÃ¼rÃ¼ltÃ¼lÃ¼) iÃ§erikleri yumuÅŸatmak iÃ§in kullanÄ±ÅŸlÄ± olabilir demek istemiÅŸ. Noisy Gradient dediÄŸi anladÄ±ÄŸÄ±m kadarÄ±yla Noisy Data iÃ§in kullanÄ±lmÄ±ÅŸ. YanlÄ±ÅŸÄ±m var ise dÃ¼zeltilmesinden memnun olurum ğŸ™‚ Ä°yi Ã§alÄ±ÅŸmalar dilerim.",
2. ->  ->  teÅŸekkÃ¼r ederim, anladÄ±m ÅŸimdi..",
3. ->  Noisy gradient, resmin saÄŸÄ±ndaki gibi loss fonksiyonumuzun dengesiz ÅŸekilde deÄŸerler almasÄ±na deniyor. EÄŸer minibatch-size'Ä± Ã§ok dÃ¼ÅŸÃ¼k seÃ§ersek veya stochastic gradient descent kullanÄ±yorsak(zaten SGD'de batch-size=1 oluyordu) loss'u hesaplarken Ã§ok az Ã¶rnek kullandÄ±ÄŸÄ±mÄ±z iÃ§in; loss deÄŸeri bir iterasyonda birden yÃ¼kselip diÄŸer iterasyonda birden azalabilir. Ã‡Ã¼nkÃ¼ loss deÄŸerimizi Ã§ok az miktarda Ã¶rneÄŸi deÄŸerlendirip gÃ¼ncelliyoruz.",
4. ->  ->  teÅŸekkÃ¼r ederim..",
    
### soru 

> quest: "Merhaba,  First Step with TF kÄ±smÄ±ndaki programming exercises bÃ¶lÃ¼mÃ¼ndeki Ã¶rnekleri aÃ§mak Ã¼zre Colab uygulamasÄ±na girmek istedigimde aÅŸaÄŸÄ±daki \"failed to fetch \" mesajÄ±yla karÅŸÄ±laÅŸtÄ±m.YardÄ±mcÄ± olabilcek olan varmÄ± Ã¶rnek uygulamalara eriÅŸebilmem iÃ§in ? TeÅŸekkÃ¼rler",

> comments:
  
1. ->  Merhaba sizin internet eriÅŸiminiz yada Colab uygulamasÄ±ndaki serverlardaki bir sorundan olabilir. Bence bir sÃ¼re sonra tekrar deneyin aÃ§Ä±lacaktÄ±r..",
2. -> ->  Merhaba ,chromeda yine acÄ±lmadÄ± ama firefox kurdum onda sorunsuz acÄ±ldÄ± cok teÅŸekkÃ¼rler.",
    
### soru 

> quest: "Az Ã¶nce kursun haftalÄ±k kÄ±smÄ±nÄ± bitirdim ama aklÄ±ma takÄ±lan bir nokta var. Biz weightleri gradient descent ile ayarlarken ÅŸu ÅŸekil bir denklem kullanÄ±yoruz: w1 = w1 - (learning_rate)*(costun_w1e_gÃ¶re_tÃ¼revi) Bu denkleme gÃ¶re n tane featurimiz olsa hepsinde aynÄ± learning rati mi kullanÄ±caÄŸÄ±z. Learning rateye ayar Ã§ekerken bunu tek bir featureye gÃ¶re yapÄ±yorduk bu feature uyan learning rate bÃ¼tÃ¼n featurelara uyar mÄ± deriz yoksa learning rate iÃ§in bÃ¼tÃ¼n featurelara karÅŸÄ±lÄ±k gelen learning ratelerin olduÄŸu bir vektÃ¶r mÃ¼ oluÅŸturmamÄ±z gerekiyor? UmarÄ±m iyi anlatabilmiÅŸimdir.",

> comments:
  
1. -> Merhaba. Learning rate gradient decent algoritmasÄ±nÄ±n bir hiperparametresidir(hiperparametreleri modeli kuran kiÅŸinin seÃ§ebileceÄŸi parametreler olarak dÃ¼ÅŸÃ¼nebilirsiniz. Ã¶rn: K-MEANS algoritmasÄ±ndaki k deÄŸeri, garadient decent de learning rate vb. Model parametreleri ise tahmin fonsiyonumuzdaki feature'larÄ±n katsayÄ±larÄ± bigi aslÄ±nda bulmaya Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z ÅŸeylerdir). Gradient decent ise direk tÃ¼rev alarak optimizasyon yÃ¶nteminin alternatifidir. feature ve sample sayÄ±sÄ±nÄ±n Ã§ok fazla olduÄŸu veri setlerinde direk tÃ¼rev alma yÃ¶ntemi Ã§ok uzun sÃ¼rdÃ¼ÄŸÃ¼ iÃ§in gradient decent kullanÄ±lÄ±r. Her iterasyonda optimum noktaya yaklaÅŸabilmek iÃ§in de learning rate belirleyerek ilerleriz. AsÄ±l sorunuzu en sonda cevaplayayÄ±m. Evet her aÄŸÄ±rlÄ±k iÃ§in tek bri tane learning rate belirleriz. AÄŸÄ±rlÄ±klarÄ±n farklÄ± olmalarÄ±nÄ±n bir Ã¶nemi yoktur. Ã‡Ã¼nkÃ¼ her iterasyonda formÃ¼lÃ¼n doÄŸasÄ± gereÄŸi hata fonksiyonun mininmum noktasÄ±na yaklaÅŸmaya devam ederiz. Tabi ki learning rate'i optimum noktayÄ± atlayacak kadar bÃ¼yÃ¼k seÃ§mediysek.,
    
### soru 
> quest: "Merhaba, Validation Set kÄ±smÄ±ndaki pratikte \"test setini ve doÄŸrulama setini nasÄ±l bÃ¶ldÃ¼ÄŸÃ¼nÃ¼z Ã¶nemli deÄŸil \" diyor fakat Validation set ile test boyutu aynÄ± olmasÄ± gerekmez mi ? Ã–rneÄŸin valid set size % 20 ise test set' de %20 olmasÄ± gerekmez mi? SonuÃ§ta modele en Ã§ok girdi nereden veriliyorsa o tarafta Ã¶ÄŸrenme artmasÄ± sÃ¶z konusu olur.",

> comments:
  
1. ->  Merhaba,Validation Set'de aslÄ±nda bir test settir. DolayÄ±sÄ±yla Test Set'in karÅŸÄ±lamasÄ± beklenen iki ÅŸartÄ±;- Ä°statistiksel olarak anlamlÄ± sonuÃ§lar ifade edecek kadar bÃ¼yÃ¼k mÃ¼?- BÃ¼tÃ¼n seti(trainin data) temsil edebiliyor mu?karÅŸÄ±lamalÄ±. BÃ¼tÃ¼n bunlarÄ± saÄŸladÄ±ÄŸÄ± sÃ¼rece test ve validation setlerini nasÄ±l bÃ¶ldÃ¼ÄŸÃ¼mÃ¼zÃ¼n Ã¶nemi olmayacaktÄ±r..",
    
### soru 

> quest: "Merhabalar herkese, BugÃ¼n genel tekrar yaparken kafama birkaÃ§ soru takÄ±ldÄ± onlarÄ± sormak istedim.  1-) Uygulama kÄ±smÄ±nda \"epoch\" ve \"batch size\" parametrelerini arasÄ±ndaki iliÅŸkiyi tam kavrayamadÄ±m.  2-) Gene uygulama kÄ±smÄ±nÄ±nÄ± son kÄ±smÄ±nda \"correlation matrix\" den bahsedilmiÅŸ, bir takÄ±m deÄŸerler Ã¼zerinden (1.0,0.0 ve -1.0 gibi) yorum yapÄ±lÄ±yor. O deÄŸerlerden nasÄ±l bir yorum Ã§Ä±karabiliriz ? 3-) Son olarak da, \"Generalization\" kÄ±smÄ±nda diagramda \"Hidden truth\" diye bir kavram var sanÄ±rÄ±m bizim referansÄ±mÄ±z ama onun kaynaÄŸÄ± ne onu tam kavrayamadÄ±m. YardÄ±mcÄ± olursanÄ±z sevinirim.",

> comments:
  
1. ->  1- bir epoch veri setimizdeki tÃ¼m verileri iÅŸlememiz anlamÄ±na geliyor, batch-size ise gradient descent grafiÄŸini hatÄ±rlarsanÄ±z orda adÄ±m adÄ±m minimuma doÄŸru gitmeye Ã§alÄ±ÅŸÄ±rken veri setimizdeki kaÃ§ Ã¶rneÄŸi deÄŸerlendirerek loss hesaplayÄ±p parametreleri gÃ¼ncelleyeceÄŸimizi ifade ediyor. Mesela 1000 verimiz olsun, 100 batch-size ve 10 epoch belirleyelim. 1 epoch iÃ§in 10 iterasyon gerekiyor ( veri sayÄ±sÄ± / batch-size). Toplamda 10 epoch ise 10x10 = 100 iterasyon gerekiyor.2- correlation matrix ise feature'larÄ±mÄ±zÄ±n birbirleriyle ne kadar iliÅŸkili olduÄŸunu gÃ¶steriyor. 1 olmasÄ± birbirlerine tamamen baÄŸlÄ± olduklarÄ±nÄ± -1 olmasÄ± ise tamamen zÄ±t olduklarÄ±nÄ± gÃ¶steriyor. Mesela oda sayÄ±sÄ± ve evin metrekaresi sÃ¼tunlarÄ±mÄ±z olsun. BunlarÄ±n correlation deÄŸerlerinin 1'e yakÄ±n olmasÄ± beklenir. Fakat evin yaÅŸÄ± sÃ¼tunu ile evin deÄŸeri sÃ¼tunlarÄ±nÄ±n correlation deÄŸerlerinin -1'e yakÄ±n olmasÄ± beklenir. UmarÄ±m aÃ§Ä±klayabildim.",
2. ->  ->  teÅŸekkÃ¼rler sanÄ±rÄ±m daha iyi anladÄ±m verdiÄŸiniz Ã¶rneklerle..",
3. -> 1. soruna gÃ¼zel cevap verebileceÄŸimi dÃ¼ÅŸÃ¼nmÃ¼yorum.2. soru benim de aklÄ±ma takÄ±lmÄ±ÅŸtÄ±, internette biraz araÅŸtÄ±rma yaptÄ±ktan sonra bÃ¶yle bir gÃ¶rselle karÅŸÄ±laÅŸtÄ±m, ([Link](https://en.wikipedia.org/wiki/Correlation_and_dependence#/media/File:Correlation_examples2.svg) anlamama yardÄ±mcÄ± oldu. Correlation deÄŸerinin 0 olmasÄ± aralarÄ±nda lineer bir baÄŸÄ±ntÄ± olmadÄ±ÄŸÄ±nÄ± gÃ¶steriyor sanÄ±rÄ±m. Yani dÃ¼zenli olarak \"artarsa artar, azalÄ±rsa azalÄ±r\" gibi yorum yapamÄ±yoruz anlamÄ±na geliyor. (yanlÄ±ÅŸÄ±m varsa lÃ¼tfen dÃ¼zeltin)3. sorun iÃ§in ÅŸÃ¶yle bir ÅŸey diyebilirim, onun verdiÄŸi Ã¶rnekten devam edecek olursak, makine Ã¶ÄŸrenmesi modelimizi belirli bir veri setiyle besleyeceÄŸiz, bu kÄ±sÄ±tlÄ± bir veri seti olacak. Elimizdeki verilere %100 uyuyor olmasÄ± \"hidden truth\"tan gelecek yeni verilerle uyuÅŸmayabilir. GerÃ§ek hayat verilerinde mutlaka anomaliler olur. KullandÄ±ÄŸÄ±Ä±mÄ±z verileri de %100 doÄŸrulukla tahmin eden bir model de bu yÃ¼zden dÃ¼zgÃ¼n bir ÅŸekilde \"generalized\" tahminlerde bulunamaz. Ã‡Ã¼nkÃ¼ makinemizi beslediÄŸimiz veri setinde de anomaliler olacaktÄ±r. AsÄ±l amacÄ±mÄ±z elimizdeki veri setini %100 doÄŸrulukla tahmin etmek deÄŸil, \"hidden truth\"a olabildiÄŸince yakÄ±nsamaktÄ±r. KarÄ±ÅŸÄ±k oldu kusura bakma, umarÄ±m anlatabilmiÅŸimdir ğŸ™‚,
4. ->  ->  TeÅŸekkÃ¼r ederim yanÄ±tÄ±n iÃ§in fotoÄŸraf anlamamda yardÄ±mcÄ± oldu..",
5. ->  ->  Rica ederim..",
6. -> epoch, batch ve batch size iÃ§in oldukÃ§a aÃ§Ä±klayÄ±cÄ± bir makale: [Link](https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/)
7. -> 2. Sorunuz iÃ§in sunu sÃ¶yleyebilirim. Korelasyon katsayÄ±sÄ± iki deÄŸiÅŸken arasÄ±ndaki iliÅŸkinin yÃ¶nÃ¼ ve derecesi hakkÄ±mda bilgi verir. Regresyon analizinde model kurarken baÄŸÄ±msÄ±z deÄŸiÅŸkenlerinizin baÄŸÄ±mlÄ± deÄŸiÅŸkenimizle ilgili olan deÄŸiÅŸkenler olmasÄ± Ã¶nemlidir. Yapilan uygulamada oda sayÄ±sÄ± ve nÃ¼fus baÄŸÄ±mlÄ±.deÄŸiÅŸkenimiz olan medyan ev deÄŸeri ile modelleri Ã§ok basarili Ã§Ä±kmamÄ±ÅŸtÄ±r. EÄŸer model anlamlÄ±ligina ve parametre tahminlerine bakilsaydi bÃ¼yÃ¼k ihtimalle anlamsÄ±z Ã§Ä±karlardÄ±.DolayÄ±sÄ±yla uygulamada daha sonra baÄŸÄ±mlÄ± deÄŸiÅŸkenle acaba hangi deÄŸiÅŸkenler (yani features) arasÄ±nda yakÄ±n iliÅŸki vardÄ±r sorusuna bakmak iÃ§in korelasyon incelemesi yapÄ±ldÄ±. SonuÃ§ olarak baÄŸÄ±mlÄ± deÄŸiÅŸken ile yani medyan ev deÄŸeri ile medyan gelir arasÄ±nda pozitif yÃ¶nde 0.70 lik bir iliÅŸki bulduk. Bu deÄŸiÅŸkeni modelimizde kullanabiliriz anlamÄ±na geliyor. Ã‡Ã¼nkÃ¼ 0.70 yeterli bir korelasyon olarak deÄŸerlendirilebilir.Zaten regresyon analizinin Ã¶zÃ¼ de biraz koreasyonlarla ilgilidir. BaÄŸÄ±mlÄ± deÄŸiÅŸkenimizi etkilemeyecek deÄŸiÅŸkeni modele katmanÄ±n anlamÄ± olmaz dÃ¼ÅŸÃ¼ncesindeyim. Biraz uzun oldu ama umarÄ±m faydasÄ± olur..",
    
### soru 

> quest: "Herkese merhaba. Benim kafamÄ± takÄ±lan bir soru vardÄ±. Learning rate, loss, cost function ve gradient arasÄ±nda nasÄ±l bir iliÅŸki var? Bu kavramlarÄ± tam olarak oturtmak istiyorum. CevaplarÄ±nÄ±z iÃ§in ÅŸimdiden teÅŸekkÃ¼r ederim ????",
> comments:

  
1. -> Merhaba,Yapay Zeka'da modelimizi eÄŸitir ve ilerideki tahminlerimizi bu modeli kullanarak gerÃ§ekleÅŸtiririz. Elimizde bir modelimiz olsun. Bu model evin oda sayÄ±sÄ±na gÃ¶re evin fiyatÄ±nÄ± tahmin etmeye Ã§alÄ±ÅŸsÄ±n. Modelimizi eÄŸittikten sonra modelimize oda sayÄ±sÄ± vererek bir tahminde bulunmasÄ±nÄ± isteyelim. Oda sayÄ±sÄ±nÄ±n tekabÃ¼l ettiÄŸi gerÃ§ek fiyat deÄŸeri ile modelimizin tahmin ettiÄŸi deÄŸer arasÄ±ndaki fark \"loss\" olmaktadÄ±r.Cost function ise modelimizdeki tÃ¼m tahminlerin hata oranlarÄ±nÄ± bize ortalama olarak dÃ¶ndÃ¼rÃ¼r ve biz modelimizdeki toplam hata oranÄ±nÄ± bu fonksiyon sayesinde bulabiliriz. Bir nevi modelimizin doÄŸruluÄŸudur(accuracy).Gradient Descent AlgoritmasÄ± ise bahsettiÄŸimiz bu cost function'Ä± minimize etmek iÃ§in kullanÄ±lÄ±r. Bunu da cost function deÄŸerinin derivative'ini alÄ±p theta deÄŸerinden Ã§Ä±kararak yapar. [Link](http://community.globalaihub.com/community/status/1043-1043-1586253928/#comment.2355.2369.2369) bu linte gradient descent algoritmasÄ±nÄ± ve learning rate'i anlatmaya Ã§alÄ±ÅŸtÄ±m ama Learning Rate'den de kÄ±saca bahsetmem gerekirse, Gradient Descent fonksiyonu cost function'Ä±mÄ±zÄ± minize ederken minimum deÄŸere atacaÄŸÄ± adÄ±m bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼ simgeliyor. Learning deÄŸeri Ã§ok kÃ¼Ã§Ã¼k bir deÄŸer verilirse minimuma yaklaÅŸmasÄ±, kÃ¼Ã§Ã¼k adÄ±mlar atacaÄŸÄ± iÃ§in Ã§ok uzun sÃ¼recek, eÄŸer Ã§ok bÃ¼yÃ¼k verlirse de belki minimumu aÅŸacaÄŸÄ± iÃ§in de yanlÄ±ÅŸ Ã§alÄ±ÅŸacaktÄ±r. Bu bahsettiÄŸim aÃ§Ä±klamayla ilgili  -> 'in gÃ¼zel bir Ã¶rneÄŸi de ÅŸurada mevcut: [Link](http://community.globalaihub.com/community/status/664-664-1586282486/#comment.2420.2475.2475) UmarÄ±m aÃ§Ä±klayÄ±cÄ± olmuÅŸtur. Ä°yi Ã§alÄ±ÅŸmalar.",
2. ->  Ben de kÄ±sa aÃ§Ä±klamalarÄ±nÄ± yazacaÄŸÄ±m. Cost function dediÄŸimiz aslÄ±nda modelimizin girdi ve Ã§Ä±ktÄ±larÄ± arasÄ±ndaki iliÅŸkiyi tahmin etme aÃ§Ä±sÄ±ndan ne kadar hatalÄ± olduÄŸudur. Loss dediÄŸimiz kavram ele alÄ±nan bir girdiden Ã§Ä±kan tahmin ile bu girdinin gerÃ§ek Ã§Ä±ktÄ±sÄ±(etiketi) arasÄ±ndaki fark. Learning rate : Ã–ÄŸrenme aÅŸamasÄ±nda aÄŸÄ±rlÄ±klarÄ± gÃ¼ncellerken kullanacaÄŸÄ±mÄ±z katsayÄ±, kÄ±saca ne kadar Ã¶ÄŸreneceÄŸim sorusuna lr ile cevap verilebilir.",
3. ->  Harika cevaplarÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederim. ???? Ã‡ok aÃ§Ä±klayÄ±cÄ± oldu...",
4. -> cost functionÄ± loss functionlarÄ±n toplamÄ± olarakta dÃ¼ÅŸÃ¼nebilirsin.",
5. ->  Merhabalar, bahsettiÄŸin parametreleri maliyet (cost) fonksiyonu Ã¼zerinden anlatmaya Ã§alÄ±ÅŸtÄ±m.",
    
### soru 

> quest: "Ä°yi akÅŸamlar  Benim Validation Set kÄ±smÄ±nda kafama tam oturtamadÄ±ÄŸÄ±m ÅŸeyler var. Uygulama: [Link](https://colab.research.google.com/github/google/eng-edu/blob/master/ml/cc/exercises/validation_and_test_sets.ipynb?utm_source=mlcc&amp;utm_campaign=colab-external&amp;utm_medium=referral&amp;utm_content=validation_tf2-colab&amp;hl=tr) 1) Bu uygulama kÄ±smÄ±nda neden en baÅŸta label valuelarÄ±mÄ±zÄ±  scale ediyoruz? 2)AnladÄ±ÄŸÄ±m kadarÄ±yla yapmamÄ±z gereken ÅŸey test setimizi tamamen bir kenara koymak ve model tamamen hazÄ±r olmadan kullanmamalÄ±yÄ±z. Valudation setimiz de bizim modelimizin parametrelerini daha uygun bir ÅŸekilde dÃ¼zeltmemiz iÃ§in erken test yapmamÄ±zÄ± saÄŸlÄ±yor.Fakat  neden train seti bÃ¶lmeden lossu indirgeyip testte test edip yeterli accuracy ye ulaÅŸamayÄ±nca dÃ¶nÃ¼p parametreleri deÄŸiÅŸtirmek yerine validation sete bÃ¶lÃ¼yoruz?  Onu aÃ§Ä±kcasÄ± tam anlayamadÄ±m. Not: Ã–nceden K-Fold cross validation'Ä± incelemiÅŸtim oradaki kullanÄ±mÄ± gÃ¼zeldi ama onun dÄ±ÅŸÄ±nda nasÄ±l kullanÄ±lacaÄŸÄ±nÄ± aÃ§Ä±kcasÄ± pek anlayamadÄ±m.  Åimdiden herkese teÅŸekkÃ¼r ederim.",

> comments:
  
1. ->  BilgiÄŸim kadarÄ±yla scaling veya normalizing iÅŸlemleri, verileri daha iyi ve kolay eÄŸitmemizi saÄŸlÄ±yor. Train seti bÃ¶lmeden loss'u minimize etmeye Ã§alÄ±ÅŸÄ±rsak overfitting ile karÅŸÄ±laÅŸabiliriz ve istediÄŸimiz loss ve accuracy'i test sette alamayabiliriz. En iyi modeli, validation setteki loss oranÄ±na bakÄ±p oluÅŸturuyoruz, daha sonrasÄ±nda test sette test ediyoruz. EÄŸer hala train ve validation arasÄ±ndaki loss farkÄ± Ã§oksa, test sete geÃ§meye gerek yoktur, zaten model kÃ¶tÃ¼ Ã§alÄ±ÅŸÄ±yordur. Parametreleri deÄŸiÅŸtirmek gerekir. Ä°yi gÃ¼nler.",
2. ->  1. sorunun cevabÄ± ÅŸÃ¶yle: mesela bir feature 1-10 arasÄ±nda deÄŸiÅŸiyor diÄŸeri 50-400 arasÄ±nda. bunlar modelimizi train ederken etki etme yÃ¼zdeleri daha farklÄ± oluyor. birisi daha Ã§ok etki ederken diÄŸeri daha az ediyor mesela. bu da accuracy'i dÃ¼ÅŸÃ¼rÃ¼yor. bu yÃ¼zden scale ederek etkilerini eÅŸitliyoruz..",
3. ->  Biraz geÃ§ bir yanÄ±t oldu ama ÅŸÃ¶yle dÃ¼ÅŸÃ¼nebilirsin; bir modeli eÄŸitiyorsun test ediyorsun ve Ã§Ä±kan test sonucuna gÃ¶re hyperparametreleri tune ediyorsun. Bunu loss deÄŸerin iyice dÃ¼ÅŸene kadar tekrar tekrar yapÄ±yorsun. Bu durum overfitting tehlikesini barÄ±ndÄ±rÄ±r. Ã‡Ã¼nkÃ¼ modelini test sete gÃ¶re ayarlÄ±yorsun aslÄ±nda. KuÅŸlarÄ± tanÄ±yan bir modelin olduÄŸunu dÃ¼ÅŸÃ¼n ve dikkat etmeyip test setine Ã§oÄŸunlukla papaÄŸan resimleri koyduysan bu sefer modelini sÃ¼rekli papaÄŸanlarÄ± tanÄ±mak iÃ§in tune ettiÄŸinden modeli load edip kullanmayÄ± denediÄŸinde farklÄ± kuÅŸ tÃ¼rlerini tanÄ±madÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼rsÃ¼n. Bu tabii uÃ§ bir Ã¶rnek ama yine de nasÄ±l overfittinge yol aÃ§aÄŸÄ±nÄ± gÃ¶zlemlemek bu yoldan mÃ¼mkÃ¼n. YanlÄ±ÅŸÄ±m olabilir..",
    
### soru 

> quest: "Merhaba,  Gradient descent algoritmasÄ±nda dataseti batchlere ayÄ±rdÄ±ktan sonra modele soktuÄŸumuzda her batch'in iÅŸlenmesinden sonra weight deÄŸeri gÃ¼ncelleniyor mu?  Yoksa tek seferde sokmuÅŸusuz gibi en son gÃ¼ncelleniyor, sadece dataseti parÃ§alar halinde iÅŸlemiÅŸ mi oluyoruz? EÄŸer bÃ¶yleyse bathe bÃ¶lmemiz nasÄ±l bir fark yaratabiliyor tek seferde deÄŸerlendirmekten?",
> comments:

1. ->  Merhaba, Evet, gÃ¼ncelleniyor. Mini-batch'lere ayÄ±rmamÄ±zÄ±n amacÄ± elimizde bÃ¼yÃ¼k bir veri seti olduÄŸu dÃ¼ÅŸÃ¼nÃ¼lÃ¼rse(1 milyon Ã¶rnekten oluÅŸan) mini-batch'lere ayÄ±rmak yerine, weight ve bias deÄŸerlerimizi bir kere gÃ¼ncellemek iÃ§in tÃ¼m veriyi iÅŸlemeye Ã§alÄ±ÅŸÄ±rsak loss deÄŸerimizi minimize etmek Ã§ok Ã§ok fazla zaman alabilir. Bu yÃ¼zden daha kÃ¼Ã§Ã¼k parÃ§alara ayÄ±rÄ±p o ÅŸekilde parametreleri gÃ¼ncellemek daha hÄ±zlÄ± ve efektif oluyor.",
2. ->  \"if the batch size is 6, then the system recalculates the model's loss value and adjusts the model's weights and bias after processing every 6 examples.\" (bu CÃ¼mle 12 verilik bir veri seti iÃ§in SÃ¶ylenmiÅŸ yani tamamÄ±nÄ± almÄ±yor , 6 - 6 iÅŸliyor) First Steps With TF pratik kÄ±smÄ±nda yazan cÃ¼mleye gore, batch_size a baÄŸlÄ± olarak aÄŸÄ±rlÄ±klar gÃ¼ncellenmekte. Bu egzersizde her ÅŸey Ã§ok daha net hale geliyor. Ä°yi Ã§alÄ±ÅŸmalar.,
3. -> ->  TeÅŸekkÃ¼r ederim ????  ->  GÃ¶zden kaÃ§Ä±rmÄ±ÅŸÄ±m teÅŸekkÃ¼r ederim ğŸ™‚",

### soru 

> quest: "Ä°yi AkÅŸamlar,  Task 4: Find the ideal combination of epochs and learning rate kÄ±smÄ±nda: learning_rate= 10  # Replace ? with a floating-point number epochs= 10   # Replace ? with an integer  Bu deÄŸerler ile label*feature grafiÄŸinde sorunun altÄ±ndaki solution kÄ±smÄ± ile benzer grafiÄŸi elde ediyorum. Ancak loss grafiÄŸinde bir anlÄ±k tepe deÄŸeri yapÄ±p ardÄ±ndan sÄ±fÄ±ra ulaÅŸÄ±yor. Bu durum yanÄ±ttan farklÄ±. BÃ¶yle bir durumun gerÃ§ek hayattaki projelerde etkisi kazanÃ§ veya zarar aÃ§Ä±sÄ±nda durumu ne olur ? Bir de okurken gÃ¶zden de kaÃ§Ä±rmÄ±ÅŸ olabilirim kayÄ±p grafiÄŸinin bu ÅŸekilde deÄŸil de bir parabol tarzÄ±nda olup alÃ§alan ÅŸekilde olmasÄ±nÄ±n gerekliliÄŸi neden ?   TeÅŸekkÃ¼r ederim",

> comments:
  
1. ->  Muhtemelen learning rate deÄŸeri 10 olduÄŸundan parametreleri (aÄŸÄ±rlÄ±k ve bias) gÃ¼ncellerken adÄ±m sayÄ±sÄ± bÃ¼yÃ¼k olduÄŸu iÃ§in yerel minimum noktasÄ±ndan daha uzaÄŸa gitmiÅŸtir. O sÄ±Ã§rama onu gÃ¶sterir. Genellikle learning rate oranÄ± daha kÃ¼Ã§Ã¼k seÃ§ilir. Ã–rneÄŸin 0.001 veya 0.01 gibi.",
2. -> GerÃ§ek hayatta bir hedefin olduÄŸunu dÃ¼ÅŸÃ¼n (Ã¶rneÄŸin bir bakkal) .Sen ve bakkalÄ±n arasÄ±ndaki mesafe 200 metre olsun learning rate aynÄ± zamanda bir anlamda senin adÄ±m boyutun oluyor sen bakkala giderken learning rate'in Ã§ok yÃ¼ksekse sen 200 metre sonra durman gerekirken bakkalÄ± geÃ§ip gidiyorsun 300 metre ilerliyorsun mesela. Bu sefer bakkala ulaÅŸabilmek iÃ§in geriye gitmen gerekiyor geri dÃ¶nerken 100m geri gitmen gerekir ki(yani bu sefer baÅŸlangÄ±Ã§taki yÃ¶nÃ¼nÃ¼n tersine bakkalÄ± geÃ§tiÄŸin iÃ§in geri dÃ¶nÃ¼p bakkala doÄŸru) bakkala ulaÅŸabil ama sen yine adÄ±m boyun cok yÃ¼ksek olduÄŸu iÃ§in 150m gidip yine bakkalÄ± geÃ§iyorsun. AslÄ±nda sen 450m yol aldÄ±ÄŸÄ±n halde 200mlik hedefe bir tÃ¼rlÃ¼ ulaÅŸamadÄ±n Ã§Ã¼nkÃ¼ learning rate'in (adÄ±m boyun) Ã§ok yÃ¼ksek bunun iÃ§in bÃ¶yle bÃ¼yÃ¼k adÄ±m atarak hedefi tutturmaya Ã§alÄ±ÅŸmak yerine daha kÃ¼Ã§Ã¼k adÄ±mlarla daha uygun bir ÅŸekilde yaklaÅŸmaya Ã§alÄ±ÅŸÄ±yoruz. AyrÄ±ca burada Learning Rate' i deÄŸiÅŸtirip gÃ¶zlemlersen daha kalÄ±cÄ± olabilir gÃ¼zel anlatamamÄ±ÅŸ olabilrim. ğŸ™‚ [Reducing Loss: Optimizing Learning Rate](https://developers.google.com/machine-learning/crash-course/fitter/graph)
3. -> \"KayÄ±p grafiÄŸinin bu ÅŸekilde deÄŸil de bir parabol tarzÄ±nda olup alÃ§alan ÅŸekilde olmasÄ±nÄ±n gerekliliÄŸi neden ? \" kaybÄ± en aza indirirken belli bir deÄŸer aralÄ±klarÄ±nda weight - loss kontrolleri yapmamÄ±z isteniyor (learning rate) , aÅŸÄ±rÄ± sÄ±Ã§ramalardan kaÃ§Ä±nmak (yoldan Ã§Ä±kmamak) iÃ§in learning rate i Ã§ok yÃ¼ksek seÃ§miyor, aynÄ± zamanda modelimizin ilerleyebilmesi iÃ§in de aÅŸÄ±rÄ± dÃ¼ÅŸÃ¼k deÄŸerler seÃ§mekten kaÃ§Ä±nÄ±yoruz. Ä°ÅŸte bu yaklaÅŸÄ±mÄ± gÃ¶rselleÅŸtirdiÄŸimizde parabolik azalmayÄ± gÃ¶zÃ¼mÃ¼zde canlandÄ±rabiliriz. Bu arada Modelimiz her iterasyonda aÄŸÄ±rlÄ±k deÄŸerlerini kontrol ederken optimum deÄŸerleri kullanmaya Ã§alÄ±ÅŸÄ±yoruz. Bu deÄŸerler \"data dependent\" olduÄŸundan ve kesin bir \"learning rate - epoch - batch_size\" belirlenemeyeceÄŸinden bahsediyor kursta ama \"summary\" kÄ±smÄ±ndaki genel Ã¶nerilerin gÃ¼zel aÃ§Ä±klandÄ±ÄŸÄ±nÄ± ve ilerleyen iÃ§eriklerde de Ã§ok iÅŸimize yarayacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum. EÄŸer yanlÄ±ÅŸÄ±m varsa lÃ¼tfen dÃ¼zeltin. Ä°yi Ã‡alÄ±ÅŸmalar..",
4. ->  \"KayÄ±p grafiÄŸinin bu ÅŸekilde deÄŸil de bir parabol tarzÄ±nda olup alÃ§alan ÅŸekilde olmasÄ±nÄ±n gerekliliÄŸi neden ? \" bu soru benimde aklÄ±ma takÄ±lmÄ±ÅŸtÄ±. ->  a ek olarak ÅŸÃ¶yle bir Ã§Ã¶zÃ¼m buldum ama ne kadar doÄŸru bilmiyorum. Loss eÄŸrisini Ã§izerkenki deÄŸiÅŸkenimiz w. Burada w ikinci dereceden bir deÄŸiÅŸken ve kat sayÄ±sÄ± pozitif. Bundan dolayÄ±da Ã§izdiÄŸimiz grafiÄŸin ÅŸekli yukarÄ± yÃ¶nlÃ¼ bir parabol olacaktÄ±r diye dÃ¼ÅŸÃ¼nÃ¼yorum..",
"Mesut YÄ±lmaz ->  selam. Loss function da sabit olan, y' deÄŸil de y olmasÄ± gerekiyor. Yani y dediÄŸimiz, desired (wx+b sonucunda Ã§Ä±kmasÄ±nÄ± istediÄŸimiz) deÄŸer yani diÄŸer bir deyiÅŸle label'Ä±mÄ±z ve y' ise wx+b sonucunda tahmin ettiÄŸimiz deÄŸerdir. Ã–zetle loss bulurken yaptÄ±ÄŸÄ±mÄ±z ÅŸey, olmasÄ± gereken deÄŸere o anki w ve b ile ne kadar uzaÄŸÄ±z bunu bulmak. Ã‡Ä±kan farka gÃ¶re w ve b'yi gÃ¼ncelleyip bu ÅŸekilde devam edeceÄŸiz. YanlÄ±ÅŸÄ±m varsa dÃ¼zeltin lÃ¼tfen..",
5. ->  Evet orada bir hata olmuÅŸ, teÅŸekkÃ¼r ederim. Ancak w^2 nin katsayÄ±sÄ± yinede pozitif oluyor..",
6. -> CevaplarÄ±nÄ±z ve ilginiz iÃ§in teÅŸekkÃ¼r ederim. BugÃ¼n bir daha inceleyeceÄŸim.",
    
### soru 

> quest: "Merhabalar, merak ettiÄŸim ÅŸey eÄŸitimin iÃ§indeki kodlama pratiÄŸi ile alakalÄ±... Acaba sÄ±navda bu modellerin tamamen kurulup, kodlanmasÄ± mÄ± istenecek yoksa daha Ã§ok yorumlama Ã¼zerine mi olacak?   Birde, bu resimde seÃ§tiÄŸim alanÄ± anlayamadÄ±m, bias bir hata deÄŸeri deÄŸil mi? neden eÄŸitiliyor?, SanÄ±rÄ±m o kÄ±sÄ±mda bir eksiklik seziyorum kendimde... Åimdiden teÅŸekkÃ¼r ederim cevaplarÄ±nÄ±z iÃ§in...",

> comments:
  
1. ->  BildiÄŸim kadarÄ±yla birden fazla bias kavramÄ± var. [Link](https://developers.google.com/machine-learning/glossary#bias) bu linkteki bias kavramlarÄ±na bakabilirsin. Belki yardmcÄ± olur.",
"Machine Learning Glossary Â |Â  Google Developersdevelopers.google.comCompilation of key machine-learning and TensorFlow terms, with beginner-friendly definitions..",
2. ->  Merhaba,Buradaki bias deÄŸeri sanÄ±rsam hipotez denklemimizdeki(basit lineer regresyon denklemi -> h(x)=theta0+theta1.x) theta0 deÄŸeri yani grafiÄŸimizdeki Ã§izilen doÄŸrunun orgiirn noktasÄ±na olan uzaklÄ±ÄŸÄ±. Ã–rneÄŸin bias deÄŸerim yani theta0 deÄŸerim 1 olursa grafikteki doÄŸru y eksenini 1 noktasÄ±nda keser. (tam Ã§izmeyi beceremesem de resimdeki gibi). Bias'Ä±n amacÄ± bildiÄŸim kadarÄ± ile daha iyi genellememize ve modelimizi tek bir veri noktasÄ±na daha az duyarlÄ± hale getirmemize yardÄ±mcÄ± olmasÄ±dÄ±r.",
3. ->  bias terimi olmadan model orjinden geÃ§meye zorlanacaÄŸÄ± iÃ§in veriye uyumu dÃ¼ÅŸecektir. Bias terimi eklemek ve eÄŸitmek daha becerikli modeller Ã¼retmemize olanak saÄŸlÄ±yor.",
4. -> ->  Yani bu bias deÄŸerleri de eÄŸitiliyor. Benim anlamadÄ±ÄŸÄ±m asÄ±l nokta buydu aslÄ±nda....",
5. ->  Bias deÄŸeri y eksenini kestiÄŸi noktadÄ±r. ML de basit bir Ã¶rnek verecek olursak Linear Regression modelinin formÃ¼lÃ¼ y=b+wx dir. b=bias w=katsayÄ± x=baÄŸÄ±msÄ±z deÄŸiÅŸken y= baÄŸÄ±mlÄ± deÄŸiÅŸkendir. MaaÅŸ ve tecrÃ¼be adÄ±nda iki sÃ¼tunumuz olsun. EÄŸitilsin. 5 yÄ±llÄ±k tecrÃ¼beye sahip birisi kaÃ§ lira maaÅŸ alÄ±r diye sorumuz olsun. bias deÄŸerimiz 50, w deÄŸeri 1023 olsun. y=50+1023*5 y=5165 deÄŸerini buluruz..",
6. ->  Bu konu aslÄ±nda \"Descending into ML\" kÄ±smÄ±nÄ±n video dersinde(3/5) grafikle anlatÄ±lmÄ±ÅŸ bi daha izlemeni tavsiye ederim . AyrÄ±ca [Link](https://www.linkedin.com/pulse/derin-%C3%B6%C4%9Frenme-uygulamalar%C4%B1nda-temel-kavramlar-skor-ve-%C3%A7arkac%C4%B1/) bu yazÄ±yÄ± da inceleyebilirsin ğŸ™‚",
"Derin Ã¶ÄŸrenme uygulamalarÄ±nda temel kavramlar : perceptron, skor fonksiyonu ve hata hesaplamasÄ±(loss function)www.linkedin.comPerceptron ve Lineer FonksiyonlarÂ  Lineer fonksiyonlar, y = W.x+ b ÅŸeklinde tanÄ±mlanan fonksiyonlardÄ±r..",
7. -> Emekleriniz ve cevaplarÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederim....",
    
### soru 

> quest: "Merhaba iyi akÅŸamlar Ã§ok kÄ±sa ve basit bir soru soracaÄŸÄ±m.Kursun baÅŸÄ±nda lineer regresyondaki kesme parametresi olarak verilen bias parametresi bizim ileride bias variance trade off yapÄ±caÄŸÄ±mÄ±z bias ile aynÄ± kavram mÄ± ? AynÄ± ise iliÅŸkisini anlayamadÄ±m teÅŸekkÃ¼r ederim.",

> comments:
  
1. -> Bir Ã¼stteki soruda ÅŸu ÅŸekilde cevap verilmiÅŸ bu soruya sanÄ±rÄ±m gÃ¶zÃ¼nÃ¼zden kaÃ§tÄ±:\"Buradaki bias deÄŸeri sanÄ±rsam hipotez denklemimizdeki(basit lineer regresyon denklemi -> h(x)=theta0+theta1.x) theta0 deÄŸeri yani grafiÄŸimizdeki Ã§izilen doÄŸrunun orgiirn noktasÄ±na olan uzaklÄ±ÄŸÄ±. Ã–rneÄŸin bias deÄŸerim yani theta0 deÄŸerim 1 olursa grafikteki doÄŸru y eksenini 1 noktasÄ±nda keser. (tam Ã§izmeyi beceremesem de resimdeki gibi). Bias'Ä±n amacÄ± bildiÄŸim kadarÄ± ile daha iyi genellememize ve modelimizi tek bir veri noktasÄ±na daha az duyarlÄ± hale getirmemize yardÄ±mcÄ± olmasÄ±dÄ±r.\".",
2. -> Merhaba Berk, Ä°kisi farklÄ± ÅŸeyler anladÄ±ÄŸÄ±m kadarÄ±yla. Ä°lki sadece parametre. Yani y=ax denklemini dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼mÃ¼zde bu denklem orijinden geÃ§ecektir. Lakin verilen data illa orijinden geÃ§mesi, her dataya uyum saÄŸlamayan doÄŸrular olacaÄŸÄ±ndan bias parametresi dediÄŸimiz Ã¶rn; y=ax+b gibi bir b (bias) ekliyoruz.Trade off ta kullanÄ±lan bias ise verinin Ã¶ÄŸrenilip Ã¶ÄŸrenilemediÄŸi ile ilgili..",
    
### soru 

> quest: "Merhabalar  Validation setin anlatÄ±ldÄ±ÄŸÄ± exerciseda validation set, training setin iÃ§inden ayrÄ±larak oluÅŸturulmuÅŸ. Benim Ã¶nceden Ã§alÄ±ÅŸtÄ±ÄŸÄ±m Andrew NG'in yapmÄ±ÅŸ olduÄŸu baÅŸka bir courseda Andrew hoca Ã¼zerine basa basa dev test ile test setin aynÄ± distributiondan gelmesi gerektiÄŸini belirtmiÅŸti her zaman. Benim bu noktada biraz kafam karÄ±ÅŸtÄ± aydÄ±nlatabilir misiniz?",

> comments:
  
1. ->  Merhaba, training setin iÃ§inden ayrÄ±larak oluÅŸturulmasÄ±, test ile validation set'in farklÄ± distributionlara sahip olmasÄ± anlamÄ±na gelmiyor. FotoÄŸraf verilerimiz olduÄŸunu dÃ¼ÅŸÃ¼nelim. Training setimiz telefon kamerasÄ±yla Ã§ekilen fotoÄŸraflardan oluÅŸuyor olsun. Validation setimizi de ordan ayÄ±rÄ±p oluÅŸturduk diyelim. Test setimizdeki veriler de telefon kamerasÄ±yla Ã§ekilmiÅŸ fotoÄŸraflardan oluÅŸuyorsa aynÄ± distribution'a sahip olmuÅŸ oluyorlar. Bence burada andrew ng'nin sÃ¶zÃ¼nÃ¼ inkar eden bir durum yok. (FotoÄŸraf Ã¶rneÄŸini ben de andrew ng'den gÃ¶rmÃ¼ÅŸtÃ¼m :)).",
2. ->  ->  DoÄŸru diyorsunuz ben de dÃ¼ÅŸÃ¼ndÃ¼m ancak testset yerine train setten ayÄ±rÄ±nca acaba bilmediÄŸim bir ÅŸey mi var diye dÃ¼ÅŸÃ¼ndÃ¼m. TeÅŸekkÃ¼r ederim ğŸ™‚.",
3. ->  ->  Supervised Learnin iÃ§in sÃ¶ylÃ¼yorum, test setinde label bulunmadÄ±ÄŸÄ± iÃ§in train setimizi train-test olarak ayÄ±rarak geliÅŸtirdiÄŸimiz modelin etkinliÄŸini test ediyoruz..",
4. ->  Train setimizi bÃ¶lerek test ve validation setlerini oluÅŸtururuz. Model eÄŸitilirlen test setini kullanarak val_acc ve val_loss gibi deÄŸerlerinie bakarak modelin etkinliÄŸini gÃ¶rebiliriz. Model eÄŸitimi bittikten sonra test setini kullanarak gerÃ§ek hayattaki Ã¶rnekleri tahmin/sÄ±nÄ±flandÄ±rma performansÄ±na bakarÄ±z..",
    
### soru 

> quest: "Merhabalar  gradient   magnitude'Ä±n ne olduÄŸunu tam anlamÄ±yla anlayamadÄ±m.Bu hazÄ±rladÄ±ÄŸÄ±mÄ±z modelin aÄŸÄ±rlÄ±ÄŸÄ± mÄ±dÄ±r yoksa farklÄ± bir ÅŸey midir ve bir de gradient magnitude ile learning rate arasÄ±ndaki iliÅŸki nasÄ±ldÄ±r ?  teÅŸekkÃ¼rler,",

> comments:
  
1. ->  Gradient deÄŸiÅŸimi ifade ediyor. Magnitude ise deÄŸiÅŸimin bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼ ifade ediyor. Learning rate fazla olduÄŸunda her bir iterasyonda grafik Ã¼zerinde minimuma (eÄŸimin 0 olduÄŸu nokta) ulaÅŸmaya Ã§alÄ±ÅŸÄ±rken daha bÃ¼yÃ¼k adÄ±mlar atacaÄŸÄ±mÄ±z iÃ§in; gradient magnitude ile learning rate doÄŸru orantÄ±lÄ± olmuÅŸ oluyor. Fakat deÄŸiÅŸimin fazla olmasÄ± her zaman iyi sonuÃ§lar vermeyebilir.",
2. -> deÄŸiÅŸimin fazla olmasÄ±, eÄŸimin sÄ±fÄ±r olduÄŸu noktayÄ± kaÃ§Ä±racaÄŸÄ±n anlamÄ±na gelebilir..",
3. ->  TeÅŸekkÃ¼r ederim.",
    
### soru 
> quest: "Merhaba. AnladÄ±ÄŸÄ±m kadarÄ± ile overfitting modelimizin verdiÄŸimiz training datasÄ±na Ã§ok yakÄ±n tahminler yapmaya Ã§alÄ±ÅŸmasÄ± ve bir bakÄ±ma predict yaparken kullanacaÄŸÄ± datanÄ±n da benzer Ã¶zelliklerde olacaÄŸÄ± yÃ¶nÃ¼nde bir Ã¶nyargÄ± oluÅŸturmasÄ±. Bunun Ã¶nÃ¼ne geÃ§mek iÃ§in data setimizi bir takÄ±m distrubition kurallarÄ±na gÃ¶re train ve test olarak ayÄ±rmamÄ±z gerektiÄŸi anlatÄ±lÄ±yor. Ancak overfitting'in nasÄ±l oluÅŸtuÄŸunu tam olarak oturtamadÄ±m. Biraz daha ayrÄ±ntÄ±lÄ± bir cevap alabilir miyim?",

> comments:
  
1. -> Merhabalar. Overfitting, oluÅŸturulan modeller iÃ§in Ã¶nlem alÄ±nmasÄ± gereken problemlerin baÅŸÄ±nda yer alanlardan birisidir. Modeli eÄŸitirken her ne kadar shuffle yÃ¶ntemiyle veriler karÄ±ÅŸtÄ±rÄ±larak eÄŸitime sunulsa da, her bir Ã§evrimde yapÄ±lan denemeler sonrasÄ±nda bir sÃ¼re sonra modelin veriye aÅŸÄ±rÄ± uyum saÄŸlayacaÄŸÄ±, yani veriyi ezberleyeceÄŸi belirtiliyor. Bu durumda model Ã§ok baÅŸarÄ±lÄ± sonuÃ§lar Ã¼retebiliyor. Siz de modelin %99 oranÄ±nda baÅŸarÄ±lÄ± olduÄŸu gibi oranlar gÃ¶rebiliyorsunuz. Gelin gÃ¶rÃ¼n ki model, eÄŸitildiÄŸi veri setini ezberlediÄŸi iÃ§in o oranlara ulaÅŸÄ±yor. Bir nevi input deÄŸerlerine (her bir x iÃ§in) karÅŸÄ±lÄ±k gelecek aÄŸÄ±rlÄ±k (w) deÄŸerlerini ezberliyor da diyebiliriz. Ancak problem, modelin daha Ã¶nce hiÃ§ gÃ¶rmediÄŸi veri setinde ortaya Ã§Ä±kÄ±yor. Ã‡oÄŸu kiÅŸinin de Ã¼zerinde hemfikir olduÄŸu nokta, overfitting gerÃ§ekleÅŸmiÅŸ olan modellerin, diÄŸer modellerde aynÄ± baÅŸarÄ±mÄ± gerÃ§ekleÅŸtirmediÄŸi. Bunun iÃ§in ilk olarak, train ve test ayrÄ±mlarÄ± gerÃ§ekleÅŸtirildi. AnlatÄ±mda da gÃ¶rÃ¼ldÃ¼ÄŸÃ¼ Ã¼zere daha karmaÅŸÄ±k veri kÃ¼melerinde bu da yeterli olmadÄ±ÄŸÄ± iÃ§in, bu defa train-validation-test iÅŸlemi gerÃ§ekleÅŸtiriliyor. ÅÃ¶yle aÃ§Ä±klayayÄ±m:Elimizde 1000 veri olsun. Bunun 100-200 arasÄ±nda bir veriyi ayÄ±rÄ±yoruz ve modele hiÃ§ sokmuyoruz. Bu ayrÄ±m sÄ±rasÄ±nda elinizdeki sÄ±nÄ±flarÄ±n oranÄ±nÄ± korursanÄ±z iyi olur. Geriye kalan 800 veri iÃ§erisinden de yine %80-%20 gibi train ve validation verilerini ayÄ±rarak modelimizi eÄŸitiyoruz. Optimum sonuca ulaÅŸÄ±nca da modeli hiÃ§ gÃ¶rmediÄŸi veri Ã¼zerinde deniyoruz.TÃ¼m bunlar modelin elimizdeki veriyi ezberleyerek (bir nevi suni) yÃ¼ksek oranda baÅŸarÄ±m gÃ¶sterdiÄŸini beyan etmesinin Ã¶nÃ¼ne geÃ§ilmesi iÃ§in yapÄ±lÄ±yor. Kendi modelinizde de train sÄ±rasÄ±nda baktÄ±nÄ±z %100 baÅŸarÄ±ma ulaÅŸmaya baÅŸladÄ±, modeli gÃ¶zden geÃ§irmenizde fayda var.Hepimize iyi kurslar diliyorum.",
2. -> Merhaba,Overfitting'i [Link](https://medium.com/data-science-tr/overfitting-underfitting-cross-validation-b47dfda0cf4e) sitesinden alÄ±ntÄ±layacaÄŸÄ±m ÅŸu durumla aÃ§Ä±klayabilirim:\"3 gÃ¼n sonra istatistik sÄ±navÄ±na gireceÄŸinizi dÃ¼ÅŸÃ¼nÃ¼n. GeÃ§miÅŸ 10 yÄ±lÄ±n sorularÄ±nÄ±n olduÄŸu bir arÅŸiv var elinizde, sÄ±navÄ±n geÃ§miÅŸ senelere benzeyeceÄŸini dÃ¼ÅŸÃ¼nÃ¼yorsunuz ve bÃ¼tÃ¼n sorularÄ±-cevaplarÄ± ezberliyorsunuz.Burada eÄŸitim seti geÃ§miÅŸ 10 yÄ±lÄ±n sorularÄ±, model sÄ±navÄ±n geÃ§miÅŸ senelere benzeyeceÄŸini dÃ¼ÅŸÃ¼nmeniz, test seti hiÃ§ gÃ¶rmediÄŸimiz istatistik sÄ±navÄ±, baÅŸarÄ± kriteri aldÄ±ÄŸÄ±nÄ±z not. SÄ±nav sorularÄ± beklendiÄŸiniz gibi gelmez de kÃ¶tÃ¼ not alÄ±rsanÄ±z bu olaya overfitting denir.\"Bu aÃ§Ä±klamaya gÃ¶re eÄŸer modelimiz eÄŸitim iÃ§in kullandÄ±ÄŸÄ±mÄ±z veri setimiz Ã¼zerinde gereÄŸinden fazla Ã§alÄ±ÅŸÄ±p artÄ±k ezber yapmaya baÅŸlamÄ±ÅŸsa overfit oluÅŸur. Tabii overfit oluÅŸturan baÅŸka durumlar da vardÄ±r. (AÅŸaÄŸÄ±da aÃ§Ä±kladÄ±m.)Overfitting olduÄŸunda tahminler eÄŸitim veri seti iÃ§in harika sonuÃ§lar verirler ama eÄŸitim veri setinde olmayan durumlarla karÅŸÄ±laÅŸtÄ±klarÄ±nda nasÄ±l davranmasÄ± gerektiklerini bilmeyeceklerin bu pek efektif olmaz. Bizim amacÄ±mÄ±zda zaten eÄŸitim veri setinde olmayan deÄŸerleri tahmin edebilmek.Overfit oluÅŸturabilecek durumlar arasÄ±nda aÅŸaÄŸÄ±dakiler yer alabilir:1.Modelimiz Ã§ok karmaÅŸÄ±ktÄ±r ve gÃ¶zlem sayÄ±sÄ±ndan Ã§ok parametremiz vardÄ±r.2.Verisetimizde az eÄŸitim verisi vardÄ±r3. EÄŸitimi sÄ±rasÄ±nda o kadar Ã§ok iterasyon yapÄ±lmÄ±ÅŸtÄ±r ki eÄŸitim loss'umuz 0'a Ã§ok yaklaÅŸmÄ±ÅŸtÄ±r.Ne yapÄ±labilir?:1. Feature sayÄ±mÄ±zÄ± azaltmak. Birbirileri ile olan korelasyonu yÃ¼ksek kolonlar silinebilir veya bu deaturelarÄ± kullanarak yeni featurelar oluÅŸturulabilir (Ã–rneÄŸin veri setinizde bir evin geniÅŸliÄŸi ve bri evin yÃ¼ksekliÄŸi featurelarÄ± var ise bu iki feature deÄŸerini Ã§arpÄ±p alan feature'Ä± oluÅŸturabilirsiniz.)2.Verisetimize daha fazla veri ekleyebiliriz.3.RegÃ¼larizasyon(Regularization) yapabiliriz.Hatam veya yanlÄ±ÅŸÄ±m var ise dÃ¼zeltmelere aÃ§Ä±ÄŸÄ±m ğŸ™‚ Ä°yi Ã§alÄ±ÅŸmalar dilerim.",
"Makine Ã–ÄŸrenmesi Dersleri 8: Cross Validationmedium.comOverfitting (High Variance).",
3. ->  Merhaba Atilla. -> 'Ä±n da sÃ¶ylediÄŸi gibi overfitting, modelimizin train datasÄ±ndaki verilerden Ã¶grenirken en ince ayrÄ±ntÄ±sÄ±na kadar Ã¶grenmesi, aÅŸÄ±rÄ±ya kaÃ§masÄ± diyebiliriz. Ama bizim model oluÅŸtururken aradÄ±mÄ±z ÅŸey optimum deger olmalÄ± aksi takdirde test datamÄ±zdaki birÃ§ok veri modelimize %90 uysa bile %10'luk kÄ±smÄ± yÃ¼zÃ¼nden ki bu overfitting yÃ¼zÃ¼nden oldugunu varsayÄ±yorum yanlÄ±ÅŸ kabul edilecek ve baÅŸarÄ± oranÄ± hep %10 larda kalÄ±caktÄ±r. Bu olayÄ±n tam terside olabilir(Underfitting). Iterasyon tablosunda accuracy degerine bakarak en uygun model tÃ¼rÃ¼nÃ¼ belirlemek daha kolay olacaktÄ±r..",
4. ->  CevaplarÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederim.",
5. ->  Kurs hakkÄ±nda bir sorum daha olacak. Kodlar kurs boyunca hep bu ÅŸekilde (sadece dÃ¼zenleme yapacaÄŸÄ±mÄ±z yerler aÃ§Ä±k ve bloklarÄ±n iÅŸlevleri yazÄ±yor) mi devam ediyor yoksa sonraki derslerde kodlarÄ±n, kullanÄ±lan fonksiyonlarÄ±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±na dair aÃ§Ä±klamalarÄ± da var mÄ±? BazÄ± derslere baktÄ±m ama gÃ¶remedim.",
6. ->  Verilen cevaplar pasta gibi Ã¼stÃ¼ne bir de Ã§ilek ekleyelim.",
7. ->  Overfitting oluÅŸmasÄ±nÄ±nÄ± temel sebepleri ÅŸunlardÄ±r. Veri sayÄ±sÄ±nÄ±nÄ±z ve Ã§eÅŸitliliÄŸi az olmasÄ±, bias ve variance nin yÃ¼ksek veya dÃ¼ÅŸÃ¼k olmasÄ±, modelin karmaÅŸÄ±klÄ±ÄŸÄ± yÃ¼ksek olmasÄ±dÄ±r. Overfitting problemini Ã§Ã¶zmek iÃ§in genellikle kullanÄ±lan yÃ¶ntemler ÅŸunlardÄ±r; Data Augmentation (Veri ArttÄ±rma) yÃ¶ntemini kullanarak verilerin sayÄ±sÄ±nÄ± arttÄ±rabiliriz. Modelimizi Ã§ok karmaÅŸÄ±k deÄŸilde basit ÅŸekilde tutabilirsek overfitting engellenmiÅŸ olur. DiÄŸer bir yÃ¶ntem ise modelin train loss un azaldÄ±ÄŸÄ± validation loss un arttÄ±ÄŸÄ± epochda eÄŸitimin durdurulmasÄ±dÄ±r. Train Test Validation setlerinin oranÄ±nÄ± deÄŸiÅŸtirebiliriz. Mesela %70 Train %15 Validation %15 Test olarak ayÄ±rabiliriz. Train boyutunu Ã§ok tutmamak lazÄ±mdÄ±r..",
8. ->  BazÄ± durumlarda yÃ¼ksek epoch sayÄ±sÄ±nÄ±n fazla olmasÄ± overfitting durumu yaratabilir, ezberlemeyi engelleyebilmek iÃ§in epoch sayÄ±sÄ±nÄ± dÃ¼zgÃ¼n ayarlamak gerekiyor ayrÄ±ca katmanlar arasÄ±ndaki geÃ§iÅŸleri azaltarak ezberlemenin Ã¶nÃ¼ne geÃ§ilebilir. Bunun iÃ§in dropout deÄŸerinin dÃ¼zgÃ¼n belirlenmesi gerekir..",
9. ->  Bir ornek vererek aciklayayim.Bir ogerenciye matematikte belli bir soru seklini ogrettigimizi varsayalim.Bir kac ornek verdik anlattik, ogrencinin gayet iyi anladigini gorduk(training).Sonra ayni soru sekli uzerinde sadece sayilari degistirdik ogrenci soruyu cozebildi(validation).Son olarak sorunun seklini verdigimiz ornekler ogrenci tarafindan gercekten anlasildiysa cozebilecegi seviyede degistirdik, gorduk ki ogrenci yapamadi, hatta soruya dogru bile yaklasamadi.(Test)Yani verdigimiz ornekleri gercekten anlamamis, ezberlemis(overfitting).",
1. ->  Overfittingin temel sebebi modelinizdeki layer sayisi arttikca model derinlesir yani complex hale gelir.Kucuk bir training seti bu complex modeli train etmek icin kullanirsaniz kotu generalization yani overfitting meydana gelir.Bunun ustesinden L2 Regularization ve/veya Dropout(ayni anda kullanilmasi tavsiye edilemz) kullanarak gelinebilir..",
    
### soru 

> quest: "[Link](http://community.globalaihub.com/community/status/1028-1028-1586434538)) yazdÄ±ÄŸÄ±m gibi sadece epoch deÄŸerleri ile oynayarak  loss/rmse grafiÄŸininin eÄŸimini sÄ±fÄ±ra yaklaÅŸtÄ±rabiliyoruz   Ancak ilerleyen Ã¶rneklerde Task 4: Find the ideal combination of epochs and learning rate [Link](https://colab.research.google.com/github/google/eng-edu/blob/master/ml/cc/exercises/linear_regression_with_synthetic_data.ipynb#scrollTo=r63YkMx82WVr) ve Task 5: Adjust the batch Size [Link](https://colab.research.google.com/github/google/eng-edu/blob/master/ml/cc/exercises/linear_regression_with_synthetic_data.ipynb#scrollTo=0NDET9e6AAbA) Ã–rneklerinde olduÄŸu gibi   Learning rate  Epochs batch_size   parametrelerini deÄŸiÅŸtirerek farklÄ± grafikler elde edebiliyoruzâ€¦.  YapÄ±lan Ã¶rnekler simple linear regression olmasÄ±ndan dolayÄ±, feature/label grafiklerinde kÄ±rmÄ±zÄ± Ã§izginin mavi Ã§izgilerin Ã¼zerine oturmasÄ± ya da hatayÄ± minimize edecek ÅŸekilde oturmasÄ±na dikkat ettiÄŸimiz durumlarda bile;   1. yalnÄ±zca epochs deÄŸerini ayarlayarak Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±mÄ±z Ã¶rneklerde; epoch deÄŸeri 300 lerde eÄŸim sÄ±fÄ±rlanÄ±yor iken, learning rate, epochs ve batch_size parametrelerini deÄŸiÅŸtirerek yaptÄ±ÄŸÄ±mÄ±z Ã¶rneklerde epoch deÄŸeri 13- 17 aralÄ±ÄŸÄ±nda iken loss / rmse grafiÄŸinin eÄŸiminin sÄ±fÄ±rlandÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼yoruzâ€¦    Genel olarak amacÄ±mÄ±z learning rate, epochs ve batch_size parametrelerini ayarlayarak loss/rmse grafiÄŸinin eÄŸiminin min epoch deÄŸerinde sÄ±fÄ±rlanmasÄ±nÄ± mÄ± yakalamaktÄ±r..

> comments:
  
1. ->  Merhabalar,YazmÄ±ÅŸ olduÄŸunuz, yazacaÄŸÄ±nÄ±z her satÄ±r kodun size bir zaman maliyeti olur. Bu aÅŸamada asÄ±l amacÄ±mÄ±z loss/rmse grafiÄŸini minimize etmek evet ancak bunu yaparken en az adÄ±mda olmasÄ±nÄ± istiyoruz, Ã§Ã¼nkÃ¼ adÄ±m ne kadar azalÄ±rsa sonuca o kadar hÄ±zlÄ± ulaÅŸÄ±rÄ±z. Bu durumda asÄ±l amacÄ±mÄ±zÄ±n gerÃ§ek minimuma ulaÅŸmak deÄŸilde, en hÄ±zlÄ± ÅŸekilde optimal bir minumum deÄŸer elde etmek.Bunu basitÃ§e test edebilirsiniz: epoch iÃ§in 1000 seÃ§tiÄŸinizde eÄŸitim iÃ§in geÃ§en zaman ile 250 seÃ§meniz halinde geÃ§en zamanÄ± karÅŸÄ±laÅŸtÄ±rÄ±n. Tabi veri setinin Ã§ok kÃ¼Ã§Ã¼k olmasÄ±(12 sentetik gÃ¶zlemden oluÅŸmakta) muazzam bir zaman farkÄ± oluÅŸturmayacaktÄ±r. Ama birde bunu yÃ¼zbinlerce gÃ¶zlemden oluÅŸan bir sette yaptÄ±ÄŸÄ±nÄ±zÄ± dÃ¼ÅŸÃ¼nÃ¼n. Ä°lk yapacaÄŸÄ±nÄ±z ÅŸey, sonuca daha hÄ±zlÄ± ulaÅŸmanÄ±n yolunu aramak olacaktÄ±r.Ä°yi Ã§alÄ±ÅŸmalar.",
2. ->  ->  az sonra graikler ile gÃ¶stereceÄŸim anlatacaÄŸÄ±mÄ±",
3. -> ->  ayrÄ±ca bende sormak isterim bu soru devamÄ±nda ,hÄ±zlÄ± ulaÅŸmaya Ã§alÄ±ÅŸÄ±lmasÄ±nda ÅŸÃ¶yle bir ÅŸey takÄ±ldÄ± aklÄ±ma,aslÄ±nda demek istediÄŸim 1000 veri den 500 batchsize ve 2 iteration yapsam 1 epoch denk geliyor. Yani bir kere ileri ve geri aktarÄ±lÄ±yor deÄŸil mi? 250 batchsize 4 iteration yapsam yine 1 epoch olur. 2 epoch iÃ§in bunlar 500 batchsize 8 iteration olur dimi? Buda bir 8 iteration 8 batch demek galiba. Epochâ€™u artÄ±rÄ±nca zaman daha Ã§ok yer kaplÄ±yor gibi bununla birlikte iteration da fazlalaÅŸÄ±yor. Peki iterationlar mini-batch ihtiyaÃ§ duyar mÄ± peki learning_rate dahilinde, Ã§Ã¼nkÃ¼ bunlarda zamanÄ± gecikterecek olaylar dimi?",
4. -> -> 250 batch size ile 2 iterasyonda batch size da deÄŸiÅŸiklik olmaz 250 olarak kalÄ±r, gerisinde sorun yok, ancak epoch ile sÄ±nÄ±rlayarak konuyu daha basit bir ÅŸekilde aÃ§Ä±klamaya Ã§alÄ±ÅŸmÄ±ÅŸtÄ±m. Batch size kÃ¼Ã§Ã¼ldÃ¼kÃ§e iterasyon artmakta, ayrÄ±ca learning_rate'ye gÃ¶re de epoch sÃ¼resi deÄŸiÅŸmekte. Ã–zetle dediÄŸiniz gibi batch_size ve learning_rate de gecikmeye sebep olmakta.Bu yÃ¼zden biz sadece epoch iÃ§in optimal deÄŸeri aramayacak, learning_rate, batch_size ve epoch Ã¼Ã§lÃ¼sÃ¼ iÃ§in optimal deÄŸerleri arayacaÄŸÄ±z.Basit bir Ã¶rnek vermek gerekirse: Direkt olarak Ã¶rnek Ã§alÄ±ÅŸmadan bakacak olursak: learning_rate=0.01 iken 350 epoch da optimum deÄŸere ulaÅŸÄ±rken, learning_rate = 0.14 olarak deÄŸiÅŸtirirsek 70 epoch gibi bir deÄŸerde minimum loss'a ulaÅŸmaktayÄ±z. Buraya batch size Ä± da ekleyip farklÄ± sonuÃ§lara ulaÅŸmak mÃ¼mkÃ¼n. Deneysel olarak hangi parametre ne kadar zaman kaybÄ±na sebep olmakta ayrÄ± ayrÄ± deneyerek gÃ¶zlemleyebilirsiniz. Tabi kÃ¼Ã§Ã¼k bir veri setinde olmasÄ±nÄ± tavsiye ederim :)Ä°yi Ã§alÄ±ÅŸmalar..",
5. ->  TeÅŸekkÃ¼rler -> , cevap son derece yeterli ancak sentetik veri seti olduÄŸunu anlamak ile birlikte,AynÄ± veri seti Ã¼zerinden dÃ¼ÅŸÃ¼nÃ¼rsek ideal olan loss/rmse grafiÄŸi iÃ§in soruyorum... min epoch deÄŸerinde eÄŸimin sÄ±fÄ±rlanmasÄ± daha iyidir gibi bir sonuÃ§ mu Ã§Ä±karmamÄ±z lazÄ±m.....",
6. ->  ->  Tam olarak Ã¶yle demeyelim min epoch dediÄŸimiz zaman epoch'un minimum olabileceÄŸi deÄŸer 1 olduÄŸu iÃ§in yanlÄ±ÅŸ anlaÅŸÄ±labilir. EÄŸimin sÄ±fÄ±rlanmasÄ±na olanak saÄŸlayan optimal epoch deÄŸeri iyidir gibi bir sonuÃ§ Ã§Ä±karabiliriz.",
    
### soru 

> quest: Merhabalar;   Task 2: Increase the number of epochs [Link](https://colab.research.google.com/github/google/eng-edu/blob/master/ml/cc/exercises/linear_regression_with_synthetic_data.ipynb#scrollTo=lLXPvqCRvgI4) uygulamasÄ±nÄ± yaparken   10 epoch deÄŸerinin Ã§alÄ±ÅŸmadÄ±ÄŸÄ± aÅŸikar,   (ki burada epoch vs RMSE grafiÄŸine baktÄ±ÄŸÄ±mÄ±zda bekletimiz grafiÄŸin eÄŸiminin sÄ±fÄ±ra yakÄ±nlaÅŸmasÄ± ya da sÄ±fÄ±r olmasÄ± )  Ancak sorun ÅŸu;  epoch= 450 deÄŸerini aldÄ±ÄŸÄ±mÄ±z zaman epoch deÄŸeri 300 ( +20) lerde iken eÄŸim sÄ±fÄ±rlanÄ±yor ve 450 epoch deÄŸerine kadar sÄ±fÄ±r olarak kalÄ±yor..  epoch=600 yaptÄ±ÄŸÄ±mÄ±zda da epoch deÄŸeri 350 - 375 arasÄ±nda iken eÄŸim sÄ±fÄ±rlanÄ±yor ve 600 epoch a kadar sÄ±fÄ±r eÄŸimle devam ediyor. Epoch deÄŸerinin makbul olanÄ± 450 midir? 600 mÃ¼dÃ¼r?   NOT: (Belki de soru ÅŸÃ¶yle olmalÄ± ) Deneysel Ã§alÄ±ÅŸmalar yapmam gerektiÄŸini ve bu deÄŸerlerin ileride Ã§ok daha net olarak belirleyebileceÄŸimizi biliyorum. Ancak ÅŸu an iÃ§in buna takÄ±lmak doÄŸrumudur? DeÄŸil midir?",

> comments:
  
    1. ->  Merhaba, bence bu deÄŸerlere takÄ±lmana gerek yok. Veri setinden veri setine bu parametreler farklÄ±lÄ±k gÃ¶sterebilir. BÃ¼yÃ¼k ihtimalle hiÃ§bir zaman bu kadar kÃ¼Ã§Ã¼k veri setleri ile Ã§alÄ±ÅŸmayacaksÄ±n. Temelleri anlayÄ±p, deneysel sonuÃ§lar Ã¼zerinde Ã§ok fazla zaman harcamamak gerektiÄŸini dÃ¼ÅŸÃ¼nÃ¼yorum.",
    
    
### soru 

> quest: "Herkese iyi gÃ¼nler. Biraz konu dÄ±ÅŸÄ±nda olacak ama kursta ilerlerken laptopa Tensorflow kurmaya karar verdim ancak ne kadar denediysem de hep hatayla karÅŸÄ±laÅŸtÄ±m. Anaconda,Pycharm vs. denedim ancak her defasÄ±nda hata aldÄ±m. Acaba daha Ã¶nce bu tarz hatayla karÅŸÄ±laÅŸÄ±p yardÄ±mcÄ± olabilen olur mu?  Hata mesajÄ±: ImportError: DLL load failed: Belirtilen modÃ¼l bulunamadÄ±.",

> comments:
  
1. ->  Ben spyder kullanÄ±yorum , bu tarz bi modÃ¼l yÃ¼kleme hatasÄ±yla karÅŸÄ±laÅŸmÄ±ÅŸtÄ±m . SpyderÄ± son sÃ¼rÃ¼mÃ¼ne gÃ¼ncelleyince problem Ã§Ã¶zÃ¼lmÃ¼ÅŸtÃ¼...",
2. ->  Merhaba,Anaconda yÃ¼klÃ¼ ise makinanda, aynÄ± zamanda Anaconda Prompt gelmekte, Anaconda Prompt'u aÃ§tÄ±ÄŸÄ±n zaman(base) C:\\Users\\user_name> ile baÅŸlayan bir komut ekranÄ± aÃ§Ä±lacak,Bu ekranda iken console'ye \"pip install tensorflow\" yazarsan sorunsuz bir ÅŸekilde tensorflow kurulacaktÄ±r..",
3. ->  ->  ve ->  Pycharm Ã¼zerinden kurmaya Ã§alÄ±ÅŸtÄ±ÄŸÄ±mda kurulurken Tensorflow kuruldu demesine raÄŸmen, programÄ±n derlenmesi sÄ±rasÄ±nda hata verdi. daha sonra pip ile kurduÄŸumda sorunsuz bir ÅŸekilde Ã§alÄ±ÅŸtÄ± bende de.",
4. ->  ->  Merhaba, dediÄŸiniz gibi console'da \"pip install tensorflow\" ile install yaptÄ±m. SonrasÄ±nda yeniden Spider'da tensorflow'u import edemedim. AÅŸaÄŸÄ±daki hatayÄ± aldÄ±m. Ne yapmam gerekir? Ã‡ok teÅŸekkÃ¼rler..",
5. ->  ->  Merhaba,1 - simply download MSVCP140.dll, unzip it and then paste it in system32 folder..2 - pip install tensorflow --upgrade --force-reinstall (Bu iÅŸlemi anaconda prompt Ã¼zerinde yapmanÄ±z gerekmekte)Bu iki adÄ±mÄ± dener misiniz, Ã¶nerilen Ã§Ã¶zÃ¼mler arasÄ±nda bulunmaktalar. Daha Ã¶nce karÅŸÄ±laÅŸmadÄ±ÄŸÄ±m iÃ§in kesin bir yol sÃ¶yleyemiyorum..",
6. ->  ->  TeÅŸekkÃ¼rler ama baÅŸarÄ±lÄ± olamadÄ±m. BaÅŸka Ã§Ã¶zÃ¼mler bakÄ±yorum netten. Ã‡ok teÅŸekkÃ¼rler..",
7. ->  Pycharm iÃ§in nasÄ±l bir indirme yÃ¶ntemi kullandÄ±n? Pycharm sÃ¼rÃ¼mÃ¼n kaÃ§? Python sÃ¼rÃ¼mÃ¼n kaÃ§?.",
8. ->  Bende anaconda Ã¼zerinden kurdum daha sonra python IDLE iÃ§in cmd kÄ±smÄ±nda pip install numpy ve tensorflow yazÄ±nca sorunsuz Ã§alÄ±ÅŸtÄ± yani ÅŸuan hem spyder,jupyter hemde normal python IDLE Ã¼zerinde kullanabiliyorum, tensorflow web sitesindeki talimatlarÄ± dikkatlice uygularsanÄ±z sorunsuz Ã§alÄ±ÅŸacaktÄ±r..",
9. ->  Herkese teÅŸekkÃ¼r ederim deÄŸerli yorumlarÄ± iÃ§in. GÃ¼nÃ¼n sonunda sorunu Ã§Ã¶zmÃ¼ÅŸ olmanÄ±n keyfini yaÅŸÄ±yorum. AnacondayÄ± silip tekrar kurdum ve farkettim ki sorun \"Microsoft Visual C++\" Ä±n gÃ¼ncel versiyonunun yÃ¼klÃ¼ olmamasÄ±ndan kaynaklÄ±ymÄ±ÅŸ.",
10. ->  Bende de 2.1 versiyonunda sorun Ã§Ä±kmÄ±ÅŸtÄ±. 2.0'a dÃ¶nÃ¼nce sorun Ã§Ã¶zÃ¼ldÃ¼. EÄŸer sizin versiyon da 2.1 ise onu kaldÄ±rÄ±p 2.0'Ä± yÃ¼klemenizi Ã¶neririm. 2.0 yÃ¼klemek iÃ§in pip install tensorflow==2.0.0 komutunu kullanabilirsiniz..",
    
### soru 

> quest: "Merhaba arkadaÅŸlar, konuyu anlamakta biraz zorluk Ã§ekiyorum ama Ã¶rnek Ã¼stÃ¼nden sormak istedim. Åimdi elimde Ã§eÅŸitli ÅŸekillerde para birimlerim olan bir data set Ã¶rneÄŸi var (bu para birimleri labels oluyor) bide bu datasette paralarÄ±n aÄŸÄ±rlÄ±klarÄ±, boyutlarÄ± gibi Ã¶rnekler var (yani features). Ben bunlardan bir model oluÅŸturmak istersem (training) kullanmÄ±ÅŸ olduÄŸum ÅŸey labeled examples oluyor. Bunaâ€ firstmodelâ€ diyelim. BÃ¶ylelikle aÄŸÄ±rlÄ±ktan hangi para birimi olduÄŸunu soranlara (classification model) tahmin yÃ¼rÃ¼tebiliyorum (suprevised learning). Modeli oluÅŸturduktan sonra, para birimi verilmeyen ama features verilen bir â€œbaÅŸkaâ€ datasetti, â€œfirstmodelâ€ dediÄŸimiz datasete uyguladÄ±ÄŸÄ±mda ise unlabeled examples iÃ§in inference yapmÄ±ÅŸ oluyorum buda â€œsecondmodelâ€ olsun. Bu â€œsecondmodelâ€ ise bir kullanÄ±cÄ±nÄ±n gÃ¶zÃ¼ kapalÄ± ÅŸekilde TL parabirimini en hÄ±zlÄ± seÃ§me olasÄ±lÄ±ÄŸÄ±nÄ± nedir sorusuna tahmin yÃ¼rÃ¼tebiliyor olsun. (regression)(unsupervised learning). Bu anlattÄ±ÄŸÄ±m doÄŸrumu dur? Yani bir etiketsiz veri datasetini eÄŸitmek istersem yada geliÅŸtirmek istersem, Ã¶nceden etiketli bir data setiyle birleÅŸtirmem mi lazÄ±m, Ã§Ä±karÄ±m iÃ§in? yoksa bu ikiside farklÄ± datasetler olabilir ve ikiside farklÄ± iÅŸlerde kullanÄ±labilir mi? Ã¶rneÄŸin bir firma \"firstmodel\" kullanarak sadece para tahmini yaparken \"secondmodel\" baÅŸka bir firmada grublama iÃ§in kullanÄ±labilir mi? BurasÄ± iyice karÄ±ÅŸtÄ± bende, yanlÄ±ÅŸÄ±m var ise lÃ¼tfen dÃ¼zeltir misiniz?",

> comments:
  
1. ->  Merhaba, AslÄ±nda bahsettiÄŸin first model ve second model aynÄ± model. First modelde veri setiyle model oluÅŸturup eÄŸitiyorsun. Second model dediÄŸin ÅŸey bilinen deÄŸerlerden bilinmeyen deÄŸeri tahmin etme. Model kurarken test datasÄ±nda model doÄŸruluÄŸunu test ederken yapÄ±lan iÅŸlem. Regresyon ile sÄ±nÄ±flama problemleri zaten ayrÄ± konular. SÄ±nÄ±flama birbiri ile kÄ±yas yapÄ±lamayan haliyle ortalamasÄ± alÄ±namayan deÄŸiÅŸkenler iÃ§in yapÄ±lÄ±r(Ã¶rneÄŸin: boy ve kilodan cinsiyet tahmin. KadÄ±nlar ve erkeklerin ortalamasÄ±nÄ± alÄ±p %30 kadÄ±n %70 erkek diyemezsin. Ä°kisinden birini seÃ§mek zorundasÄ±n nihai tahminde). Regresyon modelleri ise sÃ¼rekli deÄŸerler alabilen bir deÄŸiÅŸken tahmin edilirken kullanÄ±lÄ±r.2 months ago 7 people like this.Like ReportReply",
2. -> Merhabalar,Sizin Ã¶rnekleriniz Ã¼zerinden devam ederek aÃ§Ä±klamaya Ã§alÄ±ÅŸayÄ±m, Firstmodel iÃ§in sÃ¶ylediÄŸiniz doÄŸru, supervised learning, sonucunun ne olduÄŸunu bildiÄŸimiz veri ile algoritmamÄ±zÄ± eÄŸitip, ileriye dÃ¶nÃ¼k olarak elimize gelecek olan verilerin classification iÃ§in hangi sÄ±nÄ±fa, regression iÃ§in ise hangi deÄŸere sahip olduÄŸunu tahmin etmemiz aÅŸamalarÄ±nÄ± iÃ§ermektedir. Yani Ã¶zetle Supervised learning'de yaptÄ±ÄŸÄ±mÄ±z SONUCU BÄ°LÄ°NEN(Etiketlerimiz oluyor.) geÃ§miÅŸ tecrÃ¼belerden Ã¶ÄŸrenerek, geleceÄŸe yÃ¶nelik tahminde bulunmak.Ancak second model iÃ§in vermiÅŸ olduÄŸunuz Ã¶rnekte ki insan/ kullanÄ±cÄ± her ne kadar gÃ¶zÃ¼ kapalÄ± olsa bile TL parabimini seÃ§me olasÄ±lÄ±ÄŸÄ±ndan bahsediyorsak da Supervised Regression olur Ã§Ã¼nkÃ¼ kullanÄ±cÄ±nÄ±n TL etiketine ait feature bilgisine sahip olmasÄ± lazÄ±m aksi takdirde bu olasÄ±lÄ±k hesabÄ± oldukÃ§a basit bir ÅŸekilde sÃ¶ylenebilir(toplam TL banknotu sayÄ±sÄ±nÄ±n veri seti bÃ¼yÃ¼klÃ¼ÄŸÃ¼ne oranÄ±dÄ±r.). Unsupervised Learning iÃ§in ne yazÄ±k ki regression ile alakalÄ± bir kaynak gÃ¶rmÃ¼ÅŸ deÄŸilim bu kÄ±sÄ±m yanlÄ±ÅŸ olabilir. BildiÄŸim kadarÄ± ile Unsupervised learning iÃ§in etiket bilgisine ihtiyaÃ§ yoktur. AmaÃ§ ortak Ã¶zelliklere sahip olan kÃ¼meleri ortaya Ã§Ä±karmak olduÄŸu iÃ§in, Ã¶rneÄŸinizi eÄŸer kullanÄ±cÄ±nÄ±n gÃ¶zÃ¼ kapalÄ± bir ÅŸekilde paralarÄ± kÃ¼melemesi olursa bu unsupervised learning'e Ã¶rnek olacaktÄ±r. Bu durumda kullanÄ±cÄ±nÄ±n yapacaÄŸÄ± iÅŸlem her bir banknotu eline alarak birbirleri ile kÄ±yaslamak sureti ile kendisine aynÄ± hissi veren banknotlarÄ± aynÄ± gruplara koymak olacaktÄ±r.2 months ago 10 people like this.Like ReportReply",
3. -> Ã‡ok teÅŸekkÃ¼r ederim x 

### soru 

> quest: "Merhabalar arkadaÅŸlar, Bir soru sormayacaÄŸÄ±m ancak Simple Lineer Regresyon Ã§alÄ±ÅŸÄ±rken farkettiÄŸim bir mantÄ±k hatasÄ±nÄ± paylaÅŸmak istedim.  Linear Regression with Synthetic Data alÄ±ÅŸtÄ±rmasÄ±nÄ± incelerken, train_model()'de batch_size parametresine fonksiyona parametre olarak gelen batch_size deÄŸeri atanmamÄ±ÅŸ onun yerine None deÄŸeri atanmÄ±ÅŸ. AlÄ±ÅŸtÄ±rmanÄ±n sonuna doÄŸru batch_size ile alakalÄ± dÃ¼zenleme yapmamÄ±zÄ± en kÃ¼Ã§Ã¼k hangi deÄŸerde Ã§alÄ±ÅŸabildiÄŸini bulmamÄ±zÄ± istemiÅŸ. Bu hali ile batch_size iÃ§in biz 0.0001 gibi bir deÄŸer bile girsek hata almamÄ±z gerekirken hatasÄ±z bir ÅŸekilde Ã§alÄ±ÅŸacaktÄ±r. Ã‡Ã¼nkÃ¼ varsayÄ±lan olarak model bÃ¼tÃ¼n data ile train iÅŸlemini gerÃ§ekleÅŸtirmekte.     Ä°yi Ã§alÄ±ÅŸmalar.",

> comments:
  
1. ->  Bilgilendirme iÃ§in teÅŸekkÃ¼rler furkan bey..",
1. ->  Ã–nemli bir bilgilendirme. Ben de model fonksiyonlarÄ±na bakarken fark ettim.def train_model() fonksiyonunu;batch_size=None => batch_size=batch_size,ÅŸeklinde gÃ¼ncelleyince, batch size deÄŸikliÄŸinin etkileri gÃ¶zÃ¼kmekte..",
    
### soru 

> quest: "Merhabalar, yukarÄ±daki \"Adjust the batch size\" Ã¶rneÄŸinde batch size'Ä± 1 olarak seÃ§tiÄŸimde loss'u 2,3724 MSE ise 1,54 olarak hesaplandÄ±. Batch size'Ä± 4 olarak seÃ§tiÄŸimde ise daha dÃ¼ÅŸÃ¼k loss ve MSE'ye sahip oldum (loss = 0.8753 MSE = 0.93) . Cevap olarak en kÃ¼Ã§Ã¼k batch size'Ä± 1 olarak seÃ§ebileceÄŸimiz gÃ¶sterilmiÅŸ.  CevabÄ± 1 olarak gÃ¶stererek bize ne aÃ§Ä±klanmak istenmiÅŸ? Daha dÃ¼ÅŸÃ¼k loss ve MSE ' ye sahip olduÄŸumuzda daha doÄŸru size'Ä± bulduÄŸumuz anlamÄ±na geldiÄŸini sÃ¶yleyemez miyiz?",

> comments:
  
1. ->  Merhaba, 100 epoch'ta converge edecek ÅŸekilde seÃ§ebileceÄŸiniz en kÃ¼Ã§Ã¼k integer deÄŸer nedir diye soruyor. Cevap iÃ§in o yÃ¼zden 1 yazmÄ±ÅŸ, loss ve mse deÄŸerlerine dikkat ederek yazmamÄ±ÅŸ.",
2. ->  Ä°lk gÃ¶rÃ¼nteki en son paragrafta,100 epochs ta bile modelin 'converge' yani optimuma yakÄ±nsamÄ±ÅŸ duruma gelmesi iÃ§in verebileceÄŸimiz en kÃ¼Ã§Ã¼k batch_size sorulmuÅŸ.Problem Ã¶zÃ¼nde 1 bile yetebilmiÅŸ bunu gÃ¶stermeye Ã§alÄ±ÅŸÄ±yor aslÄ±nda.Problem iÃ§in belki de 4 ten daha optimal bir deÄŸer vardÄ±r,ancak batch_size=1 olarak kabul edildiÄŸinde de model,optimale yaklaÅŸabilmiÅŸ. batch_size bir hyperparametre olduÄŸu iÃ§in,kesin ve net bir deÄŸeri vardÄ±r diyemeyiz.LÃ¼tfen eksik veya yanlÄ±ÅŸ ifade ettiÄŸim bir ÅŸey varsa uyarÄ±n. ğŸ™‚.",
"Merve Horoz Ã‡ok teÅŸekkÃ¼rler ->  ->  ..",
3. ->  [Link](http://community.globalaihub.com/community/status/618-618-1586424145/#comment.2599.2784.2784)
    
### soru .

> quest: "Herkese iyi Ã§alÄ±ÅŸmalar,attÄ±ÄŸÄ±m gÃ¶rÃ¼ntÃ¼deki anormal olan parametreyi aÃ§Ä±kÃ§asÄ± pek anlayamadÄ±m,bu deÄŸerleri gÃ¶z Ã¶nÃ¼nde bulundururken 1000 e bÃ¶lÃ¼nmÃ¼ÅŸ Ã¶lÃ§ekli olan deÄŸeri ile mi kÄ±yaslÄ±yacaÄŸÄ±z ?",

> comments:
  
1. -> Burada benim anladÄ±ÄŸÄ±m yanlÄ±ÅŸlÄ±k ÅŸu; Ã–ncelikle oradaki deÄŸerlerin anlamlarÄ±nÄ± sÃ¶yleyim.mean: ortalama,std:standart sapma,gerisi ÅŸÃ¶yle hesaplanÄ±yor elimizde 1den 9a kadar sayÄ±lar olsun(kÃ¼Ã§Ã¼kten bÃ¼yÃ¼ÄŸe doÄŸru sÄ±ralanmÄ±ÅŸ ÅŸekilde veriler karÄ±ÅŸÄ±ksa Ã¶nce sÄ±ralanmalÄ±) [1-2-3-4-5-6-7-8-9] Burada min:en kÃ¼Ã§Ã¼k yani (1) deÄŸeri oluyor max: en bÃ¼yÃ¼k yani (9) deÄŸeri oluyor. %50 medyan(ortanca):5 deÄŸeri oluyor sÄ±ralayÄ±nca ortadaki %25: 1. Ã§eyreklik deÄŸerimiz yani (3) oluyor. %75: 7 deÄŸerimiz oluyor. Åimdi bu bilgilere gÃ¶re tablodaki yorumum ÅŸÃ¶yle: total_rooms feature'Ä±nÄ±n deÄŸerlerine bakÄ±nca her Ã§eyrek iÃ§in deÄŸerleri sÄ±rasÄ±yla 2-1462-2127-3151-37937 yani her Ã§eyrekte genellikle 1000 civarÄ± bir deÄŸiÅŸim olurken %75den max a geÃ§erken yaklasÄ±k 34000 lik bir deÄŸiÅŸim olmuÅŸ. Bu da birÃ§ok nedenden dolayÄ± olabilir yani aslÄ±nda 3793 gibi bir sayÄ± yazarken yanlÄ±ÅŸlÄ±kla fazla yazÄ±lmÄ±s olabilir.(AyrÄ±ca EÄŸer gerÃ§ekte bÃ¶yle bir deÄŸer var ve diÄŸer bÃ¼tÃ¼n deÄŸerler bu deÄŸerden uzaksa istatistikte bazen bÃ¶yle sapan deÄŸerler veri setinden Ã§Ä±karÄ±larak gÃ¶z ardÄ± edilebiliyor.)Mesela housing_median_age,median_income ve median_house_value kÄ±smÄ±nda herÅŸey normal gibi fakat total_rooms taki gibi bir anormallik ayn ÅŸekilde total_bedrooms,population ve households da da gÃ¶rÃ¼lÃ¼yor. Benim bildiklerim ile anladÄ±ÄŸÄ±m ve yorumamlamam budur. YanlÄ±ÅŸÄ±m varsa beni de dÃ¼zeltirseniz sevinirim. Ä°yi Ã§alÄ±ÅŸmalar dilerim.2 months ago 9 people like this.Like ReportReply",
2. -> Merhaba Emre,Cemhan'Ä±n sÃ¶ylediklerine bir ekleme yapmak istedim. Bu konuda bahsedilen istatistikte outlier yani aykÄ±rÄ± deÄŸer olarak geÃ§iyor. Elimizdeki verileri kÃ¼Ã§Ã¼kten bÃ¼yÃ¼ÄŸe sÄ±ralayÄ±nca en ortadaki deÄŸer medyan(Q2 veya 50th percentile), medyan ile minimum ortasÄ±ndaki deÄŸer first quartile(Q1 veya 25th percentile), son olarak medyan ile maksimum ortasÄ±ndaki deÄŸer ise third quartile(Q3 veya 75th percentile) olarak geÃ§er. Bu deÄŸerlere bakarak veri setimizin daÄŸÄ±lÄ±mÄ± hakkÄ±nda az Ã§ok bilgi sahibi olabiliriz.Gelelim en baÅŸta bahsettiÄŸim outlier tanÄ±mlamasÄ±na. Verisetimizdeki aykÄ±rÄ± deÄŸerleri saptarken aÅŸaÄŸÄ±daki formÃ¼lÃ¼ kullanÄ±yoruz(birkaÃ§ farklÄ± yaklaÅŸÄ±m var ancak en basiti):IRQ = (Q3 - Q1)Upper fence = Q3 + 1.5*IRQ, lower fence = Q1 - 1.5*IRQOutlierlar bu upper fence ve lower fence yani sÄ±nÄ±rlarÄ±nÄ±n dÄ±ÅŸÄ±nda kalan deÄŸerler oluyor. Bunlar ise bizim verisetimizi bozabilecek deÄŸerler. Tabi bu deÄŸerlerin model eÄŸitiminde kullanÄ±lÄ±p kullanÄ±lmayacaÄŸÄ± data scientistin tecrÃ¼be ve Ã¶ngÃ¶rÃ¼sÃ¼ne kalÄ±yor. AÅŸaÄŸÄ±da datasetteki median_income deÄŸerleri ile Ã§izilmiÅŸ bir box plot Ã¶rneÄŸi paylaÅŸtÄ±m. Bu grafik ile yukarÄ±da bahsettiÄŸim tÃ¼m deÄŸerleri veri Ã¼zerinde gÃ¶rebiliyoruz, upper fence Ã¼zerinde kalan tÃ¼m deÄŸerler outlier oluyor.Ä°yi Ã§alÄ±ÅŸmalar..",
3. -> TeÅŸekkÃ¼rler ğŸ™‚",
4. ->  ->  'un yorumunda bahsettiÄŸi veri bilimcinin tecrÃ¼be ve Ã¶ngÃ¼rsÃ¼ne kalma durumunu birazcÄ±k aÃ§mak istiyorum. AÅŸÄ±rÄ± deÄŸerleri gÃ¶rdÃ¼ÄŸÃ¼mÃ¼zde onlarÄ± veri setinden Ã§Ä±karÄ±p Ã§Ä±karmama noktasÄ±nda oldukÃ§a dikkatli olmak gerekiyor. EÄŸer aÅŸÄ±rÄ± deÄŸer veri giriÅŸinden kaynaklÄ± bir hataysa bunu veri setinden Ã§Ä±karabilirsin. Ã–rneÄŸin ilkÃ¶ÄŸretim Ã¶ÄŸrencilerinden elde edilen bir veride 45 yaÅŸ hatalÄ± bir veri giriÅŸi diyebiliriz. Ev fiyatlarÄ±nÄ± dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼mÃ¼zde diyelim ki 1 milyon deÄŸerinde bir ev ile karÅŸÄ±laÅŸtÄ±k. Bunun Ã¶ncelikle bir outlier(aykÄ±rÄ± deÄŸer) mi yoksa extreme value (uÃ§ deÄŸer) mi olduÄŸuna karar vermelisin. Diyelim ki evin oda sayÄ±sÄ± 25, banyo sayÄ±sÄ± 5, salon sayÄ±sÄ± 3 gibi deÄŸerler bu durumda bu evin fiyatÄ± bir uÃ§ deÄŸer( extreme value) olarak deÄŸerlendirilir. Ancak ev 2 oda bir salon ve diÄŸer Ã¶zellikleri de ortalama deÄŸerler bu durumda veri giriÅŸinde bir hata olma ihtimali daha yÃ¼ksektir..",
    
### soru 

> quest: "Merhabalar,   Reducing Loss: Playground exercise'da, eklemiÅŸ olduÄŸum resimde de gÃ¶rÃ¼ldÃ¼ÄŸÃ¼ Ã¼zere, bize verilen datalardan dÃ¶rdÃ¼ncÃ¼sÃ¼nÃ¼n eÄŸitimi iÃ§in kullanabileceÄŸim optimum deÄŸerler (batch size, learning rate... ) hakkÄ±nda Ã¶neride bulunabilecek var mÄ±?   TeÅŸekkÃ¼rler, iyi Ã§alÄ±ÅŸmalar herkese.",

> comments:
  
1. ->  Bence en iyisi deneysel olarak Ã§alÄ±ÅŸÄ±p,verdiÄŸin parametreler ve hiperparametreler arasÄ±ndaki iliÅŸkiyi gÃ¶zlemlemek olacaktÄ±r.Optimum deÄŸerler kullanÄ±p,optimum sonuca ulaÅŸtÄ±ÄŸÄ±n senaryonun Ã§ok eÄŸlenceli ve eÄŸitici olamayacaÄŸÄ± dÃ¼ÅŸÃ¼ncesindeyim ğŸ™‚.",
" ->  ->  Kesinlikle katÄ±lÄ±yorum, dÃ¶rt veri seti Ã¼zerinde de birÃ§ok deÄŸer denedim ve gÃ¶zlemledim fakat sonuncusunda optimum deÄŸil optimuma yakÄ±n bir ÅŸeyler bile bulamadÄ±m. YanÄ±tÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederim. ğŸ™‚.",
2. ->  Bu kÄ±sÄ±m neural network ile ilgili alÄ±ÅŸtÄ±rma kÄ±smÄ± bu alÄ±ÅŸtÄ±rmaya neural network kÄ±smÄ±nda sonra bakÄ±lÄ±r diye dÃ¼ÅŸÃ¼nÃ¼yorum .yinede yapmak istersen featurelarÄ± deÄŸiÅŸtirerek sÃ¶yle biÅŸey elde ettim.",
3. ->  [Coursera | Online Courses From Top Universities.](https://www.coursera.org/learn/deep-learning-business/discussions/weeks/6?sort=lastActivityAtDesc&page=1&q=)attÄ±ÄŸÄ±m linkteki Ã¼cretsiz kursun discussion formunda deÄŸerleri paylaÅŸanlar olmuÅŸtu bunun iÃ§in gÃ¶z atabilirsin",
4. -> Merhaba,Bu spiral dataset ile oynarken input feature olarak polar koordinatlarÄ±n (r,Î¸) iÅŸe yarayabileceÄŸini dÃ¼ÅŸÃ¼ndÃ¼m.playground.tensorflow.org daki input feature'lar sabit ancak kaynak koduna istediÄŸiniz feature'Ä± basitÃ§e ekleyebiliyorsunuz.playground reposunu forklayÄ±p aÅŸaÄŸÄ±daki modifikasyonu yapÄ±nca, az sayÄ±da neuron ve layer kullanarak oldukÃ§a baÅŸarÄ±lÄ± sonuÃ§ alÄ±nÄ±yor.[Link](https://github.com/cankut/playground/commit/b982c86e0d89f42b68fcda8be70cdc78df56583f)
"Tensorflow â€” Neural Network Playgroundplayground.tensorflow.orgTinker with a real neural network right here in your browser.",
    
### soru 

> quest: "Merhaba, kursun ilk haftasÄ±nda bulunan First Step with TF bÃ¶lÃ¼mÃ¼ndeki alÄ±ÅŸtÄ±rma kodlarÄ±nÄ± Python'a aktardÄ±m. Hem arkadaki kodlarÄ± gÃ¶rmek hem de biraz elleri kirletmek iÃ§in iyi olacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼mden sizinle de paylaÅŸmak istiyorum. Fakat, plot_the_loss_curve kÄ±smÄ±nda bir hatayla karÅŸÄ±laÅŸÄ±yorum, bunun Ã§Ã¶zÃ¼m arama yeri burasÄ± deÄŸil sanÄ±rÄ±m ama en azÄ±ndan diÄŸer kÄ±sÄ±mlar Ã§alÄ±ÅŸÄ±yor. Ä°yi Ã§alÄ±ÅŸmalar dilerim.[Link](https://github.com/oguzhari/GoogleMLCrashCourse)

> comments:
  
1. ->  ML kÄ±smÄ±ndan Ã§ok anlamÄ±yorum ama sayfanÄ±zda yayÄ±nlamÄ±ÅŸ olduÄŸunuz koddaepochs = 10ile epochs deÄŸerini integer olarak tanÄ±mlÄ±yorsunuz, rmse ise bir dizi olarak ki kodunuzu Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±mda 10 elemanlÄ± bir dizi olarak geliyor. tek deÄŸer ile 10 elemanlÄ± bir diziyi aynÄ± grafiÄŸe oturtmaya Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z iÃ§in hata veriyor olabilir....",
2. ->  Ã‡ok teÅŸekkÃ¼rler.",
3. ->  Merjaba, ->  hocamÄ±n da sÃ¶ylediÄŸi gibi epochs deÄŸeri sizin kodunuzda scalar bir deÄŸer olarak yani 10 olarak gelmiÅŸ. GrafiÄŸi Ã§izebilmek iÃ§in rmse ve epochs deÄŸerlerinin ilk boyutlarÄ±nÄ±n aynÄ± olmasÄ± gerekiyor. (len(epochs) ve len (rmse) ile kontrol edebilirsiniz.) Github kodunuzu forklayÄ±p sorunu giderdim ve pull request oluÅŸturdum. GÃ¶zden geÃ§irdikten sorna uygun gÃ¶rÃ¼rseniz pull requesti kabul edip yazdÄ±ÄŸÄ±m dÃ¼zeltme kodu ile sizin yazdÄ±ÄŸÄ±nÄ±z kodlarÄ± birleÅŸtirebilirsiniz.Edit: @->  hocamÄ±n belirttiÄŸi kÄ±smÄ± -> 'Ã¼ kodun iÃ§inde referans gÃ¶stererek dÃ¼zenledim..",
4. -> ->  Merhaba, katkÄ±nÄ±z iÃ§in Ã§ok teÅŸekkÃ¼r ederim..",
5. ->  -> Merhabalar,Hata ile alakalÄ± deÄŸil ancak kodunu incelediÄŸim zaman train model de batch_size = None olarak yazÄ±lmÄ±ÅŸ. Bu durumda my_batch_size deÄŸiÅŸkenini ne kadar deÄŸiÅŸtirirsek deÄŸiÅŸtirelim biz bÃ¼tÃ¼n batch_size deÄŸerini her zaman data boyutuna eÅŸit almÄ±ÅŸ olacaÄŸÄ±z. batch_size yi parametre olarak aldÄ±ÄŸÄ±n batch_size ye eÅŸitlersen farklÄ± batch'lerde nasÄ±l sonuÃ§lar Ã¼retildiÄŸini gÃ¶zlemleyebilirsin.Hata iÃ§inde basit bir ÅŸekilde np.arange(1,ecpocs+1) yaparsan sorun Ã§Ã¶zÃ¼lecektir diye dÃ¼ÅŸÃ¼nÃ¼yorum.EDIT: HatanÄ±n kaynaÄŸÄ±nÄ± ÅŸimdi buldum, Ã¶rnek olarak paylaÅŸÄ±lmÄ±ÅŸ olan kodda train_model() fonksiyonunda epochs update edilmekte, Colab Ã¼zerinde ki kodda bunu gÃ¶rebilirsin. epochs update iÅŸlemini:# The list of epochs is stored separately from the# rest of history.epochs = history.epochÅŸeklinde yapÄ±lmakta bÃ¶ylece geriye epochs iÃ§in bir skaler dÃ¶ndÃ¼rmek yerine liste dÃ¶ndÃ¼rÃ¼yor train_model fonksiyonu..",
6. -> ->  Ã‡ok teÅŸekkÃ¼r ederim",
    
### soru 

> quest: "Herkese, iyi akÅŸamlar. Goldilocks learning kavramÄ±nÄ± tam olarak anladÄ±ÄŸÄ±mÄ± dÃ¼ÅŸÃ¼nmÃ¼yorum. AnladÄ±ÄŸÄ±m kadarÄ±yla en az sayÄ±da adÄ±mla minumum local deÄŸere ulaÅŸtÄ±ÄŸÄ±mÄ±z learning rate deÄŸeri goldilocks oranÄ±na eÅŸittir diyebilir miyiz? Yoksa bu ifadem yanlÄ±ÅŸ mÄ±dÄ±r?",
> comments:

  
1. -> Burada dÃ¼n tartÄ±ÅŸÄ±ldÄ±.Bakabilirsiniz. [Link](http://community.globalaihub.com/community/status/1043-1043-1586253928/#comment.2355.2369.2369)
2. ->  ->PostlarÄ± incelemiÅŸtim ama gÃ¶zÃ¼mden kaÃ§Ä±rmÄ±ÅŸ olmam lazÄ±m teÅŸekkÃ¼rler..",
3. ->  Ã–nceki baÅŸlÄ±kta learning rate kavramÄ±na ait aÃ§Ä±klamalar var ancak kurstaki sorunun cevabÄ± olan 1.6 yÄ± nasÄ±l bulduÄŸumuzu aÃ§Ä±klayan arkadaÅŸlarÄ±n bir gÃ¶nderisini gÃ¶remedim. YardÄ±mcÄ± olacak birisi olursa sevinirim..",
    
### soru 

> quest: "Herkese merhaba! AnladÄ±ÄŸÄ±mÄ± dÃ¼ÅŸÃ¼nmekle beraber emin olamadÄ±ÄŸÄ±m ufak ayrÄ±ntÄ±larÄ± sizlere danÄ±ÅŸmak istedim .AnladÄ±ÄŸÄ±m kadarÄ±yla \"mini-batch\" parametresiyle aÄŸa girecek olan veri sayÄ±sÄ±nÄ± belirliyoruz ve her bir epochta bu sayÄ±da veri iÅŸleniyor . Her  epochta seÃ§ilen veriler Ã¼zerinden aÄŸÄ±rlÄ±klar hesaplanÄ±yor ve epoch sonunda backpropation ile son gÃ¼ncelleme yapÄ±lÄ±yor. AklÄ±ma takÄ±lan kÄ±sÄ±m Ã¶ncelikle her epochta mini-batch boyutunda seÃ§ilen veriler farklÄ± ve rastgele mi oluyor , Ã¶zellikle farklÄ± olmasÄ±na dikkat ediliyor mu  ? Bir diÄŸer detay is ÅŸu ; her epochta , bir Ã¶nceki aÄŸÄ±rlÄ±klar Ã¼zerinden gÃ¼ncelleme yaparak ilerleniyor deÄŸil mi ?",

> comments:
  
1. ->  Merhabalar,Her epoch ta toplamda aynÄ± veriler (toplam train veri setiniz) kullanÄ±lacaÄŸÄ±ndan her mini-batch te rastgele veya sÄ±ralÄ± seÃ§miÅŸ olmanÄ±z Ã§ok fark ettirmeyecektir.Epoch sonunda tÃ¼m train verniz elden geÃ§irilmiÅŸ olacak.Sorunuzda daha Ã¶nemli olan kÄ±sÄ±m ÅŸurasÄ± her epoch ta hesaplanan aÄŸÄ±rlÄ±klar bir sonraki epoch ta gÃ¼ncellenmeye devam edilecek ki daha iyi bir yakÄ±nsama olsun.Her seferinde aÄŸÄ±rlÄ±klarÄ± yeniden set edip her batch te hesaplarsanÄ±z her epoch sonucunda yaklaÅŸÄ±k aynÄ± yakÄ±nsamayÄ± yapmÄ±ÅŸ olursunuz. (Rastgelelik ten dolayÄ± ÅŸanslÄ±ysanÄ±z en iyi aÄŸÄ±rlÄ±klarÄ± bulursunuz ama bu Ã§ok Ã§ok iyi ÅŸans iÅŸi)SonuÃ§ olarak;AÄŸÄ±rlÄ±klar her epoch ta ve her batch te gÃ¼ncellenerek ilerleniyor.SaygÄ±larÄ±mlaMehmet.",
2. ->  Ã–ncelikle cevabÄ±nÄ±z iÃ§in teÅŸekkÃ¼rler .Yani her epochta aslÄ±nda bir Ã¶ncekinde iÅŸlenen veri tekrar iÅŸleniyor ... (Ben her epochta farklÄ± veriler iÅŸleniyordur ve bu iÅŸlenen veriler de rastgele ve bir Ã¶ncekinden farklÄ± olacak ÅŸekilde seÃ§iliyordur diye dÃ¼ÅŸÃ¼nmÃ¼ÅŸtÃ¼m ) yani sonuÃ§ olarak mini-batch parametresiyle belirlediÄŸimiz sayÄ± kadar veri deÄŸerlendirmiÅŸ oluyoruz .Ama bu kÄ±sÄ±mda anlamadÄ±ÄŸÄ±m ben daha kÃ¼Ã§Ã¼k bir veri seti oluÅŸturmak varken neden mini-batch parametresi kullanmÄ±ÅŸ oluyorum ?",
3. ->  \"Derin Ã¶ÄŸrenme uygulamalarÄ±nda, veri setinde bulunan tÃ¼m verileri aynÄ± anda iÅŸleyerek Ã¶ÄŸrenme, zaman ve bellek aÃ§Ä±sÄ±ndan maliyetli bir iÅŸtir. Ã‡Ã¼nkÃ¼ Ã¶ÄŸrenmenin her iterasyonunda geriyeyayÄ±lÄ±m (â€œbackpropagationâ€) iÅŸlemi ile aÄŸ Ã¼zerinde geriye dÃ¶nÃ¼k olarak gradyan (â€œgradient descentâ€) hesaplamasÄ± yapÄ±lmakta ve aÄŸÄ±rlÄ±k deÄŸerleri bu ÅŸekilde gÃ¼ncellenmektedir. Bu hesaplama iÅŸleminde veri sayÄ±sÄ± ne kadar fazla ise hesaplama da o oranda fazla sÃ¼rmektedir. Bu problemi Ã§Ã¶zmek iÃ§in; veri seti kÃ¼Ã§Ã¼k gruplara ayrÄ±lmakta ve Ã¶ÄŸrenme iÅŸlemi seÃ§ilen bu kÃ¼Ã§Ã¼k gruplar Ã¼zerinde yapÄ±lmaktadÄ±r. Bu ÅŸekilde birden fazla girdinin parÃ§alar halinde iÅŸlenmesi â€œmini-batchâ€ olarak adlandÄ±rÄ±lmaktad
 Ä±r.\ ".", 4. ->  [Derin Ã–ÄŸrenme UygulamalarÄ±nda En SÄ±k kullanÄ±lan Hiper-parametreler](https://medium.com/deep-learning-turkiye/derin-ogrenme-uygulamalarinda-en-sik-kullanilan-hiper-parametreler-ece8e9125c4)
5. ->  ->  sorduÄŸun soru benim de kafama takÄ±lmÄ±ÅŸtÄ±.SanÄ±rÄ±m zaman ve bellek aÃ§Ä±sÄ±ndan maliyetli olacaÄŸÄ±ndan dolayÄ±.",
6. ->  ->  aynÄ± yazÄ±yÄ± ben de inceledim ama en son yorumumda sorduÄŸum soruya yanÄ±t bulamadÄ±m maalesef . Acaba bazÄ± ÅŸeyleri tam olarak anlayamadÄ±m mÄ± yoksa sadece bÃ¼yÃ¼k veri setlerini uÄŸraÅŸmadan kÃ¼Ã§Ã¼ltmek iÃ§in uygulanan bir yaklaÅŸÄ±m mÄ± emin olamadÄ±m.",
7. ->  ->  Benim de anladÄ±ÄŸÄ±m kadarÄ±yla yapÄ±lan yaklaÅŸÄ±m ÅŸunun gibi; Mesela seÃ§im dÃ¶neminde istatistik ÅŸirketleri seÃ§im anketleri yapÄ±yor ve hangi adayÄ±n ne kadar oy alacaÄŸÄ±nÄ± tahmin etmeye Ã§alÄ±ÅŸÄ±yorlar.Bunu yaparken kitle=BÃ¼tÃ¼n halk ama bunu yapmak Ã§ok fazla zaman ve imkan gerektirdiÄŸi iÃ§in bunun yerine belirli Ã¶rneklem bÃ¼yÃ¼klÃ¼ÄŸÃ¼ ile hareket edip genelleme yapÄ±yorlar. Bu sonuÃ§ kesinlikle kitlenin sonucu deÄŸil kitlenin bir alt kÃ¼mesi olarak alÄ±nan Ã¶rneklemin sonucu oluyor. Fakat kitleyi temsil Ã¶zelliÄŸi taÅŸÄ±yor. EÄŸer veri sayÄ±mÄ±z Ã§ok deÄŸilse kitle ile iÅŸlem yapmak her zaman daha iyidir en doÄŸru sonucu verir. Fakat veri sayÄ±mÄ±z Ã§ok fazla (milyonlarca veya milyarlarca veri varsa) bunla uÄŸraÅŸmak yerine onu temsil edebilecek bir alt kÃ¼me alarak genelleme yapmaya Ã§alÄ±ÅŸÄ±yoruz..",
8. ->  ->  1 epoch tÃ¼m verinin iÅŸlenmesi anlamÄ±na geliyor. DolayÄ±sÄ±yla veri setimizdeki her bir veri her epoch'ta tekrar iÅŸlenmiÅŸ oluyor. mini-batch-size = 100 ise ve 1000 adet verimiz varsa, 1 epoch iÃ§in 1000 / 100 = 10 iterasyona ihtiyacÄ±mÄ±z var.",
9. ->  ->  cevabÄ±nÄ±z iÃ§in teÅŸekkÃ¼rler ÅŸu an her ÅŸey netleÅŸmiÅŸ oldu benim iÃ§in..",
10. ->  Merhabalar,->  Her epochta bÃ¼tÃ¼n setin Ã¼zerinden geÃ§iyoruz ancak amacÄ±mÄ±z Loss'u minimize etmek olduÄŸundan sÄ±ralÄ± seÃ§im yapacak olursak istediÄŸimiz sonuca ulaÅŸmamÄ±z oldukÃ§a zorlaÅŸacaktÄ±r. Elimizde bulunan seti en iyi ÅŸekilde Ã¶rnekleyen batch veya batch'ler ile minimum loss deÄŸerine ulaÅŸabiliriz. Yani her bir epoch da batch size kadar veri rastgele seÃ§ilmektedir ki Stochastic bu rastgeleliÄŸin varlÄ±ÄŸÄ±na iÅŸaret iÃ§in bulunmaktadÄ±r.->  Daha kÃ¼Ã§Ã¼k bir veri seti oluÅŸturmak varken neden mini-batch kullanÄ±yoruz sorusunun cevabÄ± ise, daha kÃ¼Ã§Ã¼k bir set oluÅŸturmak elinde olan veri setini daha az sayÄ±da gÃ¶zlem ile Ã¶rneklemek demek oluyor. En doÄŸru Ã¶rneklemi ve Ã¶rneklem bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼ tespit mini-batch ile kÄ±yaslandÄ±ÄŸÄ±nda daha maliyetli olacaÄŸÄ± iÃ§in mini-batch kullanÄ±yoruz..",
    
### soru 

> quest: "Selamlar herkese, kursta ilerlerken Gradient Descent ve benzeri algoritmalarda TÃ¼rev,Ä°ntegral... gibi Calculus 1-2 konularÄ± ve ilerleyen bÃ¶lÃ¼mlerde ise Linear Algebra,Statistics,Probability gibi konularÄ±n algoritmayÄ± anlamak iÃ§in bilinmesi gerektiÄŸini gÃ¶rdÃ¼m. 10. sÄ±nÄ±f olduÄŸumdan saydÄ±ÄŸÄ±m bu konularÄ±n hemen hemen hiÃ§birini okulda gÃ¶rmedim ki zaten matematik anlamÄ±nda sadece okula gÃ¼venmek yanlÄ±ÅŸ olur. Kendi baÅŸÄ±ma bu konularÄ± Ã§alÄ±ÅŸmaya karar verdim, ingilizce / tÃ¼rkÃ§e bu konularÄ± Ã§alÄ±ÅŸabileceÄŸim kaynaklar Ã¶nerebilir misiniz? HaftalÄ±k olarak konularÄ±n gerisinde kalmayacak ÅŸeklide ama yeterli matematik altyapÄ±sÄ±nÄ± da Ã¶ÄŸrenerek ilerlemek istiyorum. TeÅŸekkÃ¼rler...",

> comments:
  
1. ->  [Link](https://www.youtube.com/watch?v=DJ7DoGoU9E0&list=PLcNWqzWzYG2vUwIrhpYTwqm0qboR5yQRA) Lineer Cebir : Lineer Denklem Sistemleri ve Matrisler ile GÃ¶sterimi (www.buders.com)www.youtube.comBUders Ã¼niversite matematiÄŸi derslerinden lineer cebir dersine ait \"Lineer Denklem Sistemleri ve Matrisler ile GÃ¶sterimi\" videosudur. HazÄ±rlayan: Kemal Duran....",
2. ->  bende lisede ve Ã¼niversitede bu konularÄ±n Ã§oÄŸunu hiÃ§ gÃ¶rmedim. ben Ã§ok faydasÄ±nÄ± gÃ¶rdÃ¼m gÃ¶rÃ¼yorum her aradÄ±ÄŸÄ±n konu iÃ§in videolar var inÅŸallah iÅŸinize yarar..",
3. ->  ->  TamamdÄ±r, teÅŸekkÃ¼rler",
4. ->  BirkaÃ§ tane kaynak Ã¶nerebilirim senin iÃ§in umarÄ±m faydasÄ±nÄ± gÃ¶rÃ¼rsÃ¼n. Youtube Ã¼zerinden jbstatistics kanalÄ±na bakmanÄ± Ã¶neririm. Ã–zellikle istatistik , olasÄ±lÄ±k gibi konularda anlamanÄ± kolaylaÅŸtÄ±racak bir kanal. [Link](http://tutorial.math.lamar.edu/) bu site Ã¼zerinden de temel calculus konularÄ±nÄ± anlamanda sana yardÄ±mcÄ± olacak problemler ve Ã§Ã¶zÃ¼mler yer alÄ±yor. Bunu da incelemeni Ã¶neririm..",
5. ->  Professor Leonard 'da aynÄ± zamanda Youtube'da bir kanalÄ± olan ve anlatÄ±mÄ± son derece iyi olan bir hoca. Bu kanala da bakmanÄ± tavsiye ediyorum. Ä°yi Ã§alÄ±ÅŸmalar..",
6. ->  ->  Ã–nerileriniz iÃ§in saÄŸolun ğŸ™‚",
7. ->  [Link](https://mml-book.github.io/book/mml-book.pdf) Bu kitapta gerekli konularÄ± bulabilirsin. AyrÄ±ca Matematik DÃ¼nyasÄ± Dergisinin her bir konu ile ilgili sayÄ±larÄ±nÄ± edinebilirsin..",
8. ->  Bu konseptleri Ã¶ÄŸrenmem iÃ§in (oturup kaÄŸÄ±t kalemle iÅŸlem yapmama pek fayda saÄŸlamasa da) 3blue1brown'un Essence of Calculus serisinin Ã§ok faydasÄ± olmuÅŸtu bana. Limit, tÃ¼rev, integral kavramlarÄ±nÄ±n ne olduÄŸunu ve aralarÄ±ndaki iliÅŸkiyi anlamama Ã§ok yardÄ±mcÄ± oldu. Ä°zlemeni tavsiye ederim..",
9. ->  Kaynak ismi verip kendini o kaynakla kÄ±sÄ±tlamamanÄ± Ã¶neririm. Eksik olduÄŸun konularla alakalÄ± bir liste yapÄ±p YouTube Ã¼zerinden aratabilirsin bence.",
    
### soru 

> quest: "Ã–ncelikle herkese merhabalar ve iyi Ã§alÄ±ÅŸmalar. AklÄ±mda Epoch ve Batch size ile ilgili bir soru takÄ±ldÄ±. Åimdi anladÄ±ÄŸÄ±m kadarÄ±yla verimiz bÃ¼yÃ¼k olduÄŸunda tÃ¼m bu veriyi batch olarak gradient descent algoritmasÄ±na sokmamÄ±z performans ve hÄ±z aÃ§Ä±sÄ±ndan problemlere neden olacaktÄ±r. Bu yÃ¼zden verisetini kÃ¼Ã§Ã¼k batchlere bÃ¶lÃ¼p Ã¶yle algoritmamÄ±za sokmamÄ±z daha iyi olacaktÄ±r. BÃ¶ldÃ¼ÄŸÃ¼mÃ¼z veri boyutlarÄ± batch size, TÃ¼m veri setinin itere edilmesi iÅŸlemi epoch, tÃ¼m batchlerin epoch'a sokulma adÄ±mlarÄ± da iterasyon oluyor. Åimdi benim anlayamadÄ±ÄŸÄ±m ÅŸey, benim elimde 10000 verim var ise ve ben bu verileri 100'er batchlere bÃ¶lmek istiyorsam 1 epoch'un tamamlanmasÄ± iÃ§in gereken iterasyon sayÄ±sÄ± 100 olacak. Ve ben 10 kez epoch yapÄ±lmasÄ±nÄ± istiyorum yani toplamda tÃ¼m epochlarÄ±n tamamlanmasÄ± iÃ§in 1000 iterasyon yapÄ±lacak. Ben batch size'Ä±mÄ± 200 yaparsam ve epoch sayÄ±mÄ± da 20 yaparsam toplamda yapÄ±lan itere sayÄ±sÄ± mantÄ±ken aynÄ± olacak. Bu iki deÄŸer kÃ¼meleri iÃ§in de gradient descent algoritmasÄ± matematiksel olarak aynÄ± oranda mÄ± minimuma yakÄ±nsar? (Train esnasÄ±nda Ã§evresel fakÃ¶rler olan cpu gpu hÄ±zlarÄ± vs gibi ÅŸeyleri ayrÄ± tuttuÄŸumuzda). Åimdiden teÅŸekkÃ¼r ederim. Edit: Ã–mer TÃ¼ksoy'un dÃ¼zeltmesi ile sorudaki matematiksel hatalar dÃ¼zeltilmiÅŸtir. (Batch size ve epoch deÄŸerleri)",

> comments:
  
1. -> Muhtemelen aynÄ± oranda minimuma yakÄ±nsamaz, kesinlikle deneyip gÃ¶rmek gerek ama. farklÄ± batch size'lar ile Ã§alÄ±ÅŸtÄ±rÄ±p optimum sonucu elde etmek en mantÄ±klÄ±sÄ± olacaktÄ±r..",
2. ->  Bence; Ä°teresyon sayÄ±sÄ± eÅŸit olucak ama batch_size=100 alÄ±nca epoch 10 alÄ±nca her bir weight'i 10 kere gÃ¼ncellerken batch_size=200 alÄ±p epoch 5 alÄ±nca her bir weight'i 5 kere gÃ¼ncelleyecek dolayÄ±sÄ±yla muhtemelen 10 epoch yapÄ±nca loss 5 epocha gÃ¶re biraz daha kÃ¼Ã§Ã¼k olacaktÄ±r. KÄ±sacasÄ± epoch 5 ise loss function 5 kere gÃ¼ncellenirken epoch 10 iken 10 kere gÃ¼ncellenecek. DolayÄ±sÄ±yla farklÄ± olacaktÄ±r. Benim dÃ¼ÅŸÃ¼ncem bu yÃ¶nde yanlÄ±ÅŸ dÃ¼ÅŸÃ¼nÃ¼yorsam hocalarÄ±mÄ±z beni de dÃ¼zeltirse sevinirim..",
3. ->  ->  Merhaba,Sorulan soruya aÅŸaÄŸÄ±da yanÄ±t verirken batch ve epoch kavramlarÄ±nÄ± aÃ§Ä±kladÄ±m. Burada ufak bir yanlÄ±ÅŸ anlaÅŸÄ±lma var sanÄ±rÄ±m, iterasyonlar yani gÃ¼ncellemeler her bir epoch baÅŸÄ±na deÄŸil her bir batch_size baÅŸÄ±na yapÄ±lÄ±yor.Ä°yi Ã§alÄ±ÅŸmalar..",
4. ->  CevaplarÄ±nÄ±z iÃ§in Ã§ok teÅŸekkÃ¼r ederim. Epoch gÃ¼ncelleme sayÄ±sÄ± Ã§ok aÅŸÄ±rÄ± olmamak kaydÄ±yla daha fazla olduÄŸunda daha Ã§ok yakÄ±nsayacaÄŸÄ± bana da mantÄ±klÄ± geldi. EÄŸer bir hatamÄ±z varsa bizi dÃ¼zeltmekten Ã§ekinmeyin. Tekrardan teÅŸekkÃ¼r ederim..",
5. -> Merhaba Fethi,Soruna geÃ§meden Ã¶nce batch ve epoch iÃ§in net tanÄ±mlamalar yapalÄ±m: Batch, bir modeli eÄŸitirken 1 iterasyonda (weight update) kullandÄ±ÄŸÄ±n sample sayÄ±sÄ±dÄ±r. Daha aÃ§Ä±klayÄ±cÄ± olmasÄ± aÃ§Ä±sÄ±ndan, 10.000 veri iÃ§in 100 batch seÃ§ersen 1 epoch iÃ§erisinde 100 kere iterasyon yapmÄ±ÅŸ olursun, bu iterasyon sayÄ±sÄ± 200 batch iÃ§in 50 olur. Epoch ise bir modelin tÃ¼m data ile kaÃ§ kere eÄŸitileceÄŸidir.Sorunda verdiÄŸin Ã¶rnekte ufak bir yanlÄ±ÅŸ var, orayÄ± dÃ¼zeltelim. 10.000 veri, 100 batch ve 10 epoch toplam 1.000 iterasyon (10.000/100*10) yapar. VerdiÄŸin ikinci Ã¶rnekteki 200 batch ve 5 epoch ise 10.000/200*5 = 250 iterasyon yapar. DolayÄ±sÄ±yla ikinci Ã¶rnekte de aynÄ± itersyon sayÄ±sÄ±nÄ± saÄŸlamak istiyorsan epoch deÄŸerini 20 seÃ§melisin.Åimdi modelleri karÅŸÄ±laÅŸtÄ±rmaya geÃ§ebiliriz. Tamamen aynÄ± ÅŸartlar altÄ±nda Ã§alÄ±ÅŸan iki farklÄ± model eÄŸittim. EÄŸitirken 50 adet 'feature'a sahip 10.000 satÄ±r iÃ§eren ve uniform daÄŸÄ±lmÄ±ÅŸ bir data kullandÄ±m. DatanÄ±n sÄ±nÄ±flarÄ± ise 0 ve 1 olmak Ã¼zere iki adet. Modellerin her ikisi de tek hidden layerdan oluÅŸuyor ve 64 adet nÃ¶rona sahip. Sorunun yanÄ±tÄ±nÄ± daha net gÃ¶rebilmek iÃ§in ilk modeli 100 batch, 50 epoch seÃ§erek, ikinci modeli ise 200 batch, 100 epoch seÃ§erek eÄŸittim.AÅŸaÄŸÄ±da iki modelin karÅŸÄ±laÅŸtÄ±rmasÄ±nÄ± gÃ¶rebilirsin. Her iki model de toplam 5.000 iterasyon yaptÄ±ÄŸÄ± anda (mavi ve yeÅŸil) train losslar iÃ§in aynÄ± oranda yakÄ±nsamÄ±yorlar ama arada ciddi bir fark da yok diyebiliriz. Tabii burada train datasÄ± Ã¼zerinden loss aldÄ±ÄŸÄ±mÄ±zÄ± unutmayalÄ±m.FarklÄ± batch sayÄ±larÄ± ile aynÄ± epoch arasÄ±ndaki iliÅŸkiyi de turuncu ve yeÅŸil Ã§izimleri karÅŸÄ±laÅŸtÄ±rarak inceleyebilirsin.2 months ago 17 people like this.Like ReportReply",
6. ->  ->  Merhaba,CevabÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederim. Ben kafamda epoch ve batch size deÄŸerlerini ters orantÄ±lÄ± olarak dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼m iÃ§in hem basit matemaitiksel iÅŸlemimde hem de sorumda bir hata oluÅŸmuÅŸtu onu da aydÄ±nlattÄ±ÄŸÄ±nÄ±z iÃ§in ayrÄ±ca teÅŸekkÃ¼r ederim..",
    
### soru 

> quest: "Merhabalar, ben kurstaki Reducing loss (iterative approach) bÃ¶lÃ¼mÃ¼nÃ¼ tam olarak anlayamadÄ±m, iÅŸaretlediÄŸim yerdeki denklemleri ve devamÄ±nÄ± bana aÃ§Ä±klayabilir misiniz, ve iÅŸaretlediÄŸim yer tÃ¼rev midir, tÃ¼revse bunu Ã§Ã¶zmem iÃ§in gerekli olan tÃ¼rev bilgisini nasÄ±l Ã¶ÄŸrenebilirim daha liseliyim, eÄŸer kÄ±saysa sizler aÃ§Ä±layabilir misiniz?  TeÅŸekkÃ¼r ederim.",

> comments:
  
1. ->  TÃ¼rev deÄŸil, y' modelin tahmini, y ise gerÃ§ek deÄŸeri..",
2. ->  y' tÃ¼rev deÄŸil fakat tÃ¼rev de kullanÄ±lÄ±yor gradient hesaplarken, en azÄ±ndan basit olarak Ã¶ÄŸrenmen yararÄ±na olur. Oradaki denklemde tahmin yaparken tek feature(x1) kullanarak tahmin yapÄ±lmÄ±ÅŸ. Bunu ev fiyatÄ± belirlerken oda sayÄ±sÄ± olarak dÃ¼ÅŸÃ¼nebilirsin, yani o formÃ¼lde sadece oda sayÄ±sÄ±nÄ± dikkate alarak ev fiyatÄ±nÄ± tahmin etmeye Ã§alÄ±ÅŸÄ±yor. W ve b deÄŸerleri de ilk olarak 0 atanmÄ±ÅŸ. y' yani tahmin deÄŸerimiz de formÃ¼lde deÄŸerleri yerine yazdÄ±ÄŸÄ±mÄ±zda 0 Ã§Ä±kacak doÄŸal olarak. GerÃ§ek ev fiyatÄ± 0 olamayacaÄŸÄ±ndan hata deÄŸerimiz Ã§ok yÃ¼ksek Ã§Ä±kacak ve w ve b deÄŸerlerimizi hata deÄŸerimiz(loss) azalacak ÅŸekilde tekrar tekrar gÃ¼ncelleyeceÄŸiz. Gradient Descent ve Loss kÄ±sÄ±mlarÄ±nda daha detaylÄ± olarak bunlardan bahsediyor. OralarÄ± okuduÄŸunda kafanda daha iyi canlanabilir. Lisedeyken bÃ¶yle ÅŸeylerle uÄŸraÅŸmaya baÅŸlaman sÃ¼per, tebrik ederim ğŸ™‚",
3. ->  ->  Åimdi anladÄ±m, yardÄ±mÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederim.",
    
### soru 

> quest: "Herkese merhablar, bÃ¶yle basit bir soruyla sizi meÅŸgul ettiÄŸim iÃ§in Ã¶zÃ¼r dilerim ama multiple linear regression Ã§alÄ±ÅŸÄ±rken lineer modellerin genel olarak kolay aÃ§Ä±klanabilir olduÄŸunu fakat kolay aÃ§Ä±klanabilirliÄŸin Ã§oÄŸu zaman accuracy'den feragat etmeyi gerektirdiÄŸini Ã¶ÄŸrendim. Lineer modeli daha esnek bir hale getirmek veya tutarlÄ±lÄ±ÄŸÄ± arttÄ±rmak iÃ§in iki baÄŸÄ±msÄ±z deÄŸiÅŸkeni birbiri ile Ã§arpÄ±p modele ekleyebileceÄŸimizi Ã¶ÄŸrendim. Bu yeni eklenen terime \"interaction term\" denildiÄŸini Ã¶ÄŸrendim. Fakat yine de hangi koÅŸullar altÄ±nda, neden bÃ¶yle bir iÅŸlemi yapacaÄŸÄ±mÄ±zÄ± ve nasÄ±l Ã§oklu baÄŸÄ±msÄ±z deÄŸiÅŸkenler Ã¼zerinde yapacaÄŸÄ±mÄ±zÄ± kafamda oturtup bunu kullanabileceÄŸimiz bir Ã¶rnek bulamadÄ±m. Rica etsem bu tekniÄŸi kÄ±sa bir ÅŸekilde aÃ§Ä±klayÄ±p, kullanabileceÄŸimiz bir Ã¶rnek verir misiniz?",

> comments:
  
1. ->  Benim bildiÄŸim kadarÄ±yla baÄŸÄ±mlÄ± deÄŸiÅŸkene en az etki eden deÄŸiÅŸkenler Ã¼zerinden etkisiz olanlarÄ± ya modelden Ã§Ä±karmalÄ±yÄ±z yada dÃ¶nÃ¼ÅŸtÃ¼rme iÅŸlemleri uygulanabilir. Ã–rnek vermek gerekirse Ã§oklu boyut problemi veya Ã§oklu doÄŸrusal baÄŸlantÄ± problemi gibi problemlerde ilgi deÄŸiÅŸkenleri azaltmamÄ±z gerekebilir.Bunun iÃ§in PCA , lassa ridge gibi methodlar kullanÄ±labilir. sizin dediÄŸiniz deÄŸiÅŸkenleri Ã§arpmakta ayrÄ± bir method olabilir , o konu hakkÄ±nda kesin bir bilgim yok.Ã–zetle asÄ±l amaÃ§ en etkili ve etkin baÄŸÄ±msÄ±z olan deÄŸiÅŸkenleri kullanmak. YanlÄ±ÅŸÄ±m varsa lÃ¼tfen mentor arkadaÅŸlar dÃ¼zeltsin.",
2. -> ->  Ã–ncelikle cevapladÄ±ÄŸÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederim, benim bahsettiÄŸim metot'da deÄŸiÅŸken azaltma yok gibime geldi.ÅÃ¶yle bir modelimiz olsun:y = Î²1*x1 + Î²2*x2Biz burada bahsettiÄŸim gibi bir interaction term eklemek istersek modelimizin son hali ÅŸu ÅŸekilde olur:y = Î²1*x1 + Î²2*x2 + Î²3*x1*x2AnladÄ±ÄŸÄ±m kadarÄ±yla bir \"interaciton\" baÄŸÄ±msÄ±z bir deÄŸiÅŸkenin baÅŸka bir baÄŸÄ±msÄ±z deÄŸiÅŸkenin deÄŸerine gÃ¶re baÄŸÄ±mlÄ± deÄŸiÅŸkene yaptÄ±ÄŸÄ± deÄŸiÅŸiklik deÄŸiÅŸiyorsa var oluyor. Mesela ÅŸÃ¶yle bir durumu inceleyelim bir ilacÄ±mÄ±z olsun ve bu ilacÄ±mÄ±zÄ±n salgÄ±lattÄ±ÄŸÄ± kolestrol miktarÄ±na bakalÄ±m ve kolestrol miktarÄ±nÄ± tahmin etmeye Ã§alÄ±ÅŸalÄ±m. EÄŸer ilacÄ±n alÄ±nan dozu (baÄŸÄ±msÄ±z bir deÄŸiÅŸken) 'na gÃ¶re salgÄ±lanan kolestrol miktarÄ± baÅŸka bir baÄŸÄ±msÄ±z deÄŸiÅŸken olan cinsiyet deÄŸiÅŸkenine gÃ¶re farklÄ±lÄ±k gÃ¶steriyorsa burada interaction term kullanmamÄ±z gerekiyor. Ã–rnek olarak bu ilaÃ§ Ã¶rneÄŸinden devam edelim.Cinsiyetin salgÄ±lanan doza etkisi olmadÄ±ÄŸÄ± durumdaki modelimiz:y = Î± + Î²1 âˆ— doz ÅŸeklinde olurduCinsiyetin etkisi olsaydÄ± ama interaction ile alakasÄ± olmasaydÄ± (hangi cinsiyet olduÄŸu farketmeden alÄ±nan doz her iki cinsiyet'de de aynÄ± bÃ¼yÃ¼meyi saÄŸlasaydÄ±):y = = Î± + Î²1 âˆ— doz + Î²2 * cinsiyet (burada cinsiyet dummy variable olarak kabul ediliyor)Cinsiyetin etkisi interaction ile birlikte olsaydÄ±:y = Î± + Î²1 âˆ— doz + Î²2 * cinsiyet + Î²3 Ã— doz âˆ— cinsiyetÄ°sterseniz bunlarÄ±n grafiÄŸini Ã§izmeyi deneyip aklÄ±nÄ±zda daha da oturmasÄ±nÄ± saÄŸlayabilirsiniz.Ama verdiÄŸim tÃ¼m bu Ã¶rnekler 2. baÄŸÄ±msÄ±z deÄŸiÅŸkenin bir dummy variable olduÄŸu durumlardÄ±. SayÄ±sal bir deÄŸer olsaydÄ± nasÄ±l olurdu, veya gerÃ§ek hayatta bu tÃ¼r bir metodu nasÄ±l kullanabilirim hala daha anlayamadÄ±m. EÄŸer bir yanlÄ±ÅŸÄ±m varsa veya eklemek istedikleri bir yer varsa deÄŸerli mentÃ¶rlerimiz yardÄ±mcÄ± olabilir mi? CevabÄ±nÄ±zÄ± 4 gÃ¶zle bekliyorum. SaÄŸolun...",
3. -> Merhabalar,Bu durumu en iyi aÃ§Ä±klayan konunun 'kernel trick' olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yorum. [Link](https://towardsdatascience.com/truly-understanding-the-kernel-trick-1aeb11560769) Bu makaledeki ÅŸu resimdeki data seti inceleyecek olursak. [Link](https://miro.medium.com/max/1440/1*eU9PzjVcLNbNEzBC2g_iWg.jpeg) Bu data set doÄŸrusal olarak sÄ±nÄ±flandÄ±rÄ±labilir deÄŸil. Bunun iÃ§in Ã¶rneÄŸin Ã¶zelliklerimizin x ekseninin X, y eksenin de Y Ã¶zelliÄŸi olduÄŸunu varsayarsak (0,0) noktasÄ±nÄ± merkez gibi gÃ¶rÃ¼nÃ¼yor.Her Ã¶rneÄŸin merkeze olan uzaklÄ±ÄŸÄ±nÄ± tanÄ±mlayacak bir yeni Ã¶zellik tanÄ±mladÄ±ÄŸÄ±mÄ±zÄ± dÃ¼ÅŸÃ¼nelim sqrt((xi-x0)**2 + (yi-y0)**2) ÅŸeklinde hesaplanan yeni bir Ã¶zelliÄŸimiz olunca aslÄ±nda saÄŸdaki ÅŸekil elde edilmiÅŸ olacak.SaÄŸdaki ÅŸekilde doÄŸrusal olarak ayrÄ±ÅŸtÄ±rÄ±labilir bir probleme dÃ¶nÃ¼ÅŸÃ¼yor.ArtÄ±k kÄ±saca (yaklaÅŸÄ±k olarak - aynÄ± Ã¶rneÄŸe gÃ¶re-) yeni Ã¶zelliÄŸe gÃ¶re 0.5 deÄŸerinden kÃ¼Ã§Ã¼kler bir sÄ±nÄ±fa ait bÃ¼yÃ¼kler diÄŸer sÄ±nÄ±fa aittir sÃ¶ylenebilir (Bu dataya bakarak bizim gÃ¶zle gÃ¶rdÃ¼ÄŸÃ¼mÃ¼z tabikide).Ä°yi Ã§alÄ±ÅŸmalar,Mehmet",
4. -> Soru oldukÃ§a gÃ¼zel.Ã–ncelikle deÄŸiÅŸkenlerin birlikte ele alÄ±nmasÄ± (x1 * x2) Ã§alÄ±ÅŸÄ±lan konu iÃ§in mantÄ±klÄ± bir yaklaÅŸÄ±m olmalÄ±.Regresyon modellerinde hangi modeli kullanmamÄ±z gerektiÄŸi sorusu ile karÅŸÄ±laÅŸtÄ±ÄŸÄ±mÄ±zda modelin R^2' (Belirlilik katsayÄ±sÄ±) (Coefficient of Determination)sini kullanÄ±rÄ±z. Daha yÃ¼ksek R^2 daha aÃ§Ä±klayÄ±cÄ± model demektir. R^2 0 ile 1 arasÄ±nda deÄŸiÅŸen deÄŸerler alÄ±r. Ã–rneÄŸin bir regresyon modelinin R^2 si 0.72 Ã§Ä±kmasÄ± baÄŸÄ±mlÄ± deÄŸiÅŸkendeki deÄŸiÅŸimin yÃ¼zde 72'si model tarafÄ±ndan aÃ§Ä±klanÄ±yor ÅŸeklinde yorumlanabilir. Burada Ã§ok Ã§ok Ã¶nemli bir nokta bir modelin veriye uyumunu deÄŸerlendirmek iÃ§in bir tek R^2'ye gÃ¼venmemek gerek. Ä°statistikÃ§iler hata terimlerinin daÄŸÄ±lÄ±mÄ±, katsayÄ±larÄ±n anlamlÄ±lÄ±ÄŸÄ±, tahminlerin gÃ¼ven aralÄ±ÄŸÄ± gibi farklÄ± teknikler ile de modellerinin kalitesini Ã¶lÃ§erler.Basit bir regresyon modeli (y = beta0*x1 + beta1*x2) nin belli bir R^2 si var buna baÄŸÄ±msÄ±z deÄŸiÅŸkenlerin birlikte Ã¶lÃ§Ã¼mlerini eklersek (y = beta0*x1 + beta1*x2 + beta2*x1*x2) acaba daha iyi bir model elde eder miyiz ?Bunun cevabÄ± iÃ§in R^2 ye baÅŸvurmak yeterli mi ? Maalesef deÄŸil. Ã‡Ã¼nkÃ¼ bir modele yeni terimler eklemek her zaman R^2 yi yÃ¼kseltir. Bu yÃ¼zden yeni terim eklediÄŸimizde modelin veriye uyumunu kontrol etmek iÃ§in terim sayÄ±sÄ±nÄ±n etkisinden arÄ±ndÄ±rÄ±lmÄ±ÅŸ DÃ¼zeltilmiÅŸ Belirlilik KatsayÄ±sÄ± (Adjusted R^2) kullanÄ±lmalÄ±dÄ±r. Daha yÃ¼ksek Adjusted R^2 daha iyi model demek..",
5. ->  Bunun yanÄ±nda model katsayÄ±larÄ±nÄ±n anlamlÄ±lÄ±ÄŸÄ±nÄ± test edip eÄŸer interaction_term'in katsayÄ±sÄ± istatisiksel olarak anlamlÄ± ise (p<0.05) ise modeline eklemelisin.Not: Python'da yukarÄ±da verilen hesaplamalar kolaylÄ±kla yapÄ±labiliyor.GerÃ§ek bir Ã¶rnek olarak cinsiyet yerine baÅŸka bir ilaÃ§ dÃ¼ÅŸÃ¼nebilirsin. Ä°laÃ§lar ayrÄ± ayrÄ± kullanÄ±ldÄ±klarÄ±nda etkileri olumlu olsun ama beraber kullanÄ±ldÄ±klarÄ±nda girdikleri tepkime sonucu Ã¼rettikleri baÅŸka bir kimyasal yÃ¼zÃ¼nden olumsuz etki gÃ¶stersin. Bu tip bir durumda bu iki ilacÄ±n birlikte ele alÄ±nÄ±p regresyon modeline eklenmeleri gerekir..",
6. ->  ->  Ã‡ok net anlatmÄ±ÅŸsÄ±nÄ±z, teÅŸekkÃ¼rler..",
7. -> BulunduÄŸum sektÃ¶rden (sigortacÄ±lÄ±k) ÅŸÃ¶yle bir Ã¶rnek ile aÃ§Ä±klayabilirim.AraÃ§larÄ±n kasko fiyatlarÄ±nÄ± tahminlemek iÃ§in genelleÅŸtirilmiÅŸ lineer modeller kullanÄ±rÄ±z. AslÄ±nda sÃ¶ylemde basitleÅŸtirmek istersek olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ± deÄŸiÅŸtirilmiÅŸ multi lineer regresyon. Ã–rneÄŸe gelecek olursak sÃ¼rÃ¼cÃ¼lerin yaÅŸÄ± ve cinsiyeti bilgileri ile kasko fiyatlarÄ±nÄ± tahmin ettiÄŸimizi dÃ¼ÅŸÃ¼nelim. Fiyatlar regresyon modellerinde erkeklerde 45-50 li yaÅŸlarda, kadÄ±nlarda 40 - 45li yaÅŸlarda bir tÄ±k yÃ¼ksek tahminlenir. Bunun sebebi ise araÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda bu yaÅŸlardaki insanlarÄ±n Ã§ocuklarÄ±nÄ±n genÃ§lik dÃ¶nemlerinde olduÄŸu ve araÃ§larÄ± izinsiz alarak kazalar yapÄ±klarÄ± ÅŸeklinde aÃ§Ä±klanÄ±r. Bu durum herkes iÃ§in geÃ§erli olmayacaÄŸÄ±ndan o yaÅŸlar iÃ§in interaction yapÄ±lmasÄ± gerekmektedir. cinsiyet ve yaÅŸ Interaction'Ä± sonrasÄ± elle bir miktar modele mÃ¼dahale edilerek fiyattaki bu artÄ±ÅŸ bir miktar tÃ¶rpÃ¼lenir. Interaction kurmazsanÄ±z yaÅŸ ve cinsiyet baÄŸÄ±msÄ±z deÄŸiÅŸkenlerini birlikte etkileÅŸime sokamaz ve yalnÄ±zca istediÄŸiniz noktaya mÃ¼dahale edemezsiniz. Interaction'da zaten etkileÅŸim anlamÄ±na gelmektedir. Modellerde doÄŸrusunu bildiÄŸiniz ve dÃ¼zeltebileceÄŸiniz istisna durumlar iÃ§in belirli deÄŸiÅŸkenler arasÄ±nda kullanÄ±rsÄ±nÄ±z. UmarÄ±m bir miktar aÃ§Ä±klayabilmiÅŸimdir.",
    
### soru 

> quest: "Learning Rate kÄ±smÄ±nda bir grafik var, learning rate'i kendimiz ayarlayÄ±p lossu minimize edebiliyoruz. Kafama takÄ±lan bÃ¼yÃ¼k bir learning rate seÃ§mek burda avantajlÄ± gibi gÃ¶zÃ¼kÃ¼yor, ilk adÄ±mÄ± bÃ¼yÃ¼k atÄ±yor minimum lossa yaklaÅŸtÄ±kÃ§a adÄ±m bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼ azaltÄ±p hedefe ulaÅŸÄ±yor. Bunun normalde mÃ¼mkÃ¼n olmamasÄ± gerekiyor sanÄ±rÄ±m, Rate eÄŸitim boyu aynÄ± kalmasÄ± gerekmez mi?",

> comments:
  
1. ->  Learning rate orada da eÄŸitim boyunca aynÄ±, orada adÄ±m olarak gÃ¶rdÃ¼klerin gradient descent sonucu oluÅŸan deÄŸerler. Gradient descent iÅŸleminde local minimuma yaklaÅŸÄ±ldÄ±kÃ§a vektÃ¶rlerin boyu kÄ±salÄ±r.AÅŸaÄŸÄ±da linkini koymuÅŸ olduÄŸum videoyu izlersen kafanda biraz daha oturacaktÄ±r. AnlatÄ±lan ders Gradient, dolayÄ±sÄ±yla oklar local minimuma doÄŸru deÄŸil local maximuma doÄŸru gidiyor. Ancak biz lossu minimize etmeye Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z iÃ§in bu vektÃ¶rlerin negatiflerini kullanÄ±yoruz.[Link](https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/gradient-and-directional-derivatives/v/gradient-and-graphs),
"Gradient and graphs (video) | Khan Academywww.khanacademy.orgLearn how the gradient can be thought of as pointing in the \"direction of steepest ascent\". This is a rather important interpretation for the gradient.Â ",
2. ->  learning rate ile costun tÃ¼rvini Ã§arpÄ±yoruz cost azaldÄ±kÃ§a learning ratein etkiside azalÄ±yor gibi anladÄ±m ben.Weight = Weight - (learning rate)x(costun tÃ¼revi)",
3. ->  ->  cost ile mean square errorÃ¼ kastettim. Bide yukarÄ±da cost azaldÄ±kÃ§a deÄŸilde costun tÃ¼revi azaldÄ±kÃ§a demek istedim. Minimuma yaklaÅŸtÄ±kÃ§a costun tÃ¼revi azalÄ±yor, tÃ¼rev azaldÄ±kÃ§a learning rate ile Ã§arpÄ±mÄ± daha az deÄŸiÅŸikliÄŸe sebep oluyor..",
4. -> ->  Kursta gradient olarak adlandÄ±rdÄ±ÄŸÄ±mÄ±z deÄŸiÅŸken cost'un tÃ¼revi dediÄŸiniz deÄŸer mi? Bu fonksiyonun adÄ± cost olarak mÄ± geÃ§iyor?",
5. ->  ->  Eger cost , mean square error dersek yanlis olur.Hedefimiz prediction ise MSE, ancak classification ise Categorical Cross Entropy ya da Binary Cross Entropy olabilir.Yani cost function probleme gore degisir.Buun disinda soylediklerinize katiliyorum.",
6. -> Learning rate sabitken bile adÄ±mlar itere edildikÃ§e kÄ±salÄ±r Ã§Ã¼nkÃ¼ gradient descent fonksiyonunda cost fonksiyonumuzun derivative'Ä° alÄ±nÄ±r ve bu deÄŸerimiz*learning rate theta deÄŸerimizden Ã§Ä±karÄ±lÄ±r. Theta deÄŸeri dediÄŸimiz deÄŸer bizim minimize edilmiÅŸ cost function deÄŸerimizdir. Ã–rneÄŸin theta1 lineer regresyon formÃ¼lÃ¼ndeki (y=ax1+bx2+cx3) x1 deÄŸerini temsil eder. x2 ve x3 iÃ§in de deÄŸerler aynÄ±dÄ±r.(Burada 3 tane feature'Ä±mÄ±z varmÄ±ÅŸ gibi kabul ettiÄŸimiz iÃ§in x3'e kadar gittik. Bu featurelar daha az veya daha fazla olabilir.) Yani her iterede bir sonraki theta deÄŸeri daha az kÄ±salÄ±r. Resimde formÃ¼lÃ¼ gÃ¶rebilirsiniz. Learning rate iÃ§in kesinleÅŸmiÅŸ bir deÄŸer yoktur, veri setine gÃ¶re en optimum learning rate deÄŸeri deÄŸiÅŸir. Learning rate olmasÄ± gerekenden bÃ¼yÃ¼k olursa minimum local deÄŸerini Ä±skalar ve bÃ¶ylece aslÄ±nda minimum deÄŸere yaklaÅŸacaÄŸÄ±na uzaklaÅŸmÄ±ÅŸ olur. Learning rate deÄŸerimiz Ã§ok kÃ¼Ã§Ã¼k olursa da minimuma ulaÅŸmak Ã§ok fazla vakit alÄ±r. AslÄ±nda orada deÄŸiÅŸen ÅŸey learning rate deÄŸil derivative'i alÄ±nmÄ±ÅŸ fonksiyonun azalma sayÄ±sÄ±dÄ±r. Ã–rneÄŸin 10x^2 deÄŸerinin derivative'ini alÄ±rsanÄ±z 20x olur. Yani ilk iterede 10x^2-20x kadarlÄ±k bir azalma olmuÅŸ. Tekrar 20x'in derivative'ini alÄ±rsanÄ±z deÄŸer 20 olur yani burada da 20x-20'lik bir azalma olmuÅŸ. (10x^2-20x) > (20x-20). Bu nedenle atÄ±lan stepler de itere boyunca kÃ¼Ã§Ã¼lÃ¼r.",
7. ->  AslÄ±nda ÅŸÃ¶yle dÃ¼ÅŸÃ¼nÃ¼lebilir, bir arazide su birikintisini arÄ±yorsunuz ve learning rate sizin adÄ±mÄ±nÄ±zÄ±n mesafesi olsun. Su birikintisine yaklaÅŸana kadar bÃ¼yÃ¼k bÃ¼yÃ¼k adÄ±mlar atÄ±yorsunuz mesela 5 metre diyelim ama artÄ±k su bitikintisine 3 metre uzakatasÄ±nÄ±z. 5 metre adÄ±m atÄ±nca diÄŸer tarafta 2 metre uzaktasÄ±nÄ±z. Bir tÃ¼rlÃ¼ yaklaÅŸamÄ±yorsunuz. Mecburen adÄ±m mesafenizi 5 metreden daha kÃ¼Ã§Ã¼k hale getirmelisiniz ki mesela 1 metre olsun. 2 metre uzaklÄ±ktan sonra 2 iterasyon sonra yani 2 adÄ±m sonra artÄ±k su birikintisindesiniz.En baÅŸÄ±nda da adÄ±mÄ±nÄ±zÄ± 1 metre atabilirdiniz ama su birikintisine ulaÅŸana kadar Ã§ok adÄ±m atmÄ±ÅŸ olurdunuz. Bu da sizi yani sistemi yorardÄ±. AmacÄ±mÄ±z minimum adÄ±mla su birikintisine ulaÅŸmak aslÄ±nda. BÃ¶yle dÃ¼ÅŸÃ¼nebilirsiniz.",
    
### soru 

> quest: "Learning rate, batch ve epoch deÄŸerlerinim optimumunu bulmak iÃ§in her zaman deneysel bir yol mu izlemeliyiz ? Bu deÄŸerleri bulmanÄ±n deneysel yoldan farklÄ± olarak formÃ¼l yada farklÄ± bir yolla bulmak mÃ¼mkÃ¼n mÃ¼?",

> comments:
  
1. ->  BunlarÄ± bulmanÄ±n direk bir formÃ¼lÃ¼ yok ne yazÄ±k ki. SÄ±fÄ±rdan bir algoritma geliÅŸtirmiyorsanÄ±z genelde kullandÄ±ÄŸÄ±nÄ±z algoritmanÄ±n makalelerinde bu tarz deÄŸerler en alt sayfada paylaÅŸÄ±lÄ±r(veya makale iÃ§erisinde). Tabiki bu yaptÄ±ÄŸÄ±nÄ±z uygulamanÄ±n tÃ¼rÃ¼ ve elinizde ki verinin yoÄŸunluÄŸuna gÃ¶re Ã§ok deÄŸiÅŸim gÃ¶steriyor. AslÄ±nda iÅŸin mÃ¼hendislik kÄ±smÄ± bunlarla oynayÄ±p(hyperparamer tuning) ve belirli optimizasyonlar yaparak(Ã¶rneÄŸin modelin eÄŸitilme sÃ¼resi - deneme sÃ¼reniz - hesaplama gÃ¼cÃ¼ kullanÄ±mÄ± vs ) optimal deÄŸerleri seÃ§mekteKÄ±sacasÄ± , direk formÃ¼l yok ama yapÄ±lmÄ±ÅŸ Ã§alÄ±ÅŸmalarÄ± incelemek en yararlÄ±sÄ±..",
2. ->  Bunu ben de merak ediyorum. Lakin her veri kÃ¼mesi ve iÃ§erisindeki gÃ¼rÃ¼ltÃ¼ vs. gibi faktÃ¶rler farklÄ± olduÄŸundan sanÄ±rÄ±m bir formÃ¼lÃ¼ yok. Kursta da belirtildiÄŸi gibi, gÃ¶zetimli Ã¶ÄŸrenmede (supervised learning) bir makine Ã¶ÄŸrenme algoritmasÄ± birÃ§ok Ã¶rneÄŸi inceleyerek kaybÄ± en aza indiren en iyi modeli bulmaya Ã§alÄ±ÅŸÄ±yor. Bu sÃ¼rece de ampirik risk minimizasyonu (empirical risk minimization) deniyor. Ampirik = Deneysel yani deneyerek bulmak gerekiyor diye biliyorum. LÃ¼tfen hatam varsa dÃ¼zeltiniz. Ä°yi gÃ¼nler????..",
3. ->  En iyi learning rate deÄŸerinin ne olduÄŸunu bulmak iÃ§in analitik bir yÃ¶ntem yok. Bunun iÃ§in diÄŸerlerine gÃ¶re daha iyi olan learning rate'i deneysel yol izleyerek buluyoruz..",
4. ->  BÃ¼yÃ¼k bir veri setinde bu deÄŸerleri bulmak deneyerek bulmak zaman kaybÄ±na neden olabilir baya",
5. ->  ->  Deneyerek bulmak yerine akademik Ã§alÄ±ÅŸmalarda Ã§ok kullanÄ±lan deÄŸerleri deneyip sonuÃ§larÄ± inceledikten sonra hangi kÄ±sÄ±mlarda yanlÄ±ÅŸ tahminler veiryor ona gÃ¶re tune / ince ayar Ã§ekmeniz gerekir.",
6. ->  [Link](https://arxiv.org/pdf/1506.01186.pdf) ÅŸu yayÄ±nÄ± okumanÄ± tavsiye ederim.Ramazan Kartal Hiper parametre analizi icin 'Grid Search' konusuna bakabilirsin. [Link](https://medium.com/deep-learning-turkiye/derin-ogrenme-uygulamalarinda-model-dogrulama-ve-hiper-parametre-secim-yontemleri-823812d95f3)",
"Derin Ã–ÄŸrenme UygulamalarÄ±nda Hiper Parametre SeÃ§im YÃ¶ntemlerimedium.comDerin Ã¶ÄŸrenme uygulamalarÄ±nda hiper parametreler yazÄ± serisinin ilk bÃ¶lÃ¼mÃ¼nde, derin Ã¶ÄŸrenme uygulamalarÄ±nda en sÄ±k kullanÄ±lan hiperâ€¦.",
"Muhammed Fatih GÃ¼ltekin Optuna diye bir kÃ¼tÃ¼phane var bakabilirsin.",
7. -> Grid search, random search veya informed search gibi metodolojilere bakÄ±labilir. Tabi bunlar da deneme temelli yÃ¶ntemler.",
"Ramazan ÃœnlÃ¼ Learning rate iÃ§in kesin bir kural yok. Ancak gradient descentâ€™Ä±n mantÄ±ÄŸÄ± gereÄŸi hangi deÄŸeri seÃ§erseniz seÃ§in optimum noktaya yaklaÅŸtÄ±kÃ§a etki deÄŸeri kademeli olarak azalÄ±r. Ã‡ok kÃ¼Ã§Ã¼k deÄŸerler seÃ§ildiÄŸinde local minumuma dÃ¼ÅŸme riski artar. 0.01 0.001 gibi deÄŸerler yeterince iÅŸ gÃ¶rÃ¼yor genelde.Epoch iÃ§in bayesian error ile eÄŸitim setindeki hata karÅŸÄ±laÅŸtÄ±rÄ±labilir. EÄŸer yeterince veriniz varsa, aÄŸ yeterince bÃ¼yÃ¼kse ancak bayesian error ile eÄŸitim setindeki hata farkÄ± yÃ¼ksekse epoch sayÄ±sÄ±nÄ±n artÄ±rÄ±lmasÄ±nÄ±n fayda saÄŸlayacaÄŸÄ± sonucuna varÄ±labilir..",
8. ->  Ramazan ÃœnlÃ¼ 'Epoch icin Bayesian error ile egitim setindeki hata karsilastirilabilir ' ifadesini hic anlayamadim.Egitim seti derken egitim sirasinda demek istediniz sanirim.Egitim sirasindaki hata derken loss dan bahsediyorsunuz saniyorum.Soylemek istediginiz: Hedefiniz prediction yapmaksa Mean Square Error kullanarak hesaplayacaginiz loss degerine bakilarak epoch konusunda karar verebilirsiniz gibi birsey sanirim.",
9. ->  Deneyerek learning rate gibi hyperparametrelerin optimum degerini bulmaya calismanin zaman tuketici bir is oldugunu gozonune aldigimizda,bu isin basinda oldugumuzu varsayarak en iyi yontem uzmanlarca denenmis kullanagelinene basvurmak olabilir diye dusunuyorum.Mesela Adam optimizer ile learning_rate=1e-3 kullaniyorum ya da yukarida soylendigi gibi 0.01 ya da 0.001 seciyorum genellikle...",
    
### soru 
> quest: "merhaba! reducing loss konusuna Ã§alÄ±ÅŸÄ±rken gradient descent ve stochastic gradient descent arasÄ±ndaki farkÄ± tam anlayamadÄ±m. bana bu konuda yardÄ±mcÄ± olabilir misiniz?",

> comments:
  
1. ->  Merhaba, bu sorunun aynÄ±sÄ± sorulmuÅŸtu ->  arkadaÅŸÄ±mÄ±z tarafÄ±ndan. O post'u okursan soruna yanÄ±t bulabilirsin bence..",
" ->  ->  Onu okumuÅŸtum ama orda mini-batch SGD ve SGD arasÄ±ndaki fark sorulmuÅŸ ve yanÄ±t olarak batch ifadesi aÃ§Ä±klanmÄ±ÅŸ daha Ã§ok fakat ben GD ve SGDyi sormuÅŸtum bildiÄŸim kadarla bu ikisinde batch size hiperparametresi girilmiyor bu yÃ¼zden sorumun yanÄ±tÄ±nÄ± tam alamadÄ±m ama yine de teÅŸekkÃ¼rler yanÄ±tÄ±n iÃ§in.",
2. ->   ->  Gradient Descent loss'u minimize etmek iÃ§in kullanÄ±lan yÃ¶ntemin adÄ±. Stochastic Gradient Descent ise loss'u minimize ederken veri setimizdeki her bir Ã¶rneÄŸimiz iÃ§in gradient descent'in bir adÄ±m atmasÄ± anlamÄ±na geliyor. Yani tek bir Ã¶rneÄŸe bakarak loss'taki deÄŸiÅŸimi hesaplayÄ±p parametreleri gÃ¼ncelliyor. Gradient Descent'in Ã¶nÃ¼ne gelen kelimeler, kaÃ§ tane Ã¶rneÄŸi dikkate alarak iterasyon yapacaÄŸÄ±mÄ±zÄ± belirtiyor. AslÄ±nda SGD, batch-size'in 1 e eÅŸit olduÄŸunu belirtmek iÃ§in kullanÄ±lan Ã¶zel bir isim sadece.2 months ago 16 people like this.Like ReportReply",
3. ->  ->  ÅŸimdi anladÄ±m teÅŸekkÃ¼r ederim.",
    
### soru 

> quest: "Merhaba. Train-Test setlerimizi ayÄ±rÄ±rken, videoda 1 milyar datamÄ±z olsa dahi %10 test %90 train olarak ayÄ±rmaktan bahsediliyor. 1 milyar gayet bÃ¼yÃ¼k bir rakam. Bu ÅŸekilde ayÄ±rmak eskiden(kÃ¼Ã§Ã¼k datasetler iÃ§in) mantÄ±klÄ±ydÄ± ama artÄ±k bir Ã§ok konuda big data mevcut. Bunu %98 train, %1 test(10 milyon!), %1 validation(10 milyon!) olarak ayÄ±rmamÄ±z daha mantÄ±klÄ± olmaz mÄ±?",

> comments:
  
1. ->  Evet ben de andrew ng deep learning kursunda dediÄŸiniz gibi 98-1-1 ÅŸeklinde yapÄ±lmasÄ±nÄ±n daha mantÄ±klÄ± olduÄŸunu duymuÅŸtum ğŸ™‚.",
2. -> Ã–ncelikle literatÃ¼rde bu konu Ã¼zerinde net bir fikir birliÄŸine varÄ±lmÄ±ÅŸ deÄŸil. Kimi araÅŸtÄ±rmacÄ±lar 80:20 oranÄ±nÄ± benimserken kimileri 90:10 bazÄ±larÄ± 70:30 oranlarÄ±nÄ±n daha iyi sonuÃ§lar vereceÄŸini iddia ediyorlar. Andrew Ng Ã§ok bÃ¼yÃ¼k veri setlerinde 98:1:1 ve hatta 99:0.5:0.5 oranlarÄ±nÄ±n kullanÄ±lmasÄ± gerektiÄŸini ifade ediyor. Klasik makine Ã¶ÄŸrenmesi algoritmalarÄ±nda veri miktarÄ± arttÄ±kÃ§a baÅŸarÄ± oranÄ± belli bir noktadan sonra dÃ¼zlÃ¼ÄŸe ulaÅŸmakta, derin Ã¶ÄŸrenme algoritmalarÄ±nda ise veri miktarÄ± arttÄ±kÃ§a baÅŸarÄ±nÄ±n artÄ±ÅŸÄ± daha doÄŸrusal. Bu yÃ¼zden klasik makine Ã¶ÄŸrenmesi algoritmalarÄ± kullanÄ±yorsanÄ±z train:test oranÄ±nÄ± biraz daha dÃ¼ÅŸÃ¼k tutabilirsiniz. Derin Ã¶ÄŸrenme algoritmalarÄ±nda ise eÄŸitime mÃ¼mkÃ¼n mertebe daha fazla veri saÄŸlamak daha baÅŸarÄ±lÄ± sonuÃ§ demek.Tabii ki gerÃ§ek bir uygulamada en gÃ¼zeli farklÄ± oranlarÄ± deneyip sonuÃ§larÄ± karÅŸÄ±laÅŸtÄ±rmak.AyrÄ±ca ek olarak toplamda ne kadar veri kullanmalÄ±yÄ±m sorusunu kendinize sorabilirsiniz.Bir modelin eÄŸitimi iÃ§in ne kadar veri gerektiÄŸi Ä°statistiksel Ã–ÄŸrenme Teorisi (Statistical Learning Theory) ile Ã§Ã¶zÃ¼lebilecek bir problem. Bu bÃ¼yÃ¼klÃ¼k kullanacaÄŸÄ±nÄ±z modelin karmaÅŸÄ±klÄ±ÄŸÄ±, parametreler arasÄ±ndaki iliÅŸkiler, gÃ¼rÃ¼ltÃ¼lÃ¼ veri miktarÄ± ve her bir deÄŸiÅŸkenin varyansÄ± gibi Ã§eÅŸitli etmenlere baÄŸlÄ±.Peki bunlarÄ± bilmeden bir makine Ã¶ÄŸrenmesi algoritmasÄ± geliÅŸtirilebilir mi? Sorunun cevabÄ± evet. Her problem farklÄ±dÄ±r. En gÃ¼zel yÃ¶ntem farklÄ± oranlarÄ± deneyip sonuÃ§larÄ± karÅŸÄ±laÅŸtÄ±rmak.",
3. ->  Test ve validation datasÄ±nÄ± o kadar bÃ¼yÃ¼k tutmanÄ±n Ã§ok bir manasÄ± yok. DediÄŸiniz gibi 10 milyon test datasÄ± pek kullanÄ±ÅŸlÄ± deÄŸil. Belirli bir boyutlara ulaÅŸtÄ±ÄŸÄ±nÄ±zda o oranlarÄ± kendinize gÃ¶re ÅŸekillendirebilirsiniz. GerÃ§ek hayat uygulamalarÄ± yaparken \"benchmark\" datasetleri gibi elinizde Ã§ok data bulunmayabiliyor..",
4. ->  ->  %1i 10 milyon yapÄ±yor, sÃ¶ylendiÄŸi gibi %10 teste ayÄ±rsak 100 milyon test datasÄ± olacak.",
5. ->  ->  Onu hesaplamadÄ±m tabi direk yazÄ±lan oranÄ± aldÄ±m ama genelde 10 bin yeterli bir sayÄ±. 100 Milyonluk kaliteli etiketli veri (resim olarak dÃ¼ÅŸÃ¼nÃ¼rsek) Ã§oÄŸu zaman elde edebildiÄŸimiz bir veri deÄŸil. Benchmark , algoritmalarÄ±n denendiÄŸi datasetlerde ancak bÃ¶yle veri olabiliyor.",

### soru 

> quest: "Merhabalar. Goldilocks learning rate deÄŸeri tam olarak nedir ve nasÄ±l bulunur? Tam anlayamadÄ±m aÃ§Ä±klayabilir misiniz ? TeÅŸekkÃ¼rler. [goldilocks](https://community.globalaihub.com/community/hashtag/goldilocks/)

> comments:

1. -> Bunun iÃ§in Ã¶ncelikle Goldilocks prensibinin tanÄ±mÄ±na bakmamÄ±z gerekiyor. [Link](http://www.tolgaakkus.com/goldilocks-prensibi-79-gun/) websitesinden aldÄ±ÄŸÄ±m kÄ±sa bir Ã¶zeti alÄ±ntÄ±lamak istiyorum.\"Ormanda yaÅŸayan Ã¼Ã§ kiÅŸilik bir ayÄ± ailesi var. Anne ayÄ± yaptÄ±ÄŸÄ± Ã§orbalarÄ± tabaklara doldurur ve Ã§orbalar soÄŸuyana kadar ailecek dÄ±ÅŸarÄ± Ã§Ä±karlar. O sÄ±rada dÄ±ÅŸarda gezen minik kÄ±z Goldilocks evi gÃ¶rÃ¼nce iÃ§eri girer ve Ã§orbalara ile karÅŸÄ±laÅŸÄ±r. Ã–nce bÃ¼yÃ¼k tabaktaki baba ayÄ±nÄ±n Ã§orbasÄ±na bakar ama aÄŸzÄ± yanar, sonra orta tabaktaki anne ayÄ±nÄ±n Ã§orbasÄ±na bakar yine aÄŸzÄ± yanar, en son kÃ¼Ã§Ã¼k tabaktakini iÃ§er, kÃ¼Ã§Ã¼k Ã§orba her ÅŸeyi ile tam Goldilocksâ€™a gÃ¶redir.\"Buna gÃ¶re burada Goldilocks learning rate aslÄ±nda gradient descent algoritmamÄ±zÄ±n en optimizasyonlu duruma gelmesi iÃ§in gereken learning rate deÄŸeridir. Goldilocks prensibini hatÄ±rlarsak burada Goldilocks kendi aÄŸzÄ±nÄ±n yanmayacaÄŸÄ± optimum tabak bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼ bulup ondan Ã§orba iÃ§iyordu.Learning rate ise gradient descent algoritmamÄ±zda her bir iterasyonda optimum deÄŸere atÄ±lacak adÄ±m bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼ temsil eder. Ama Ã¶nemli bir not vermek istiyorum; itere edildikÃ§e optimuma atÄ±lan adÄ±mlar azalÄ±r bunun nedeni cost function'Ä±mÄ±zÄ±n her derviative'de daha da kÃ¼Ã§Ã¼lmesidir. YalnÄ±z bu sizi yanÄ±ltmasÄ±n, learning rate'i seÃ§erken bu adÄ±m kÃ¼Ã§Ã¼lmelerine gÃ¼venmemeliyiz Ã§Ã¼nkÃ¼ bahsettiÄŸim bu kÃ¼Ã§Ã¼lmeler 2-3 iterasyonda olan ÅŸeyler deÄŸil ve learning rate her iterasyonda atÄ±lacak adÄ±mÄ±n bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼ simgelediÄŸi iÃ§in learning rate'Ä° kÃ¼Ã§Ã¼k seÃ§erseniz algoritmanÄ±z Ã§ok yavaÅŸ, Ã§ok bÃ¼yÃ¼k seÃ§erseniz de optimum noktayÄ± aÅŸacaÄŸÄ± iÃ§in yanlÄ±ÅŸ Ã§alÄ±ÅŸacaktÄ±r. Uygun learning rate'i bulmak iÃ§in ise bir Ã§ok yÃ¶ntem mevcut:Sabit deÄŸer olarak belirlenebilir, ya da adÄ±m adÄ±m artan bir deÄŸer olarak da belirlenebilir (Ã¶rneÄŸin belli bir Ã¶ÄŸrenme adÄ±mÄ±na kadar 0.001 o adÄ±mdan sonra 0.01 gibi), momentum deÄŸerine baÄŸlÄ± olarak belirlenebilir ya da adaptif algoritmalar tarafÄ±ndan Ã¶ÄŸrenme esnasÄ±nda Ã¶ÄŸrenilebilir.Burada benim hakim olduÄŸum yÃ¶ntem bir deÄŸer aralÄ±ÄŸÄ± belirleyip o deÄŸer aralÄ±ÄŸÄ±nda kalan deÄŸerleri learning rate deÄŸeri olarak verip algoritmayÄ± denemek. Ã–rneÄŸin 0.1-1 arasÄ±nda bir aralÄ±k seÃ§tiÄŸinizde ve gradient descent algoritmasÄ±nda learning rate olarak verdiÄŸinizde Ã§Ä±kan sonucun optimuma yaklaÅŸma step sayÄ±sÄ±, optimumdan uzaklaÅŸma durumlarÄ±na gÃ¶re doÄŸru aralÄ±ÄŸÄ± seÃ§ebilirsiniz. EÄŸer bu aralÄ±kta learning rate bulamazsanÄ±z aralÄ±ÄŸÄ±nÄ±zÄ± geniÅŸletebilirsiniz. DiÄŸer learning rate bulma yÃ¶ntemleri ile ilgili bir bilgiye sahip deÄŸilim maalesef ama olunca burayÄ± gÃ¼ncellerim ğŸ™‚ YanlÄ±ÅŸÄ±ÄŸÄ±m eksiÄŸim olursa lÃ¼tfen dÃ¼zeltmekten eklemekten Ã§ekinmeyin, umarÄ±m aÃ§Ä±klayÄ±cÄ± olmuÅŸtur :)Ã–nemli bir trivia: Gradient Descent algoritmamÄ±z ne kadar optimumsa grafiÄŸimizdeki cost function Ã§izgimiz o kadar dÃ¼zdÃ¼r ve eÄŸimi yoktur. Derivative de zaten eÄŸim almak demek olduÄŸu iÃ§in artÄ±k alÄ±nacak bir eÄŸimi kalmadÄ±ÄŸÄ±ndan artÄ±k iterasyonlar optimum deÄŸere ulaÅŸtÄ±ktan sonra cost function deÄŸerimizi kÃ¼Ã§Ã¼ltmeyecektir. Buradan ÅŸÃ¶yle trivia bir ÅŸey sÃ¶yleyebilirim. EÄŸer Gradient Descent algoritmamÄ±z lokal minimum deÄŸerine ulaÅŸtÄ±ysa ve bulunduÄŸu lokal minimumdan daha optimum bir lokal minimum deÄŸeri varsa bir sonraki iterasyonda daha optimum olan lokal minimum deÄŸerine yaklaÅŸmaz, bulunduÄŸu noktada kalÄ±r. Resimdeki denklemi incelediÄŸinizde optimuma ulaÅŸan cost function deÄŸerinin eÄŸimi (derivative'i) sÄ±fÄ±r olacaÄŸÄ± iÃ§in (resimdeki grafikte mevcut) thetaj=thetaj olur yani deÄŸer deÄŸiÅŸmez.2 months ago 36 people like this.Like ReportReply",
2. ->  ->  TeÅŸekkÃ¼r ederim.",
3. ->  Merhaba. AnladÄ±ÄŸÄ±m ve araÅŸtÄ±rdÄ±ÄŸÄ±m kadarÄ±yla; Goldilocks Prensibi, matematik ve istatistikte \"Bias ve varyanstan gelen hatalarÄ± azaltmak iÃ§in 'mÃ¼kemmel esnekliÄŸi' temsil eden doÄŸrusal regresyon modelini\" ifade ediyor. Yani olabilecek en iyi modeli ifade ediyor. Kursta da belirtildiÄŸi gibi Goldilocks deÄŸeri, olabilecek en iyi learning rate deÄŸeridir ve kayÄ±p fonksiyonunun ne kadar dÃ¼z olduÄŸu ile ilgili olan bir ÅŸeydir. KayÄ±p fonksiyonunun gradient'inin bÃ¼yÃ¼klÃ¼ÄŸÃ¼ne gÃ¶re, o bÃ¼yÃ¼klÃ¼ÄŸÃ¼ telafi etmek iÃ§in ona gÃ¶re learning rate seÃ§iliyor. Ben bÃ¶yle anladÄ±m, yanlÄ±ÅŸÄ±m veya eksiÄŸim olabilir. Tabii ki eleÅŸtiriye ve dÃ¼zeltmelere aÃ§Ä±ÄŸÄ±m. Ä°lk soru cevaplama deneyimim, mentorlarÄ±mÄ±z daha iyi cevabÄ± verecektir????. Ä°yi gÃ¼nler.2 months ago 12 people like this.Like ReportReply",
4. ->   ->  TeÅŸekkÃ¼r ederim.",
5. ->  ArkadaÅŸlar goldilocks kavramÄ±nÄ± learning rate ile birlikte aÃ§Ä±klamÄ±ÅŸ ama kurstaki sorunun cevabÄ± olan 1.6 deÄŸerini nasÄ±l bulduÄŸumuza deÄŸinmemiÅŸ. Bu konuya aÃ§Ä±klÄ±k getirebilecek bir arkadaÅŸÄ±mÄ±z var mÄ±dÄ±r ?.",
6. ->  Merhabalar, eklediÄŸim gÃ¶rselde aÃ§Ä±klamaya Ã§alÄ±ÅŸtÄ±m..",
7. ->  EÄŸitimin bir kÄ±smÄ±nda ÅŸu geÃ§iyordu: \"MÃ¼kemmel Ã¶ÄŸrenme oranÄ±nÄ± bulmak ÅŸart deÄŸildir 'yeterince' hÄ±zlÄ± yakÄ±nsayacak deÄŸer seÃ§mek yeterlidir.\" Belirli Ã¶ÄŸrenme oranlarÄ±nÄ± seÃ§mek Ã§oÄŸu zaman iÅŸe yarÄ±yormuÅŸ. Andrew NG'den hatÄ±rladÄ±ÄŸÄ±m kadarÄ±yla 0.03 0.01 0.1 0.3 deÄŸerleri gibi.",
8. ->  Cevaplar iÃ§in teÅŸekkÃ¼rler ancak bu soruda nasÄ±l 1.6 cevabÄ±nÄ± bulduÄŸumuzu aÃ§Ä±klamÄ±yor:) soÄŸuk Ä±lÄ±k ve sÄ±cak deÄŸerlerine sÄ±rasÄ±yla 1,2 ve 3 verdikten sonra mÄ± bu learning rate oranÄ±nÄ± bulacaÄŸÄ±z bu Ã¶rnekte ?.",
9. ->  ->  Merhaba, 1.6 olmasÄ±nÄ±n sebebi gradient descent fonksiyonumuzun sadece bir adÄ±mda optimum deÄŸere ulaÅŸmasÄ±ndandÄ±r. AmacÄ±mÄ±z olabilecek en kÄ±sa sÃ¼rede ve adÄ±mda minimum noktasÄ±na gitmek. Learning rate'imiz minimum deÄŸere atacaÄŸÄ±mÄ±z adÄ±mÄ± simgelediÄŸi iÃ§in 1.6 bÃ¼yÃ¼klÃ¼ÄŸÃ¼nde adÄ±m bizi tek seferde minimuma gÃ¶tÃ¼rdÃ¼. Burada Learning Rate deÄŸeri deneme yanÄ±lma ile bulunur kesin olarak her modelde 1.6'dÄ±r veya sabittir diyemeyiz. Ä°yi Ã§alÄ±ÅŸmalar dilerim.",
10. ->  ->  Ã–rnek, bize orada Ã¶ÄŸrenme oranÄ±ndaki deÄŸiÅŸimin adÄ±m sayÄ±sÄ±nÄ± nasÄ±l deÄŸiÅŸtirdiÄŸini gÃ¶stermek iÃ§in konulmuÅŸ sadece. Yani her iterasyonda en iyi deÄŸeri bulmak zorunda deÄŸiliz. Ne Ã§ok bÃ¼yÃ¼k olsun ne de Ã§ok kÃ¼Ã§Ã¼k orta deÄŸerler iÅŸimizi gÃ¶rÃ¼yor. Ã–nceki yorumda yazdÄ±ÄŸÄ±m gibi genelde ilk denen deÄŸerler var. Bu deÄŸerlere gÃ¶re arttÄ±rÄ±p azaltacaÄŸÄ±mÄ±za karar veriyoruz..",
11. ->  ->  teÅŸekkÃ¼rler yanÄ±t iÃ§in.Ben buna yakÄ±n bir dÃ¼ÅŸÃ¼ndÃ¼m ve sonucun 1.5 olabileceÄŸini varsaydÄ±m. Cevap olarak 1.6 yazÄ±nca kaÃ§Ä±rdÄ±ÄŸÄ±m bir ÅŸey olabilir diye sormak istedim teÅŸekkÃ¼rler..",
    
### soru 

> quest: "Ä°lk soruyu soracak olmanÄ±n verdiÄŸi heyecanÄ±ndan dolayÄ± yanlÄ±ÅŸ bir ÅŸekilde sorarsam kusuruma bakmayÄ±n. BugÃ¼n ki Ã§alÄ±ÅŸmamda Reducing Loss ile alakalÄ± kafamda takÄ±lan konu Stochastic Loss ile mini batch loss function arasÄ±ndaki farkÄ± Ã§ok iyi anlayamadÄ±m. Bana bu konuda yardÄ±mcÄ± olabilir misiniz? [ReducingLoss](https://community.globalaihub.com/community/hashtag/reducingloss/) [Minibatch](https://community.globalaihub.com/community/hashtag/minibatch/)

> comments:
  
1. -> Merhaba.Ã–zetle ÅŸunu sÃ¶yleyebilirim.Derin Ã¶ÄŸrenmede veri setinde bulunan tÃ¼m verileri aynÄ± anda iÅŸleyerek Ã¶ÄŸrenme maliyetli bir iÅŸ.Veri sayÄ±sÄ± ne kadar fazla ise hesaplama da o oranda fazla sÃ¼rmekte.Bu problemi Ã§Ã¶zmek iÃ§in veri seti kÃ¼Ã§Ã¼k gruplara ayrÄ±lmakta ve Ã¶ÄŸrenme iÅŸlemi seÃ§ilen bu kÃ¼Ã§Ã¼k gruplar Ã¼zerinde yapÄ±lmakta.Birden fazla girdinin parÃ§alar halinde iÅŸlenmesi â€œmini-batchâ€ olarak adlandÄ±rÄ±lmakta.Yani Stochastic gradient descent ile veriyi tekbir bÃ¼tÃ¼n olarak incelerken Mini-batch stochastic gradient descent ile daha kÃ¼Ã§Ã¼k parÃ§alara ayÄ±rarak inceleniyor..",
2. -> eski izlediÄŸim videolarÄ±da gÃ¶z Ã¶nÃ¼nde bulundurarak mini batch parametresini kullanÄ±rken veriyi kÃ¼Ã§Ã¼k kÃ¼Ã§Ã¼k ayÄ±rÄ±p modele yavaÅŸ yavaÅŸ veriyor diyebiliriz fakat burada bazÄ± veriler uygun iken bazÄ± veriler uygun olmayabilir bu yÃ¼zden gÃ¼rÃ¼ltÃ¼ Ã§ok olur burada Ã¶nemli olan anladÄ±ÄŸÄ±m kadarÄ±yla learning rate deÄŸeri Ã¶nem kazanÄ±yor onuda 1 yaptÄ±ÄŸÄ±mÄ±zda stochastic parametresi ile aynÄ± iÅŸi yapmÄ±ÅŸ oluyoruz bende eÄŸitimden kalan bilgilerim ile cevap vermeye Ã§alÄ±ÅŸtÄ±m umarÄ±m birÅŸeyleri doÄŸru anlamÄ±ÅŸÄ±zdÄ±r ğŸ™‚ iyi Ã§alÄ±ÅŸmalar.",
3. ->  stochastic gradient descent Ã¶ÄŸrenme iÅŸlemini yaparken sadece tek bir Ã¶rneÄŸe bakmÄ±yor mu ? ->.",
4. -> Veri setine bÃ¼tÃ¼n olarak bakÄ±yor..",
5. ->  Stochastic gradient descent (SGD) takes this idea to the extreme--it uses only a single example (a batch size of 1) per iteration. Given enough iterations, SGD works but is very noisy. The term \"stochastic\" indicates that the one example comprising each batch is chosen at random yazÄ±yor da o yÃ¼zden sordum. sizin dediÄŸiniz bÃ¼tÃ¼n olarak bakmasÄ±na batch gradient descent deniyor diye biliyorum. ->.",
" ->  Biraz araÅŸtÄ±rdÄ±ÄŸÄ±m kadarÄ±ylaSchoastic gredient decent ile her iterasyonda sadece bir veri Ã¼zerinde iÅŸlem yapÄ±yoruz.BÃ¼tÃ¼n olarak bakmasÄ±na batch gredient descent deniyor.(AslÄ±nda Mini-batch deÄŸerini eÄŸitim kÃ¼mesinde bÃ¼tÃ¼n eleman sayÄ±sÄ± kadar yaparsak, eÄŸitim kÃ¼mesindeki tÃ¼m veriler eÄŸitime gireceÄŸi iÃ§in yapÄ±lan iÅŸlem de yine â€œbatch gredient descentâ€ oluyor.)Mini-batch stochastic gradient descentte ise seÃ§ilen deÄŸerin 1 ile eÄŸitim kÃ¼mesindeki veri sayÄ±sÄ± arasÄ±nda ne Ã§ok kÃ¼Ã§Ã¼k ne de Ã§ok bÃ¼yÃ¼k olmayan bir deÄŸer olarak belirlenmesi gerekiyor. ( Crash course da yanlÄ±ÅŸ hatÄ±rlamÄ±yorsam 100 ile 1000 arasÄ±nda demiÅŸti. Elimizdeki veriyi yÃ¼zlÃ¼k , binlik ÅŸekilde parÃ§alara ayrÄ±ldÄ±ÄŸÄ±mÄ±zÄ± dÃ¼ÅŸÃ¼nÃ¼n).Bu konuyu ben de bugÃ¼n yeni Ã¶ÄŸrendim. LÃ¼tfen herhangi bir hatam varsa belirtiniz ????",
6. -> Gradient Descent algoritmasÄ± Cost Function'Ä±mÄ±zÄ± optimize etmek iÃ§in uyguladÄ±ÄŸÄ±mÄ±z bir algoritmadÄ±r. Optimizasyonu ise cost function'Ä±mÄ±zÄ±n sÃ¼rekli derivative'ini alarak yapmaktadÄ±r. Cost functionÄ±mÄ±z ise aslÄ±nda tÃ¼m tahmin edilen y deÄŸerleri-gerÃ§ek y deÄŸerlerinin karelerinin toplamÄ±/(veri sayÄ±sÄ± * 2). (Resim olarak ekledim. 2m olmasÄ±nÄ±n sebebi derivative alÄ±nÄ±rken kolaylÄ±k saÄŸlanmasÄ± iÃ§indir.)Gradient Descent formÃ¼lÃ¼mÃ¼ze baktÄ±ÄŸÄ±mÄ±zda ise (Resim olarak ekledim.) Cost function'Ä±mÄ±zÄ±n derivative'inin alÄ±ndÄ±ÄŸÄ±nÄ± ve bunun optimize olana kadar devam ettiÄŸini yani iterative olarak yaptÄ±ÄŸÄ±nÄ± gÃ¶zlemleyebiliriz. Gradient Descent formÃ¼l resmindeki kÄ±rmÄ±zÄ± alan ise bizim cost function'Ä±mÄ±zdÄ±r. Gradient Descent algoritmamÄ±z her iterasyonda cost function'Ä±mÄ±zÄ±n derivative'ini alÄ±r. Bu iterasyon sÄ±rasÄ±nda itere edilen cost functionÄ±mÄ±zÄ±n range'ini belirleyebiliriz. Bu range Ã§eÅŸitlerine gÃ¶re de Gradient Descent ayrÄ±lÄ±r. Ã–rneÄŸin;Batch Gradient Descent: Her iterasyonda tÃ¼m veri seti iÃ§in cost function hesaplar ve hepsinin derivative'ini alÄ±r. Veri fazlalaÅŸtÄ±kÃ§a bu yÃ¶ntem yavaÅŸlar.Mini-Batch Gradient Descent: Her iterasyonda tÃ¼m veri setini almak yerine veri setinin belli bir kÄ±smÄ± iÃ§in cost function hesaplayÄ±p derivative'ini alÄ±r.Stochastic Gradient Descent: Her iterasyonda verisetinden sadece bir Ã¶rnek iÃ§in cost function hesaplayÄ±p derivative'ini alÄ±r.EÄŸer bir hatam veya eksiÄŸim olduysa dÃ¼zeltmelere aÃ§Ä±ÄŸÄ±m ğŸ™‚ UmarÄ±m aÃ§Ä±klayÄ±cÄ± olmuÅŸtur ğŸ™‚2 months ago 22 people like this.Like ReportReply",
7. ->  ->  harika aÃ§Ä±klamanÄ±z iÃ§in Ã§ok teÅŸekkÃ¼r ederim. cost fonksiyonunu pythonda yazarken loss = np.sum(deltas**2) / 2 / observations olarak ifade ettiÄŸimizi hatÄ±rladÄ±ÄŸÄ±m iÃ§in yazma gereÄŸi duydum. hatam olabilir olursa lÃ¼tfen bildirmekten Ã§ekinmeyin. Fethi hocam yukarÄ±da \"y deÄŸerleri-gerÃ§ek y deÄŸerlerinin karelerinin toplamÄ±/ortalamadÄ±r\" demiÅŸsiniz. burdan anladÄ±ÄŸÄ±m kadarÄ±yla \"ortalama = m\" deÄŸeri oluyor yukardaki verdiÄŸiniz resim ekine gÃ¶re de. benim anladÄ±ÄŸÄ±m m = gÃ¶zlem sayÄ±sÄ± demek. acaba cost fonksiyonu iÃ§in \"karesi alÄ±nmÄ±ÅŸ farklarÄ±n, toplamÄ±nÄ±n, ortalamasÄ±\" mÄ± demek istediniz de ben anlayamadÄ±m tam olarak kafam karÄ±ÅŸtÄ±. Ã§ok yeni olduÄŸum iÃ§in burda verilen cevaplar bazen aklÄ±mda kural olarak kalabiliyor.",
8. ->  ->  Merhaba Ã¶ncelikle cevabÄ±nÄ±z iÃ§in Ã§ok teÅŸekkÃ¼r ederim. Evet orada bir hata yapmÄ±ÅŸÄ±m ve bu cevabÄ± yazdÄ±ktan sonra da dÃ¼zeltmesini yapacaÄŸÄ±m. Oradaki M, verisetindeki veri sayÄ±sÄ± oluyor yani sizden alÄ±ntÄ±layarak ve biraz dÃ¼zenleyerek ÅŸu Ã§Ä±karÄ±mÄ±nÄ±zÄ± onaylayabilirim: \"cost fonksiyonu \"karesi alÄ±nmÄ±ÅŸ farklarÄ±n karelerinin toplamÄ± deÄŸerinin veri boyutu*2 'ye bÃ¶lÃ¼nmesidir. Ã–rneÄŸin verisetimde 100 deÄŸer var ise bu 100 deÄŸer iÃ§n tahmin edilen deÄŸer - olmasÄ± gereken deÄŸerlerinin karelerinin toplamÄ± / (2*100) yaptÄ±ÄŸÄ±mzda cost function deÄŸerimizi bulabiliyoruz. (2 olmasÄ±nÄ±n sebebi kareli deÄŸerin derivative'i alÄ±ndÄ±ÄŸÄ±nda iÅŸlem kolaylÄ±ÄŸÄ± saÄŸlamak) Fark toplamlarÄ±/(Ã¶rnek sayÄ±sÄ±*2)=cost function deÄŸeri bulunuyor yazmam gerekirken uykusuzluÄŸun da vermiÅŸ olduÄŸu bir hal ile yanlÄ±ÅŸ yazmÄ±ÅŸÄ±m ğŸ™‚ EÄŸer anlatamadÄ±ÄŸÄ±m bir yer var ise lÃ¼tfen yazmaktan Ã§ekinmeyin ğŸ™‚.",
9. -> Veri setindeki tÃ¼m verileri aynÄ± anda iÅŸlemek, hem zaman hem de bellek aÃ§Ä±ÅŸÄ±ndan Ã§ok maliyetli bir sÃ¼reÃ§tir. Maliyeti minimize etmek, tahmine baÄŸlÄ± hata oranÄ±nÄ± en aza indirmek iÃ§in de en uygun aÄŸÄ±rlÄ±k deÄŸerlerini bulmaya Ã§alÄ±ÅŸÄ±yoruz. Bunu da gradient descent optimizasyonu ile yapÄ±yoruz. Veri miktarÄ± ne kadar fazla ise bu hesaplama da o kadar uzun sÃ¼rÃ¼yor. DolayÄ±sÄ±yla veri setini kÃ¼Ã§Ã¼k gruplara ayÄ±rarak Ã¶ÄŸrenme iÅŸlemini bu kÃ¼Ã§Ã¼k gruplar Ã¼zerinden devam ettiriyoruz. Bu ÅŸekilde verinin kÃ¼Ã§Ã¼k gruplar halinde iÅŸlenmesi mini-batch olarak adlandÄ±rÄ±lÄ±yor. Mini-batch parametresi olarak belirtilen deÄŸer, modelin aynÄ± anda kaÃ§ veriyi iÅŸleyeceÄŸini belirtiyor. Veri genelde 10-1000 arasÄ±nda random seÃ§ilmiÅŸ Ã¶rneklere bÃ¶lÃ¼nerek iÅŸleniyor. Mini-batch deÄŸerini 1 olarak belirlediÄŸimizde de alabileceÄŸi en kÃ¼Ã§Ã¼k deÄŸeri almÄ±ÅŸ oluyor, buna da stochastic gradient descent diyoruz. Yani her iterasyonda sadece tek bir veri Ã¼zerinde iÅŸlem yapÄ±lmasÄ± durumu. Her iki uygulamanÄ±n da, min-batch ve stochastic, kendi iÃ§inde artÄ±/eksi yanlarÄ± var. Ã–nemli olan burada sizin veri setiniz ve belleÄŸinize en uygun batch deÄŸerini belirlemeniz. Bunun iÃ§in de ayrÄ±ca belli kriterler var zaten.2 months ago 42 people like this.Like ReportReply",
10. ->  ->  AslÄ± HanÄ±m bu batch deÄŸerin belirlemede belli kriterler nedir? Ã–rneÄŸin makinenin core sayÄ±sÄ± felan mÄ± ya da ekstra veri Ã¼zerinden de bir kriter oluÅŸturulabiliyor mu?.",
11. -> ->  Bununla ilgili ÅŸÃ¶yle bir liste paylaÅŸayÄ±m sizinle;-Mini-batch deÄŸerinin seÃ§iminde en uygun deÄŸer 1 ile eÄŸitim kÃ¼mesindeki tÃ¼m verilerin sayÄ±sÄ± arasÄ±nda ne Ã§ok kÃ¼Ã§Ã¼k ne de Ã§ok bÃ¼yÃ¼k olmayan bir deÄŸer belirlenmelidir. Bu hÄ±zlÄ± ÅŸekilde Ã¶ÄŸrenmeyi saÄŸlayacaktÄ±r.-Batch sizeâ€™Ä±n bÃ¼yÃ¼k olmasÄ±, daha doÄŸru gradyan deÄŸerinin hesaplanmasÄ±nÄ± saÄŸlamaktadÄ±r. Bu durum da linerizasyonu azaltmaktadÄ±r.-Belirlenen batch deÄŸerinin GPU belleÄŸine sÄ±ÄŸmasÄ± gerekiyor. Bu nedenle batch boyutu 2â€™nin katlarÄ± ÅŸeklinde belirlenmelidir; 2, 4, 8, 16, 32, â€¦ 512 vb. Bu ÅŸekilde belirlenmemiÅŸse baÅŸarÄ±mda ani dÃ¼ÅŸÃ¼ÅŸler yaÅŸanabilir.-Batch size genelde 64 ile 512 arasÄ±nda 2'nin katÄ± olan deÄŸerlerden belirleniyor.-EÄŸitim kÃ¼mesindeki eleman sayÄ±sÄ± kÃ¼Ã§Ã¼kse (yani 2000'den az ise) eÄŸitim kÃ¼mesindeki tÃ¼m elemanlar aynÄ± anda kullanÄ±labilir. Yani batch gradyan hesaplamasÄ± yapÄ±labilir.-EvriÅŸimsel sinir aÄŸlarÄ± (Convolutional Neural Networks) batch deÄŸerine karÅŸÄ± hassastÄ±r. Batch deÄŸerindeki kÃ¼Ã§Ã¼k deÄŸiÅŸiklikler baÅŸarÄ±mda bÃ¼yÃ¼k etkiler oluÅŸturabilir.-Batch boyutunun diÄŸer bir kÄ±stasÄ± da bellek boyutudur. EÄŸer kÃ¼Ã§Ã¼k belleÄŸe sahip ortamda Ã§alÄ±ÅŸÄ±yorsanÄ±z, batch bÃ¼yÃ¼k tutmakta zorlanabilirsiniz. Bu nedenle modeli tasarlarken Ã¶ncesinde kullanabileceÄŸiniz maksimum batch deÄŸeri hesaplamak verimli olacaktÄ±r.-Batch size kÃ¼Ã§Ã¼k olmasÄ± iyileÅŸtirme (reguralization) etkisi yaratmaktadÄ±r. Modele veri bÃ¼yÃ¼k gruplar halinde verildiÄŸinde ezberleme daha fazla oluyor.-Batch iÅŸleminde, veri seti batch deÄŸeri olarak belirlenen deÄŸere gÃ¶re parÃ§alara ayrÄ±lmakta ve her iterasyonda modelin eÄŸitimi bu parÃ§a Ã¼zerinden yapÄ±lmaktadÄ±r. Bununla birlikte bazÄ± durumlarda veri kendi iÃ§inde gruplanmÄ±ÅŸ olabilmektedir. Bu durum veri seti iÃ§inde korelasyon oluÅŸturacak; bu veri setinden seÃ§ilecek test setin de yÃ¼ksek baÅŸarÄ±m vermesini saÄŸlayacak bÃ¶ylece ezberleme (â€œoverfittingâ€) olacaktÄ±r. Bunu Ã¶nlemek iÃ§in eÄŸitim baÅŸlamadan veri seti parÃ§alara ayrÄ±lmadan Ã¶nce veri seti karÄ±ÅŸtÄ±rÄ±lmalÄ±dÄ±r (shuffle). Batch seÃ§iminde verilerin rastgele seÃ§ilmesi Ã¶nemlidir.2 months ago 15 people like this.Like ReportReply",
12. ->  ->  2'nin katÄ± deÄŸil de 2'nin kuvveti yazmak istediniz sanÄ±rÄ±m",
13. ->  ->  evet ğŸ™‚",
14. ->  ->  teÅŸekkÃ¼rler verdiÄŸiniz bilgiler iÃ§in.",
15. ->  ->  Ã‡ok teÅŸekkÃ¼r ederim AslÄ± HanÄ±m..",
16. ->  ->  AslÄ± hanÄ±m Ã§ok anlaÅŸÄ±lÄ±r bir dille aÃ§Ä±klamÄ±ÅŸsÄ±nÄ±z yavaÅŸ yavaÅŸ aÅŸina olan bizler iÃ§in Ã§ok gÃ¼zel bir kolaylÄ±k bu teÅŸekkÃ¼rler..",
17. ->  AydÄ±nlatÄ±cÄ± aÃ§Ä±klamalarÄ±nÄ±z iÃ§in herkese Ã§ok teÅŸekkÃ¼r ederim. Ã‡ok faydalÄ± oluyor..",
    
### soru 

> quest: "Merhabalar! Bu akÅŸam 21:00'de Facebook AI' da Yapay Zeka AraÅŸtÄ±rma MÃ¼hendisi olarak Ã§alÄ±ÅŸan TuÄŸÃ§e TaÅŸÃ§Ä± ile Sinirbilim ve Yapay Zeka Ã¼zerine konuÅŸuyor olacaÄŸÄ±z. Birazdan baÅŸlayacak canlÄ± yayÄ±nÄ±mÄ±zÄ± kaÃ§Ä±rmayÄ±n âœ¨ [Link](https://www.youtube.com/channel/UCpB-u_FJegcM0WrMtr-W27w\) 

> comments:
  
    1. ->  Ã‡ok gÃ¼zel bir yayÄ±ndÄ±. Ellerinize saÄŸlÄ±k ğŸ™‚.",
    1. ->  ->  TeÅŸekkÃ¼r ederiz ğŸ™‚.",
    
### soru 

> quest: "ML ile ilgili bazÄ± temel soru ve cevaplar:  Makine Ã–ÄŸrenmesi Nedir? Makine Ã¶ÄŸrenimi (ML â€“ Machine Learning), yazÄ±lÄ±m programlarÄ±nÄ±n aÃ§Ä±k bir ÅŸekilde programlanmadan sonuÃ§larÄ± tahmin etmede daha doÄŸru olmasÄ±nÄ± saÄŸlayan bir algoritma kategorisidir. Makine Ã¶ÄŸrenmesinin temel dayanaÄŸÄ±, giriÅŸ verisini alabilen algoritmalar oluÅŸturmak ve Ã§Ä±ktÄ±larÄ± yeni veriler ortaya Ã§Ä±ktÄ±kÃ§a gÃ¼ncellerken bir Ã§Ä±ktÄ±yÄ± tahmin etmek iÃ§in istatistiksel analiz kullanmaktÄ±r.  Makine Ã–ÄŸrenmesinin KullanÄ±m AlanlarÄ± Nedir? HayatÄ±mÄ±za yerleÅŸmiÅŸ Ã§oÄŸu teknolojide makine Ã¶ÄŸrenmesi teknikleri kullanÄ±lmakta. KullanÄ±ldÄ±ÄŸÄ± alanlarÄ±n spektrumu ise ifade edilemeyecek kadar geniÅŸ.  Twitter nasÄ±l beÄŸendiklerime gÃ¶re anasayfamÄ± kiÅŸiselleÅŸtirebiliyor? LinkedIn bana nasÄ±l tanÄ±dÄ±ÄŸÄ±m insanlarÄ± Ã¶nerebiliyor? Mail kutuma dÃ¼ÅŸen spam mesajlar nasÄ±l belirleniyor?  Google Maps gibi trafik uygulamalarÄ±nda en hÄ±zlÄ± rota belirlenirken, Facebookâ€™a yÃ¼klenen fotoÄŸraflara kiÅŸiler otomatik etiketlenirken, online alÄ±ÅŸveriÅŸ sitelerinde bir Ã¼rÃ¼n arattÄ±ktan sonra size o Ã¼rÃ¼nlerle ilgili reklamlar gÃ¶sterilirken ve her gÃ¼n bir ÅŸekilde kullandÄ±ÄŸÄ±mÄ±z Siri, Alexa, Google ve Cortana gibi asistanlarda makine Ã¶ÄŸrenmesi teknikleri sÄ±kÃ§a kullanÄ±lÄ±yor.  Makine Ã–ÄŸrenmesinin Alt DallarÄ± Neledir? Makine Ã¶ÄŸrenmesinin baÅŸlÄ±ca alt dallarÄ± ÅŸunlardÄ±r:  DoÄŸal Dil Ä°ÅŸleme (Natural Language Processing - NLP) - Ä°nsanlarÄ±n gÃ¼nlÃ¼k hayatta kullandÄ±ÄŸÄ± dili â€œanlayÄ±pâ€ bu bilgiyi metin Ã¶zetleme, muhabbet edebileceÄŸiniz chatbotlar yaratma, ÅŸirketinizin sosyal medyada nasÄ±l algÄ±landÄ±ÄŸÄ±nÄ± tespit etme gibi iÃ§ine kelimelerin girdiÄŸi her alanda kullanan NLP her hayatÄ±mÄ±zda daha Ã¶nemli bir role sahip oluyor.  Bilgisayarla GÃ¶rÃ¼ (Computer Vision - CV) - Otonom araÃ§larÄ±n yolda gitmesini, Instagram filtrelerinin yÃ¼zÃ¼nÃ¼zÃ¼ bulmasÄ±nÄ±, derinizdeki polis kameralarÄ±nÄ±n kim olduÄŸunuzu tespit etmesini, geri dÃ¶nÃ¼ÅŸÃ¼m atÄ±klarÄ±nÄ±n tÃ¼rlerine gÃ¶re ayrÄ±ÅŸtÄ±rÄ±lmasÄ±nÄ± ve daha nicesini saÄŸlayan CV yarattÄ±ÄŸÄ± yeni olanaklarla hem hayatÄ±mÄ±zÄ± kolaylaÅŸtÄ±rÄ±yor hem de yapay zeka etiÄŸinin tartÄ±ÅŸÄ±lmasÄ±na sebep oluyor.  DolandÄ±rÄ±cÄ±lÄ±k Tespiti (Fraud Detection) - Bir alÄ±ÅŸveriÅŸin yaÅŸandÄ±ÄŸÄ± herhangi bir mecrada yaÅŸanabilecek dolandÄ±rÄ±cÄ±lÄ±k gÃ¼nÃ¼mÃ¼zde ML algoritmalarÄ± ile yaÅŸanmadan Ã¶nce tespit edilebilmektedir. Fraud Detectionâ€™Ä± Ã¶zellikle bankalar ve Amazon gibi e-alÄ±ÅŸveriÅŸ siteleri kullanmaktadÄ±r.",

> comments:
  
### soru 

> quest: "{Ã–RNEK SORU} Yapay Ã¶ÄŸrenme modellerinin genelleÅŸtirme yeteneÄŸini artÄ±rmak iÃ§in hangi yÃ¶ntemleri kullanabilirim?",

> comments:
  
1. ->  GenelleÅŸtirmeyi arttÄ±rmak iÃ§in eÄŸitimi erken bitirme, baÅŸlangÄ±Ã§ weight deÄŸerlerini sÄ±nÄ±rlandÄ±rma, regularization ( Ã¶rnek PCA) , inputa biraz gÃ¼rÃ¼ltÃ¼(noise) eklemek Ã¶rnek olarak verilebilir..",
2. ->  ->  Merhaba Enes bu bir Ã¶rnek sorudur ğŸ™‚ Ama yine de dikkate alÄ±p yanÄ±tladÄ±ÄŸÄ±n iÃ§in teÅŸekkÃ¼r ederim..",
3. ->  Ã¼nlÃ¼ Merhaba Crash Course iÃ§eriÄŸinde Ã¶n gereksinimler kÄ±smÄ±ndan da baÅŸlasak olur mu acaba?.",