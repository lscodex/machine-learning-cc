====================================================================================

"question_isim": "->",
"quest": "Herkese merhaba, Projemiz iÃ§in kÄ±sa bir anketimiz var, doldurabilir misiniz? 

[Link](https://forms.gle/37cKLdoENGVNKbue9) - TeÅŸekkÃ¼rler
"comment": [
]
====================================================================================
"question_isim": "->",
"quest": "1 aylÄ±k eÄŸlenceli ve Ã¶ÄŸretici serÃ¼venin ardÄ±ndan ÅŸÃ¶yle bir yazÄ± yazmaya karar verdim umarÄ±m hepimiz iÃ§in faydalÄ± bir ay olmuÅŸtur. DeÄŸerli yorumlarÄ±nÄ±zÄ± bekliyorum :) [Link](https://medium.com/@emrekarakoc36/yeni-baÅŸlayanlar-iÌ‡Ã§in-makine-Ã¶ÄŸrenimi-projeleri-76f940da6bd8)
"comment": [
    "->  Kesinlikle Ã§ok faydalÄ± bir yazÄ± olmuÅŸ bence, iÅŸin pratiÄŸine baÅŸlamak isteyenler iÃ§in nerden baÅŸlanacaÄŸÄ±na (genelde veri seti bulmak da bu sÃ¼recin iÃ§inde) birebir ğŸ™‚ Tebrik ederim, yazÄ±larÄ±n devamÄ±nÄ± bekliyorum ğŸ™‚.",
    "-> ->  teÅŸekkÃ¼rler ederim fethi ğŸ™‚ sayende de birÃ§ok ÅŸey Ã¶ÄŸrendik eksik olma ğŸ™‚2 weeks ago 2 people like this.Like ReportReply",
    "->  BaÅŸarÄ±lÄ± bir Ã§alÄ±ÅŸma olmuÅŸ eline saÄŸlÄ±k ğŸ™‚ gÃ¼ncellemek ister misin bilmiyorum ancak:SÄ±nÄ±fÄ±landÄ±rma Ã§alÄ±ÅŸmasÄ±nda bir klasik olan Titanik'i ve Regresyon Ã§alÄ±masÄ± iÃ§in Boston House Prices'Ä± da dahil edebilirsin istersen :))Ä°yi Ã§alÄ±ÅŸmalar ğŸ™‚2 weeks ago 2 people like this.Like ReportReply",
    "-> ->  hali hazÄ±rda kendi Ã§alÄ±ÅŸtÄ±klarÄ±mla bir yazÄ± yazmak istedim sÃ¶ylediklerine en kÄ±sa zamanda bakÄ±cam yorumun iÃ§in Ã§ok teÅŸekkÃ¼r ederim ğŸ™‚.",
    "-> GÃ¼zel fikir belki herkesin desteÄŸiyle daha da bÃ¼yÃ¼yebilir ğŸ™‚ belki faydasÄ± olur ilgilenenlere diye ben de Ã¶nceden yazidigim bir yazÄ±yÄ± paylaÅŸmak isterim sorun olmazsa .Makina Ã¶ÄŸrenmesi ile EEG sinyalleri den epilepsi hastalÄ±ÄŸÄ± tahmini [Link](https://medium.com/kodluyoruz/eeg-sinyallerinden-makine-%C3%B6%C4%9Frenmesi-ile-epilepsi-hastal%C4%B1%C4%9F%C4%B1-tespiti-542aa61e2337)
    "EEG Sinyallerinden Makine Ã–ÄŸrenmesi ile Epilepsi HastalÄ±ÄŸÄ± Tespitimedium.comHerkese merhaba ben -> bundan bir kaÃ§ ay Ã¶nce Kodluyoruz ekibinin planladÄ±ÄŸÄ± Microsoft ve Avrupa BirliÄŸi sponsorluÄŸunda", 
==========================================================================================
{
"question_isim": "-> ",
"quest": "Merhaba ArkadaÅŸlar,  Final sÄ±navÄ± ara quizlerden biraz daha farklÄ± olacak, asÄ±l Ã¶nemli olan bu sÄ±nava katÄ±lÄ±m gÃ¶stermeniz diye belirtmiÅŸtik, dolayÄ±sÄ±yla ara quizlerden farklÄ± olarak saat aralÄ±ÄŸÄ±nÄ± da daha rahat tutmayacaktÄ±k tabii ki. Quizler gibi oldukÃ§a rahat Ã§Ã¶zebileceÄŸiniz sorular hazÄ±rlandÄ±, ara quizlere eksiksiz katÄ±lan arkadaÅŸlarÄ±n oldukÃ§a rahat geÃ§ebileceÄŸi bir sÄ±nav oldu. US'den katÄ±lÄ±m gÃ¶steren arkadaÅŸlarÄ±mÄ±z bana ayrÄ±ca bildirdiler, onlar farklÄ± bir saatte tamamladÄ±lar. Ä°stisnai durumdan kastÄ±mÄ±z bu gibi sebeplerdi. SÄ±nav saatini 22:00'ye kadar sanÄ±p kaÃ§Ä±ran arkadaÅŸlarÄ±mÄ±zÄ±n da 4 haftalÄ±k emeklerinin boÅŸa gitmesini istemeyiz. BugÃ¼n Ã¶ÄŸleden sonra saat 13:00'e kadar yanÄ±tlarÄ±nÄ±zÄ± gÃ¶nderebilirsiniz. Ancak bugÃ¼n yanÄ±t gÃ¶nderecek arkadaÅŸlarÄ±n bu postun altÄ±na + olarak yorum yapmalarÄ±nÄ± rica ediyorum, ona gÃ¶re deÄŸerlendirmeye alacaÄŸÄ±z.  Ä°yi Ã§alÄ±ÅŸmalar",
"comment": [
    "",
    "->  +.",
    "-> DÃ¼n 15.00dan sonra cevaplarÄ±mÄ±zÄ± gÃ¶nderdiysek de bugÃ¼n 13.00a kadar tekrar gÃ¶ndermemiz gerekir mi?.",
    "->  -> bu post unuzla da isim almÄ±ÅŸ olduk, gerekli deÄŸil, teÅŸekkÃ¼rler..",
    "-> +.",
    "->  +.",
    "->  +.",
    "-> +.",
    "->  +.",
    "->  +.",
    "->  +.",
    "->  +.",
    "-> Merhaba, ben dun ogleden sonra saatlerinde, saatini cok iyi hatirlamiyorum ama sanirim 18:00 civari gondermistim. Gecerli sayilir mi? Ulasmistir degil mi?.",
    "->  -> Merhaba, evet ulaÅŸmÄ±ÅŸtÄ±r, deÄŸerlendirmeye alacaÄŸÄ±z..",
    "-> ->  Cok tesekkurler :).",
    "->  +.",
    "->  Ben de dÃ¼n kendimi denemek amacÄ±yla sÄ±navÄ± yapmÄ±ÅŸtÄ±m ancak saat aralÄ±ÄŸÄ±nÄ±n dÄ±ÅŸÄ±ndaydÄ±. Tekrar yapmalÄ± mÄ±yÄ±m?.",
    "->  ->  bu yorumu yapmanÄ±z yeterli, deÄŸerlendirmeye alacaÄŸÄ±z..",
    "->  Ben de dÃ¼n 15:00â€™ten sonra gÃ¶nderdim. SanÄ±rÄ±m bugÃ¼n tekrar gÃ¶ndermeme gerek yok, Ã¶yle mi?.",
    "->  ->  Aynen, bu yorumunuz yeterli..",
    "->  +.",
    "->  geÃ§mek iÃ§in belirlenen taban puanÄ± nedir? ayrÄ±ca bu eÄŸitim iÃ§in mentorlerimize ve programÄ± dÃ¼zenleyenlere teÅŸekkÃ¼r ediyorum..",
    "->  ->  50 ve Ã¼zeri alan sertifika almaya hak kazanacak, teÅŸekkÃ¼rler..",
    "->  + Ben dÃ¼n saat 16 civarÄ± gÃ¶rdÃ¼ÄŸÃ¼m gibi hemen yollamÄ±ÅŸtÄ±m sÄ±navÄ±, teÅŸekkÃ¼rler..",
    "->  +.",
    "->  +.",
    "->  Ben Singapur'da oldugumdan dolayi dun saati kacirmistim. Az once gonderdim. Tesekkurler..",
    "->  ben sonradan paylaÅŸÄ±lan bu postu gÃ¶rmedim dÃ¼n kaÃ§Ä±rdÄ±ÄŸÄ±m iÃ§in girememmiÅŸtim ÅŸimdi gÃ¶nderdim umarÄ±m kabul edersiniz. +.",
    "->  ->  ÃœzgÃ¼nÃ¼m, Google ekibine sonuÃ§larÄ± ilettik...",
    "->  Merhaba ben dÃ¼n saat deÄŸiÅŸikliÄŸini gÃ¶rmediÄŸim iÃ§in geÃ§ yollamÄ±ÅŸtÄ±m. Bu post bildirimi daha yeni geldi. Benim testimde geÃ§erli sayÄ±labilecek mi?.",
    "->  ->  ÃœzgÃ¼nÃ¼m, 13:00 ten sonra listeyi netleÅŸtirip Google ekibine ilettik.. Sebep belirtmeden sizin gibi geÃ§ iletenleri de ilettim kendilerine, artÄ±k onlarÄ±n deÄŸerlendirmesinde konu...",
    "->  ->  AnladÄ±m her ÅŸey iÃ§in teÅŸekkÃ¼r ederim.",
    "->  +.",
    "->  Ben de saat 16 gibi doldurmuÅŸtum..",
    "->  Ben de dÃ¼n yollamÄ±ÅŸtÄ±m ama ÅŸuan geÃ§ kaldÄ±m + iÃ§in Ã§alÄ±ÅŸtÄ±ÄŸÄ±mdan dolayÄ± sÃ¼rekli bakamÄ±yorum siteye lÃ¼tfen beni de ekler misiniz?.",
    "->  Benden sabah bekledikleri listeyi 13:00 den sonra kendilerine ilettim arkadaÅŸlar, son kiÅŸileri de alabilelim diye ğŸ™‚ GeÃ§ gÃ¶nderenleri de ayrÄ±ca bildirdim, onlarÄ±n deÄŸerlendirmesinde artÄ±k konu..2 weeks ago 3 people like this.Like ReportReply",
    "->  ->  teÅŸekkÃ¼r ederiz her ÅŸey iÃ§in â˜ºï¸.",
    "->  Merhaba Asli Hanim bende dun gec gonderenlerdenim.Yurtdisindayim ve sizin saatinizle aksam 8 civari sanirim yolladim..",
    "->  merhabalar, dÃ¼n geÃ§ gÃ¶nderenler +1.",
    "-> dÃ¼n 9.30da gÃ¶nderdim +.",
    "ozan ilter Her ÅŸeyi kaÃ§Ä±rdÄ±m....",
    "->  Merhaba ->  siz bu aÃ§Ä±klamalarÄ± yapmadan Ã¶nce ben dÃ¼n paylaÅŸmÄ±ÅŸ olduÄŸunuz postun altÄ±na sÄ±navÄ± kaÃ§Ä±rdÄ±ÄŸÄ±mÄ± ama yine de kendimi test etmek iÃ§in sÄ±navÄ± yaptÄ±ÄŸÄ±mÄ± belirtmiÅŸtim. Bu bildirimleri de gÃ¶z Ã¶nÃ¼ne aldÄ±nÄ±z mÄ±?.",
    "->  +.",
    "-> Merhaba, ben de 3 -5 dakika gec gonderdim. Saat farkim Amerika kadar degil sadece 2 saat ama sinava gec baslayinca dalmisim. Kabul edilir mi bilmiyorum ama sinav icin cok cok tesekkurler .. Bilgiler pekismis oldu bu sinavla. Herkese kolayliklar dilerim....",
    "-> -> Final sÄ±navÄ±yla Ã¶nceki sÄ±navlarÄ±n ortalamasÄ± birlikte mi alÄ±nacak? TeÅŸekkÃ¼rler bÃ¼tÃ¼n program eÄŸitici oldu, herkese bu alanda baÅŸarÄ±lar :)).",
    "->  Bende 22.00 sanÄ±p, bu mesajÄ± da Ã§ok geÃ§ gÃ¶rdÃ¼m. Neyse saÄŸlÄ±k olsun. Ã‡ok eÄŸitici bir organizasyon oldu..",
    "->  +.",
    "-> burada okul mailim ile kayÄ±tlÄ± olduÄŸum iÃ§in ve bu maili Ã§ok sÄ±k kontrol etmediÄŸim iÃ§in hem ilk seferde hemde ikinc kez uzatmanÄ±zda gÃ¶zden kaÃ§Ä±rdÄ±m gerÃ§eten bÃ¼yÃ¼k talihsizlik oldu yardÄ±mcÄ± olabilirseniz Ã§ok sevinirim.",
    "->  + ben pazar gunu sinavi saat 15.00'dan yaklasik 40 dakika sonra yaptim. Pazartesi gunu elimde olmayan nedenlerden oturu bilgisayarimi acamadim. Sinavim dikkate alinmadiysa yapacak bir sey yok artik. Tesekkurler her sey icin..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "4 haftalÄ±k bu faydalÄ± sÃ¼reÃ§te emeklerini esirgemeyen tÃ¼m mentÃ¶rlere ve bu fikri hayata geÃ§irilmesinde faydasÄ± olan herkese tek tek teÅŸekkÃ¼r ederim. Bu sayfada sorulan sorulardan da Ã§ok faydalanmÄ±ÅŸ birisi olarak sayfayÄ± 15 mayÄ±s tarihinde kapatmamanÄ±zÄ± isteyebilir miyiz ğŸ™‚ ? ÅŸahsen tÃ¼m sorulan sorulara bakmaya Ã§alÄ±ÅŸmÄ±ÅŸ olsamda kaÃ§Ä±rdÄ±ÄŸÄ±m bir sÃ¼rÃ¼ soru ve deÄŸerli mentÃ¶rlerin cevaplarÄ± mevcut. Hepsi kocaman bir emek ve zaman. Kurs sÃ¼resince konulara Ã§alÄ±ÅŸarak haftalÄ±k sÄ±navlara yetiÅŸmek benim iÃ§in yoÄŸun bir tempoydu Ã§Ã¼nkÃ¼ ekstra zaman ayÄ±rarak ancak takip edebildim. GÃ¶z atamadÄ±ÄŸÄ±m sorularÄ± okumak iÃ§in can atÄ±yorum lakin grubun kapanma tehlikesi var ğŸ™‚ LÃ¼tfen kapatmayÄ±n ğŸ™‚ DeÄŸerli MentÃ¶rlerimizin zamanlarÄ± ve emekleri Ã§Ã¶pe gitmesin ğŸ™‚",
"comment": [
    "",
    "->  GÃ¼zel bir noktaya deÄŸinmiÅŸsiniz, aslÄ±nda buradaki soru ve cevaplar bir pdf dosyasÄ±nda toplatÄ±lÄ±rsa Ã§oÄŸumuz fayadalanacaÄŸÄ±z. SanÄ±rÄ±m 15 tÃª kapanacak grup az bir sÃ¼re var2 weeks ago 5 people like this.Like ReportReply",
    "->  Merhaba, hub hep aÃ§Ä±k kalacak zaten, 15 MayÄ±s'tan sonra sadece paylaÅŸÄ±ma kapatÄ±lacak ve bÃ¼tÃ¼n geÃ§miÅŸe eriÅŸimimiz olacak. AyrÄ±ca 15 MayÄ±s'tan sonra da sorularÄ±mÄ±zÄ± Turkish AI Hub Ã¼zerinden sorabileceÄŸiz.2 weeks ago 6 people like this.Like ReportReply",
    "->  ->  Ã¶yle mi bilmiyordum bunu Ã§ok teÅŸekkÃ¼r ederim ğŸ™.",
    " "
]
},
{
"question_isim": "->  uploaded 1 photo",
"quest": "Merhabalar, Ã¶ncelikle emeÄŸi geÃ§en herkese Ã§ok teÅŸekkÃ¼rler.  Final sÄ±navÄ± ile ilgili olarak bir sorum olacak. 17. soruda \"classifier that trains to 99% accuracy or above\" geÃ§iyor ama if koÅŸul yapÄ±sÄ± iÃ§erisinde \"if(logs.get('accuracy')&gt;0.99): \" denmiÅŸ. &gt;=0.99 olmasÄ± gerekmiyor mu? Ben bu ÅŸekilde olmasÄ± gerektiÄŸini dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼m iÃ§in diÄŸer ÅŸÄ±klara bakmadan #1 olarak iÅŸaretledim.",
"comment": [
    "",
    "-> ben altÄ± okuyamadan 2 dedim Ã§Ã¼nkÃ¼ if satÄ±rÄ±nÄ±n altÄ±nda girinti olmasÄ± gerekirdi diye tabiki yanlÄ±ÅŸ Ã§Ä±ktÄ± ğŸ™‚2 weeks ago 2 people like this.Like ReportReply",
    "-> -> bu dediÄŸinizi Ã¶nce ben de dÃ¼ÅŸÃ¼ndÃ¼m ta ki en alttaki epoch=12 yi gÃ¶rene kadar ,bu noktada da ÅŸÃ¶yle dÃ¼ÅŸÃ¼ndÃ¼m burada syntax hatasÄ±ndan ziyade semantic hata istiyorlar bizden ve o soruda da 10 epochdan fazla olmasÄ±n tarzÄ± bir bilgi vardÄ± o yÃ¼zden 4. ÅÄ±kkÄ± seÃ§tim sonradan ğŸ™‚.",
    "->  -> Evet. Åu an fark ettim, haklÄ±sÄ±nÄ±z. #2 de yanlÄ±ÅŸ..",
    "->  Merhaba, hayÄ±r,bende aynÄ± hatayÄ± yaptÄ±m ya hep karÄ±ÅŸtÄ±rÄ±rm, â€œ veya â€œ ifadesi olduÄŸu iÃ§in bu ÅŸekilde oluyor. â€œ ve â€œ olmuÅŸ olsaydÄ± o zaman >= kullanÄ±rdÄ±k. Diye dÃ¼ÅŸÃ¼nÃ¼yorum...2 weeks ago 2 people like this.Like ReportReply",
    "->  ->  BildiÄŸim kadarÄ±yla o ÅŸekilde olmuyor. EÄŸer \"veya\" kullanÄ±lmÄ±ÅŸsa \"veya\" ile baÄŸlanmÄ±ÅŸ koÅŸullardan herhangi birinin saÄŸlanmÄ±ÅŸ olmasÄ± sonucun doÄŸru olmasÄ±nÄ± saÄŸlar fakat \"ve\" kullanÄ±ldÄ±ysa \"ve\" ile baÄŸlanmÄ±ÅŸ koÅŸullarÄ±n tÃ¼mÃ¼nÃ¼n doÄŸru olmasÄ± bir gerekliliktir. BakÄ±nÄ±z Boolean Algebra: https://medium.com/i-math/intro-to-truth-tables-boolean-algebra-73b331dd9b94",
    "Intro to Truth Tables & Boolean Algebramedium.comA truth table is a handy little logical device that shows up not only in mathematics but also in Computer Science and Philosophy, making itâ€¦.",
    "->  ->  bende iÅŸte sÃ¼rekli karÄ±ÅŸtÄ±rÄ±rÄ±m bunlarÄ±( python Ã¼zerinde sadece) o yÃ¼zden hataya dÃ¼ÅŸerim sorgularÄ±m ama sizde ÅŸunu bi inceleyin isterseniz https://charon.me/posts/tf1/ Ã¶rneÄŸin aynÄ±sÄ± bu ÅŸekilde yapÄ±lmÄ±ÅŸ bu durumda bizim final sÄ±navÄ±ndaki soruya gÃ¶re girdide sÄ±kÄ±ntÄ± var ve epoch 12 hatasÄ± var1. Introduction to TensorFlow for AI, ML, and DLcharon.meA new programming paradigm Traditional Programming Paradigm V.S. Machine Learning Paradigm V.S. ML is all about a computer learning patterns that distinguish things E.g. X = -1, 0, 1, 2, 3, 4 Y = -3, -1, 1, 3, 5, 7 What is the pattern between them? Answer: Y = 2X - 1 Code: model =â€¦.",
    "->  ->  Bence bu sadece dÃ¼z bir if statement ve \"=\" koÅŸulu olmadÄ±ÄŸÄ± sÃ¼rece 99% accuracy'de koÅŸul saÄŸlanmamÄ±ÅŸ olacak.AynÄ± hatanÄ±n farklÄ± bir websitesinde yapÄ±lmÄ±ÅŸ olmasÄ± hatanÄ±n doÄŸru olduÄŸunu ispatlamaz diye dÃ¼ÅŸÃ¼nÃ¼yorum..",
    "->  ->  birden fazla sitede cevabÄ± bÃ¶yle ve bu operatÃ¶rlerin mantÄ±ksal karÅŸÄ±tlÄ±klarÄ±da var ama burda oda deÄŸil, onu geÃ§tim ÅŸÃ¶yle dÃ¼ÅŸÃ¼nÃ¼yorum bu soruyu mesela 18 yaÅŸ ve Ã¼stÃ¼ ehliyet alabilir bu durumda iki koÅŸuluda saÄŸlamak gerekiyor >= kullanmamÄ±z lazÄ±m, cevaplarÄ± merakla bekliyorum bende..",
    "->  Ben de 3 numaradan yana kullanmÄ±ÅŸtÄ±m tercihimi, sonra benim de gÃ¶zÃ¼m 2'ye kaydÄ± girinti olmasÄ± gerekirdi diye ama doÄŸru cevap 3 deÄŸilmiÅŸ. YanlÄ±ÅŸ diyen var demek ki 1 ve 2 de deÄŸil. Neden 4 acaba doÄŸru yapan biri bizi aydÄ±nlatabilir mi?.",
    "-> ->  En fazla 10 epoch yapÄ±lmasÄ±nÄ± istemiÅŸti soruda, ama kodda 12 epoch koÅŸturulmuÅŸ.2 weeks ago 3 people like this.Like ReportReply",
    "->  TeÅŸekkÃ¼rler..",
    "->  Epoch maksimum 10 olmalÄ± diyordu soruda yani istediÄŸimiz accuracy rate Ã§Ä±kmasa bile 10 epoch ile modelimiz sÄ±nÄ±rlÄ± kalmalÄ±ydÄ± fakat 4. soruda epoch = 12 yazÄ±lmÄ±ÅŸ yanlÄ±ÅŸ bundan dolayÄ± diye dÃ¼ÅŸÃ¼nÃ¼yorum..",
    "-> HaklÄ±sÄ±nÄ±z, >= 0.99 olmasÄ± gerekiyor ve if'in altÄ±nda indentation eksik, bu benim de dikkatimi Ã§ekti ancak #4 daha kavramsal bir yanlÄ±ÅŸ olduÄŸu iÃ§in tercih ettim.2 weeks ago 3 people like this.Like ReportReply",
    "->  DoÄŸru cevaplar aÃ§Ä±klandÄ± mÄ±? Ä°kinci satÄ±rda indentation problemi var, program hata verir, hatta altÄ±ndaki satÄ±r da girdili olmalÄ±. CevabÄ±n iki olmasÄ± gerekmez mi?2 weeks ago 4 people like this.Like ReportReply",
    "->  bence bu soruda hangisi doÄŸruydu diye sorulmalÄ±ydÄ±. #1 iÃ§in = sembolÃ¼ yok , #2 iÃ§in if'e girmese hata alacaÄŸÄ±z #4 zaten epoch 10 dan fazla. Ben 4 yapmÄ±ÅŸtÄ±m fakat Ã¼zerine gerÃ§ekten dÃ¼ÅŸÃ¼ndÃ¼m en aÃ§Ä±k yanlÄ±ÅŸ bu geldi bir ara soru yanlÄ±ÅŸ mÄ± sorulmuÅŸ diye #3'Ã¼ bile iÅŸaretlemeyi dÃ¼ÅŸÃ¼ndÃ¼m. (YanlÄ±ÅŸ dÃ¼ÅŸÃ¼nÃ¼yorsam lÃ¼tfen dÃ¼zeltin.)2 weeks ago 3 people like this.Like ReportReply",
    "->  ->  Ne yazÄ±k ki, if iÃ§erisine girmese bile yazdÄ±rma durumu sÃ¶z konusu deÄŸil, ilgili fonksiyon tetiklendiÄŸi gibi IndentationError verecektir. Python da kod bloklarÄ± girintiler ile belirlendiÄŸi iÃ§in, #2 deki ifade python syntax'Ä±nda bir hata olarak karÅŸÄ±lanmakta.Ä°yi Ã§alÄ±ÅŸmalar.2 weeks ago 3 people like this.Like ReportReply",
    "->  ->  evet haklÄ±sÄ±n hata alÄ±rÄ±z , dÃ¼zelttim..",
    "->  Benim gÃ¶rÃ¼ÅŸÃ¼m; \"if(logs.get('accuracy')>0.99) hatasÄ± ile epoch=12 hatasÄ± arasÄ±nda bir fark yok gibi. 2si de yazÄ±m hatasÄ± ve hatalÄ± Ã§alÄ±ÅŸmaya sebep oluyor. 2si de traningin farklÄ± sonlanmasÄ±na sebep olmaz mÄ±?2 weeks ago 2 people like this.Like ReportReply",
    "->  ArkadaÅŸlarÄ±ma katÄ±lÄ±yorum, 1 ve 4 kesinlikle yanlÄ±ÅŸ evet, ayrÄ±ca ne tÃ¼r bir hata(semantic/syntax) olmasÄ± gerektiÄŸi ile ilgili bir bilgilendirme yok soruda ve ÅŸu ifade geÃ§iyor net bir ÅŸekilde \"When it reaches 99% or greater it should print out the string\" fakat indentation hatasÄ± sebebi ile stringi yazdÄ±rmasÄ± da sÃ¶z konusu deÄŸil bu sebeple sorunun iptal edilmesi veya 1 ve 2'nin de doÄŸru kabul edilmesi gerektiÄŸini dÃ¼ÅŸÃ¼nÃ¼yorum..",
    "->  Ben de bu ÅŸekilde dÃ¼ÅŸÃ¼nerek #1 olan seÃ§eneÄŸi iÅŸaretledim.2 weeks ago 2 people like this.Like ReportReply",
    "->  99 'a eÅŸit ve bÃ¼yÃ¼k diye metinde ifade edilirken kodda sadece 99'dan bÃ¼yÃ¼k olarak yazÄ±lmÄ±ÅŸ. Diger taraftan ise, bu kadar kompleks bir kod bloÄŸunda indent hatasÄ± yÃ¼zÃ¼nden bir ÅŸÄ±k iÅŸaretlenmemeli. Ã‡Ã¼nkÃ¼ soru Ã§ok gÃ¼zeldi ama cevap bu kadar basit olmamalÄ± ğŸ™‚2 weeks ago 2 people like this.Like ReportReply",
    "->  Merhaba -> , bence hangi cevabÄ±n daha doÄŸru olduÄŸunu tartÄ±ÅŸmÄ±yoruz, birden fazla doÄŸru cevap var ortada ifade edilmeye Ã§alÄ±ÅŸÄ±lan ÅŸey de bu..",
    "->  Merhaba ->  , aslÄ±nda hangi cevabÄ±n daha doÄŸru olduÄŸu konusunda bir tespitte bulunmadÄ±m. Indent hatasÄ± gibi veya syntax hatasÄ± gibi hatalar compile yapan editor ler tarafÄ±ndan tespit edilebilir. Ã‡Ã¼nkÃ¼ if in altÄ±nda hiÃ§ kod yok. Daha kod Ã§alÄ±ÅŸmadan evvel gerÃ§ekleÅŸecek bir hata. bu gÃ¼zel soruda bÃ¶yle cevap olmamÄ±ÅŸ ama haddime deÄŸil naÃ§izane:).",
    "->  Ben de #3 yaptÄ±m. activation function deÄŸiÅŸkeni tanÄ±mlanmadÄ±ÄŸÄ± iÃ§in \"tf.nn.softmax\" Normalde \"softmax\" veya \"relu\" yazmak yeterliydi. TanÄ±mlÄ± deÄŸiÅŸken olmazsa kullanÄ±lmamalÄ± diyor class iÃ§inde diye #3 yaptÄ±m. Did it right? ğŸ™‚.",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar,  Final sÄ±navÄ±nÄ±n ilk sorusunda bir yazÄ±m hatasÄ± olabilir mi?  Ä°kinci ÅŸÄ±k; \"The regressor might overfit to test set if we don't use validation sets.\" Burada \"overfit to test set\" yerine \"overfit to training set\" olmasÄ± gerekmiyor mu?",
"comment": [
    "",
    "-> Merhaba Toygar,HayÄ±r bir yazÄ±m yanlÄ±ÅŸÄ± yok. ÅÃ¶yle aÃ§Ä±klayayÄ±m, elimizde sadece training ve test setleri olduÄŸunu dÃ¼ÅŸÃ¼nelim. Modelimizi train seti ile eÄŸitip, hem train hem de test seti iÃ§in iyi bir sonuÃ§ verecek ÅŸekilde hiper parametrelerimizi ayarladÄ±k. Ancak burada modeli eÄŸitirken elimizdeki tÃ¼m setleri kullandÄ±k, yani hem train hem de test datamÄ±zÄ± iyi bir ÅŸekilde Ã¶ÄŸrendik. Ä°ÅŸte bu noktada test datasÄ±na da overfit oluÅŸabiliyor.Bunu engellemenin yolu da validation seti oluÅŸturmak. YukarÄ±daki iÅŸlemler gibi, train seti ile modeli eÄŸitiyor, validation seti ile hiperparametrelerimizi ayarlÄ±yoruz. Hem train hem de validation seti Ã¼zerinde tatminkar bir model kurduktan sonra modelimizi daha Ã¶nce hiÃ§ gÃ¶rmemiÅŸ olduÄŸu bir test seti ile test ediyoruz. Bu sayede modelimizin performansÄ±nÄ± gerÃ§eÄŸe yakÄ±n bir ÅŸekilde Ã¶lÃ§mÃ¼ÅŸ oluyoruz.DolayÄ±sÄ±yla validation seti kullanmak test datasÄ±na overfit etmeyi engelleme konusunda iÅŸe yarÄ±yor.Ä°yi Ã§alÄ±ÅŸmalar.2 weeks ago 2 people like this.Like ReportReply",
    "->  EÄŸitim setinden elde ettiÄŸin aÄŸÄ±rlÄ±klarÄ± test setindeki sonucu deÄŸerlendirerek gÃ¼ncelliyorsun. Yani eÄŸitim setine test setinin sonucuna gÃ¶re ÅŸekil veriyorsun. KÄ±sacasÄ± overfit olma durumu ya validation sete ya da test setine gÃ¶re olabiliyor..",
    "-> Ä°lk haftanÄ±n quzinde de sorulmuÅŸ olan bu sorunun cevabÄ± iÃ§in yazÄ±lan aÃ§Ä±klamayÄ± aÅŸaÄŸÄ±ya bÄ±rakÄ±yorum. UmarÄ±m faydalÄ± olur. \"Bu soruya veriye validation set eklemezsek ne olur'la baksak Ã§ok daha iyi olacak. Siz bir modelgeliÅŸtiriyorsunuz, training ve test seti ayÄ±rdÄ±nÄ±z, 100 Ã¶rnekten 80'i training 20'si test. Ev fiyatlarÄ±nÄ±tahminlemeye Ã§alÄ±ÅŸÄ±yorsunuz. Bir regresyon modeli train ettiniz, sonra iÃ§ine test verisinden 4 odalÄ± ve ikibanyolu bir ev koydunuz o da size bu evin fiyatÄ±nÄ±n 100 bin lira olmasÄ± gerektiÄŸini sÃ¶yledi, ama gerÃ§ekte oev (test verisindeki ev fiyatÄ± kolonu) 120 bin lira, buna gÃ¶re hatanÄ±za baktÄ±nÄ±z, parametrelerinizi deÄŸiÅŸtiripyeniden train ettiniz. Zamanla kendinizi bu test verisinden aldÄ±ÄŸÄ±nÄ±z hatalara gÃ¶re adapte ediyorsunuz,yani test verisine overfit ediyorsunuz. Farkettiyseniz test verisiyle hem parametreleri deÄŸiÅŸtiriyoruz hemde test ediyoruz, bu yanlÄ±ÅŸ, bu yÃ¼zden validation set ekliyoruz, hataya bakÄ±p parametre deÄŸiÅŸtirmeiÅŸlemini validation set'te yapÄ±yoruz, ardÄ±ndan yeni Ã§Ä±kan modeli test verisiyle test ediyoruz, bÃ¶ylecemodelin gerÃ§ekten iyi bir performans sergileyip sergilemediÄŸini gÃ¶rebiliyoruz.\"2 weeks ago 2 people like this.Like ReportReply",
    "->  Ä°lk haftanÄ±n quizinde bu soruyu yanlÄ±ÅŸ okumuÅŸ olmalÄ±yÄ±m.Ã–yleyse burada modelin *sadece* test setine overfit olmasÄ±ndan bahsetmiyoruz. Ki bu zaten mÃ¼mkÃ¼n deÄŸil. Test setine *de* overfit olmasÄ±ndan bahsediyoruz. Sorunum cÃ¼mleyi yanlÄ±ÅŸ yorumlamamla ilgili demek ki.TeÅŸekkÃ¼r ederim..",
    " "
]
},

{
"question_isim": " ->  uploaded 1 photo",
"quest": "Merhaba, konularÄ± tekrar ederken ÅŸu kÄ±sÄ±mÄ± tam kavrayamadÄ±ÄŸÄ±mÄ± fark ettim. AÃ§Ä±klayabilir misiniz lÃ¼tfen.",
"comment": [
    "",
    "-> merhaba kendim Ã¶ÄŸrendiÄŸim kadarÄ±yla cevap vereceÄŸim yanlÄ±ÅŸÄ±m olabilir; Vanishing gradient iÃ§in; Bu problem sadece derin aÄŸlarda karÅŸÄ±mÄ±za Ã§Ä±kÄ±yor oraya Ã¶zel denebilir. Biz derin aÄŸlarda ne yapÄ±yorduk? Katmanlar arasÄ± inputtan outputa Forward propagation Outputa geldiÄŸimizde hatamÄ±z yÃ¼ksek olacaÄŸÄ± iÃ§in katmanlarda aralardaki weightleri gÃ¼ncellememiz lazÄ±m. Yani geri (back propagation) gelmemiz lazÄ±m. Bu ileri geri tÃ¼m epochlarda defalarca oluyor. Bu geri gelme esnasÄ±nda tÃ¼rev alÄ±yorduk, ancak iÅŸte tam burada vanishing problem baÅŸlÄ±yor, aralarda activasyon fonksiyonlarÄ± var, bu sigmoid olduÄŸunda deÄŸerleri 0-1arasÄ±na indiriyordu. Biz tÃ¼revi aldÄ±ÄŸÄ±mÄ±zda deÄŸer 0-1(Ã¶rn 0.5) aralÄ±ÄŸÄ±nda ise tÃ¼revini alabiliyoruz ve gÃ¼zel bir weight gÃ¼ncellemesi yapabiliyoruz. Ancak deÄŸer 0ya da1 e Ã§ok yakÄ±n olduÄŸunda tekrarlayan back propagationlarda artÄ±k modelimiz Ã§ok dÃ¼ÅŸÃ¼k tÃ¼rev sonuÃ§larÄ±yla weightleri cezalandÄ±ramamaya baÅŸlÄ±yor. BÃ¶ylece Vanishing gradient yani benim tabirimle model boÅŸa kÃ¼rek Ã§ekiyor ve Ã¶ÄŸrenme bir tÃ¼rlÃ¼ gerÃ§ekleÅŸmiyor. Bunu Ã¶nlemek iÃ§in aktivasyon fonksiyonunu deÄŸiÅŸtirip ReLU yapÄ±yorlar ki + deÄŸerlerde Vanishing olmasÄ±n.2 weeks ago 2 people like this.Like ReportReply",
    " ->  ->  AnladÄ±m, teÅŸekkÃ¼r ederim..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Herkese Merhaba!  Final sÄ±navÄ±mÄ±z yarÄ±n 11:00-15:00 saatleri arasÄ±nda gerÃ§ekleÅŸecektir. 25 soru test ÅŸeklinde olacak. SÄ±nav saatine yakÄ±n bir zamanda sÄ±nav linkini yine buradan paylaÅŸÄ±yor olacaÄŸÄ±m. Ä°stisnai durumlar dÄ±ÅŸÄ±nda, saat 15:00'den sonra iletilen yanÄ±tlar ne yazÄ±k ki deÄŸerlendirmeye alÄ±nmayacaktÄ±r.  Åimdiden baÅŸarÄ±lar!",
"comment": [
    "",
    "->  TeÅŸekkÃ¼rler -> .",
    "->  UÃ§ar Merhaba, test iÃ§in dakika sÄ±nÄ±rlamasÄ± olacak mÄ±?2 weeks ago 4 people like this.Like ReportReply",
    "->  ->  UÃ§ar belirttiÄŸimiz saat aralÄ±ÄŸÄ±nda yapÄ±p iletmenizi bekliyoruz ğŸ™‚.",
    "->  UÃ§ar TeÅŸekkÃ¼rler AslÄ± HanÄ±m, ancak biz aslÄ±nda kronometrik bir sÃ¼re olup olmayacaÄŸÄ±nÄ± merak ediyoruz. AtÄ±yorum toplam 60 dk/75 dk da Ã§Ã¶zmeniz gerekli ÅŸeklinde bir kural var mÄ±?.",
    " ->  yetenek programÄ±na alÄ±m sadece bu sÄ±nav Ã¼stÃ¼nden mi olacak yoksa mÃ¼lakata girecek miyiz.",
    "->   ->  sonradan mÃ¼lakata da gireceksiniz ğŸ™‚.",
    "->  Ã‡ok heyecanlÄ±yÄ±m, sabÄ±rsÄ±zlÄ±kla bekliyorum, umarÄ±m geÃ§ebilirim ğŸ™‚.",
    "->  GeÃ§mek iÃ§in minimum puan kaÃ§ olacak?.",
    "->  ->  GerÃ§ekten samimi davranÄ±p, Ã¶zverili ile Ã§alÄ±ÅŸan herkesin geÃ§eceÄŸini dÃ¼ÅŸÃ¼nÃ¼yoruz ğŸ™‚.",
    "->  sÄ±navda tensorflow veya herhangi bir python kÃ¼tÃ¼phanesi bilmemiz gerekiyor mu bu sÄ±nav iÃ§in..",
    " ->  SÄ±navda kod olacak mÄ± yoksa diÄŸerleri gibi teorik bilgi mi sorulacak?.",
    "->  Merhaba ->  HanÄ±m, sÄ±nav sÃ¼resi ne kadar?2 weeks ago 2 people like this.Like ReportReply",
    "->  sÄ±navÄ± geÃ§ince google sertifikasÄ± verilecek mi ? -> .",
    "->  ->  evet verilecek denmiÅŸti Ã¶nceden..",
    " -> SÄ±nav konusunda hÄ±zlÄ± Ã§Ã¶zmek zorunda kaldÄ±m fakat 20'nci sorunun hatalÄ± olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yorum. EÄŸitim boyunca emeÄŸi geÃ§en herkese teÅŸekkÃ¼r ederim..",
    "->  Ä°stisnai duruma postu yeni gÃ¶renler dahil mi? ğŸ™2 weeks ago 4 people like this.Like ReportReply",
    "->  ->  4 hafta boyunca quizlere katÄ±ldÄ±ysanÄ±z emeklerinizin boÅŸa gitmesini istemeyiz, isminizi not alacaÄŸÄ±m, bugÃ¼n Ã¶ÄŸleden sonra 13:00'e kadar yanÄ±tlarÄ±nÄ±zÄ± iletebilirsiniz, iyi Ã§alÄ±ÅŸmalar:).",
    "->  evet ben de yeni gÃ¶rdÃ¼m yine saat 22:00 diye dÃ¼ÅŸÃ¼nmÃ¼ÅŸtÃ¼m ğŸ™2 weeks ago 4 people like this.Like ReportReply",
    "->  ->  4 hafta boyunca quizlere katÄ±ldÄ±ysanÄ±z emeklerinizin boÅŸa gitmesini istemeyiz, isminizi not alacaÄŸÄ±m, bugÃ¼n Ã¶ÄŸleden sonra 13:00'e kadar yanÄ±tlarÄ±nÄ±zÄ± iletebilirsiniz, iyi Ã§alÄ±ÅŸmalar:).",
    "->  Her hafta olduÄŸu gibi akÅŸam 10'a kadar vakit olur sanmÄ±ÅŸtÄ±m ğŸ™ kaÃ§Ä±rmÄ±ÅŸÄ±m bende.2 weeks ago 4 people like this.Like ReportReply",
    "->  ->  4 hafta boyunca quizlere katÄ±ldÄ±ysanÄ±z emeklerinizin boÅŸa gitmesini istemeyiz, isminizi not alacaÄŸÄ±m, bugÃ¼n Ã¶ÄŸleden sonra 13:00'e kadar yanÄ±tlarÄ±nÄ±zÄ± iletebilirsiniz, iyi Ã§alÄ±ÅŸmalar:).",
    "->  Ben de saat 22:00 a kadar olur sanmÄ±ÅŸtÄ±m sÄ±navÄ± kaÃ§Ä±rdÄ±m ğŸ˜”2 weeks ago 3 people like this.Like ReportReply",
    "->  ->  4 hafta boyunca quizlere katÄ±ldÄ±ysanÄ±z emeklerinizin boÅŸa gitmesini istemeyiz, isminizi not alacaÄŸÄ±m, bugÃ¼n Ã¶ÄŸleden sonra 13:00'e kadar yanÄ±tlarÄ±nÄ±zÄ± iletebilirsiniz, iyi Ã§alÄ±ÅŸmalar:).",
    " ->  O istisnai durumlar hangileri acaba? ğŸ™‚2 weeks ago 3 people like this.Like ReportReply",
    "-> testi simdi gonderdim. kabul olmasi icin istisnai durumlar nedir acaba? Ben 15:00 kisitini bugun gordum ve bu bilgiden haberim yoktu..2 weeks ago 2 people like this.Like ReportReply",
    "-> 22.00 sanmÄ±ÅŸtÄ±m ğŸ™2 weeks ago 2 people like this.Like ReportReply",
    "->  Her hafta 22:00 olduÄŸu iÃ§in ben kaÃ§Ä±rmÄ±ÅŸÄ±m. 13.00'e kadar yollama imkanÄ±mÄ±z var mÄ±?.",
    "->  ->  yukarÄ±da paylaÅŸtÄ±ÄŸÄ±m post un altÄ±na + olarak belirtebilir misiniz, yorumlardaki isimleri deÄŸerlendirmeye alacaÄŸÄ±z, teÅŸekkÃ¼rler..",
    "->  Merhaba, mÃ¼lakatlara seÃ§ilebilmek adÄ±na belirlemiÅŸ olduÄŸunuz taban puan veya kriterler nedir acaba? Åu ana kadar olan tÃ¼m ilginiz ve desteÄŸiniz iÃ§in de ayrÄ±ca Ã§ok teÅŸekkÃ¼rler..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba, ilgilenenler iÃ§in yeni bir makale Matthews correlation coefficient (MCC) deÄŸerinin F1 score Ã¼zerine olan Ã¼stÃ¼nlÃ¼ÄŸÃ¼nÃ¼ tartÄ±ÅŸÄ±yor: <a class=\"ps-media-link\" href=\"https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-019-6413-7\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-019-6413-7</a>",
"comment": [
    "",
    " "
]
},
{
"question_isim": "->  uploaded 6 photos",
"quest": "ArkadaÅŸlar merhaba,  AÅŸaÄŸÄ±da sizinle paylaÅŸtÄ±ÄŸÄ±m deÄŸerler hakkÄ±nda gÃ¶rÃ¼ÅŸleriniz nedir ?  TeÅŸekkÃ¼r ederim",
"comment": [
    "",
    "->  F1 Score Test ve Train'de gÃ¼zel bir ÅŸekilde 200 Epoch'da maximum(Test set'i Train set'den ayrÄ± olarak aldÄ±ÄŸÄ±nÄ±zÄ± dÃ¼ÅŸÃ¼nÃ¼rsek gayet gÃ¼zel sonuÃ§). 200'den sonra accuracy Test'de verimsizleÅŸiyor. Loss'da pek deÄŸiÅŸiklik olmuyor. 200 Epoch'un optimum deÄŸer, Ã¶ncesinde ve sonrasÄ±nda verimsiz olduÄŸu gÃ¶rÃ¼lÃ¼yor.2 weeks ago 2 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "->  uploaded 1 photo",
"quest": "Merhaba arkadaÅŸlar, Genel bir tekrar yapÄ±yorum ve Ã¶zellikle kod kÄ±smÄ±nda kafama takÄ±lan bazÄ± sorular oluyor. Ã–ncelikle Validation ve test set bÃ¶lÃ¼mÃ¼nde eklediÄŸim kodda validation_set=0.2 demek training setin'den mi %20 ayÄ±r demek istiyor. BÃ¶yle ise aslÄ±nda daha ilk baÅŸta Train_set, Validation_set ve test_seti ayÄ±rmak daha mantÄ±klÄ± olmaz mÄ±? Veya bir fark yaratÄ±r mÄ±?  Ä°kincisi Train_set ve test_seti kod yazarak nasÄ±l ayÄ±rabiliriz? Ã‡Ã¼nkÃ¼ burada hazÄ±r olan train ve test setlerini kullanmÄ±ÅŸ.  YardÄ±mcÄ± olursanÄ±z sevinirim. TeÅŸekkÃ¼rler",
"comment": [
    "",
    " ->  https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.htmlsklearn.model_selection.train_test_split â€” scikit-learn 0.22.2 documentationscikit-learn.orghttps://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html.",
    " ->  validation_set parametresi train datasÄ±ndan alÄ±r (yanlÄ±ÅŸ hatÄ±rlamÄ±yorsam listenin son elemanlarÄ±nÄ± alÄ±yordu). bundan dolayÄ± yukarÄ±da yolladÄ±ÄŸÄ±m fonksiyonu iki kere kullanÄ±p train,test,validation datasi ayarlamak daha mantÄ±klÄ±..",
    " ->  model.fit(x_train,y_train,validation_data=(x_val, y_val))bu ÅŸekilde validation datasÄ±nÄ± verebilirsin.",
    " ->  x0, x1 ve x2 deÄŸiÅŸkenlerine baÄŸlÄ± olarak deÄŸiÅŸen y0 outputunun bulunduÄŸu .csv olarak formatlanmÄ±ÅŸ uydurma bir veri seti iÃ§in aÅŸaÄŸÄ±daki ÅŸekilde veriyi train ve test olarak ayÄ±rabilirsiniz. EÄŸer networkunuz keras ile oluÅŸturulmuÅŸsa fit ederken x_train, y_train verilerinden bir kÄ±smÄ± validation iÃ§in ayÄ±rabilirsiniz. OkuduÄŸunuz veri pandas dataframeâ€™i yerine dÃ¼z numpy array olsa bile yine bu ÅŸekilde veriyi ayÄ±rÄ±p networkÃ¼nÃ¼ze baÄŸlÄ± olarak yine numpy array olarak kullanabilir ya da tensora Ã§evirebilirsiniz..",
    " ->  https://github.com/metobom/basit-cnnler-ve-keras-ile-uygulanislari Biraz daha kafa aÃ§mak isterseniz repodaki get_data.pyâ€™Ä± inceleyebilirsiniz.GitHub - metobom/basit-cnnler-ve-keras-ile-uygulanislarigithub.comhttps://github.com/metobom/basit-cnnler-ve-keras-ile-uygulanislari.",
    "->  Ã–rneÄŸin 10000 gÃ¶zlemimiz varsa slicing Ã¶zelliÄŸini kullanarak df_1[0 : 1000], df_2[1000 : 10000] uygulayarak 1000 e 9000 ÅŸeklinde ayÄ±rabiliyoruz. Ä°lk iÅŸlem, 0. indexten baÅŸlayÄ±p 1000. indexe kadar olanlarÄ± almamÄ±zÄ± saÄŸlÄ±yor. ikincisi de aynÄ± mantÄ±k. -> .",
    "->  Ã‡ok teÅŸekkÃ¼rler arkadaÅŸlar. Ä°yi Ã§alÄ±ÅŸmalar..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Herkese Merhaba  AkÄ±ÅŸa bakmama raÄŸmen 10 MayÄ±sta olucak sÄ±nav hakkÄ±nda bir detay gÃ¶remediÄŸim iÃ§in soruyorum. Genel deÄŸerlendirme sÄ±navÄ± Ã¶nceki quizler gibi belli bir zaman aralÄ±ÄŸÄ±nda form doldurma  ÅŸeklinde mi olucak acaba?  Ä°yi Ã§alÄ±ÅŸmalar, saÄŸlÄ±klÄ± gÃ¼nler",
"comment": [
    "",
    " "
]
},
{
"question_isim": " -> ",
"quest": "Herkese merhaba, 4 haftayÄ± bitirdik ve son bir sÄ±navÄ±mÄ±z kaldÄ±, herkesi tebrik etmek istiyorum.   Benim bu alana adÄ±m atma sÃ¼recimde faydalandÄ±ÄŸÄ±m kaynaklarÄ± sizlerle paylaÅŸmak istiyorum. Ã–zellikle yeni baÅŸlamÄ±ÅŸsanÄ±z iÅŸinize yarayacÄ±ÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum.  Bence kursu bitirmemiz demek Machine Learning temelimizi Ã§ok daha saÄŸlam hale getirdiÄŸimiz anlamÄ±na geliyor. Neden mi? Bir sÃ¼redir bu alanla ilgileniyorum ve projeler Ã¼zerinde Ã§alÄ±ÅŸÄ±p pratik yapÄ±yorum hatta ÅŸu anda da elimde bir proje var fakat teorik aÃ§Ä±dan sÃ¼rekli eksiklikler hissediyordum ve bu kurstan sonra bu aÃ§Ä±ÄŸÄ±mÄ±n bÃ¼yÃ¼k oranda kapandÄ±ÄŸÄ±nÄ± farkettim. Konulara daha hakimim.  Kurs boyunca her hafta TÃ¼rkÃ§e notlar aldÄ±m, hem kaÄŸÄ±t Ã¼zerinde hem de Jupyter Notebook Ã¼zerinde. BunlarÄ± her hafta Github repoâ€™mda gÃ¼ncelledim. NotlarÄ±n dÃ¼zenlemesini bitirdim. Sizlerle paylaÅŸmak istiyorum. Genel hatlarÄ±â€¦ <a class=\"ps-stream-post-more ps-js-content-excerpt-toggle\" href=\"#\">Read more</a></div><div class=\"ps-js-content-full\" style=\"\">Herkese merhaba, 4 haftayÄ± bitirdik ve son bir sÄ±navÄ±mÄ±z kaldÄ±, herkesi tebrik etmek istiyorum.   Benim bu alana adÄ±m atma sÃ¼recimde faydalandÄ±ÄŸÄ±m kaynaklarÄ± sizlerle paylaÅŸmak istiyorum. Ã–zellikle yeni baÅŸlamÄ±ÅŸsanÄ±z iÅŸinize yarayacÄ±ÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum.  Bence kursu bitirmemiz demek Machine Learning temelimizi Ã§ok daha saÄŸlam hale getirdiÄŸimiz anlamÄ±na geliyor. Neden mi? Bir sÃ¼redir bu alanla ilgileniyorum ve projeler Ã¼zerinde Ã§alÄ±ÅŸÄ±p pratik yapÄ±yorum hatta ÅŸu anda da elimde bir proje var fakat teorik aÃ§Ä±dan sÃ¼rekli eksiklikler hissediyordum ve bu kurstan sonra bu aÃ§Ä±ÄŸÄ±mÄ±n bÃ¼yÃ¼k oranda kapandÄ±ÄŸÄ±nÄ± farkettim. Konulara daha hakimim.  Kurs boyunca her hafta TÃ¼rkÃ§e notlar aldÄ±m, hem kaÄŸÄ±t Ã¼zerinde hem de Jupyter Notebook Ã¼zerinde. BunlarÄ± her hafta Github repoâ€™mda gÃ¼ncelledim. NotlarÄ±n dÃ¼zenlemesini bitirdim. Sizlerle paylaÅŸmak istiyorum. Genel hatlarÄ± ile konularÄ± hatÄ±rlatacak notlar olduklarÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum. Son sÄ±navda iÅŸinize yarayabilir.   Blog tutmak, online notlar almak gerÃ§ekten faydalÄ± oluyor. Kesinlikle tavsiye ederim. BirÃ§ok kiÅŸinin faydalanabilecek olmasÄ± da gÃ¼zel hissettiriyor.  GitHub Repo:  <a class=\"ps-media-link\" href=\"https://github.com/enesoriginal/ML-crash-course-notes\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">https://github.com/enesoriginal/ML-crash-course-notes</a>   Son olarak, bÃ¶yle bir organizasyonu bizlere sunup aynÄ± zamanda sÃ¼reÃ§ boyunca emek veren ve zaman ayÄ±rÄ±p bizlere destek olan baÅŸta <a class=\"ps-tag__link ps-csr\" href=\"https://community.globalaihub.com/community/profile/fuat/\" data-hover-card=\"14\">-> </a> ve <a class=\"ps-tag__link ps-csr\" href=\"https://community.globalaihub.com/community/profile/aslii/\" data-hover-card=\"176\">-> </a> olmak Ã¼zere tÃ¼m mentorlerimize ve arkadaÅŸlarÄ±ma teÅŸekkÃ¼r ediyorum.   Bu bir son deÄŸil, bÃ¼yÃ¼k bir maceranÄ±n ilk adÄ±mÄ±nÄ± atmÄ±ÅŸ bulunuyoruz.  ML kariyerinizde baÅŸarÄ±larâ€¦   BahsettiÄŸim ek kaynaklarÄ± yorum olarak bÄ±rakÄ±yorum.</div></div>",
"comment": [
    "",
    " -> Youtube kanallarÄ±:StatQuest Machine Learning Playlist - Teorik aÃ§Ä±dan Ã§ok faydalÄ± oluyor.https://www.youtube.com/playlist?list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJFSentdex Hem eÄŸlenceli hem Ã¶ÄŸretici bir kanalhttps://www.youtube.com/playlist?list=PLQVvvaa0QuDfKTOs3Keq_kaG2P55YRn5vBu sitelerin Medium BloglarÄ±nÄ± Ã¶neririm:Machine Learning Masteryhttps://machinelearningmastery.com/start-here/Towardsdatascience - Veriler Ã¼zerinde hakimiyeti artÄ±racak bir sÃ¼rÃ¼ makale ve daha fazlasÄ±https://towardsdatascience.com/machine-learning/homeEÄŸitim Ã¶ncesi veriyi gÃ¶rmemiz ve Ã¼zerinde iÅŸlemler yapabilmemiz aÃ§Ä±sÄ±ndan Pandas ve Matplotlib kÃ¼tÃ¼phanelerini bilmek de Ã§ok iÅŸe yarÄ±yor.Deep Learning TÃ¼rkiyeâ€™den Mert Ã‡obanoÄŸlu - Pandas Egzersilerihttps://www.youtube.com/playlist?list=PLk54I7lqQSsaV8SxQDj19JVKfE_cM-SkpMachine Learningwww.youtube.comMachine Learning covers a lot of topics and this can be intimidating. However, there is no reason to fear, this play list will help you trough it all, one st....",
    "->  Ã–ncelikle Enes eline saÄŸlÄ±k. Teorik bilgileri githubta derlemen Ã§ok faydalÄ± oldu ben ve bu alana yeni baÅŸlayanlar iÃ§in. Tekrar teÅŸekkÃ¼r ederim.Bir de https://pybilim.wordpress.com/ ilgilenler iÃ§in tavsiye edebilirim Ã¶zellikle kaynakÃ§a kÄ±smÄ±ndan Ã§ok faydalanÄ±yorum.",
    "PythonBilimpybilim.wordpress.comPython ile bilimsel programlama, sayÄ±sal analiz, simÃ¼lasyon2 weeks ago 2 people like this.Like ReportReply",
    "->   TeÅŸekkÃ¼rler.",
    "->  TeÅŸekkÃ¼rler.",
    " ->  Ellerine saÄŸlÄ±k.",
    "->  TeÅŸekkÃ¼rler Onur Bey..",
    "->  ->  TeÅŸekkÃ¼r ettiÄŸi iÃ§in mi ğŸ™‚.",
    " -> Ellerine saÄŸlÄ±k..",
    " -> Ellerine saÄŸlÄ±k Ã§ok yararlÄ± oldu fakat hafta 3Ã¼n classification konularÄ±nda precision tanÄ±mlaman biraz yanlÄ±ÅŸ olmuÅŸ sanÄ±rÄ±m, unutmadan gÃ¼ncellemeni Ã¶neririm.",
    " ->   -> TanÄ±mÄ±n ikinci cÃ¼mlesinden bahsediyorsan eÄŸer ? evet yanlÄ±ÅŸ yorumlanabilir. Onun yerine \"Ã‡obanÄ±n dÃ¼rÃ¼stlÃ¼ÄŸÃ¼nÃ¼ Ã¶lÃ§Ã¼yoruz\" diyebiliriz. TeÅŸekkÃ¼r ederim..",
    "->  Eline saÄŸlÄ±k Ã§ok gÃ¼zel olmuÅŸ..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Herkese Merhaba!  Son haftanÄ±n quiz soru ve cevaplarÄ±na aÅŸaÄŸÄ±dan ulaÅŸabilirsiniz.  ğŸ‘‰ğŸ‘‰https://community.globalaihub.com/mlcc_week4-qas/  Ä°yi Ã§alÄ±ÅŸmalarâœ¨âœ¨",
"comment": [
    "",
    " ->  Merhaba, Final sorularÄ±nÄ±n cevaplarÄ± var mÄ± acaba? ğŸ™‚ TeÅŸekkÃ¼rler1 week ago Like ReportReply",
    " "
]
},
{
"question_isim": " -> ",
"quest": "Merhaba,   4. hafta quizinin sonuÃ§larÄ±nÄ±n olduÄŸu linki bulamÄ±yorum. PaylaÅŸabilir misiniz? <a class=\"ps-tag__link ps-csr\" href=\"https://community.globalaihub.com/community/profile/aslii/\" data-hover-card=\"176\">-> </a>  TeÅŸekkÃ¼rler",
"comment": [
    "",
    "->  Evet onu birazdan paylaÅŸacaÄŸÄ±m ğŸ˜‰2 weeks ago 3 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Easy to let this grow stale(static model) Will adapt to changes, staleness issues avoided(dynamic model)  Merhabalar. Bu cÃ¼mlelerde anlatÄ±lmak istenen ne ve stale kelimesi hangi anlamda kullanÄ±lmÄ±ÅŸ?",
"comment": [
    "",
    "->  Static modelde elinizdeki sabit bir veriyle Ã¶ÄŸretiyorsunuz. Ã–rneÄŸin 2019 senesi Ä°stanbul ev fiyatlarÄ± veri setinizi kullanÄ±yorsunuz. Bu veriyle eÄŸittiÄŸiniz sistem bir sÃ¼re sonra eskiyecektir(stale). Dynamic model ile ise 2020 verilerini de kullanacaÄŸÄ±nÄ±z iÃ§in, daha doÄŸrusu sÃ¼rekli veriyle besleyeceÄŸiniz iÃ§in; deÄŸiÅŸikliklere uyum saÄŸlayacaktÄ±r.3 weeks ago 1 person likes thisLike ReportReply",
    "->  ->  CevabÄ±nÄ±z iÃ§in teÅŸekkÃ¼rler..",
    " "
]
},
{
"question_isim": " -> ",
"quest": "Herkese merhaba. Keras kullanarak bir model eÄŸitiyorum.Bu eÄŸitimden sonra ben bu eÄŸitilmiÅŸ modeli bir uygulamada kullanmak istiyorum.Yani bu modelde Ã¶ÄŸrendiÄŸim parametrelere gÃ¶re baÅŸka bir programda sadece karar vermek istiyorum.Bunu nasÄ±l yapabilirim? Aramam gereken ÅŸeyler neler yÃ¶nlendirebilirseniz sevinirim.",
"comment": [
    "",
    "->  Merhaba,https://machinelearningmastery.com/save-load-keras-deep-learning-models/ linki size yardÄ±mcÄ± olacaktÄ±r.Ä°yi Ã§alÄ±ÅŸmalar.3 weeks ago 2 people like this.Like ReportReply",
    "-> Keras'ta eÄŸittiÄŸiniz modeli bir dosyaya kaydedin, kullanmak istediÄŸiniz uygulamada bu dosyayÄ± load edip ilgili modele tahmin yaptÄ±rabilirsiniz. Modeli kaydetme ÅŸurada anlatÄ±lÄ±yor: https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model , Prediction yapmak istediÄŸiniz programlama ortamÄ±na gÃ¶re load ve prediction aÅŸamalarÄ± deÄŸiÅŸiklik gÃ¶sterecektir.FAQ - Keras Documentationkeras.iohttps://keras.io/getting-started/faq/#how-can-i-save-a-keras-model3 weeks ago 1 person likes thisLike ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Okul tarafÄ±ndan verilen projeyle uÄŸraÅŸtÄ±ÄŸÄ±m iÃ§in lansman saati tamamen aklÄ±mdan Ã§Ä±kmÄ±ÅŸ. O yÃ¼zden kaÃ§Ä±rdÄ±m ve Ã§ok Ã¼zgÃ¼nÃ¼m. YayÄ±n tekrarÄ±nÄ± bir yere yÃ¼kleyecek misiniz veya iÃ§eriÄŸini Ã¶ÄŸrenebileceÄŸim bir yazÄ± vs olacak mÄ± acaba? <a class=\"ps-tag__link ps-csr\" href=\"https://community.globalaihub.com/community/profile/fuat/\" data-hover-card=\"14\">-> </a> <a class=\"ps-tag__link ps-csr\" href=\"https://community.globalaihub.com/community/profile/aslii/\" data-hover-card=\"176\">-> </a> ",
"comment": [
    "",
    " "
]
},
{
"question_isim": "-> ",
"quest": "ML modelimizdeki bias sadece modelimizi beslediÄŸimiz veriden mi kaynaklanÄ±r? Modelimiz kendiliÄŸinden bir Ã¶nyargÄ± geliÅŸtirebilir mi?",
"comment": [
    "",
    " ->  Merhaba, sanÄ±rÄ±m bÃ¶yle bir durum sÃ¶z konusu. Linkini ekelediÄŸim videoda 1:28den itibaren bahsettiÄŸi latent bias buna Ã¶rnek olabilir. KurduÄŸumuz algoritamalar bazen cinsiyet, Ä±rk ya da herhangi bir baÅŸka Ã¶zellikle yanlÄ±ÅŸ baÄŸlantÄ±lar kurabiliyor. Hatam ya da eksiÄŸim varsa dÃ¼zeltirseniz sevinirim. Kolay gelsin. https://youtu.be/59bMh59JQDoMachine Learning and Human Biasyoutu.beAs researchers and engineers, our goal is to make machine learning technology work for everyone.3 weeks ago 6 people like this.Like ReportReply",
    "->   ->  video sÃ¼per teÅŸekkÃ¼ler. yine de bizim modele vermiÅŸ olduÄŸumuz veri ile alakalÄ±. bence model kendi kendine bir bias oluÅŸturmuyor, eÄŸer bir Ã§ocuÄŸa sÃ¼rekli erkek fizikÃ§i resimlerini gÃ¶sterirsek, Ã§ocuk, kadÄ±n fizikÃ§i olamayacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nebilir, onun gibi bir ÅŸey. aslÄ±nda Ã§ok ilginÃ§ ve derin bir konu yapay zekanÄ±n etiksel boyutu. kÃ¼Ã§Ã¼k bir hikaye duymuÅŸtum bu konularla ilgili;bir araÃ§ sigortasÄ± ÅŸirketi yapay zeka kullandÄ±ÄŸÄ±nda kadÄ±n sÃ¼rÃ¼cÃ¼lere aylÄ±k olarak daha fazla Ã¼cret Ã§Ä±kartÄ±yormuÅŸ. kadÄ±nlarÄ±n kaza oranÄ± daha yÃ¼ksek olduÄŸu iÃ§in (en azÄ±ndan verilen veride Ã¶yle). ama iyi araÃ§ kullanan kadÄ±nlar haksÄ±z yere fazla para Ã¶demiÅŸ oluyor. ama olayÄ±n doÄŸruluk kÄ±smÄ± da var. milyonlarca gÃ¶zlem tesadÃ¼f olamaz, kadÄ±nlar % olarak daha Ã§ok kaza yapÄ±yormuÅŸ. bilmiyorum Ã¼zerine Ã§ok dÃ¼ÅŸÃ¼nÃ¼lmesi gereken ÅŸeyler ğŸ™‚3 weeks ago 2 people like this.Like ReportReply",
    " ->  ->  Evet haklÄ±sÄ±n, bir Ã§ocuÄŸa fizikÃ§iler data setinden random bir ÅŸekilde fizikÃ§i resimleri gÃ¶stersek halihazÄ±rda erkek fizikÃ§i yÃ¼zdesi daha fazla olduÄŸu iÃ§in ona karÅŸÄ± bir bias geliÅŸtirebilir. Yani gÃ¼nÃ¼mÃ¼zdeki mevcut durumda Ã§ocuÄŸun bias geliÅŸtirmemesi iÃ§in data setini manipÃ¼le etmemiz(yani kadÄ±n fizikÃ§ileri daha gÃ¶rÃ¼nÃ¼r yapmamÄ±z) gerekebilir. Bu anolojinin makine Ã¶ÄŸrenmesindeki karÅŸÄ±lÄ±ÄŸÄ± ne olur ya da saÄŸlÄ±klÄ± bir anoloji olur mu emin deÄŸilim. GerÃ§ekten ucu aÃ§Ä±k bir konu3 weeks ago 1 person likes thisLike ReportReply",
    "->   ->  ->  Bunu da izlemenizi tavsiye ederimhttps://www.youtube.com/watch?v=jEcDzHYonLU&tLecture 4.3 Discrimination / Bias - [AI For Everyone | Andrew Ng]www.youtube.comAI For Everyone lectures by Andrew Ng and our own Learning Notes. playlist https://www.youtube.com/playlist?list=PLuyk1nLMhRm5aV6_eeUIuj_MKEekvwGDR3 weeks ago 3 people like this.Like ReportReply",
    " ->  ->  teÅŸekkÃ¼rler3 weeks ago Like ReportReply",
    "->   ->  TeÅŸekkÃ¼r ederim.",
    " "
]
},
{
"question_isim": " -> ",
"quest": "Merhaba, 9. soruyu anlayamadÄ±m yardÄ±mcÄ± olabilir misiniz acaba? AÄŸÄ±rlÄ±klarÄ± input'tan baÅŸlayarak ileriye veya output'tan baÅŸlayarak geriye doÄŸru gÃ¼ncelleyerek ilerleyebiliriz tamam fakat niye bu 3 boyutlu olmalÄ±, regresyon olduÄŸu iÃ§in mi? Bu bir sÄ±nÄ±flandÄ±rma problemi olsa 2 boyut yeterli olur muydu? Sadece feed forward veya sadece back propagation kullanÄ±lmasÄ± gereken durumlar var mÄ±? Ã‡ok teÅŸekkÃ¼rler ÅŸimdiden.",
"comment": [
    "",
    "->  Merhaba,Burada 3 boyutlu bir embedding'imiz var. Her boyut ayrÄ± bir nÃ¶ronu iÅŸaret eder. (Ã–rneÄŸin film verisetimizi daha dÃ¼ÅŸÃ¼k boyutlu bir dÃ¼zleme indirgemek istediÄŸimizde ve film tÃ¼rÃ¼nÃ¼ bir boyut olarak dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼mÃ¼zde bu aslÄ±nda bir nÃ¶ron olur ve ayrÄ± hesaplama gerektirir. 4 boyutlu dÃ¼zleme indirirsek 4 nÃ¶ron olur.)Feed Forward modelimizin eÄŸitilme ÅŸeklidir ve feed forward ile modelimizi eÄŸitebilirsiniz. Ancak bu nural networkte eÄŸittiÄŸiniz modelin costunu minimize etmek isterseniz (-ki muhtemelen isteyeceksinz) gradient descent yÃ¶ntemine baÅŸvurmalÄ±sÄ±nÄ±z. Burada da iÅŸin iÃ§ine back propagation giriyor Ã§Ã¼nkÃ¼ back propagation ile her nÃ¶ronun weight'ini tekrar ayarlayabiliyorsunuz. (Ã‡Ã¼nkÃ¼ neural networkte layerlar arasÄ±nda geri gidebiliyorsunuz)HatalÄ± olduÄŸum yer varsa dÃ¼zeltilmesinden memnun olurum.Ä°yi Ã§alÄ±ÅŸmalar.3 weeks ago 2 people like this.Like ReportReply",
    " ->  Ã‡ok teÅŸekkÃ¼rler3 weeks ago Like ReportReply",
    " "
]
},
{
"question_isim": " -> ",
"quest": "Merhabalar,herkese Ã§ok teÅŸekkÃ¼rler. BÃ¶yle soru -cevap platformuna hep ihtiyacÄ±mÄ±zÄ±n olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yorum. Yani kendi adÄ±ma sÃ¶yleyecek olursam benim ihtiyacÄ±m var Ã§oÄŸu ÅŸeyin mantÄ±ÄŸÄ±nÄ± buradaki soru cevaplardan kavradÄ±m ve cevaplara eÅŸ zamanlÄ± ulaÅŸmak gerÃ§ekten Ã§ok gÃ¼zeldi. Bu platform gibi soru-cevap platformu aÃ§mayÄ± dÃ¼ÅŸÃ¼nÃ¼yor musunuz? Herkesin eline emeÄŸine saÄŸlÄ±k baÄŸlandÄ±ÄŸÄ±m benimsediÄŸim bir kurs oldu teÅŸekkÃ¼rler :).",
"comment": [
    "",
    "->  Merhaba TuÄŸba, Turkish AI Hub iÃ§erisinde tÃ¼m sorularÄ±nÄ± TÃ¼rkÃ§e olarak dilediÄŸin zaman paylaÅŸabilirsin ğŸ˜‰3 weeks ago 5 people like this.Like ReportReply",
    " ->  ->  TeÅŸekkÃ¼r ederim iyi ki varsÄ±nÄ±z ğŸ™‚3 weeks ago 1 person likes thisLike ReportReply",
    "->  ->  Program tamamen sonlandÄ±ktan sonra \"Machine Learning Crash Course\" bÃ¶lÃ¼mÃ¼ne de girme fÄ±rsatÄ±mÄ±z olacak mÄ±? Girebilirsek faydalÄ± olur Ã§Ã¼nkÃ¼ burada gÃ¼zel bir geÃ§miÅŸ var.3 weeks ago Like ReportReply",
    "->  ->  Merhaba, tabii bu hub hep aÃ§Ä±k kalacak sadece 15 MayÄ±s'tan sonra soru sorabilme durumunu kapatÄ±yoruz. SorularÄ±nÄ±zÄ± Turkish AI Hub iÃ§inden sorabilirsiniz bu tarihten sonra ğŸ™‚3 weeks ago 2 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba,  Hafta 4 - Soru #8 ile ilgili olarak,  \"Classifying people as eligible for a credit (positive) or not (negative)\" ÅŸÄ±kkÄ± iÃ§in de precision'a odaklanmamÄ±z gerekmez mi?  Modelin, bir kiÅŸinin kredi verilmeye uygun olup olmadÄ±ÄŸÄ±nÄ± tespit iÃ§in bankalar tarafÄ±ndan kullanÄ±ldÄ±ÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nelim. Model iki tÃ¼rlÃ¼ yanÄ±labilir;  1 - GerÃ§ekte krediye uygun olmayan birini \"krediye uygundur\" olarak etiketleyebilir (false positive) 2 - GerÃ§ekte krediye uygun olan birini \"krediye uygun deÄŸil\" olarak etiketleyebilir (false negative)   Banka burada herhalde 1 no'lu hata tipinden (false positive) kaÃ§Ä±nmak isteyecektir zira bu hata diÄŸerine nazaran daha maliyetli. Kredinin geri Ã¶demesini yapamayacak birine kredi verildi.  False positive'lerin sayÄ±sÄ±nÄ± azaltmak da precision'Ä± artÄ±racaÄŸÄ± iÃ§in, ilgili ÅŸÄ±kkÄ±n daâ€¦ <a class=\"ps-stream-post-more ps-js-content-excerpt-toggle\" href=\"#\">Read more</a></div><div class=\"ps-js-content-full\" style=\"\">Merhaba,  Hafta 4 - Soru #8 ile ilgili olarak,  \"Classifying people as eligible for a credit (positive) or not (negative)\" ÅŸÄ±kkÄ± iÃ§in de precision'a odaklanmamÄ±z gerekmez mi?  Modelin, bir kiÅŸinin kredi verilmeye uygun olup olmadÄ±ÄŸÄ±nÄ± tespit iÃ§in bankalar tarafÄ±ndan kullanÄ±ldÄ±ÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nelim. Model iki tÃ¼rlÃ¼ yanÄ±labilir;  1 - GerÃ§ekte krediye uygun olmayan birini \"krediye uygundur\" olarak etiketleyebilir (false positive) 2 - GerÃ§ekte krediye uygun olan birini \"krediye uygun deÄŸil\" olarak etiketleyebilir (false negative)   Banka burada herhalde 1 no'lu hata tipinden (false positive) kaÃ§Ä±nmak isteyecektir zira bu hata diÄŸerine nazaran daha maliyetli. Kredinin geri Ã¶demesini yapamayacak birine kredi verildi.  False positive'lerin sayÄ±sÄ±nÄ± azaltmak da precision'Ä± artÄ±racaÄŸÄ± iÃ§in, ilgili ÅŸÄ±kkÄ±n da doÄŸru cevap olmasÄ± gerektiÄŸini dÃ¼ÅŸÃ¼nÃ¼yorum.</div></div>",
"comment": [
    "",
    " ->  Ben de size katÄ±lÄ±yorum. Sistemin eligible olmayan birini eligible olarak tahmin etmesi bankaya zorluk Ã§Ä±karabilir. Yani false positive sayÄ±sÄ±nÄ±n azaltÄ±lmasÄ± gerekiyor.3 weeks ago Like ReportReply",
    " -> Ben de bÃ¶yle dÃ¼ÅŸÃ¼nÃ¼yorum. Mail olayÄ±nÄ±n precisiona Ã¶nem verdiÄŸini bilmeme raÄŸmen sÄ±rf kredi durumunun daha elzem olduÄŸunu dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼m iÃ§in kredi ÅŸÄ±kkÄ±nÄ± seÃ§tim.3 weeks ago Like ReportReply",
    "->  Ben de sizin gibi kararsÄ±z kalarak yanlÄ±ÅŸ yaptÄ±m. Hala da kararsÄ±zÄ±m bu konuda ama en son ÅŸu sonuca vardÄ±m kendimce ğŸ™‚ AslÄ±nda kredi verme kararÄ±nda banka iÃ§in FP i azaltmak daha Ã¶nemli ancak kredi alabilecek olumlu mÃ¼ÅŸteriye kredi verilmemesi de kaynaklarÄ±n verimsiz kullanÄ±lmasÄ±na yol aÃ§ar aslÄ±nda. O nedenle FN i de azaltmak Ã¶nemli aslÄ±nda. Bu nedenle F1 skoruna bakmak daha doÄŸru olacak sanÄ±rÄ±m. Ek olarak gerÃ§ek hayatta ise bu probleme iliÅŸkin mÃ¼ÅŸterilerin kredi batma olasÄ±lÄ±ÄŸÄ± hesaplanÄ±rken logistic regresyon ile modellenip accuracy ratio ve roc curve e bakÄ±ldÄ±ÄŸÄ± uygulamalar biliyorum.3 weeks ago 1 person likes thisLike ReportReply",
    " ->  AynÄ± mantÄ±k ile dÃ¼ÅŸÃ¼nerek bende aynÄ± ÅŸÄ±kkÄ± iÅŸaretledim. DiÄŸerlerinde recall daha Ã¶nemli bir durumdayken kredi iÃ§in precision bence daha Ã¶nemli konumda Ã§Ã¼nkÃ¼ hatalÄ± kredi verme lÃ¼ksÃ¼ yok.3 weeks ago 1 person likes thisLike ReportReply",
    "->  Bana da Ã¶yle geldi, Precision: positive tanÄ±mlamalarÄ±n ne kadarÄ±nÄ±n doÄŸru olduÄŸuyla ilgileniyor. Bu durumda credit (positive) , bunun dÄ±ÅŸÄ±nda kalan kÄ±sÄ±m negative ile bilgi vermez mi diye dÃ¼ÅŸÃ¼nmedim deÄŸil ğŸ™‚3 weeks ago Like ReportReply",
    "->  Bence sadece fp deÄŸil fn lere de bakÄ±lmasÄ± gerekildiÄŸi iÃ§in ben o ÅŸÄ±kkÄ± iÅŸaretlemedim. Ne de olsa krediye uygun olan birine kredi vermemekte sÄ±kÄ±ntÄ± Ã§Ä±karabilir.3 weeks ago Like ReportReply",
    "-> ->  Zaten mesele iki hata tÃ¼rÃ¼ arasÄ±nda seÃ§im yapmakta, krediye uygun olmayan birine onay vermek mi, krediye uygun olan birine red vermek mi ? Hangisi daha maliyetli?3 weeks ago Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba, Kurs iÃ§eriklerine son eriÅŸim tarihi hakkÄ±nda bilgi verebilir misiniz?  10 MayÄ±s'a kadar genel tekrar yapmayÄ± planlÄ±yorum.",
"comment": [
    "",
    "->  Merhaba, kurs(https://developers.google.com/machine-learning/crash-course) iÃ§eriklerine eriÅŸim iÃ§in bir zaman kÄ±sÄ±tlamasÄ± yok, istediÄŸin zaman eriÅŸebilirsin.3 weeks ago 2 people like this.Like ReportReply",
    "->  TeÅŸekkÃ¼rler3 weeks ago Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "BÃ¶yle bir programÄ± gerÃ§ekleÅŸmesinde emeÄŸi geÃ§en herkese teÅŸekkÃ¼rler. Tek baÅŸÄ±na uÄŸraÅŸmaktansa, burada bir grup ÅŸeklinde uÄŸraÅŸmak daha faydalÄ± oldu. Bazen aklÄ±mÄ±za gelmeyenleri veya yanlÄ±ÅŸ bildiÄŸimiz ÅŸeyleri, mentÃ¶rlerimizin soran arkadaÅŸlara verdiÄŸi cevaplardan Ã¶ÄŸrenebiliyoruz. KeÅŸke bÃ¶yle bir konsept programdan sonra da devam edebilse. Final sÄ±navÄ±nÄ±n iÃ§eriÄŸi ne tÃ¼r olacak? Kodlama iÃ§erecek mi?",
"comment": [
    "",
    "->  Merhaba Enes, test olacak yine, tabii orada kodlama da sormayÄ± planlÄ±yoruz ğŸ˜‰3 weeks ago Like ReportReply",
    " "
]
},
{
"question_isim": " -> ",
"quest": "Herkese merhabalar. OldukÃ§a eÄŸitici ve verimli geÃ§en bu eÄŸitimin belli bir disiplin iÃ§erisinde gerÃ§ekleÅŸmesinde emeÄŸi olan tÃ¼m admin ve mentorlarÄ±mÄ±za teÅŸekkÃ¼r ediyorum. AyrÄ±ca soru soran ve cevap veren her bir arkadaÅŸÄ±mÄ±za da ayrÄ±ca teÅŸekkÃ¼rler; gÃ¶zden kaÃ§masÄ± muhtemel birÃ§ok ÅŸeyi, sorulan sorularda ve onlara verilen yanÄ±tlarda gÃ¶rme fÄ±rsatÄ± bulduk. Herkese, asla bitmeyecek yapay zeka yolculuÄŸunda baÅŸarÄ±lar diliyorum.",
"comment": [
    "",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Ä°yi gÃ¼nler  Machine Learning Crash Course'un 15 mayÄ±sta kapanacaÄŸÄ±nÄ± sÃ¶ylemiÅŸtiniz, peki kursun devamÄ±ndaki data prep, clustering, testing and debugging, GANs.. gibi konular bulunan o kÄ±sÄ±mlarda mÄ± 15 mayÄ±sa kadar aÃ§Ä±k kalacak? Bunun hakkÄ±nda bilgi verebilir misiniz?",
"comment": [
    "",
    "->  Global AI bÃ¼nyesindeki 'Machine Learning Crash Course' tan bahsedilmiÅŸ, (https://developers.google.com/machine-learning/crash-course) tamamÄ±yla Google bÃ¼nyesinde bir kurstur ğŸ™‚3 weeks ago 3 people like this.Like ReportReply",
    "->  AyrÄ±ntÄ±yÄ± kaÃ§Ä±rmÄ±ÅŸÄ±m. teÅŸekkÃ¼r ederim ğŸ™‚3 weeks ago Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba arkadaÅŸlar! Ã–ncelikle sabredip 4 hafta sÃ¼reyle programÄ± takip edip elinden geleni yapan herkesi tek tek tebrik etmek istiyorum. Pandemi sÃ¼recini kendileri adÄ±na avantaja Ã§evirip kendilerine Machine Learning'le ilgili bir ÅŸeyler katan tÃ¼m herkesin Ã¶nÃ¼nde saygÄ±yla eÄŸiliyorum. Bu programÄ± verimli bir ÅŸekilde tamamlayanlar artÄ±k ben \"ML'le ilgiliyim\" gibi altÄ± boÅŸ cÃ¼mleler yerine \"Ben ML'de ÅŸunlarÄ± iyi biliyorum\" diyebilecek.   Machine Learning Crash Course sÄ±navlarÄ±nda baÅŸarÄ± gÃ¶steren arkadaÅŸlarÄ± Deep Learning TÃ¼rkiye'de baÅŸlattÄ±ÄŸÄ±mÄ±z Yapay Zeka Yetenek ProgramÄ±na (AI Talent Programme) davet edeceÄŸiz. Uzun soluklu bir yolculuÄŸa BÄ°ZÄ°MLE BÄ°RLÄ°KTE Ã§Ä±kmak isterseniz bu program size bir Ã§ok fÄ±rsat sunacak.  SOSYAL MEDYADA PAYLAÅIM Programla ilgili duygu ve dÃ¼ÅŸÃ¼ncelerinizi Ã¶zellikle LinkedIn ve Twitter'da Deep Learning TÃ¼rkiye, Turkish AI Hub ve Google Develepors'Ä±â€¦ <a class=\"ps-stream-post-more ps-js-content-excerpt-toggle\" href=\"#\" data-single-act=\"1\">Read more</a></div><div class=\"ps-js-content-full\" style=\"display:none\">Merhaba arkadaÅŸlar! Ã–ncelikle sabredip 4 hafta sÃ¼reyle programÄ± takip edip elinden geleni yapan herkesi tek tek tebrik etmek istiyorum. Pandemi sÃ¼recini kendileri adÄ±na avantaja Ã§evirip kendilerine Machine Learning'le ilgili bir ÅŸeyler katan tÃ¼m herkesin Ã¶nÃ¼nde saygÄ±yla eÄŸiliyorum. Bu programÄ± verimli bir ÅŸekilde tamamlayanlar artÄ±k ben \"ML'le ilgiliyim\" gibi altÄ± boÅŸ cÃ¼mleler yerine \"Ben ML'de ÅŸunlarÄ± iyi biliyorum\" diyebilecek.   Machine Learning Crash Course sÄ±navlarÄ±nda baÅŸarÄ± gÃ¶steren arkadaÅŸlarÄ± Deep Learning TÃ¼rkiye'de baÅŸlattÄ±ÄŸÄ±mÄ±z Yapay Zeka Yetenek ProgramÄ±na (AI Talent Programme) davet edeceÄŸiz. Uzun soluklu bir yolculuÄŸa BÄ°ZÄ°MLE BÄ°RLÄ°KTE Ã§Ä±kmak isterseniz bu program size bir Ã§ok fÄ±rsat sunacak.  SOSYAL MEDYADA PAYLAÅIM Programla ilgili duygu ve dÃ¼ÅŸÃ¼ncelerinizi Ã¶zellikle LinkedIn ve Twitter'da Deep Learning TÃ¼rkiye, Turkish AI Hub ve Google Develepors'Ä± etiketleyerek paylaÅŸmanÄ±Ä±z Ã§ok isterim.   <a class=\"ps-media-link\" href=\"https://twitter.com/deeplearningtr\" rel=\"nofollow\" target=\"_blank\">https://twitter.com/deeplearningtr</a> <a class=\"ps-media-link\" href=\"https://www.linkedin.com/company/deep-learning-turkiye/\" rel=\"nofollow\" target=\"_blank\">https://www.linkedin.com/company/deep-learning-turkiye/</a>  GeleceÄŸin yapay zekÃ¢da olduÄŸuna yÃ¼rekten inanan bir insan olarak kendi geleceÄŸinizi ÅŸekillendirmek adÄ±na gÃ¼zel bir iÅŸ yaptÄ±nÄ±z. Bizimle birlikte olduÄŸunuz iÃ§in teÅŸekkÃ¼r ederiz. Bu program sonlandÄ±ÄŸÄ± iÃ§in 15 MayÄ±s'ta bu hub kapanmÄ±ÅŸ olacak. Bu nedenle alacaÄŸÄ±nÄ±z notlar varsa lÃ¼tfen alÄ±n. Buradaki sorulardan seÃ§tiklerimizi ve derlediklerimizi daha sonra blog yazÄ±sÄ± olarak yayÄ±mlamayÄ± dÃ¼ÅŸÃ¼nÃ¼yoruz.  <a class=\"ps-media-link\" href=\"https://community.globalaihub.com/community/hubs/turkish-ai-hub/\" rel=\"nofollow\" target=\"_blank\">https://community.globalaihub.com/community/hubs/turkish-ai-hub/</a> katÄ±lÄ±m saÄŸlayabilirsiniz. Burada sorularÄ±nÄ±zÄ± sormaya devam edebilirsiniz. AynÄ± ÅŸekilde diÄŸer Hub'lara da katÄ±labilirsiniz. Turkish AI Hub haricinde diÄŸer Hub'larda paylaÅŸÄ±m dili Ä°ngilizcedir.  <a class=\"ps-media-link\" href=\"https://globalaihub.com\" rel=\"nofollow\" target=\"_blank\">globalaihub.com</a> platformunu aktif olarak kullanmaya devam edeceÄŸiz. Global AI Hub, Ä°sviÃ§re merkezli bir yapay zeka topluluÄŸudur.   SaÄŸlÄ±klÄ± gÃ¼nler ve sevgiler,  ->  Google Develeper Expert on Machine Learning Founder of Deep Learning TÃ¼rkiye AI Ambassador at deeplearning.ai Country Managing Director at AI Business School</div></div>",
"comment": [
    "",
    "->  Bize bu fÄ±rsatÄ± sunup kendimizi geliÅŸtirme imkanÄ± verdiÄŸiniz iÃ§in asÄ±l ben teÅŸekkÃ¼r ederim. Bu program ile beraber kafamdan geÃ§en \"bir gÃ¼n yaparÄ±m\" dÃ¼ÅŸÃ¼ncesi yerini \"yapacaÄŸÄ±m ve yapÄ±yorum\"a bÄ±raktÄ±. Programda emeÄŸi geÃ§en herkese, mentorlarÄ±mÄ±za, kurs arkadaÅŸlarÄ±ma Ã§ok teÅŸekkÃ¼r ediyorum. Umuyorum ki kurs arkadaÅŸlarÄ±mla ileride bu alanda daha da ilerlemiÅŸ bir ÅŸekilde tekrar farklÄ± yerlerde gÃ¶rÃ¼ÅŸÃ¼rÃ¼z. Ve tekrar umuyorum ki bu uzun yola Global AI Hub ile Ã§Ä±kabilirim ğŸ™‚ Herkese sÄ±navlarÄ±nda baÅŸarÄ±lar, iyi Ã§alÄ±ÅŸmalar ve bol huzurlu bir pazar gÃ¼nÃ¼ diliyorum ğŸ™‚3 weeks ago 12 people like this.Like ReportReply",
    "->  Merhaba, her ÅŸey iÃ§in teÅŸekkÃ¼rler, bilim-yazÄ±lÄ±m alanlarÄ±nda devam etmek istediÄŸim iÃ§in bu konulara yÃ¶neldim ve iyi ki bÃ¶yle bir programa katÄ±lmÄ±ÅŸÄ±m, umarÄ±m bu yolculuÄŸa birlikte Ã§Ä±kabiliriz, iyi gÃ¼nler dilerim... ğŸ™‚3 weeks ago 3 people like this.Like ReportReply",
    "-> Ã–ncelikle bilin ki, BÄ°ZE Ã‡OK ÅEY KATTINIZ! Åunuda sÃ¶ylemek istiyorum yapay zeka yetenek programÄ± iÃ§in elimizden geleni yapacaÄŸÄ±m sizinle kendimi geliÅŸtirme hÄ±zÄ±m iki kat daha arttÄ± diyebilirim. DiÄŸer arkadaÅŸlarda benimle aynÄ± gÃ¶rÃ¼ÅŸtedir sanÄ±yorum ama yinede kendi adÄ±ma konuÅŸmak gerekirse seÃ§ilemesek bile bu yolda desteklerinize her zaman ihtiyacÄ±mÄ±z olacaktÄ±r. Bu yolda ilerlemeyi Ã§ok istiyorumğŸ¤— kendimi daha ileride gÃ¶rmek istiyorum. TeÅŸekkÃ¼r ederim herÅŸey iÃ§in! Ä°yi ki varsÄ±nÄ±z.3 weeks ago 3 people like this.Like ReportReply",
    "->  Ã‡ok verimli bir 4 hafta geÃ§irdiÄŸimizi dÃ¼ÅŸÃ¼nÃ¼yorum. Bize bu imkanÄ± sunan herkese ve sorduÄŸumuz sorularÄ± cevaplayan mentÃ¶r ve katÄ±lÄ±mcÄ± arkadaÅŸlara Ã§ok ederim. UmarÄ±m farklÄ± etkinliklerde tekrar gÃ¶rÃ¼ÅŸebiliriz.3 weeks ago 3 people like this.Like ReportReply",
    "-> ertelemeyi bir kenara bÄ±rakarak icraata geÃ§memde yardÄ±mcÄ± olduÄŸunuz iÃ§in ne kadar teÅŸekkÃ¼r etsem az. hem siz mentorlerimize hem de siz deÄŸerli menteelere teÅŸekkÃ¼r ederim. bu hubda sorulan sorular ve altÄ±na verdiÄŸiniz cevaplarÄ±n bana Ã§ok faydasÄ± dokundu. umarÄ±m yollarÄ±mÄ±z ilerde tekrardan kesiÅŸir. kendinize Ã§ok iyi bakÄ±n. saÄŸlÄ±cakla kalÄ±n. ğŸ™‚3 weeks ago 3 people like this.Like ReportReply",
    " ->  Ã–ncellikle verdiÄŸiniz desteklerden dolayÄ± Ã§ok teÅŸekkÃ¼r ederim. Bu alanda atÄ±labilecek kendi adÄ±ma en bÃ¼yÃ¼k adÄ±mÄ± attÄ±ÄŸÄ±mÄ± dÃ¼ÅŸÃ¼nÃ¼yorum sizlerin sayesinde. Bu adÄ±mÄ±n en bÃ¼yÃ¼k temellerini sizlerle attÄ±ÄŸÄ±m iÃ§in de ayrÄ± mutluyum. Bu platformda sorduÄŸumuz sorulara cevap veren herkese de ayrÄ±ca teÅŸekkÃ¼rlerimi iletmek istiyorum. Emek veren mÃ¼cadele eden herekese Ã§alÄ±ÅŸmalarÄ±nda baÅŸarÄ±lar dilerim ğŸ™‚3 weeks ago Like ReportReply",
    " ->  Ã–ncelikle bÃ¶yle bir programÄ± baÅŸlattÄ±ÄŸÄ±nÄ±z iÃ§in size ne kadar teÅŸekkÃ¼r etsek az. Bu zorlu sÃ¼reÃ§lerde kendimizi geliÅŸtirmek adÄ±na bu kurs ve program bize Ã§ok yardÄ±mcÄ± oldu. DÃ¼zenli ve sistemli bir Ã§alÄ±ÅŸma, 4 haftada, Ã¼cret vermeden bir kursu bitirmemizi saÄŸladÄ±,. ML dÃ¼nyasÄ± hakkÄ±nda bir ÅŸeyler bilmek gurur verici. Hepinize teÅŸekkÃ¼r ederim.3 weeks ago 1 person likes thisLike ReportReply",
    "->  Kesinlikle Ã§ok faydalÄ± ve yararlÄ± bir program oldu. EmeÄŸi geÃ§en herkese gÃ¶nÃ¼lden teÅŸekkÃ¼r ederim.3 weeks ago Like ReportReply",
    "-> Bu kaliteli eÄŸitimi almamÄ±za fÄ±rsat tanÄ±yan tÃ¼m iÅŸbirliklere ve hubda gÃ¶zden kaÃ§an kÃ¼Ã§Ã¼k trickler hakkÄ±nda sorular soran ve bunlarÄ± tÃ¼m Ã¶zverisiyle cevaplayan tÃ¼m arkadaÅŸlara teÅŸekkÃ¼r ederim.Bu fÄ±rsatÄ± elde ettiÄŸim iÃ§in kendimi Ã§ok ÅŸanslÄ± hissediyorum ,umarÄ±m burdaki arkadaÅŸlarla ileride yapay zeka ile ilgili alanlarda Ã§alÄ±ÅŸma fÄ±rsatÄ± buluruz bu alanda Ã§alÄ±ÅŸmak isteyen biri olarak bir sonraki deep learning yapay zeka etkinlik programÄ±na seÃ§ilmeyi Ã§ok isterim tekrar her ÅŸey iÃ§in teÅŸekkÃ¼rlerHappy codes .3 weeks ago Like ReportReply",
    "-> Program kesinlikle Ã§ok faydalÄ± oldu. Ertelemeye, bahane bulmaya fÄ±rsat bÄ±rakmadan belli bir dÃ¼zen iÃ§inde, yardÄ±mlarla beraber kursa baÅŸlayÄ±p bitirmek iÃ§in Ã§ok gÃ¼zel bir fÄ±rsattÄ±. Planlayan, emek sarf eden herkese Ã§ok teÅŸekkÃ¼rler.3 weeks ago 1 person likes thisLike ReportReply",
    "->  Bilmiyorum benim kadar 0 dan bu kursa baÅŸlayan oldu mu? SayÄ±salcÄ± deÄŸilim, Ä°ngilizcem kÃ¶tÃ¼ Matematik gÃ¶rmeyeli 5 yÄ±l oldu. En sevmediÄŸim laftÄ± eskiden ama kursta zannediyorum herkes ÅŸunu fark etti; GerÃ§ekten Ã§alÄ±ÅŸÄ±nca oluyor. Ben bu bir ayda birÃ§ok ÅŸeyi aynÄ± anda Ã¶ÄŸrenmeye Ã§alÄ±ÅŸtÄ±m. Ä°ngilizce kursu aldÄ±m, bir yandan gradyan iniÅŸine tosladÄ±m, bu nedir dedim gittim tÃ¼reve baktÄ±m, tÃ¼revi anlamak iÃ§in limit Ã¶ÄŸrenmem gerekti, chain rule, matrisler vektÃ¶rler tensÃ¶rler derken 24 saat yetmez oldu. 1 ay da tabi ki yetmedi her ÅŸeyi Ã¶ÄŸrenmek iÃ§in, ancak insanÄ±n bÃ¶yle bir ortamÄ± olmasÄ± olmazlarÄ± oldurur. Hepinize teÅŸekkÃ¼rler...3 weeks ago 4 people like this.Like ReportReply",
    " -> Makine Ã¶ÄŸrenmesi temellerini Ã¶ÄŸrenmek iÃ§in verimli bir program oldu. EmeÄŸi geÃ§en herkese Ã§ok teÅŸekkÃ¼r ederim, iyi Ã§alÄ±ÅŸmalar dilerim ğŸ™‚3 weeks ago Like ReportReply",
    "->  Bu sÃ¼reÃ§te gÃ¼zel ve verimli 4 hafta geÃ§irdim. Bu alanÄ±n temelini atmak iÃ§in Ã§ok gÃ¼zel bir fÄ±rsattÄ± benim iÃ§in. UmarÄ±m ilerleyen zamanlarda yapay zeka dÃ¼nyasÄ±nda yollarÄ±mÄ±z kesiÅŸir. Bu programda emeÄŸi geÃ§en herkese teÅŸekkÃ¼r ederim..3 weeks ago Like ReportReply",
    "-> Size ve sorulan sorulara yorumlarÄ±nÄ± eksik etmeyen arkadaÅŸlara Ã§ok teÅŸekkÃ¼rler. Teorik bilgilerimi tazeledim ve eksiklerimi gÃ¶rmÃ¼ÅŸ oldum. Herkese iyi Ã§alÄ±ÅŸmalar.3 weeks ago 1 person likes thisLike ReportReply",
    " ->  Machine Learning mantÄ±ÄŸÄ±nÄ± kavramak iÃ§in Ã§ok gÃ¼zel bir baÅŸlangÄ±Ã§ oldu,bÃ¶yle sorularÄ±n sorulup cevaplanmasÄ± takip etmemiz de harikaydÄ± bunun devam etmesini Ã§ok isterim bÃ¶yle bir soru platformunun, her ÅŸey iÃ§in teÅŸekkÃ¼rler. Herkese de teÅŸekkÃ¼rler ,aklÄ±mda olan sorularla ve cevaplarÄ±yla karÅŸÄ±laÅŸtÄ±m, sÄ±navlarda Ã§eliÅŸtiÄŸim sorularda mantÄ±ÄŸa dayalÄ± cevaplarÄ±nÄ± gÃ¶rdÃ¼m,herkesin emeÄŸinin olmasÄ± Ã§ok gÃ¼zeldi.3 weeks ago 1 person likes thisLike ReportReply",
    "->  FaydalÄ± ve keyifli bir program oldu. SorularÄ±mÄ±zÄ± cevaplayan alanÄ±nda yetkin kiÅŸilerin olmasÄ±nÄ±n Ã§ok yardÄ±mÄ± oldu. EmeÄŸi geÃ§en herkese teÅŸekkÃ¼rler.3 weeks ago Like ReportReply",
    "->  Tam da bahsettiÄŸiniz gibi bugÃ¼ne kadar lafta kalanlar artÄ±k somut ÅŸeylere dÃ¶nÃ¼ÅŸtÃ¼. EmeÄŸi geÃ§en herkese teÅŸekkÃ¼rler.3 weeks ago Like ReportReply",
    "->  Ben hala son ara sÄ±navÄ± kÄ±yÄ±p Ã§Ã¶zemiyorum normalde bu saate asla kalmazdÄ±m. Åimdilik sadece teÅŸekkÃ¼r edebilirim emeÄŸiniz, Ã¶zveriniz iÃ§in. Ä°leride yollarÄ±mÄ±z kesiÅŸecektir. Her birinizi tanÄ±dÄ±ÄŸÄ±m iÃ§in mutluyum. Hepimize yol aÃ§Ä±klÄ±ÄŸÄ± diliyorum.3 weeks ago Like ReportReply",
    "->  Soru soran, cevaplayan arkadaÅŸlara, mentorlere kÄ±saca emeÄŸi geÃ§en herkese teÅŸekkÃ¼r ederim, teorik olarak Ã§ok verimli geÃ§tiÄŸini sÃ¶yleyebilirim. Herkese iyi Ã§alÄ±ÅŸmalar.3 weeks ago Like ReportReply",
    "->  TÃ¼m tanÄ±dÄ±klarÄ±m bu sÃ¼reci dizi-film izleyip oyun oynayarak geÃ§irirken kendime birÅŸeyler katmak istediÄŸim anda karÅŸÄ±ma Ã§Ä±ktÄ± bu program. BirÅŸeyler baÅŸarÄ±yor olmanÄ±n hazzÄ± var ÅŸuan Ã¼zerimde. EmeÄŸi geÃ§en herkese Ã§ok teÅŸekkÃ¼rler, ufkumu aÃ§tÄ±nÄ±z vizyonumu geliÅŸtirdiniz.3 weeks ago Like ReportReply",
    "->  MentÃ¶rlÃ¼k programÄ± sayesinde Ã§ok verimli ve dÃ¼zenli 4 hafta geÃ§irdim. KonularÄ±n haftalara daÄŸÄ±lÄ±mÄ±ndan , quizlerde yer alan sorulara kadar her ÅŸeyin gÃ¼zel ayarlandÄ±ÄŸÄ± bu program iÃ§in emeÄŸi geÃ§en herkese teÅŸekkÃ¼r etmek istiyorum. AyrÄ±ca soru & cevap kÄ±sÄ±mlarÄ± da Ã§ok Ã§ok faydalÄ± idi. Cevap veren tÃ¼m mentÃ¶rlere ve arkadaÅŸlara Ã§ok teÅŸekkÃ¼r ederim. Bu programÄ±n bir parÃ§asÄ± olarak bu sÃ¼reci kendim iÃ§in en yararlÄ± ÅŸekilde geÃ§irdiÄŸimi dÃ¼ÅŸÃ¼nÃ¼yorum. Herkese baÅŸarÄ±lar ve iyi Ã§alÄ±ÅŸmalar diliyorum ğŸ™‚3 weeks ago Like ReportReply",
    "->  Quizler ve aÃ§Ä±klamalarÄ± oldukÃ§a faydalÄ±ydÄ±.DÃ¼zenleyen ve emek sarf eden herkese Ã§ok teÅŸekkÃ¼rler.Daha gÃ¼zel gÃ¼nlerde bir araya gelebiliriz umarÄ±m. Herkese iyi Ã§alÄ±ÅŸmalar3 weeks ago Like ReportReply",
    "->  Uzun zamandÄ±r takip ettiÄŸim Deep Learning TÃ¼rkiye Twitter hesabÄ±ndan; haberdar olduÄŸumuz ilk andan bu yana bizim kendimize gÃ¼venimizin kalmadÄ±ÄŸÄ± vakitlerde dahi umut olan, iÅŸlerinin arasÄ±nda bize yer ayÄ±ran ve birbirinden yetenekli insanlarÄ± bir araya getiren koca yÃ¼rekli ekibe Ã§ok teÅŸekkÃ¼r ederim. ğŸ˜Š Bu sene iÃ§inde kendime verdiÄŸim -hub genelindeki herkesin sayesinde- gÃ¼zel bir hediye oldu. Ãœniversite yÄ±llarÄ±mda yarÄ±m kalan yazÄ±lÄ±m macerama karÅŸÄ± tekrardan hevesimi yerine getirdi. Burada gerÃ§ekten baÅŸarÄ±lÄ± arkadaÅŸlarÄ±mÄ±z var. Ve de Ã§aba gÃ¶sterip herkese yetiÅŸmeye Ã§alÄ±ÅŸan arkadaÅŸlarÄ±mÄ±z var. Herkesi yÃ¼rekten kutluyorum. â˜ºï¸ Bence hepimiz baÅŸardÄ±k. Ve herkes bir ay Ã¶ncesine gÃ¶re kendini geliÅŸtirdi. FarkÄ±ndalÄ±k oluÅŸturuldu. Bundan sonraki sÃ¼reÃ§te herkese baÅŸarÄ±lar diliyorum. Her ÅŸey gÃ¶nlÃ¼nÃ¼zce olsun arkadaÅŸlar ğŸ™ğŸ»ğŸ˜ŠğŸ¤—3 weeks ago Like ReportReply",
    "->  EmeÄŸi geÃ§en herkese teÅŸekkÃ¼rler.3 weeks ago Like ReportReply",
    "->  Emegi gecen herkese tesekkurler.Ozellikle sorulari cok yakindan takip ederek verdigi cevaplarla anlayisimizi zenginlestiren ->  e tesekkur ederim.3 weeks ago 3 people like this.Like ReportReply",
    "->  ->  BazÄ± noktalarda hatalarÄ±mÄ± dÃ¼zeltip bildiÄŸim bazÄ± ÅŸeylerin eksik ve yanlÄ±ÅŸ olduÄŸunu farketmemde yardÄ±mcÄ± olduÄŸunuz iÃ§in ben teÅŸekkÃ¼r ederim. YardÄ±mcÄ± olabildiysem ne mutlu bana ğŸ™‚3 weeks ago 2 people like this.Like ReportReply",
    "-> Benim aÃ§Ä±mdan Ã§ok verimli geÃ§ti. Kendim iÃ§in bÃ¼yÃ¼k bir adÄ±m atmÄ±ÅŸ oldum. MentÃ¶rlere ve emeÄŸi geÃ§en tÃ¼m arkadaÅŸlara teÅŸekkÃ¼rler.3 weeks ago Like ReportReply",
    "->  ML, nereden baÅŸlayacaÄŸÄ±mÄ±, nasÄ±l ilerleyeceÄŸimi bilmediÄŸim ve Ã¼zerinde Ã§alÄ±ÅŸmak istediÄŸim bir alandÄ± ama biraz korkuyordum. Åimdi ise saÄŸlam bir temel attÄ±ÄŸÄ±mÄ± dÃ¼ÅŸÃ¼nÃ¼yorum. Ã–nÃ¼mde keÅŸfedilmeyi bekleyen kocaman bir ML dÃ¼nyasÄ± var ve bu beni Ã§ok heyecanlandÄ±rÄ±yor. Bize yol gÃ¶sterip destek olan baÅŸta mentorlarÄ±mÄ±z olmak Ã¼zere emeÄŸi geÃ§en bÃ¼tÃ¼n arkadaÅŸlara teÅŸekkÃ¼r ederim. UmarÄ±m bundan sonraki iÅŸlerde de birlikte Ã§alÄ±ÅŸma fÄ±rsatÄ±mÄ±z olur. Herkese saÄŸlÄ±klÄ± ve baÅŸarÄ±lÄ± bir hayat diliyorum. ğŸ˜Š3 weeks ago Like ReportReply",
    " ->  emeÄŸi geÃ§en herkese teÅŸekkÃ¼r ederim. benim iÃ§in verilimli bir sÃ¼reÃ§ti. umarÄ±m devamÄ± gelir.3 weeks ago Like ReportReply",
    "-> EÄŸer boyle bir platform olmasaydÄ± birÃ§ok eÄŸitime ya baÅŸlamaz ya da yarÄ±da birakirdi. AyrÄ±ca sorulan sorular ve verilen cevaplarla birlikte quiz lerin Ã§ok katkÄ±sÄ± oldu Ã¶ÄŸrenme surecine. EmeÄŸiniz ve destekleriniz iÃ§in teÅŸekkÃ¼rler.3 weeks ago Like ReportReply",
    "->  LinkedIn sayesinde denk geldiÄŸim bu program 4 hafta boyunca bana Ã§ok ÅŸey kattÄ±. YapÄ±lan quizler, yanÄ±tlanan sorular her ÅŸey Ã§ok verimliydi. Bu alanda kendimi geliÅŸtirmeme katkÄ±da bulunduÄŸunuz iÃ§in emeÄŸi geÃ§en herkese teÅŸekkÃ¼r ederim.3 weeks ago 1 person likes thisLike ReportReply",
    "->  Kendim araÅŸtÄ±rÄ±rken bazÄ± konularÄ± ertelediÄŸim veya online kurslarda yarÄ±m bÄ±raktÄ±ÄŸÄ±m oluyor ancak bu programda dÃ¼zenli bir ÅŸekilde kursu takip edip notlar aldÄ±m. Bu aÃ§Ä±dan bu gibi programlarÄ± devam ettirmenizi Ã§ok isterim. Kendim soru soramadan bazÄ± arkadaÅŸlarÄ±n aynÄ± ÅŸeyi Ã¶nceden sorduÄŸu ve cevaplandÄ±ÄŸÄ± gÃ¶rdÃ¼ÄŸÃ¼m Ã§ok oldu. Size ve yardÄ±mcÄ± olan arkadaÅŸlara teÅŸekkÃ¼r ederim.3 weeks ago Like ReportReply",
    "-> -> TeÅŸekkÃ¼r ederiz, gÃ¼zel bir Ã§alÄ±ma grubu oldu. ğŸ™‚3 weeks ago Like ReportReply",
    "-> Merhaba bu programÄ± bize sunmanÄ±zla baÅŸlayÄ±p Ã§ok gÃ¼zel geÃ§en bir 4 haftamÄ±z oldu. Ã–ÄŸrendiklerim, bana saÄŸladÄ±ÄŸÄ± katkÄ±lar ve vizyona baktÄ±ÄŸÄ±mda mutluluk duyuyorum, bunu bize hissettirdiÄŸiniz iÃ§in Ã§ok teÅŸekkÃ¼rler. BÃ¶yle bir dÃ¶nemi en verimli ÅŸekilde geÃ§irmemize yardÄ±mcÄ± oldunuz. MentorlarÄ±mÄ±za ve gerek sorularÄ± gerek cevaplarÄ± ile ilerlememize katkÄ± saÄŸlayan tÃ¼m kurs arkadaÅŸlarÄ±ma da ayrÄ±ca teÅŸekkÃ¼r ederim. Bu tarz program ve projelerde yeniden gÃ¶rÃ¼ÅŸmek dileÄŸiyle herkese iyi Ã§alÄ±ÅŸmalar.3 weeks ago Like ReportReply",
    " ->  Ã–ncelikle bu karantina dÃ¶nemini verimli geÃ§irmemizi saÄŸladÄ±ÄŸÄ±nÄ±z ve bize vakit ayÄ±rdÄ±ÄŸÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederim. HerÅŸey Ã§ok gÃ¼zeldi.3 weeks ago Like ReportReply",
    "->  Bu sÃ¼reÃ§te yazÄ±lan bÃ¼tÃ¼n postlarÄ± ve cevaplarÄ± okumaya Ã§alÄ±ÅŸtÄ±m.Anlama ve Ã¶ÄŸrenmemde Ã§ok faydalÄ± oldu. Soru soran arkadaÅŸlara , mentÃ¶rlere ve emeÄŸi geÃ§en herkese teÅŸekkÃ¼r ederim.3 weeks ago Like ReportReply",
    "->  Merhaba, sayenizde Ã§ok verimli bir 4 hafta geÃ§irdik. BirÃ§ok bilgi Ã¶ÄŸrendik. Ã‡ok ÅŸey kattÄ±k kendimize. BÃ¶yle bir program gerÃ§ekleÅŸtirmemizi saÄŸlayan herkese tek tek Ã§ok teÅŸekkÃ¼r ederim. AyrÄ±yetten sorularÄ±mÄ±za cevap veren mentorlerimize de teÅŸekkÃ¼rler. UmarÄ±m ileride daha birÃ§ok bÃ¶yle programlar olur biz de katÄ±lÄ±r ve kendimizi geliÅŸtirmeye devam edebiliriz. Herkese kariyerinde baÅŸarÄ±lar diliyorum3 weeks ago Like ReportReply",
    "-> Benim iÃ§in Ã§ok verimli bir sÃ¼reÃ§ oldu.Gerek eÄŸitim iÃ§eriÄŸi gerekse eÄŸitimle alakalÄ± sorulan sorulara verilen cevaplar benim iÃ§in Ã§ok faydalÄ± oldu. Bundan sonrasÄ± iÃ§inde burada Ã¶ÄŸrendiklerimi temel alarak devam ettirmeyi hedefleiyorum. EmeÄŸi geÃ§en herkese Ã§ok teÅŸekkÃ¼r ederim.3 weeks ago Like ReportReply",
    "->  uzun sÃ¼redir ilgi duyup bir tÃ¼rlÃ¼ baÅŸlayamadÄ±ÄŸÄ±m bu alana ilk adÄ±mÄ±m oldu bu program. tek sÄ±nav yerine arada sÄ±navlarÄ±n olmasÄ± da eksiklerimizi ve hatalarÄ±mÄ±zÄ± gÃ¶rmemizde Ã§ok yardÄ±mcÄ± oldu. merak ettiÄŸim bir Ã§ok konuyu sormama bile gerek kalmadan Ã¶ÄŸrenme fÄ±rsatÄ±m oldu. hepinize Ã§ok teÅŸekkÃ¼r ediyorum. umarÄ±m emeklerinizin karÅŸÄ±lÄ±ÄŸÄ±nÄ± verebiliriz ğŸ™‚3 weeks ago Like ReportReply",
    "-> EÄŸitim boyunca sorularÄ±mÄ±zÄ± detaylÄ± bir ÅŸekilde yanÄ±tlayan ve daha ileri okumalar iÃ§in yÃ¶nlendirme yapan tÃ¼m eÄŸitmen ve katÄ±lÄ±mcÄ±lara teÅŸekkÃ¼rler.Benim iÃ§in kurs kadar burada sorulan sorular ve cevaplarÄ± da Ã¶ÄŸretici oldu.Bu eÄŸitim sayesinde daha dÃ¼zenli bir ÅŸekilde Ã§alÄ±ÅŸmamÄ±za yardÄ±mcÄ± olan dÃ¼zenleyici ekibe ve eÄŸitmenlere ayrÄ±ca teÅŸekkÃ¼r ederim.3 weeks ago Like ReportReply",
    "->  FaydalÄ± bir program oldu. EmeÄŸi geÃ§en herkese teÅŸekkÃ¼r ederim.3 weeks ago Like ReportReply",
    "->  Benim iÃ§in Ã§ok verimli bir kurs oldu. EmeÄŸi geÃ§en herkese Ã§ok teÅŸekkÃ¼rler.3 weeks ago Like ReportReply",
    "->  Ã‡abalarÄ±nÄ±z iÃ§in Ã§ok teÅŸekkÃ¼r ederim. Emeklerinize saÄŸlÄ±k3 weeks ago Like ReportReply",
    "->  eksiklerimizin farkÄ±na vardÄ±k ve var gÃ¼cÃ¼mÃ¼zle Ã§alÄ±ÅŸmaya devam ediyoruz umarÄ±m ilerleyen gruplada da kendimize yer bulabilir ve ML de aktif Ã§alÄ±ÅŸan Ã¼reten insanlar olabiliriz3 weeks ago Like ReportReply",
    "->  Ã¼nlÃ¼ Kendi adÄ±ma Ã§ok faydalÄ± bulduÄŸum bir aylÄ±k sÃ¼reÃ§ oldu. EÄŸitimin, zaman kÄ±sÄ±tlamasÄ± ve insanlarÄ±n birbirlerine yardÄ±mcÄ± olmaya Ã§alÄ±ÅŸmasÄ± gibi yanlarÄ±, gÃ¼nlÃ¼k yaÅŸantÄ±nÄ±n zorluklarÄ± yanÄ±nda bana olumlu faydalarÄ± olan Ã¶zellikleri oldu. EmeÄŸi geÃ§en herkese teÅŸekkÃ¼r ederim.3 weeks ago Like ReportReply",
    "->  Benim iÃ§in Ã§ok verimli geÃ§en bu programÄ± dÃ¼zenleyen muhteÅŸem ekibe, mentor hocalarÄ±ma ve emeÄŸi geÃ§en bÃ¼tÃ¼n arkadaÅŸlarÄ±ma AI yolculuÄŸumdaki destekleriniz iÃ§in teÅŸekkÃ¼r ederim. Ã–zleyeceÄŸim.3 weeks ago Like ReportReply",
    "->  Bu kaliteli eÄŸitimi almamÄ±za fÄ±rsat tanÄ±yan tÃ¼m kiÅŸilere, hubta sorular soran ve bunlarÄ± tÃ¼m Ã¶zverisiyle cevaplayan arkadaÅŸlara teÅŸekkÃ¼r ederim.Bu fÄ±rsatÄ± elde ettiÄŸim iÃ§in kendimi Ã§ok ÅŸanslÄ± hissediyorum.UmarÄ±m buradaki arkadaÅŸlarla ileride yapay zeka ile ilgili alanlarda Ã§alÄ±ÅŸma fÄ±rsatÄ± bulabiliriz. Bu alanda Ã§alÄ±ÅŸmak isteyen biri olarak bir sonraki deep learning yapay zeka etkinlik programÄ±na seÃ§ilmeyi Ã§ok isterim. Emekleriniz iÃ§in tekrar teÅŸekkÃ¼rler ->  ->  ğŸ™‚3 weeks ago 2 people like this.Like ReportReply",
    "->  Bu imkanÄ± bizlere saÄŸladÄ±ÄŸÄ±nÄ±z iÃ§in emeÄŸi geÃ§en herkese Ã§ok teÅŸekkÃ¼rler. Benim aÃ§Ä±mda da her arkadaÅŸlarÄ±mÄ±n bahsettiÄŸi gibi Ã§ok verimli bir kurs serÃ¼veni yaÅŸadÄ±m. Yeni yeni bilgiler Ã¶ÄŸrendim ve bildiklerimi Ã¼stÃ¼ne koyarak yeniden pekiÅŸtirdim. Ã–zellikle aÃ§Ä±k olarak sorulan sorulardan ve her arkadaÅŸÄ±mÄ±n ve mentÃ¶rlerimizin aÃ§Ä±klayÄ±cÄ± cevaplarÄ±yla Ã§ok daha net bir ÅŸekilde aydÄ±nlandÄ±k. Herkesin emekleri iÃ§in Ã§ok teÅŸekkÃ¼rler.3 weeks ago 1 person likes thisLike ReportReply",
    "->  YoÄŸun bi tempoda farklÄ± hoÅŸ bir etkinlik oldu. EmeÄŸi geÃ§en herkese teÅŸekkÃ¼rler.3 weeks ago 1 person likes thisLike ReportReply",
    "->  Bu kurs bende baÄŸÄ±mlÄ±lÄ±k yaptÄ± ğŸ˜€ SÃ¼rekli tabletten, telefondan, laptoptan yeni bildirim geldi mi, hangi sorular sorulmuÅŸ, sorulara nasÄ±l yanÄ±tlar verilmiÅŸ, yeni neler olmuÅŸ diye sÃ¼rekli bildirimleri kontrol eder hale geldim ğŸ™‚ Youtube etkinlikleri, her Pazar sÄ±navlar derken bir ay boyunca haftasonlarÄ± hiÃ§ sÄ±kÄ±lmadan, Ã§ok verimli bir ÅŸekilde geÃ§irdim. YokluÄŸuna alÄ±ÅŸmak biraz zor olacak ğŸ™ EmeÄŸi geÃ§en tÃ¼m arkadaÅŸlara teÅŸekkÃ¼rler, katÄ±lÄ±mcÄ± arkadaÅŸlar da Ã§ok Ã¶zverili ve dinamik, neredeyse kimsenin sorusu yanÄ±tsÄ±z kalmadÄ±, herkesin emeÄŸine saÄŸlÄ±k. Yeni projelerde ve etkinliklerde gÃ¶rÃ¼ÅŸebilmek dileÄŸiyle..3 weeks ago 5 people like this.Like ReportReply",
    "->  Ã–ncelikle bu karantina sÃ¼recini verimli geÃ§irmemizi saÄŸlamak iÃ§in vakit ayÄ±rdÄ±ÄŸÄ±nÄ±zdan dolayÄ± emeÄŸi geÃ§en herkese ayrÄ± ayrÄ± Ã§ok teÅŸekkÃ¼r ederim. Genel bir deÄŸerlendirme yapacak olursam her hafta belli konularÄ±n olmasÄ± ,bu konulara odaklÄ± Ã§alÄ±ÅŸma gerÃ§ekleÅŸtirilmesi, benim aÃ§Ä±mdan insana devamlÄ±lÄ±ÄŸÄ±n ve kontrol altÄ±nda olmanÄ±n zevkini yaÅŸatmakta .Bu konular Ã¼zerinde Ã§alÄ±ÅŸÄ±rken fark etmediÄŸim ama baÅŸka bir kiÅŸinin o konular Ã¼zerinden soru sormasÄ± bana orada bir ÅŸeylerin farkÄ±na varmamÄ± ve dikkatimi o yÃ¶ne yÃ¶neltmemi saÄŸladÄ±. Eksiklerimi bu sayede keÅŸfetmiÅŸ oldum.ğŸ™ğŸ»ğŸ˜ŠGerÃ§ekten verimli bir program oldu. Her ÅŸey gÃ¶nlÃ¼nÃ¼zce olmasÄ± dileÄŸiyle ,Ä°yi Ã‡alÄ±ÅŸmalar3 weeks ago 1 person likes thisLike ReportReply",
    "->  Bu kurs ile beraber teorik olarak Ã§ok saÄŸlam bir temel atmÄ±ÅŸ olduÄŸumu dÃ¼ÅŸÃ¼nÃ¼yorum. MentorlarÄ±mÄ±za ve sorularÄ±mÄ±za cevap veren tÃ¼m arkadaÅŸlara teÅŸekkÃ¼rler. AyrÄ±ca bu kursun organize edilmesinde, sÄ±navlarÄ±n hazÄ±rlanmasÄ±nda emeÄŸi geÃ§en DL TÃ¼rkiye grubuna ayrÄ±ca teÅŸekkÃ¼r ederim. UmarÄ±m yetenek programÄ±nÄ±n bir parÃ§asÄ± olabilir ve bundan sonrasÄ±nda da emin adÄ±mlarla ilerleyebilirim.3 weeks ago 1 person likes thisLike ReportReply",
    "->  Bu kurs sayesinde (Ã¶zellikle mentor destekli olmasÄ±nÄ±n bÃ¼yÃ¼k payÄ± olmakla beraber) aklÄ±mda makine Ã¶ÄŸrenmesinde: Bu nasÄ±l olur, bunun mantÄ±ÄŸÄ± ne, ama neden bÃ¶yle deÄŸil? gibi sorularÄ±mÄ±n bÃ¼yÃ¼k Ã§oÄŸunluÄŸuna hem kurs iÃ§erikleri sayesinde, hem de deÄŸerli mentor hocalarÄ±mÄ±z sayesinde yanÄ±t bulma fÄ±rsatÄ± yakaladÄ±m. Toplu olarak eÄŸitim gÃ¶rmek ve herkesin sorularÄ±nÄ±n aÃ§Ä±k bir ÅŸekilde sorulup diÄŸerlerinin de bundan istifade edebileceÄŸi bÃ¶yle bir grubun kurulmasÄ± dolayÄ±sÄ± ile de Ã§ok ÅŸanslÄ±ydÄ±k, merak ettiÄŸim, aklÄ±ma takÄ±lan bir konuyu baÅŸka bir katÄ±lÄ±mcÄ± sorduÄŸu iÃ§in hÄ±zlÄ± bir ÅŸekilde yanÄ±t alÄ±p kursa odaklanma ÅŸansÄ± yakalamÄ±ÅŸ olduk. BÃ¶yle bir programÄ± dÃ¼zenlediÄŸiniz iÃ§in sizlere tÃ¼m katÄ±lÄ±mcÄ±lar adÄ±na bir kez de ben teÅŸekkÃ¼r etmek istiyorum. BÃ¶yle programlarÄ±nÄ±n devamÄ±nÄ±n gelmesi dileÄŸiyle... Tekrardan emeÄŸi geÃ§en herkese teÅŸekkÃ¼r ediyorum, esenlikle kalÄ±n.3 weeks ago Like ReportReply",
    "->  Makine Ã¶ÄŸrenimi konusunda neredeyse sÄ±fÄ±r bilgi ile baÅŸladÄ±m. Bir kurs ile bu iÅŸ bitmiyor tabi ancak teorik baÅŸlangÄ±cÄ± bu program ile yapmak gerÃ§ekten ÅŸans oldu. ProgramÄ±n hazÄ±rlanmasÄ±nda emeÄŸi geÃ§en herkese, mentorlara, soru soran ve yanÄ±tlayan tÃ¼m katÄ±lÄ±mcÄ±lara teÅŸekkÃ¼r ederim.3 weeks ago Like ReportReply",
    "-> Merhaba, Ã¶ncelikle bir yerden baÅŸlamamÄ±za ve bu yerin yeterince aÃ§Ä±klayÄ±cÄ±, temeli veren bir yer olmasÄ±na vesile olduÄŸunuz iÃ§in teÅŸekkÃ¼r ederim. AyrÄ±ca bu kadar iÅŸin ve okulun arasÄ±nda kursu baÅŸarÄ±yla tamamlayÄ±p konularÄ± Ã¶zÃ¼msediÄŸim iÃ§in de kendimler gurur duyuyorum. Sayenizde, kursu bitiren diÄŸer arkadaÅŸlar gibi ben de artÄ±k gerÃ§ek bir problemi ele alÄ±p Ã§Ã¶zebileceÄŸim zamanÄ±n geldiÄŸini dÃ¼ÅŸÃ¼nÃ¼yorum. Bir yandan real-world problemlerin Ã¼zerine gidip bir yandan da yapay zeka kursuna katÄ±lmayÄ± Ã§ok isterim. Bize bu fÄ±rsatÄ± verdiÄŸiniz iÃ§in teÅŸekkÃ¼rler..",
    "->  EmeÄŸi geÃ§en herkese Ã§ok teÅŸekkÃ¼rler. KafamÄ±za takÄ±lan sorularÄ± anÄ±nda sorabilmek, baÅŸka sorularÄ±n cevaplarÄ±nÄ± gÃ¶rebilmek Ã§ok bÃ¼yÃ¼k bir ÅŸanstÄ±..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Herkese Merhaba!  Son haftanÄ±n ara quiz ine aÅŸaÄŸÄ±daki linkten ulaÅŸabilirsiniz. Her hafta olduÄŸu gibi, yanÄ±tlarÄ± TR saati ile 22:00'ye kadar alÄ±yor olacaÄŸÄ±z.  ğŸ‘‰ğŸ‘‰ <a class=\"ps-media-link\" href=\"https://forms.gle/mpubCyD8Fo8wT8uc6\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">https://forms.gle/mpubCyD8Fo8wT8uc6</a>  BaÅŸarÄ±larğŸ€ğŸŒŸ",
"comment": [
    "",
    "->  SÄ±navÄ± ÅŸimdi tamamladÄ±m, sÄ±navda emeÄŸi geÃ§en herkese teÅŸekkÃ¼r ederim, son haftanÄ±n sÄ±navÄ±nda herkese baÅŸarÄ±lar ğŸ™‚3 weeks ago 3 people like this.Like ReportReply",
    "->  Ben de sÄ±navÄ± tamamladÄ±m. Soru soran ve cevaplayan arkadaÅŸlara, bizimle ilgilenen mentorlarÄ±mÄ±za Ã§ok teÅŸekkÃ¼r ederim. ğŸ˜ŠğŸ™ğŸ» Son iki haftadÄ±r konulara daha Ã§ok hakimim. Herkese baÅŸarÄ±lar diliyorum. ğŸ˜Š3 weeks ago Like ReportReply",
    "->  Ant Bitirdim .BirkaÃ§ soruda sÄ±kÄ±ntÄ±m var . 10 MayÄ±s sÄ±navÄ± hakkÄ±nda bilgilendirme olacak mÄ± ? Kod yazacak mÄ±yÄ±z ? Herkese baÅŸarÄ±lar .3 weeks ago 2 people like this.Like ReportReply",
    "-> Her ÅŸey iÃ§in teÅŸekkÃ¼r ederim, GerÃ§ekten gÃ¼zel sorulardÄ±. Buradan Steve'e seslenmek isterim, beni yakan sensin adamÄ±m ğŸ™‚3 weeks ago Like Reply Edit",
    "->  8. sorunun 2 cevabi olabilir mi?3 weeks ago 5 people like this.Like ReportReply",
    "-> ->  Bu konuda yorum yapmak iÃ§in sonuÃ§larÄ± bekliyorum ğŸ™‚3 weeks ago 1 person likes thisLike ReportReply",
    "-> ->  Bence bir cevabÄ± diÄŸerinden Ã§ok daha bariz ve hayati. Ama ilginÃ§tir ki o cevap yanlÄ±ÅŸ.3 weeks ago Like ReportReply",
    "->  ->  Orada kÃ¼Ã§Ã¼k bir trick var hayati olup olmamasÄ±nÄ± kastetmiyor soruda sÄ±navdan sonra okuyunca farkettim ben de ğŸ™‚3 weeks ago Like ReportReply",
    " ->  Herkese baÅŸarÄ±lar. Kitaptan alÄ±ntÄ± Ã§ok hoÅŸuma gitti :d3 weeks ago Like ReportReply",
    " -> GeÃ§en hafta da olduÄŸu gibi, dikkatli okunmadÄ±ÄŸÄ±nda sorular kaÃ§Ä±yor... Ã‡ok gÃ¼zel hazÄ±rlanmÄ±ÅŸ dikkat gerektiren sorular, teÅŸekkÃ¼r ederim ğŸ™‚3 weeks ago 2 people like this.Like ReportReply",
    "->  herkesin emeÄŸine saÄŸlÄ±k, her ÅŸey iÃ§in Ã§ok teÅŸekkÃ¼rler.3 weeks ago Like ReportReply",
    "->  SÄ±navÄ± tamamlamÄ±ÅŸ durumdayÄ±m; kendim doÄŸrudan soru sormadÄ±m ama sorulan sorularÄ± ve cevaplarÄ±nÄ± sÃ¼rekli takip ettim, emeÄŸi geÃ§en herkese teÅŸekkÃ¼rler ğŸ™‚3 weeks ago 2 people like this.Like ReportReply",
    "->  Merhaba, kursun baÅŸÄ±nda 1 hafta geriden gelinebileceÄŸi yazÄ±yordu. O artÄ±k geÃ§erli deÄŸil mi?3 weeks ago Like ReportReply",
    "->  4. soru sanÄ±rÄ±m bir sosyal psikoloji tezi iÃ§in sÄ±nava yerleÅŸtirilmiÅŸ!Thinking, Fast and Slow'u okuyanlarÄ±n Ã§ok iyi bildiÄŸi gibi bu sorunun (Steveâ€™i gerÃ§ekten tanÄ±madÄ±ÄŸÄ±nÄ±z sÃ¼rece) doÄŸru bir cevabÄ± yok. Sadece â€˜cognitive biasâ€™larÄ±mÄ±z bizi bir ÅŸÄ±kkÄ± seÃ§meye zorluyor. Bu nedenle bu soruyu gÃ¶rÃ¼nce tek dÃ¼ÅŸÃ¼ncem \"heralde birinin tezine yardÄ±m ediyoruz\" oldu.SayÄ±n mentÃ¶rlerimiz, bu sorunun amacÄ± hakkÄ±nda bilgi verebilirseniz sevinirim.3 weeks ago 10 people like this.Like ReportReply",
    "->  ->  Ben de soruyu gÃ¶rÃ¼nce senin gibi dÃ¼ÅŸÃ¼ndÃ¼m ve bÃ¼tÃ¼n ÅŸÄ±klar doÄŸru sayÄ±lÄ±r dedim fakat sorunun bir doÄŸru cevabÄ± varmÄ±ÅŸ. MentorlarÄ±mÄ±zdan soruyla ilgili bir aÃ§Ä±klama Ã§ok gÃ¼zel olur.3 weeks ago Like ReportReply",
    "-> ArtÄ±k tekrar yapÄ±p son sÄ±navÄ±n ardÄ±ndan siz deÄŸerli mentÃ¶rlerle Ã§alÄ±ÅŸma fÄ±rsatÄ± yakalamak ğŸ™‚ herÅŸey iÃ§in teÅŸekkÃ¼rler .3 weeks ago 1 person likes thisLike ReportReply",
    " ->  SÄ±navlarÄ±n ikisinde Ã§ok dÃ¼ÅŸÃ¼k puanlar alsamda kendime Ã§ok deÄŸerli bilgiler kattÄ±ÄŸÄ±mÄ± dÃ¼ÅŸÃ¼nÃ¼yorum. BazÄ± sorularda halen anlamadÄ±ÄŸÄ±m yerler var ancak pratik ile Ã§Ã¶zebileceÄŸimi dÃ¼ÅŸÃ¼nÃ¼yorum ğŸ™‚ TeÅŸekkÃ¼rler herkese..3 weeks ago Like ReportReply",
    "->  Sorular mÄ± yanÄ±ltÄ±cÄ±ydÄ± ben mi anlamadÄ±m pek bilemedim. EmeÄŸi geÃ§enlere teÅŸekkÃ¼rler. ğŸ™‚3 weeks ago Like ReportReply",
    "->  Son haftanÄ±n quizini de tamamlamÄ±ÅŸ bulunuyorum. EmeÄŸi geÃ§en herkese teÅŸekkÃ¼rler. ğŸ™‚3 weeks ago Like ReportReply",
    " ->  Merhabalar, bende tamamladÄ±m ÅŸimdi testi. iki yorum sorusu beni gerÃ§ekten uÄŸraÅŸtÄ±rdÄ± ancak sonucum beni mutlu etti. YoÄŸunluk iÃ§erisinde bu kursu tamamlayabilmek benim iÃ§in bir mucizeydi diyebilirim. Hatta meraktan, kursun devamÄ±ndaki linklere bile baÅŸlayÄ±p yarÄ±ladÄ±m konularÄ±. KÄ±sacasÄ± bu kurs Ã§alÄ±ÅŸmalarÄ±mda yol gÃ¶sterdi diyebilirim. Åimdi ise merak ettiÄŸim ÅŸu, esas sÄ±nav nasÄ±l olacak, biraz bilgi verebilir misiniz? AyrÄ±ca herÅŸey iÃ§in Ã§ok teÅŸekkÃ¼rler.3 weeks ago 1 person likes thisLike ReportReply",
    "->  SÄ±navÄ± tamamladÄ±m. SorularÄ±n hazÄ±rlanmasÄ±nda emeÄŸi geÃ§en herkese teÅŸekkÃ¼rler.3 weeks ago Like ReportReply",
    "-> Sorular gayet gÃ¼zeldi, tekrar teÅŸekkÃ¼rler ğŸ™‚3 weeks ago Like ReportReply",
    "-> SÄ±navÄ± tamamladÄ±m, emeÄŸi geÃ§en herkese teÅŸekkÃ¼r ederim. AyrÄ±ca 4.sorudaki mantÄ±k hoÅŸtu, yani \"Risk nedir ? - Risk budur\" repliÄŸinin ''Group attribution bias nedir ? '' modeli oldu bu soru ğŸ™‚3 weeks ago 1 person likes thisLike ReportReply",
    "->  SÄ±navÄ± yeni tamamladÄ±m. Okuma hatasÄ±ndan yanlÄ±ÅŸ yaptÄ±klarÄ±m var neyse artÄ±k. BÃ¶yle bir programÄ± gerÃ§ekleÅŸtirdiÄŸiniz iÃ§in teÅŸekkÃ¼rler ğŸ™‚3 weeks ago Like ReportReply",
    "->  80 / 100'la birlikte 8. soruyla alakalÄ± felsefik aÃ§Ä±dan yaklaÅŸÄ±mlarÄ±m var ğŸ™‚3 weeks ago Like ReportReply",
    "->  SanÄ±rÄ±m en caydÄ±rÄ±cÄ± sorularÄ±n olduÄŸu sÄ±nav buydu. TeÅŸekkÃ¼rler emeÄŸi geÃ§enlere.3 weeks ago Like ReportReply",
    "->  Eksiklerimi gÃ¶rdÃ¼m bazÄ± durumlarÄ± daha iyi kavramam gerekiyormuÅŸ demek ki . TeÅŸekkÃ¼rler3 weeks ago Like ReportReply",
    "->  O kadar gÃ¼zel bir program oldu ki, burada aktif takip eden, cevap veren soru soran, ilgilenen herkese Ã§ok teÅŸekkÃ¼r ederim.3 weeks ago Like ReportReply",
    " ->  her ÅŸey iÃ§in Ã§ok teÅŸekkÃ¼rler.ğŸ™3 weeks ago Like ReportReply",
    "-> Bu haftanÄ±n sÄ±navÄ±nÄ± da az Ã¶nce tamamladÄ±m. Online vizelerimin baÅŸlamasÄ±yla birlikte yoÄŸun ve yorucu bir hafta olsa da yine de Ã¶ÄŸrenmek ve baÅŸarmak keyifliydi. Kendimi de iyi bir ÅŸekilde test etmiÅŸ oldum. Bir yandan mutluyum, diÄŸer yandan kursun bitmiÅŸ olmasÄ±nÄ±n hÃ¼znÃ¼nÃ¼ yaÅŸÄ±yorum. Her ÅŸey Ã§ok gÃ¼zeldi, emeÄŸi geÃ§en herkese Ã§ok teÅŸekkÃ¼rler.3 weeks ago Like ReportReply",
    "->  EmeÄŸi geÃ§en herkese Ã§ok teÅŸekkÃ¼r ederiz, sorular eksiklerimizi gÃ¶rmemizi saÄŸladÄ±.3 weeks ago Like ReportReply",
    "->  Merhaba, 3. HaftanÄ±n quizini kaÃ§Ä±rdÄ±m yine de final sÄ±navÄ±na girebilir miyim? Ek olarak final sÄ±navÄ± ne zaman olacak?3 weeks ago Like ReportReply",
    "-> Yine 80 aldim ğŸ™‚ Her hafta iki yanlisimi gordum bu sinavlar sayesinde, cok keyif aldim.. Cok ama cok tesekkurler..3 weeks ago 1 person likes thisLike ReportReply",
    "->  Merhaba, yoÄŸunluktan bu haftanÄ±n quizini kaÃ§Ä±rdÄ±m. Make up imkanÄ±mÄ±z var mÄ±? Veya bu quizi tamamlamasam da final sÄ±navÄ±na girebilir miyim? TeÅŸekkÃ¼r ederim.3 weeks ago 2 people like this.Like ReportReply",
    "->  ->  Merhaba, tabii girebilirsiniz, sertifika alabilmeniz iÃ§in bu haftaki sÄ±nava mutlaka girmeniz gerekli ğŸ˜‰3 weeks ago Like ReportReply",
    "->  ->  TeÅŸekkÃ¼r ederim ğŸ™‚3 weeks ago 1 person likes thisLike ReportReply",
    " ->  Merhaba, bende yoÄŸunluktan bu haftanÄ±n quizini kaÃ§Ä±rdÄ±m. Ne yapmam gerekiyor?3 weeks ago Like ReportReply",
    "->   ->  Bu ara sÄ±navlar kendinizi Ã¶lÃ§meniz iÃ§indi, bu haftaki sÄ±navÄ± kaÃ§Ä±rmayÄ±n yalnÄ±z, sertifika alabilmeniz iÃ§in bu sÄ±nav gerekli olacak ğŸ˜‰3 weeks ago Like ReportReply",
    "->  Ben de aynÄ± ÅŸekilde final sÄ±navÄ±na girme ÅŸansÄ±mÄ±z hala var deÄŸil mi?3 weeks ago Like ReportReply",
    "->  ->  Tabii, final sÄ±navÄ±na girebilirsiniz ğŸ˜‰3 weeks ago Like ReportReply",
    "->  Ã‡ok gÃ¼zel bir yolculuktu. AslÄ± hocam ilginiz iÃ§in teÅŸekkÃ¼r ederim. ğŸ™‚3 weeks ago 1 person likes thisLike ReportReply",
    "->  ->  Biz teÅŸekkÃ¼r ederiz ğŸ˜‰3 weeks ago Like ReportReply",
    " ->  YapmayÄ± istediÄŸim ama kendimde iÃ§ enerjimi toparlayÄ±p yapamadÄ±ÄŸÄ±m bir ÅŸeyi yapmama vesile olduÄŸunuz iÃ§in Ã§ok Ã§ok teÅŸekkÃ¼r ederim.3 weeks ago 1 person likes thisLike ReportReply",
    "->  Hocam selamlar, zorunlu bir taÅŸÄ±nma iÅŸim olduÄŸundan bu haftanÄ±n ara sÄ±navÄ±nÄ± kaÃ§Ä±rmak durumunda kaldÄ±m. Daha Ã¶nce benzer bir sÄ±kÄ±ntÄ±sÄ± olan bir Ã¶ÄŸrenciye asÄ±l Ã¶nemli sÄ±navÄ±n final sÄ±navÄ± olduÄŸunu sÃ¶ylemiÅŸtiniz, bu sÄ±kÄ±ntÄ± Ã§Ä±karÄ±r mÄ±?3 weeks ago Like ReportReply",
    "->  ->  Olmaz diye umuyorum. Zira Amerika'da yasadigim icin hicbir sinavi zamaninda gonderemedim...3 weeks ago Like ReportReply",
    "->  ->  Evet Ã¶nemli olan final sÄ±navÄ±ydÄ±, bu haftaki sÄ±navÄ± kaÃ§Ä±rmayÄ±n derim o halde ğŸ˜‰ Hafta iÃ§inde detaylarÄ± paylaÅŸmÄ±ÅŸ oluruz sizlerle.3 weeks ago Like ReportReply",
    "->  ->  Merhaba Final sÄ±navÄ±nÄ±n tarihi belirlendi mi ?.",
    "->  ->  Merhaba, bu pazar olacak, detaylarÄ± en geÃ§ yarÄ±n bildirmiÅŸ olurum sizlere ğŸ™‚.",
    " "
]
},
{
"question_isim": " -> ",
"quest": "Merhaba herkese. Fairness: Types of Bias bÃ¶lÃ¼mÃ¼ndeki bias Ã§eÅŸitlerini tam olarak anlayamadÄ±m. Bu konuda yardÄ±mcÄ± olabilirseniz sevinirim.",
"comment": [
    "",
    "->  Merhaba,Bu konu ile alakalÄ± bir yazÄ± yayÄ±nladÄ±m. Buradan inceleyebilirsiniz: https://medium.com/@ftfethi/hatas%C4%B1z-kul-olmaz-makine-%C3%B6%C4%9Frenmesinde-i%CC%87nsan-yanl%C4%B1l%C4%B1%C4%9F%C4%B1-ede8dc2255f1AklÄ±nÄ±za takÄ±lan bir yer olursa sorabilrsiniz.Ä°yi Ã§alÄ±ÅŸmalar.3 weeks ago 8 people like this.Like ReportReply",
    "->  ->  Allah razÄ± olsun. TÃ¼rkÃ§e olunca o kadar kolay anladÄ±m ki, google kursta saÄŸolsun ilk defa duyduÄŸum kelimelerle cÃ¼mleleri uzata uzata anlatmaya Ã§alÄ±ÅŸmÄ±ÅŸ.3 weeks ago 1 person likes thisLike ReportReply",
    "->  ->  Hepimizden razÄ± olsun ğŸ™‚ Yorumunuz iÃ§in Ã§ok teÅŸekkÃ¼r ederim yardÄ±mcÄ± olabildiysem ne mutlu bana ğŸ™‚3 weeks ago 2 people like this.Like ReportReply",
    " ->  TeÅŸekkÃ¼r ederim3 weeks ago 1 person likes thisLike ReportReply",
    " "
]
},
{
"question_isim": " -> ",
"quest": "Merhabalar, Data Dependencies konusunu tam anlayamadÄ±m. Ã–zellikle  correlations ve feedback loops kÄ±sÄ±mlarÄ±nda kafam biraz karÄ±ÅŸtÄ±. YardÄ±mcÄ± olabilir misiniz?",
"comment": [
    "",
    "-> Merhaba,Bu kÄ±sÄ±mda datalarÄ±mÄ±zÄ±n olmasÄ± gereken ÅŸekliyle alakalÄ± bilgiler verilmektedir.1.Reliability:DatamÄ±z reliable olmalÄ±. Ã–rneÄŸin biz datalara her zaman eriÅŸebilecek miyiz yoksa gÃ¼vensiz bir kaynaktan mÄ± geliyorlar? EÄŸer baÅŸka bir serverdan geliyorsa server sÄ±kÄ±ntÄ± Ã§Ä±kardÄ±ÄŸÄ±nda modelimizi de etkileyecektir. Veya bu datalar sadece aÄŸustos ayÄ±nda tatile giden insanlarÄ± mÄ± iÃ§eriyor.(burada stationary'i de bozuyor)2.VersioningBurada modelimiz deÄŸiÅŸecek mi sorusunu sormalÄ±yÄ±z. EÄŸer deÄŸiÅŸecekse ne sÄ±klÄ±kla ve deÄŸiÅŸtiÄŸi zaman nasÄ±l bileceksiniz? DatalarÄ±mÄ±z bir kaynaktan geliyorsa bu kaynak sorun Ã§Ä±kardÄ±ÄŸÄ±nda datalarÄ±mÄ±zÄ± almakta sorun yaÅŸayacaÄŸÄ±z. Burada bu sorunalra karÅŸÄ± bu kaynaktan aldÄ±ÄŸÄ±mÄ±z verilerin bir kopyasÄ±nÄ± oluÅŸturabilirsiniz.3.NecessityBir feature deÄŸeri gerÃ§ekten gerekli mi bunu sorar. Burada kÄ±sa sÃ¼reliÄŸine modelinizin performansÄ±nÄ± yÃ¼kseltecek bir feature bulup onu eklediÄŸinizde oluÅŸacak ekstra costu gÃ¶z Ã¶nÃ¼nde bulundurmalÄ±sÄ±nÄ±z. EÄŸer yeni bulduÄŸunuz bu feature bozulmaya uÄŸrayabilir bu yÃ¼zden bu feature'Ä± monitÃ¶rlemeniz gerekir.4.CorrelationsBurada bazÄ± featurelarÄ±n diÄŸer featurelar ile korele olabilecekleri sÃ¶ylenmiÅŸtir. Veri setinizde bu ÅŸekilde birbirine baÄŸlÄ± bulunan ve ayÄ±rmak iÃ§in ekstra strateji gerektiren baÅŸka featurelar var mÄ±?Correlated featurelar modelimizi her zaman geliÅŸtirecek veya her zaman kÃ¶tÃ¼ etkileyecek diye bir ÅŸey diyemeyiz ama onlarÄ± istemememiz iÃ§in nedenlerimiz:a)AlgoritmamÄ±zÄ±n daha da hÄ±zlÄ± Ã§alÄ±ÅŸmasÄ±: Curse of dimensionality nedeniyle ne kadar az feature'ImÄ±z olursa algoritmamÄ±z o kadar hÄ±zlÄ± Ã§alÄ±ÅŸÄ±r.b)Modelimizin yorumlanabilirliÄŸi artar: Ockham'Ä± hatÄ±rlarsanÄ±z bir model ne kadar basitse o kadar iyidir. Buradaki basitlik feature deÄŸerlerinin az olmasÄ± olarak yorumlanabilir.Burada correlated feature kÃ¶tÃ¼ bir ÅŸeydir diyemeyiz modelinizin yapÄ±sÄ±na gÃ¶re deÄŸiÅŸen bir olgudur bu.5.Feedback Loops:Bu kÄ±smÄ± uzun bir ÅŸekilde https://community.globalaihub.com/community/status/1321-1321-1588419875/#comment.5489.5298.5298 linkinde aÃ§Ä±klamÄ±ÅŸtÄ±m.TakÄ±ldÄ±ÄŸÄ±nÄ±z bir yer olursa sorabilirsiniz. YanlÄ±ÅŸÄ±m var ise dÃ¼zeltilmesinden memnun olurum.Ä°yi Ã§alÄ±ÅŸmalar.",
    "Global AI Hubcommunity.globalaihub.comCome and join our community. Expand your network and get to know new people!3 weeks ago 10 people like this.Like ReportReply",
    "->  ->  Burada sizin corralated featurelarÄ±n bize kazanÃ§ saÄŸlamayacaÄŸÄ±nÄ± sÃ¶yleyerek ÅŸunu mu kastetmeye Ã§alÄ±ÅŸyorsunuz. Correlated featurelarÄ±mÄ±zÄ± birleÅŸtirip modele katmalÄ±yÄ±z Ã¶bÃ¼rtÃ¼rlÃ¼ tek baÅŸlarÄ±na bir anlam ifade etmeye biliyor ve bize ek yÃ¼k oluyor.3 weeks ago 1 person likes thisLike ReportReply",
    "->  ->  Merhaba,EÄŸer imkanÄ±mÄ±z var ise featurelarÄ± birleÅŸtirip yeni feature elde etmemiz daha iiyi olacaktÄ±r ancak bazen bu correlated featurelardan oluÅŸan yeni feature deÄŸerimiz label ile korele olamayabilir. Zaten correlated feature her koÅŸulda kÃ¶tÃ¼dÃ¼r ve kullanmamalÄ±yÄ±z diyemeyiz evet feature sayÄ±sÄ± olarak yÃ¼k oluyor ve modelimzi kompleks hale getiriyor ama unutmamalÄ±yÄ±z ki istediÄŸimiz basitlik ve komplekslik arasÄ±ndaki en optimum yeri bulmak.Ä°yi Ã§alÄ±ÅŸmalar.3 weeks ago Like ReportReply",
    " ->  ->  aÃ§Ä±klama iÃ§in teÅŸekkÃ¼r ederim, sorularda kafam karÄ±ÅŸmÄ±ÅŸtÄ± bu ÅŸekilde daha aÃ§Ä±k oldu3 weeks ago Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Selamlar, Ã¶nceki konularÄ±mÄ±zdan aklÄ±ma takÄ±lan bir soruyu sormak istiyorum. AÅŸaÄŸÄ±da soruldu ise gÃ¶remedim.  Classification: Prediction Bias kÄ±smÄ±nda bias Ä±n kÃ¶k sebeplerin biri olarak Buggy pipeline da listelenmiÅŸ. Buggy pipeline nedir? nasÄ±l oluÅŸur? TeÅŸekkÃ¼rler,",
"comment": [
    "",
    "-> Emin olmamakla birlikte, dÃ¼ÅŸÃ¼ncemi paylaÅŸÄ±yorum: Bir tahminleme modeli oluÅŸturmak iÃ§in iÅŸletilen sÃ¼reÃ§lerim tÃ¼mÃ¼ (veri toplama, temizleme, feature engineering, training, evaluation vb.) pipeline. Bu adÄ±mlardan herhangi birinin uygulanÄ±ÅŸÄ±nda bir hata varsa elde ettiÄŸimiz pipeline \"buggy\" oluyor. Yani bu sanki biraz mevcut kategorilere ait olmayan hatalarÄ±n kategorisi. Ã–rneÄŸin, uygulamanÄ±n matris Ã§arpÄ±mÄ±nda bir hata yaptÄ±n, bu diÄŸer hata kategorilerinin hiÃ§birine girmiyor ama buggy pipeline olarak dÃ¼ÅŸÃ¼nÃ¼lebilir.3 weeks ago 3 people like this.Like ReportReply",
    "->  Merhaba,Pipeline, makine Ã¶ÄŸrenmesindeki akÄ±ÅŸlarÄ± otomatize etmek iÃ§in kullanÄ±lÄ±r. Pipeline hesaplamalarÄ±n bir derlemesi olan bir bileÅŸen dizisinden oluÅŸur. Veriler bu bileÅŸenler aracÄ±lÄ±ÄŸÄ±yla gÃ¶nderilir ve hesaplama yardÄ±mÄ± ile iÅŸlenir. EÄŸer pipeline da bug olursa verilerimiz yanlÄ±ÅŸ tahmin edilecektir.Pipeline ile ilgili daha fazla bilgi iÃ§in: https://medium.com/analytics-vidhya/what-is-a-pipeline-in-machine-learning-how-to-create-one-bda91d0ceacaÄ°yi Ã§alÄ±ÅŸmalar.",
    "WHAT IS A PIPELINE IN MACHINE LEARNING?HOW TO CREATE ONE?medium.comMachine Learning Is Burgeoning3 weeks ago 2 people like this.Like ReportReply",
    "->  Ã‡ok teÅŸekkÃ¼rler arkadaÅŸlar. kolaylÄ±klar.3 weeks ago Like ReportReply",
    " "
]
},
{
"question_isim": "->",
"quest": "Static vs. Dynamic Inference ve Data Dependencies konularÄ±nÄ± pek anlamadÄ±ÄŸÄ±mÄ± dÃ¼ÅŸÃ¼nmÃ¼yorum, sorularÄ±nda yanlÄ±ÅŸlarÄ±m varğŸ¤”ğŸ¤”",
"comment": [
    "",
    "-> Merhaba,Inference kavramÄ± modelimizin tahminde bulunmasÄ± demektir diyebiliriz kaba ve kÄ±sa bir tabirle. Burada static ve dynamic inference dediÄŸi onlibne offline inference diyebiliriz.Offline inference'ta statik bir veri kÃ¼meniz vardÄ±r.Online inference'ta sorgu geldikÃ§e eÄŸitime sokulur.Online inference'ta daha fazla veriniz vardÄ±r fakat zaman kÄ±sÄ±tlamanÄ±z vardÄ±r.Offline inference iyi(+) ve kÃ¶tÃ¼(-) yÃ¶nleri:+ Tahmin costunu dÃ¼ÅŸÃ¼nmek zorunda deÄŸilsiniz+ Tahminlerimizi verify edebiliriz Ã§Ã¼nkÃ¼ verisetinde olmayan bir ÅŸey tahmin etmiyoruz.-Sadece bildiÄŸimiz ÅŸeyleri predict edebiliriz.Online inference iyi(+) ve kÃ¶tÃ¼(-) yÃ¶nleri:+Yeni veri geldikÃ§e onun hakkÄ±nda tahmin yapabiliriz.-YoÄŸun hesaplama gerektirir, gecikmeye Ã§ok duyarlÄ±dÄ±r. Bu da modelin kompleksitesini kÄ±sÄ±tlayabilir.-:Modelinizi daha yoÄŸun monitÃ¶rlemeniz gerekmektedir.Data Dependencies konusunu https://community.globalaihub.com/community/status/1338-1338-1588435795/#comment.5507.5315.5315 linkinde aÃ§Ä±klamaya Ã§alÄ±ÅŸtÄ±m. Sorunuz olursa sorabilirsiniz.Ä°yi Ã§alÄ±ÅŸmalar.",
    "Global AI Hubcommunity.globalaihub.comCome and join our community. Expand your network and get to know new people!3 weeks ago 3 people like this.Like ReportReply",
    "-> TeÅŸekkÃ¼r ederim ğŸ˜Š3 weeks ago 1 person likes thisLike ReportReply",
    "->  Online inference i sÃ¼rekli canlÄ± veri akan bir sistemdeki sorgulama yapmaya Ã§alÄ±ÅŸmak gibi dÃ¼ÅŸÃ¼nebilirsin. Ã–rneÄŸin twitter to tt olan bir konu Ã¼zerinde sorgulama yapÄ±yorsun. Offline inference te ise stream olmayan bir veri setinin sonuÃ§larÄ±ndan bahsedebiliriz.3 weeks ago 1 person likes thisLike ReportReply",
    "-> ->  TeÅŸekkÃ¼r ederim:)3 weeks ago Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba,  Embedding kÄ±smÄ±nda Logit Layer'Ä±n foksiyonunu tam olarak anlamadÄ±m. YardÄ±mcÄ± olabilirseniz sevinirim.",
"comment": [
    "",
    "->  Merhaba,Logit layer kÄ±smÄ± aslÄ±nda output katmanÄ± yani bizim outputumuz.0 dan 9 a kadar elle yazÄ±lmÄ±ÅŸ rakamlarÄ± tespit eden bir modelimiz olsaydÄ± logit layerÄ±mÄ±z yani outputumuz, her biri farklÄ± bir rakamÄ± temsil eden 10 farklÄ± nÃ¶rondan oluÅŸacaktÄ±, en yÃ¼ksek outputu veren nÃ¶ron da bizim cevabÄ±mÄ±z olacaktÄ±.Movie recommendation Ã¶rneÄŸinde de amacÄ±mÄ±z 500 bin film arasÄ±ndan 2-3 tane film izlemiÅŸ bir izleyiciye bu filmler arasÄ±ndan hangi filmleri Ã¶nerebileceÄŸimizi hesaplayan bir model oluÅŸturmak. Outputumuz Ã¶rneÄŸin 500 bin den 4-5 tane film olacak. Bunun iÃ§in, her bir film iÃ§in bir nÃ¶ron olacak ÅŸekilde 500 bin nÃ¶ron iÃ§eren bir logit layer katmanÄ± oluÅŸturuyoruz, modelimiz hangi filmleri Ã¶nerdiyse o filmlerin nÃ¶ronlarÄ± Ã§Ä±kÄ±ÅŸ veriyor.3 weeks ago 6 people like this.Like ReportReply",
    "->  TeÅŸekkÃ¼rler3 weeks ago 1 person likes thisLike ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba arkadaÅŸlar,  ML Engineering bÃ¶lÃ¼mÃ¼ Data Dependencies baÅŸlÄ±ÄŸÄ±nÄ±n altÄ±ndaki soruyu tam yapamadÄ±m ve bahsedilen feedback loop kavramÄ±nÄ± anlamadÄ±ÄŸÄ±mÄ± farkettim. YardÄ±mcÄ± olabilir misiniz?",
"comment": [
    "",
    "-> Merhaba, anladÄ±ÄŸÄ±m kadarÄ±yla feedback loops dediÄŸimiz kavramda modelin kendi ya da baÅŸka modelin verilerini etkilemesi sÃ¶z konusu, mesela model a model b'nin sonuÃ§larÄ±nÄ± doÄŸrudan ya da dolaylÄ± olarak input feature olarak kullanabilir. Sistemin kalitesi input featurelarÄ±n kalitesine baÄŸlÄ±, Ã§Ã¶p giren Ã§Ã¶p Ã§Ä±kar mantÄ±ÄŸÄ±yla modelimizi test, verify, monitoring dediÄŸimiz aÅŸamalardan geÃ§irmeliyiz. Sorunun doÄŸru cevabÄ±nda olan seÃ§eneklerimizi aÃ§Ä±klamaya Ã§alÄ±ÅŸayÄ±m.1)\"A book-recommendation model that suggests novels its users may like based on their popularity (i.e., the number of times the books have been purchased)\" KullanÄ±cÄ±lara popÃ¼lerliÄŸe gÃ¶re roman Ã¶neren kitap tavsiye modelinde en Ã§ok satÄ±lan kitaplarÄ±n daha Ã§ok Ã¶nerilmesi satÄ±n almayÄ± arttÄ±rabilir. Girdi olarak geri beslediÄŸi iÃ§in aynÄ± kitaplarÄ± Ã¶nerme olasÄ±lÄ±ÄŸÄ± artar.2) \" A traffic-forecasting model that predicts congestion at highway exits near the beach, using beach crowd size as one of its features.\" sahile yakÄ±n otoyol Ã§Ä±kÄ±ÅŸlarÄ±nÄ±n tÄ±kanÄ±klÄ±ÄŸÄ±nÄ± tahmin eden model, plaj kalabalÄ±ÄŸÄ± boyutunu feature olarak kullanmÄ±ÅŸ ve trafik yoÄŸun olduÄŸu zaman insanlar alternatif planlar yapar ve dÃ¶ngÃ¼ bÃ¶ylece devam eder. 3) \"A university-ranking model that rates schools in part by their selectivityâ€”the percentage of students who applied that were admitted.\" burada anladÄ±ÄŸÄ±m kadarÄ±yla okullarÄ± seÃ§iciliklerine gÃ¶re deÄŸerlendiren bir Ã¼niversite ranking modeli var. Ve sÄ±ralamada en yÃ¼ksek dereceli okullar daha Ã§ok ilgi gÃ¶receÄŸi iÃ§in bu diÄŸer senenin sonuÃ§larÄ±nÄ± etkiler.3 weeks ago 6 people like this.Like ReportReply",
    "->  -> Ã‡ok teÅŸekkÃ¼r ederim cevabÄ±nÄ±z iÃ§in3 weeks ago 1 person likes thisLike ReportReply",
    " -> -> Rica ederim ğŸ™‚3 weeks ago Like ReportReply",
    "-> Not: YazdÄ±klarÄ±mÄ±n tamamÄ± gÃ¶zÃ¼kmediÄŸi iÃ§in devamÄ±nÄ± resim olarak paylaÅŸÄ±yorum.Merhaba,Feedback Loop bir modelin outputunun kendisini veya baÅŸka modeli etkilemesidir. Ã–rneÄŸin elimizde A ve B modelleri olsun ve A'nÄ±n outputunu B'yi etkiliyor olsun. A eÄŸer hatalÄ± bir model ise outputu da hatalÄ± olacaktÄ±r ve B de dolayÄ±sÄ± ile hatalÄ± olacaktÄ±r.Crash Course'taki Ã¶rnek Ã¼zerinden ilerlersek:A modelimiz hatalÄ± olup X hissesini almaya karar veriyor olsun. Bu stok alÄ±mÄ± stok fiyatÄ±nÄ± yÃ¼kseltecektir. B modelimiz de bu stok fiyatlarÄ±nÄ± input alÄ±yor olsun. B modeli kolayca X hissesinin fiyatÄ± konusunda hatalÄ± bir sonuca ulaÅŸacaktÄ±r. Bunun nedeni kendisini etkileyen A modelinin hatalÄ± hatalÄ± olmasÄ±dÄ±r. B modeli bu fiyata gÃ¶re bu hisseyi alÄ±p satmaya karar verebilir. AynÄ± zamanda B'Nin sonucu da A'yÄ± etkileyebilir.Dipnot: Makine Ã–ÄŸrenmesinde modellerimiz hep hatalÄ±dÄ±r(gerÃ§ek deÄŸere yakÄ±n tahmin Ã¼retse de gerÃ§ek deÄŸeri Ã¼retmez). Burada hatadan kastÄ±mÄ±z buggy durumu yani mdoelimizin normal dÄ±ÅŸÄ± hatalÄ± olmasÄ±dÄ±r.Soruya gelirsek de sorumuzda bize hangi modelin feedback loop olmaya aÃ§Ä±k olduÄŸunu soruyor;Burada doÄŸru cevaplar Ã¼zerinden aÃ§Ä±klamamÄ± yapayÄ±m Ã¶nce:1.A book-recommendation model that suggests novels its users may like based on their popularity (i.e., the number of times the books have been purchased).Burada satÄ±lan kitap sayÄ±sÄ±na gÃ¶re kitaplarÄ±n popÃ¼laritesi Ã¶lÃ§Ã¼lÃ¼r ve kulalnÄ±cÄ±ya bununla ilgili bir Ã¶neride bulunulur. Modelin inpute deÄŸerine kitaplarÄ±n satÄ±lma sayÄ±sÄ± diyelim outputa da Ã¶nerilecek kitap diyelim. Ã–neride bulunulan kitaplarÄ±n ise satÄ±ÅŸlarÄ±nÄ±n artmasÄ± olasÄ±dÄ±r yani bu modelin kendi outputu aslÄ±nda kendi inputunu etkilemiÅŸtir. (Output kitap Ã¶nerisi - input bu Ã¶neriye baÄŸlÄ± artan satÄ±ÅŸ sayÄ±sÄ±)2.A university-ranking model that rates schools in part by their selectivityâ€”the percentage of students who applied that were admitted.Burada okullarÄ± seÃ§iciliklerine gÃ¶re derecelendirmek istiyoruz. Burada seÃ§cilik dediÄŸimiz ÅŸey de baÅŸvuranlardan kabul edilen Ã¶ÄŸrencilerin yÃ¼zdesidir. Burada ise ÅŸu etkiyle karÅŸÄ±laÅŸÄ±rÄ±z: en yÃ¼ksek derecede olan okula ek ilgi uyanabilir ve aldÄ±klarÄ± baÅŸvuru sayÄ±sÄ± artabilir. Bu okullar kontenjanÄ± aynÄ± tutup aynÄ± sayÄ±da Ã¶ÄŸrenci kabul etmeye devam ederse seÃ§icilik artacaktÄ±r. (Ã§Ã¼nkÃ¼ baÅŸvuran sayÄ±sÄ± artÄ±yor.) Bu ÅŸekilde modelin outputu inputunu etkilemiÅŸ diyebilriz. (input seÃ§icilik oranÄ±, output derece)3.A traffic-forecasting model that predicts congestion at highway exits near the beach, using beach crowd size as one of its features.Burada modelimiz sahile yakÄ±n otoyol sÄ±kÄ±ÅŸÄ±klÄ±ÄŸÄ±nÄ± tahmin ederken plajdaki kalabalÄ±ÄŸÄ± feature olarak kullanÄ±yor.Burada plaja gitmeyi dÃ¼ÅŸÃ¼nen insanlar trafik olduÄŸu tahmin edilirse plaja gitmekten vagzeÃ§ebilir bÃ¶ylece kalabalÄ±k azalÄ±r ve kalabalÄ±k azalÄ±rsa otoyol aÃ§Ä±lacaÄŸÄ± iÃ§in bu sefer plaja gitmeyi dÃ¼ÅŸÃ¼nenler plaja gitmek isteyecek ve orayÄ± kalabalÄ±klalÅŸtÄ±rarak trafiÄŸi arttÄ±racaktÄ±r. (input plaj kalabalÄ±ÄŸÄ±, output sahile yakÄ±n otoyolun sÄ±kÄ±ÅŸÄ±klÄ±k durumu)HatalÄ± olanlara gelirsek:1.A face-attributes model that detects whether a person is smiling in a photo, which is regularly trained on a database of stock photography that is automatically updated monthly.Burada modelimizn yÃ¼zÃ¼mÃ¼zdeki mimikleri tahmin etmesinin kendisine veya baÅŸka bir modele etkisi yoktur. Modelimiz bu tahminyle bir dÃ¶ngÃ¼ durumu oluÅŸturmamaktadÄ±r. Sadece gÃ¼len yÃ¼z, aÄŸlayan yÃ¼z vb tahminlerde bulunmuÅŸtur.2.A housing-value model that predicts house prices, using size (area in square meters), number of bedrooms, and geographic location as features.Burada modelimizin outputu modelimizin featurelarÄ±nÄ± etkilememektedir. Ã–rneÄŸin Londrada 6 odalÄ± 300 metrekare 2 yatak odalÄ± bir evin fiyatÄ± 500000 pound olarak tahmin edilirse bu tahmin bizim yatak odasÄ± s3 weeks ago 7 people like this.Like ReportReply",
    "-> ->  Ã‡ok teÅŸekkÃ¼rler cevabÄ±nÄ±z iÃ§in gayet aÃ§Ä±klayÄ±cÄ± oldu.3 weeks ago 1 person likes thisLike ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar herkese, keyifli haftasonlarÄ± :)  Ben \"Fairness: Evaluating for Bias\" iÃ§eriÄŸinden bir soru sormak istiyorum. Verilen Ã¶rneÄŸi tekrar Ã¶zetlersek; 500 erkek ve 500 kadÄ±n hastanÄ±n tÄ±bbi kayÄ±tlarÄ±nÄ± almÄ±ÅŸlar ve tÃ¼mÃ¶r olup olmadÄ±ÄŸÄ±nÄ± tespit eden bir model geliÅŸtirmiÅŸler. Model performansÄ± sonucu recall %80, precision %73 Ã§Ä±kmÄ±ÅŸ. SonrasÄ±nda test datasÄ±nÄ± kadÄ±n ve erkek olarak ikiye ayÄ±rÄ±p performansÄ± incelediklerinde;  KadÄ±n hastalar iÃ§in perfomans: precision %91, recall %91 Erkek hastalar iÃ§in performans: precision %67, recall % 54 olduÄŸu gÃ¶rÃ¼lmÃ¼ÅŸ, buradan bias Ä±n Ã¶nemini anlÄ±yoruz demiÅŸ.  Burada tam olarak hangi tip bias olabilir (selection, reporting, implicit vs.) ? Dataset imbalanced (negative sayÄ±sÄ± pozitif sayÄ±sÄ±ndan daha fazla) ama erkek-kadÄ±n ayrÄ±ldÄ±ÄŸÄ±nda iki grup iÃ§in de oran aynÄ±. Bu hata farkÄ± erkeklerde gÃ¶rÃ¼len tÃ¼mÃ¶rÃ¼n tespitâ€¦ <a class=\"ps-stream-post-more ps-js-content-excerpt-toggle\" href=\"#\">Read more</a></div><div class=\"ps-js-content-full\" style=\"\">Merhabalar herkese, keyifli haftasonlarÄ± :)  Ben \"Fairness: Evaluating for Bias\" iÃ§eriÄŸinden bir soru sormak istiyorum. Verilen Ã¶rneÄŸi tekrar Ã¶zetlersek; 500 erkek ve 500 kadÄ±n hastanÄ±n tÄ±bbi kayÄ±tlarÄ±nÄ± almÄ±ÅŸlar ve tÃ¼mÃ¶r olup olmadÄ±ÄŸÄ±nÄ± tespit eden bir model geliÅŸtirmiÅŸler. Model performansÄ± sonucu recall %80, precision %73 Ã§Ä±kmÄ±ÅŸ. SonrasÄ±nda test datasÄ±nÄ± kadÄ±n ve erkek olarak ikiye ayÄ±rÄ±p performansÄ± incelediklerinde;  KadÄ±n hastalar iÃ§in perfomans: precision %91, recall %91 Erkek hastalar iÃ§in performans: precision %67, recall % 54 olduÄŸu gÃ¶rÃ¼lmÃ¼ÅŸ, buradan bias Ä±n Ã¶nemini anlÄ±yoruz demiÅŸ.  Burada tam olarak hangi tip bias olabilir (selection, reporting, implicit vs.) ? Dataset imbalanced (negative sayÄ±sÄ± pozitif sayÄ±sÄ±ndan daha fazla) ama erkek-kadÄ±n ayrÄ±ldÄ±ÄŸÄ±nda iki grup iÃ§in de oran aynÄ±. Bu hata farkÄ± erkeklerde gÃ¶rÃ¼len tÃ¼mÃ¶rÃ¼n tespit edilmesi daha zor olduÄŸu iÃ§in olabilir mi?  Ã‡Ã¶zÃ¼m olarak sample sayÄ±sÄ±nÄ± artÄ±rmaktan baÅŸka modelde nasÄ±l bir deÄŸiÅŸiklik yapÄ±labilir? Cinsiyeti (e-k) ilave bir feature olarak versek performansÄ±mÄ±z artar mÄ±ydÄ±?  TartÄ±ÅŸmaya aÃ§Ä±ktÄ±r, teÅŸekkÃ¼rler ğŸ™‚</div></div>",
"comment": [
    "",
    "-> Validation set 500E/500K olarak ayrÄ±lmÄ±ÅŸ ancak training set hakkÄ±nda bilgi verilmemiÅŸ. Training set'te bir coverage bias sÃ¶zkonusu olabilir. Sadece validation set sonucuna bakarak cinsiyeti bir feature olarak eklemek doÄŸru olmayabilir (gerÃ§ekten de bias var ise). Bu noktada, eÄŸitim materyelinde de anlatÄ±ldÄ±ÄŸÄ± gibi, bir tÄ±bbi uzmana danÄ±ÅŸÄ±p, cinsiyetin hastalÄ±ÄŸa etkisinin biyolojik temeli olup olmadÄ±ÄŸÄ± Ã¶ÄŸrenilebilir. EÄŸer bÃ¶yle bir temel var ise feature olarak eklenebilir.3 weeks ago 1 person likes thisLike ReportReply",
    " "
]
},
{
"question_isim": "->  uploaded 1 photo",
"quest": "Merhaba. Static vs. Dynamic Training kÄ±smÄ±nda anlamadÄ±ÄŸÄ±m bazÄ± kÄ±sÄ±mlar oldu. FotoÄŸrafta altÄ± Ã§izili olan maddeleri aÃ§Ä±klayabilir misiniz ? TeÅŸekkÃ¼r ederim.",
"comment": [
    "",
    " -> Burada anlatmak istediÄŸi ÅŸeyler ÅŸu, monitoring'ten kastÄ± modele girdilerin izlenmesi gerekiyor. modele giren ÅŸeylerin, eÄŸitilmiÅŸ modelin yapÄ±sÄ±nÄ± bozmamasÄ±nÄ± bekleriz, o yÃ¼zden inputlar (eÄŸer feedback odaklÄ± bir sistem kullanÄ±yorsak) Ã§ok Ã¶nemli. Statik model iÃ§in diyor ki, yine girdileri izlemeniz gerekiyor ve bu modelin geÃ§erliliÄŸini kaybetmesi Ã§ok kÄ±sa bir zaman alÄ±r. Dinamik model iÃ§in de, giren datayÄ± izlemeniz ve gerekmektedir. Data karantinasÄ±ndan aslÄ±nda ne demek istediÄŸini az Ã§ok anlarsÄ±nÄ±z. Son altÄ± Ã§izili yer de ÅŸunu sÃ¶ylÃ¼yor, statik modelimiz geÃ§erliliÄŸini kÄ±sa zamanda kaybederken, dinamik modelimiz bu sÃ¼reÃ§ten daha yavaÅŸ etkileniyor Ã§Ã¼nkÃ¼ sÃ¼rekli gÃ¼ncel veri geliyor ve model bunlara gÃ¶re kendini yeniliyor3 weeks ago 3 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "->  uploaded 1 photo",
"quest": "Merhaba ArkadaÅŸlar, \"Embeddings as lookup tables\" bÃ¶lÃ¼mÃ¼nÃ¼ anlayamadÄ±m. YardÄ±mcÄ± olabilir misinz?  Ã‡ok teÅŸekkÃ¼rler",
"comment": [
    "",
    "->  Merhaba,https://community.globalaihub.com/community/status/1002-1002-1588159848/ bu postun altÄ±nda bu konu tartÄ±ÅŸÄ±ldÄ±, kafanÄ±zda soru iÅŸareti olursa yanÄ±tlamaktan memnuniyet duyarÄ±m.Ä°yi Ã§alÄ±ÅŸmalar.",
    
    "->  Ã‡ok teÅŸekkÃ¼rler -> . Ä°yi Ã§alÄ±ÅŸmalar.3 weeks ago 1 person likes thisLike ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba nu haftaki konumuza alakalÄ± olmamakla birlikte geÃ§miÅŸ haftalarda konu olan back propagation konusunun ne olduÄŸunu pek anlayamadÄ±m bunu biz neden kullanÄ±yoruz?",
"comment": [
    "",
    "-> Neural network ta basitÃ§e; girdiler, hidden layers, Ã§Ä±ktÄ± katmanÄ±. Modelimizi kurduk. Forward propagation ile baÅŸladÄ±k. Burada biz farazi deÄŸerler vererek iÅŸlemleri giriÅŸ katmanÄ±ndan Ã§Ä±kÄ±ÅŸ katmanÄ±na kadar gÃ¶tÃ¼rÃ¼yoruz ancak tabiki hatamÄ±z sonunda yÃ¼ksek Ã§Ä±kÄ±cak. Ne yapmamÄ±z lazÄ±m geri dÃ¶nÃ¼p (back propagation) parametreleri gÃ¼ncelleyeceÄŸiz. Bu geri dÃ¶nme direk en baÅŸa dÃ¶nme olarak deÄŸil, nasÄ±l geldiysek tek tek katmanlar arasÄ± dÃ¶nÃ¼ÅŸ yapÄ±yoruz. Ã§Ä±kÄ±ÅŸ- hidden layers- girdilerin ilk aÄŸÄ±rlÄ±klarÄ±na kadar. Bu geri dÃ¶nme iÅŸlemini tÃ¼rev alarak yapÄ±yoruz tabi ki. Backpropagation'Ä± tamamladÄ±ÄŸÄ±mÄ±zda en baÅŸa yani inputlarÄ±n aÄŸÄ±rlÄ±klarÄ±na gelmiÅŸ oluyoruz. Sonra tekrar forward propagation yapÄ±yoruz Ã§Ä±ktÄ±ya geliyoruz, hatamÄ±za bakÄ±yoruz, olmadÄ± mÄ± tekrar back propagation ....Back propagationa baÅŸladÄ±ÄŸÄ±nda her parametre iÃ§in aldÄ±ÄŸÄ±n tÃ¼revler hatanÄ±n yÃ¼ksek Ã§Ä±kmasÄ±na sebep olan parametreler iÃ§in ceza deÄŸeri oluyor.3 weeks ago 2 people like this.Like ReportReply",
    "->  Merhaba,Back propagation yapmamÄ±zÄ±n sebebi neural network'Ã¼mÃ¼zÃ¼n hatasÄ±nÄ± minimize edebilmek. Back propagation yaptÄ±ÄŸÄ±mÄ±zda gradient descent yapmaya olanak saÄŸlÄ±yoruz. AÅŸaÄŸÄ±daki resmi dÃ¼ÅŸÃ¼nÃ¼n. Burada hidden layerÄ±mÄ±zdaki her nÃ¶ronun weight hata oranÄ±mÄ±zÄ± etkiliyor. Bizim bu weight deÄŸerleriyle oynama yaparak hata oranÄ±mÄ±zÄ± minimize etmemiz lazÄ±m. Ama hidden layer weightleir de input layer weightleri tarafÄ±ndan etkileniyor yani hidden layerÄ± deÄŸiÅŸtirmek iÃ§in input layer'a kaddar uzanÄ±p oaradaki weightleri deÄŸiÅŸtirmemiz lazÄ±m. Bu sayede neural network'Ã¼mÃ¼z layerlarda geri giderek uygun weight ayarlamalarÄ±nÄ± gradient descent kullanarak yapabilir.Ä°yi Ã§alÄ±ÅŸmalar.3 weeks ago 1 person likes thisLike ReportReply",
    "-> Merhaba Ã–zkaya,Back propagation iÅŸlemi aslÄ±nda modelimizi train ettiÄŸimiz iÅŸlem oluyor.Modelimizi hiperparametrelerini ayarladÄ±ktan sonra rastgele weight deÄŸerleri ile train datasÄ± Ã¼zerinde tahmin yapacak ÅŸekilde Ã§alÄ±ÅŸtÄ±rÄ±yoruz. Bu iÅŸlem sonucunda elde ettiÄŸimiz deÄŸerler modelimizin tahmin ettiÄŸi deÄŸerler oluyor ve gerÃ§ekte olmasÄ± gereken deÄŸerler ile karÅŸÄ±laÅŸtÄ±rÄ±yoruz.Bu karÅŸÄ±laÅŸtÄ±rma sonucunda Ã§Ä±kan loss deÄŸerleri ile modelimizin weightlerini geriye doÄŸru gÃ¼ncelliyoruz. Bu iÅŸleme back propagation deniyor. Bu iÅŸlem ile amacÄ±mÄ±z lossu mÃ¼mkÃ¼n olduÄŸunca azaltmak.Ä°ÅŸlemde tÃ¼rev kullanÄ±lÄ±yor Ã§Ã¼nkÃ¼ hangi neuronun sonucu ne kadar deÄŸiÅŸtirdiÄŸini bularak her bir neuronun optimum weight deÄŸerini set etmeye Ã§alÄ±ÅŸÄ±yoruz.AÅŸaÄŸÄ±da paylaÅŸtÄ±ÄŸÄ±m linki incelemen Ã§ok faydalÄ± olacaktÄ±r. BasitÃ§e bir neural network Ã¼zerinde feed forward ve back propagation iÅŸlemleri gÃ¶steriliyor.Ä°yi Ã§alÄ±ÅŸmalar.https://developers-dot-devsite-v2-prod.appspot.com/machine-learning/crash-course/backprop-scroll/Google Developersdevelopers-dot-devsite-v2-prod.appspot.comhttps://developers-dot-devsite-v2-prod.appspot.com/machine-learning/crash-course/backprop-scroll/3 weeks ago 8 people like this.Like ReportReply",
    "->  teÅŸekkÃ¼r ederim3 weeks ago Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba, Neural Networkler ile ilgili bulduÄŸum yararlÄ± olabileceÄŸini dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼m bir kaynaÄŸÄ± sizlerle paylaÅŸmak istedim. OldukÃ§a aÃ§Ä±klamalÄ± ve eÄŸlenceli anlatÄ±m tarzÄ±yla anlamanÄ±za yardÄ±mcÄ± olacaÄŸÄ±nÄ± umuyorum. <a class=\"ps-media-link\" href=\"https://www.youtube.com/watch?v=XJ7HLz9VYz0&amp;list=PLRqwX-V7Uu6aCibgK1PTWWu9by6XFdCfh\" rel=\"nofollow\" target=\"_blank\">https://www.youtube.com/watch?v=XJ7HLz9VYz0&amp;list=PLRqwX-V7Uu6aCibgK1PTWWu9by6XFdCfh</a> Bu playlist neural networkler ile ilgilidir daha fazlasÄ± iÃ§in kanalÄ± inceleyebilirsiniz. Herkese iyi Ã§alÄ±ÅŸmalar dilerim.",
"comment": [
    "",
    "-> GÃ¼zel paylaÅŸÄ±m teÅŸekkÃ¼rler. 3-4 gÃ¼n kadar Ã¶nce Embedding konusunu Ã§alÄ±ÅŸÄ±rken bu kanalÄ± keÅŸfetmiÅŸtim ve word2vec konusunu daha iyi kavrayabilmemde kanaldaki ÅŸu video oldukÃ§a yardÄ±mcÄ± olmuÅŸtu:https://www.youtube.com/watch?v=LSS_bos_TPI12.1: What is word2vec? - Programming with Textwww.youtube.comIn this new playlist, I explain word embeddings and the machine learning model word2vec with an eye towards creating JavaScript examples with ml5.js. ğŸ¥ Next ...3 weeks ago 9 people like this.Like ReportReply",
    "->  FaydalÄ± paylaÅŸÄ±mlarÄ±nÄ±z iÃ§in Ã§ok teÅŸekkÃ¼r ediyorum3 weeks ago Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba, Neural Networks-&gt;Structure bÃ¶lÃ¼mÃ¼nde lineer olmayan modelimizi hidden layer yardÄ±mÄ±yla lineer bir modele Ã§evirebiliyoduk biliyorduk. Bir hidden layer iÅŸimizi gÃ¶rÃ¼rken neden ikinci bir hidden layere ihtiyaÃ§ duduk.",
"comment": [
    "",
    "->  Merhabalar,Daha fazla katman demek,teorik olarak daha fazla detay demektir.Hidden Layer'larda,Ã¶zellik Ã§Ä±karÄ±mÄ± yapÄ±lÄ±r yani 'Ã¶zellikler Ã¶ÄŸrenilir.'Daha fazla katman,daha fazla node ve weight demektir,biliyoruz ki modelimiz veriyi tahmin gÃ¼cÃ¼nÃ¼ 'node' ve 'weight' lerden alÄ±r.Bu yÃ¼zden dir ki,birden fazla hidden layer kullanÄ±yoruz.Bunu,beynimizden ilham alarak hayal edebiliriz.Beynimiz milyarlarca birbirinie baÄŸlÄ± nÃ¶ronlardan (node) oluÅŸan ve bu nÃ¶ronlar arasÄ±ndaki iletiÅŸim (weight) sayesinde dÃ¼ÅŸÃ¼nÃ¼r. Ki 'Artificial Neural Network' alanÄ± da tamamÄ±yla buradan ilham almÄ±ÅŸtÄ±r.LÃ¼tfen eksik veya yanlÄ±ÅŸ olduÄŸum bir yer varsa bilgilendiriniz ğŸ™‚3 weeks ago 2 people like this.Like ReportReply",
    "->  ->  AnladÄ±m, Ã§ok teÅŸekkÃ¼rler3 weeks ago Like ReportReply",
    "->  'Linear olmayan modeli hidden layer yardimiyla linear modele ceviriyoruz' ifadesi butunuyle yanlis.Hidden layer ekleyerek modelini daha komplex hale getirerek modelin daha fazla feature ogrenmesine olanak veriyorsun..Layer larinda kullandigin non-linear activation function ile non-lineariteyi yakalamis oluyorsun.3 weeks ago 3 people like this.Like ReportReply",
    "->  ->  DÃ¼zelttiÄŸiniz iÃ§in teÅŸekkÃ¼r ederim, haklÄ±sÄ±nÄ±z. SanÄ±rÄ±m soruyu sorarken cÃ¼mlemi doÄŸru kuramadÄ±m.3 weeks ago 1 person likes thisLike ReportReply",
    "->  Rica ederim ğŸ™‚3 weeks ago Like ReportReply",
    "->  Bu hataya bende sÄ±navda dÃ¼ÅŸtÃ¼m ğŸ™‚3 weeks ago Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "merhabalar, bu haftanÄ±n konusu deÄŸil ama aklÄ±ma takÄ±ldÄ±. Scale ve kategorik dÃ¶nÃ¼ÅŸtÃ¼rme(encoding) iÅŸlemlerini modeli split etmeden Ã¶nce mi yapmak gerekir yoksa split ettikten sonra mÄ±? EÄŸer split ettikten sonraysa y test ve train iÃ§in de bunlarÄ± yapmak gerekiyor mu?",
"comment": [
    "",
    "-> Evet,en azÄ±ndan kategorik dÃ¶nÃ¼ÅŸtÃ¼rmeyi kullanacaÄŸÄ±nÄ±z tÃ¼m veriler Ã¼zerinde gerÃ§ekleÅŸtirip,modelin iÅŸleyebilmesi iÃ§in encode en iyisidir. Scale iÅŸlemine gelirsek, y_test ve y_train gibi Label yani sÄ±nÄ±f-Ã§Ã¶zÃ¼m-Ã§Ä±kÄ±ÅŸ belirten setler,genellikte Encoding iÅŸlemi ile kullanÄ±ma hazÄ±r hale gelebilirler.Verisetindeki anlam,iÅŸlem yÃ¼kÃ¼,iÅŸlem hassasiyeti vs gibi parametlere gÃ¶re scale ve encoding iÅŸlemlerinin yeri deÄŸiÅŸebilir.Ancak kodlama esnasÄ±nda,en azÄ±ndan kendi gÃ¶rdÃ¼ÄŸÃ¼m ve yazdÄ±ÄŸÄ±m Ã¶rneklerde,ayÄ±rma iÅŸlemi yapÄ±ldÄ±ktan sonra Scale-Encoding-Preprocessing gibi iÅŸlemler yapÄ±lÄ±r,kodun okunabilirliÄŸi arttÄ±rÄ±lÄ±r. AyrÄ±ca,aynÄ± verisetinden split edilmiÅŸ alt-gruplarÄ±n farklÄ± iÅŸlemlere tabi tutulabileceÄŸini unutmamak lazÄ±m.KÄ±saca,tutorial ve state-of-art Ã§alÄ±ÅŸmalarÄ±nÄ± inceleyip,kendinize gÃ¶re bir yol haritasÄ± Ã§Ä±karmayÄ± denemenizi tavsiye ederim.Eksik veya yanlÄ±ÅŸ ifade ettiÄŸim bir ÅŸey varsa sÃ¶ylemekten Ã§ekinmeyin lÃ¼tfen ğŸ™‚3 weeks ago Like ReportReply",
    "->  ->  Ã§ok teÅŸekkÃ¼r ederim3 weeks ago 1 person likes thisLike ReportReply",
    " "
]
},
{
"question_isim": " -> ",
"quest": "Merhabalar, genel tekrar yaparken iki konuda anlamadÄ±ÄŸÄ±m yerler olduÄŸunu farkettim.  1-) playground exercise bÃ¶lÃ¼mlerinde turuncu ve mavi alanlar arasÄ±nda bazen Ã§ok net ve keskin bir beyaz Ã§izgi olurken bazen arada kalan bu beyaz alan daha geniÅŸ ve bulut gibi daÄŸÄ±nÄ±k olarak bulunuyor bunun anlamÄ± nedir?  2-) Sparse vektÃ¶r ve sparse representation kavramlarÄ±nÄ± tam oturtamadÄ±m. bir vektÃ¶r eÄŸer Ã§ok fazla zero iÃ§eriyorsa buna sparse vektÃ¶r diyoruz ancak sparse representation bunun tam tersi olarak sadece non-zero elemanlarÄ±n gÃ¶sterimi olarak karÅŸÄ±mÄ±za Ã§Ä±kÄ±yor. Burada anlam karmaÅŸasÄ± yaÅŸadÄ±ÄŸÄ±m bir yer olduÄŸunu ve gÃ¶zden kaÃ§Ä±rdÄ±ÄŸÄ±mÄ± dÃ¼ÅŸÃ¼nÃ¼yorum.  CevaplarÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederim.",
"comment": [
    "",
    "->  Merhaba,1. Modeliniz eÄŸitilirken eÄŸitim ve test seti random olarak daÄŸÄ±ldÄ±ÄŸÄ± iÃ§in eÄŸitiminiz her seferinde aynÄ± performansÄ± vermez. Bu yÃ¼zden her zaman aynÄ± sonucu elde edemezsiniz.3. Sparse VektÃ¶rÃ¼mÃ¼z one hot veya multi hot encoding vektÃ¶rÃ¼ olabilir ve iÃ§serisinde 0lara nazaran Ã§ok az 1 deÄŸeri vardÄ±r Ã§ok gereksiz 0 deÄŸeri vardÄ±r. Sparse representation'Ä±mÄ±z ise sparse vektÃ¶rlerdeki 0 olan deÄŸerleri deÄŸil 1 olan deÄŸerleri alÄ±p feature olarak kullanma iÅŸlemimizdir. Bunu yapma sebebimiz ise 0 olan deÄŸerlerin Ã§ok olduÄŸu bir vektÃ¶r hem performans hem de storage olarak problem oluÅŸturmaya yaklaÅŸmÄ±ÅŸ olacaktÄ±r.Ä°yi Ã§alÄ±ÅŸmalar.3 weeks ago 6 people like this.Like ReportReply",
    " ->  ->  cevaplar iÃ§in teÅŸekkÃ¼rler ancak birinci sorumu doÄŸru soramamÄ±ÅŸÄ±m sanÄ±rÄ±m. Ä°ki alan arasÄ±ndaki Ã§izginin net olmasÄ±ndan ne gibi bir anlam Ã§Ä±karabiliriz? mesela turuncu ve mavi arasÄ±ndaki beyaz alan ince bir Ã§izgi oluyorsa model daha iyi Ã¶ÄŸrenmiÅŸ veya karmaÅŸÄ±klÄ±ÄŸÄ± daha yÃ¼ksektir gibi bir yorum Ã§Ä±karmamÄ±z mÃ¼mkÃ¼n mÃ¼dÃ¼r?3 weeks ago Like ReportReply",
    "->   ->  Renk Ã§ok yoÄŸunsa modelimiz tahminlerini daha emin bir ÅŸekilde gerÃ§ekleÅŸtiriyoe, yoÄŸun deÄŸilse de tam tersini sÃ¶yleyebiliriz. Beyaz Ã§izgimiz hipotez fonksiyonumuzun grafiÄŸe dÃ¶kÃ¼lmÃ¼ÅŸ halidir ve tam emin olmamakla beraber bu alanÄ±n Ã§ok geniÅŸlemesi veya Ã§ok daralmasÄ± bu modelimizin performansÄ±nÄ±n kÃ¶tÃ¼ olduÄŸunu gÃ¶stermektedir.Ä°yi Ã§alÄ±ÅŸmalar.3 weeks ago 2 people like this.Like ReportReply",
    " ->  ->  cevaplarÄ±nÄ±z iÃ§in Ã§ok teÅŸekkÃ¼r ederim3 weeks ago 1 person likes thisLike ReportReply",
    " "
]
},
{
"question_isim": " -> uploaded 1 photo",
"quest": "Merhaba, bu kÄ±sÄ±mda neden native_country ve occupation'Ä± embeddings olarak alÄ±rken diÄŸerlerini one-hot encoding olarak aldÄ±k?",
"comment": [
    "",
    "->  Merhaba,Bunun nedeni indicator_column parametre olarak kategorik bir veri alÄ±r, embedding_column ise sparse bir vektÃ¶r alÄ±r.occupation = tf.feature_column.categorical_column_with_hash_bucket(\"occupation\", hash_bucket_size=1000)native_country = tf.feature_column.categorical_column_with_hash_bucket(\"native_country\", hash_bucket_size=1000)Kod satÄ±rlarÄ±nda bu iki feature iÃ§in possible range'i bilmememizden Ã¶tÃ¼rÃ¼ her bir feature deÄŸerini sayÄ± deÄŸerine Ã§evirmeyi amaÃ§lÄ±yoruz.Bu nedenle de bu iki feature deÄŸerimiz sparse vektÃ¶r olmuÅŸ oluyor ve embedding_column ile bu iki sparse vektÃ¶r olan feature deÄŸerlerini daha dÃ¼ÅŸÃ¼k boyutlu bir dÃ¼zleme oturtuyoruz.Ä°yi Ã§alÄ±ÅŸmalar.3 weeks ago 2 people like this.Like ReportReply",
    " ->  ->  buradaki hash_bucket dediÄŸimiz ÅŸey nedir? teÅŸekkÃ¼rler3 weeks ago Like ReportReply",
    "->   ->  Merhaba,https://community.globalaihub.com/community/status/687-687-1587030142/#comment.4200.4092.4092 yorumumda hash_bucket'Ä± anlatmÄ±ÅŸtÄ±m. AnlamadÄ±ÄŸÄ±nÄ±z bir yer olursa sorabilirsiniz.Ä°yi Ã§alÄ±ÅŸmalar.",
    
    " "
]
},
{
"question_isim": " -> ",
"quest": "Merhabalar herkese ve kolaylÄ±klar dilerim.LSTM- Long Short Term Memory networks nedir? Hangi durumlarda kullanÄ±rÄ±z? DÃ¶rt katmandan oluÅŸmasÄ±nÄ±n sebebi nedir? Tam anlayamadÄ±ÄŸÄ±m bir konu oldu.  AÃ§Ä±klamalar iÃ§in ÅŸimdiden Ã§ok teÅŸekkÃ¼r ederim. ",
"comment": [
    "",
    "->  AÅŸaÄŸÄ±daki urlye bak aradÄ±ÄŸÄ±n sorularÄ±n cevabÄ±nÄ± bulacaksÄ±n.https://devhunteryz.wordpress.com/2018/07/14/uzun-kisa-sureli-bellek-long-short-term-memory/Uzun-KÄ±sa SÃ¼reli Bellek (Long Short-TermÂ Memory)4 weeks ago 4 people like this.Like ReportReply",
    " ->  ->  teÅŸekkÃ¼r ederim3 weeks ago Like ReportReply",
    " "
]
},
{
"question_isim": " ->  uploaded 1 photo",
"quest": "Merhabalar, herkese kolay gelsin Ã¶ncelikle. Prediction bias konusunda kafama takÄ±lan birkaÃ§ soru var. California'daki ev fiyatlarÄ± Ã¶rneÄŸinden yola Ã§Ä±karsak evlerin gerÃ§ek ortalama fiyatlarÄ± ile bizim tahmin ettiÄŸimiz fiyatlarÄ±n ortalamasÄ± aynÄ± Ã§Ä±karsa prediction biasÄ±mÄ±z 0 olur gibi bir sonuca vardÄ±m yanlÄ±ÅŸ anlamadÄ±ysam. Ancak ortalama deÄŸer kullandÄ±ÄŸÄ±mÄ±z iÃ§in aslÄ±nda her bir Ã¶rneÄŸi tek tek ele aldÄ±ÄŸÄ±mÄ±zda Ã§Ä±kacak hatalarÄ± gÃ¶zden kaÃ§Ä±rmÄ±ÅŸ oluyoruz. 40 -60 ile 10-90 ikililerinin ortalamasÄ±nÄ±n aynÄ± olmasÄ± gibi. Bu yÃ¼zden prediction biasÄ±n sonucunu yorumlarken neye dikkat etmeliyiz? AyrÄ±ca ortalamalarÄ±n bir fonksiyonu olmasÄ±na raÄŸmen positive labellarÄ±n frekansÄ±(sÄ±klÄ±ÄŸÄ±) ile ilgili bilgiye bizi nasÄ±l yÃ¶nlendiriyor? AralarÄ±ndaki iliÅŸkiyi Ã§Ã¶zebilmiÅŸ deÄŸilim, yardÄ±mcÄ± olabilirseniz sevinirim.",
"comment": [
    "",
    "->  Merhaba, dediÄŸiniz gibi hatalarÄ± gÃ¶zden kaÃ§Ä±rabiliriz. o yÃ¼zden 0 olmasÄ± modelimizin mÃ¼kemmel olduÄŸu hakkÄ±nda saÄŸlÄ±klÄ± bir bilgi veremez. ancak 0'a uzak bir deÄŸer elde edersek modelimizin yanlÄ±ÅŸ olduÄŸunu belirleyebiliriz. doÄŸruluÄŸu deÄŸil de problemi tespit etmek iÃ§in kullanÄ±lÄ±yor diye dÃ¼ÅŸÃ¼nÃ¼yorum. positive label iÃ§in ise; prediction bias kavramÄ± logistic regression baÅŸlÄ±ÄŸÄ±nda anlatÄ±lmÄ±ÅŸ. logistic regressionda binary classification yapÄ±yorduk. dolayÄ±sÄ±yla deÄŸerlerimiz 0 ve 1 olduÄŸunda ve ortalamasÄ±nÄ± aldÄ±ÄŸÄ±mÄ±zda direkt olarak positive labellarÄ±n frekansÄ± hakkÄ±nda bir fikir edinebiliriz. prediction bias 0.20 Ã§Ä±karsa olduÄŸundan daha fazla positive tahmin yapmÄ±ÅŸÄ±z diyebiliriz mesela.4 weeks ago 3 people like this.Like ReportReply",
    " ->  ->  Ã§ok teÅŸekkÃ¼rler3 weeks ago 1 person likes thisLike ReportReply",
    "->  Sizin verdiÄŸiniz Ã¶rnekten yola Ã§Ä±karsak gerÃ§ek deÄŸerlerin ortalamasÄ±nÄ±n 50 olduÄŸu bir veride 40-60 ve 10-90 tahminlerini Ã¼reten modellerin ikisinde de prediction bias = 0 dÄ±r. Fakat ikincisinde prediction variance Ã§ok daha yÃ¼ksek. Ä°lk model daha iyidir diyebiliriz. Hatta 51-52 tahminlerini Ã¼reten bir model, kÃ¼Ã§Ã¼k bir pred.bias ortaya Ã§Ä±karsa bile prediction variance neredeyse sÄ±fÄ±r olduÄŸu iÃ§in daha kabul edilebilirdir.4 weeks ago 1 person likes thisLike ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar, 2.haftanÄ±n quizi ile ilgili bir sorum vardÄ±. 8.soruda sparse representationlarÄ± ne zaman kullandÄ±ÄŸÄ±mÄ±zÄ± sormuÅŸ ve cevap olarak da \"When data size is large and most of feature value that we are interested in is zero. \" demiÅŸ. Ancak aÃ§Ä±klama kÄ±smÄ±nda yalnÄ±zca sÄ±fÄ±r olmayanlarÄ±n depolanmasÄ±ndan bahsettmiÅŸ. Sadece sÄ±fÄ±r olmayanlarÄ± depoluyorsak non-zero olanlarla ilgileniyor olmaz mÄ±yÄ±z? Bu kÄ±sÄ±m biraz kafamÄ± karÄ±ÅŸtÄ±rdÄ±. Åimdiden aÃ§Ä±klamanÄ±z iÃ§in teÅŸekkÃ¼rler.",
"comment": [
    "",
    "->  GÃ¶kÃ§e merhaba,\"When data size is large and most of feature value that we are interested in is zero.\" ile anlatÄ±lmak istenen, datadaki Ã§oÄŸu feature'Ä±n sÄ±fÄ±r olmasÄ± durumu. DediÄŸin gibi non-zero olanlarla ilgilenmiÅŸ oluyoruz, aÃ§Ä±klama kÄ±smÄ±ndan anladÄ±ÄŸÄ±n doÄŸru.Verilen ÅŸÄ±kkÄ±n anlamÄ± ile ilgili bir yanlÄ±ÅŸ anlaÅŸÄ±lma var sanÄ±rÄ±m.4 weeks ago Like ReportReply",
    "->  ->  YardÄ±mlarÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederim3 weeks ago Like ReportReply",
    "->  Merhabalar, ne zaman ve niÃ§in seyrek (sparse) gÃ¶sterim kullanÄ±lÄ±r sorusunun cevabÄ±nÄ± gÃ¶rsel olarak ekledim. Burada seyrek gÃ¶sterimin amacÄ± Ã§ok fazla sayÄ±da niteliÄŸin (feature) deÄŸerinin sÄ±fÄ±r olmasÄ± ve veri setimizinde bÃ¼yÃ¼k olduÄŸu durumlarda kullanÄ±lmaktadÄ±r. Senin sorunun cevabÄ±, bir Ã§ok nitelik sÄ±fÄ±r olduÄŸu iÃ§in (beni ilgilendiren durum) geri kalan az miktarda niteliÄŸi saklÄ±yorum. Tersten bakarsak eÄŸer bir Ã§ok deÄŸer sÄ±fÄ±r olmasaydÄ± (yine beni ilgilendiren durum) seyrek gÃ¶sterim kullanamazdÄ±m. Yani burada az sayÄ±da niteliÄŸimiz sÄ±fÄ±r olmadÄ±ÄŸÄ± iÃ§in deÄŸil,Ã§ok sayÄ±da niteliÄŸimiz sÄ±fÄ±r olduÄŸu iÃ§in seyrek (sparse) gÃ¶sterim kullanÄ±lÄ±yor. UmarÄ±m aÃ§Ä±k olmuÅŸtur ğŸ™‚4 weeks ago Like ReportReply",
    "->  ->  TeÅŸekkÃ¼rler ğŸ™‚3 weeks ago 1 person likes thisLike ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba arkadaÅŸlar, Embeddings&gt;Obtaining Embeddings bÃ¶lÃ¼mÃ¼nde yer alan \"Training an Embedding as Part of a Larger Model\" kÄ±smÄ±nÄ± pek anlayamadÄ±m. YardÄ±mcÄ± olabilir misiniz?",
"comment": [
    "",
    "->  Merhaba,Word2vec iÅŸleminin amacÄ± sÄ±nÄ±flandÄ±rma yapmak deÄŸil kelimelerimizi numerik veriye Ã§evirmektir. Word2vec iÅŸlemi sonucunda embedding elde ederiz. Bu word2vec iÅŸlemini daha geniÅŸ bir modelimizin bir parÃ§asÄ± olarak kullanabiliriz. Bu yaklaÅŸÄ±mla daha Ã¶zelleÅŸtirilmiÅŸ bir embedding elde ederiz ancak bu iÅŸ embedding'in ayrÄ± eÄŸitilmesine oranla daha uzun sÃ¼rer.https://developers.google.com/machine-learning/crash-course/embeddings/obtaining-embeddings sayfasÄ±ndaki figÃ¼r 5'te pembe nÃ¶ronlar ekstra embedding katmanÄ±mÄ±z olup diÄŸer feature ve hidden layerlarla da birleÅŸtirilebilirler bÃ¶ylece modelimiz daha Ã¶zelleÅŸtirilmiÅŸ bir embeddinge sahip olur. Embedding layerÄ±mÄ±zdan Ã§Ä±kan sonucumuz numerik olur. Burada kÄ±sacasÄ± embedding iÅŸlemi yapan yeni bir hidden layerÄ± modelimize yerleÅŸtirdik bÃ¶ylece daha bÃ¼yÃ¼k bir modelin parÃ§asÄ± olarak embedding iÅŸlemini gerÃ§ekleÅŸtirmiÅŸ olduk.Ä°yi Ã§alÄ±ÅŸmalar.",
    "Embeddings: Obtaining Embeddings Â |Â  Machine Learning Crash Coursedevelopers.google.comhttps://developers.google.com/machine-learning/crash-course/embeddings/obtaining-embeddings3 weeks ago 2 people like this.Like ReportReply",
    "-> ->  Bu yapÄ±yÄ± anlamakta gÃ¼Ã§lÃ¼k Ã§ekiyorum. Buradan sormanÄ±n daha uygun olacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼ndÃ¼m.3 weeks ago Like ReportReply",
    "->  ->  teÅŸekkÃ¼r ederim ÅŸimdi anladÄ±m.3 weeks ago 1 person likes thisLike ReportReply",
    "->  -> Merhaba yorumunuzu geÃ§ farkettim kusuruma bakmayÄ±n.Bu yapÄ± bizim modelimizin yapÄ±sÄ±. Modelimizde kullanÄ±cÄ±larÄ±n filmler i ve diÄŸer featurelarÄ± belirlediÄŸimiz 3 boyutlu embedding iiÅŸlemine sokup 3 boyutlu dÃ¼zleme indirgiyoruz. Burada pembe nÃ¶ronlar ekstra embedding katmanlarÄ±mÄ±z olur. Bu katmanlar sayesinde embedding daha Ã¶zelleÅŸtirilmiÅŸ olur. Burada logits dediÄŸimiz katman softmax katmanÄ±mÄ±zdÄ±r yani sonuÃ§ katmanÄ±. Softmax seÃ§ilen softmax tipine gÃ¶re (full veya candidate) belli output seti iÃ§in bir probabilty hesaplamasÄ± yapar. Bu softmax sonuÃ§larÄ±yla saÄŸdaki sarÄ±msÄ± dikdÃ¶rtgenin temsil ettiÄŸi gerÃ§ek deÄŸerlerini kÄ±yaslarÄ±z ve softmax loss hesaplarÄ±z.Ä°yi Ã§alÄ±ÅŸmalar.3 weeks ago Like ReportReply",
    " "
]
},
{
"question_isim": " -> uploaded 1 photo",
"quest": "Merhaba, Embeddings: Translating to a Lower-Dimensional Space kÄ±smÄ±nda biraz kafam karÄ±ÅŸtÄ±. Bag of words'un embedding ile iliÅŸkisini ve matrix multiplication'u anlayamadÄ±m. YardÄ±mcÄ± olabilir misiniz? TeÅŸekkÃ¼r ederim. <a class=\"ps-media-link\" href=\"https://developers.google.com/machine-learning/crash-course/embeddings/translating-to-a-lower-dimensional-space\" rel=\"nofollow\" target=\"_blank\">https://developers.google.com/machine-learning/crash-course/embeddings/translating-to-a-lower-dimensional-space</a>",
"comment": [
    "",
    "->  Merhaba, matrix multiplication'u Ã¶zet olarak Ã§izmeye Ã§alÄ±ÅŸtÄ±m, umarÄ±m okunur4 weeks ago 13 people like this.Like ReportReply",
    " -> ->  TeÅŸekkÃ¼r ederim ğŸ™‚3 weeks ago 1 person likes thisLike ReportReply",
    "-> Merhaba,Ã–ncelikle Word Embedding'i aÃ§Ä±klayayÄ±m. Word Embedding kelimeleri daha dÃ¼ÅŸÃ¼k boyutlu bir dÃ¼zleme oturtup (vektÃ¶r olarak) bu vektÃ¶rler arasÄ±nda matematiksel iÅŸlemler yaptÄ±kÃ§a yeni anlamlÄ± vektÃ¶rler(bunlara diÄŸer textler de diyebiliriz) elde ettiÄŸimiz bir NLP sÃ¼recidirMakine Ã¶ÄŸrenmesi algoritmamÄ±z plain textleri olduklarÄ± formunda iÅŸleyemediÄŸinden word embedding yÃ¶ntemine baÅŸvuruyoruz.Burada word embedding ile textlerin dil anlamlarÄ±nÄ± oldukÃ§a yakalamaya Ã§alÄ±ÅŸÄ±yoruz.Her bir wordÃ¼mÃ¼z kategorik bir veriydi ve bunlarÄ± one hot-multi hot encoding ile numerik veriye Ã§evirerek iÅŸleme sokabilirdik ama bu sefer de oluÅŸacak sparse vektÃ¶rÃ¼mÃ¼z performans sorunlarÄ±na yol aÃ§acaktÄ±.(Ã¶rneÄŸin 100000000 kelimelik bir dictionarynizde cat kelimesini one hot encoding ile gÃ¶stermek istediÄŸinizde vektÃ¶rÃ¼nÃ¼zde sadece 1 adet 1 deÄŸeriniz ve 99999999 tane 0 deÄŸeri olacaktÄ±r ve elinizde sparse bir vektÃ¶r olacaktÄ±r)Ã–rneÄŸin ÅŸÃ¶yle bir cÃ¼mlemiz olsun: \"Word Embedding kelimeleri numaralara Ã§evirir.\"Dictionary: CÃ¼mlemizdeki unique kelimeler listesi. YukarÄ±daki cÃ¼mlemize gÃ¶re dictionary'miz: ['Word','Embedding','kelimeleri','numaralara','Ã§evirir']VektÃ¶rlerimizi One Hot Encoding kullanarak gÃ¶sterebiliriz Ã¶rneÄŸin numaralara kelimesi iÃ§in vektÃ¶rÃ¼mÃ¼z: [0,0,0,1,0] olur. Tek bir kelime Ã¶ÄŸesi iÃ§in dense vektÃ¶rÃ¼ elde etmek iÃ§in, o Ã¶ÄŸeye karÅŸÄ±lÄ±k gelen sÃ¼tunu alÄ±rsÄ±nÄ±z.Sparse multi-hot encoding tÃ¼rÃ¼nde olan bir vektÃ¶rÃ¼ Ã§evirebilmeniz iÃ§in her embeddingi alÄ±p bunlarÄ± birbiriyle toplayabilirsiniz.Count Vector cÃ¼mlenizde unique kelimelerin tekrar sayÄ±sÄ±nÄ± tutar. Ã–rneÄŸin elimizde aÅŸaÄŸÄ±daki gibi bir dictionary'miz olsun:['mÃ¼dÃ¼r','gerÃ§ekten','kedi']Ã–rneÄŸin \"mÃ¼dÃ¼r gerÃ§ekten mÃ¼dÃ¼r mÃ¼dÃ¼r\" sorusunu count vector'e Ã§evirdiÄŸimizde:['mÃ¼dÃ¼r','gerÃ§ekten','kedi']3 1 0Burada sÃ¶ylenen de eÄŸer bu vektÃ¶rÃ¼ dense vektÃ¶re Ã§evirmek istersek her birininn embeddingini almadan Ã¶nce gÃ¶rÃ¼ntÃ¼lenme sayÄ±sÄ± kadar Ã§arpabiliriz. Burada bu toplama ve Ã§arpma iÅŸlemi aslÄ±nda vektÃ¶r toplama ve Ã§arpÄ±mÄ±dÄ±r. Matrix Ã§arpÄ±mÄ± kuralÄ±na gÃ¶re ilk vektÃ¶rÃ¼nÃ¼z(sparse'Ä±mÄ±z) 1xM boyuttaysa ve ikinci vektÃ¶rÃ¼nÃ¼z(Embedding'imiz) MxN boyuttaysa Ã§arpÄ±m sonucu 1xN boyutta olur.Not: -> 'Ä±n eklemeleriyle aÃ§Ä±klama yeniden dÃ¼zenlenmiÅŸtir.Ä°yi Ã§alÄ±ÅŸmalar.3 weeks ago 6 people like this.Like ReportReply",
    " -> TeÅŸekkÃ¼r ederim ğŸ™‚ -> 3 weeks ago Like ReportReply",
    "->  ->  Burada embedding konusunda yaptiginiz aciklamalar maalesef pek saglikli degil Bu sebeple bu aciklamanin baska arkadaslara tavsiye edilmesini dogru bulmuyorum.3 weeks ago Like ReportReply",
    "->  ->  Merhaba,EleÅŸtiriniz iÃ§in teÅŸekkÃ¼r ederim. SaÄŸlÄ±klÄ± olmadÄ±ÄŸÄ±nÄ± dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼nÃ¼z yerde bana yardÄ±mcÄ± olmanÄ±zÄ± ve ben de size olabileceksem yardÄ±mcÄ± olmaya Ã§alÄ±ÅŸmak isterim. EÄŸer yardÄ±mcÄ± olamayacaksam da mutlaka yerime yardÄ±mcÄ± olacaklardÄ±r.3 weeks ago 1 person likes thisLike ReportReply",
    "->  ->  Word embedding taniminizi ve neden word embedding kullaniyoruz konusundaki aciklamalarinizda sorun var.Sorun tam olarak 'word embedding icin textleri numerik yapiya cevirmemizdir ' cumlesi ve 'Makine Ã¶ÄŸrenmesi algoritmamÄ±z plain textleri olduklarÄ± formunda iÅŸleyemediÄŸinden word embedding yÃ¶ntemine baÅŸvuruyoruz.'cumleleridir.3 weeks ago Like ReportReply",
    "-> ->  DÃ¼zeltmeleriniz ve yorumunuz iÃ§in Ã§ok teÅŸekkÃ¼r ederim.Burada word embeddingin text'i numerik yapÄ±ya Ã§evirmek iÃ§in olduÄŸunu sÃ¶ylediÄŸimde aslÄ±nda bu textlerin dil anlamlarÄ±nÄ± oldukÃ§a yakalamaya Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±zÄ± da eklemeliydim. Burada makine Ã¶ÄŸrenmesi algoritmamÄ±z textleri(kategorik veri olduklarÄ± iÃ§in) one veya multi hot encoding kullanarak da eÄŸitebilirdi fakat bu sparse vektÃ¶r sorununa yol aÃ§ardÄ± bu yÃ¼zden bunun yerine word embedding tercih ediyoruz demeliydim. Son olarak Word embedding iÃ§in kelimeleri daha dÃ¼ÅŸÃ¼k boyutlu bir dÃ¼zleme oturtup (vektÃ¶r olarak) bu vektÃ¶rler arasÄ±nda matematiksel iÅŸlemler yaptÄ±kÃ§a yeni anlamlÄ± vektÃ¶rler(bunlara diÄŸer textler de diyebiliriz) elde ettiÄŸimiz bir NLP sÃ¼recidir diye de bahsetmeliydim. Halen yanlÄ±ÅŸlarÄ±m var ise dÃ¼zeltmenizden ve doÄŸrularÄ±nÄ± Ã¶ÄŸrenmekten memnun olurum, eÄŸer yanlÄ±ÅŸÄ±m yoksa yukarÄ±daki cevabÄ±mÄ± bu ÅŸekilde gÃ¼ncellemek isterim.Ä°yi Ã§alÄ±ÅŸmalar.3 weeks ago Like ReportReply",
    "->  ->  Bu aciklamanizda one hot coding veya multi one codig kullanmak sparse vektor sorununa yol acar kisminda sorun var.Sparse vektor sorunu diye bir sorun yok Sorun curse of dimensionality olabilir.3 weeks ago Like ReportReply",
    "->  Embedding konusunu duzgun Turkce kelimelerle anlatabilecegim bir yaziya basladim ancak Turkce ifade etmek kolay degil.Ama yazimi tamamlayip paylasacagim3 weeks ago Like ReportReply",
    "->  ->  ÅÃ¶yle ki bu problemde Ã§ok fazla kelime iÃ§eren bir dictionaryniz varsa bu kelimeleri one hot encoding ile ifade etmek sparse sorununa yol aÃ§acaktÄ±r Ã¶rneÄŸin 100000000 kelimelik bir dictionarynizde cat kelimesini one hot encoding ile gÃ¶stermek istediÄŸinizde vektÃ¶rÃ¼nÃ¼zde sadece 1 adet 1 deÄŸeriniz ve 99999999 tane 0 deÄŸeri olacaktÄ±r ve elinizde sparse bir vektÃ¶r olacaktÄ±r bu da performans problemlerine yol aÃ§acaktÄ±r. Sparse vektÃ¶r sorunundan kastÄ±m buydu. YazÄ±nÄ±zÄ± sabÄ±rsÄ±zlÄ±kla bekliyorum okuyup bilmediklerimi Ã¶ÄŸrenmek isterim ama ÅŸu an hatalarÄ±mÄ± dÃ¼zeltip burada kurs alan arkadaÅŸlarÄ±ma bilgiyi daha hÄ±zlÄ± iletmek isterim. YazÄ±m sÃ¼resince kolaylÄ±klar ve iyi Ã§alÄ±ÅŸmalar dilerim.3 weeks ago 2 people like this.Like ReportReply",
    "->  ->  Tesekkur ederim3 weeks ago 1 person likes thisLike ReportReply",
    " "
]
},
{
"question_isim": " -> ",
"quest": "Merhabalar, Embeddings bÃ¶lÃ¼mÃ¼nde \"Lack of meaningfull \" kÄ±smÄ±nda  anlatÄ±lmak istenileni tam anlayamadÄ±m. Bu kÄ±sÄ±mda yardÄ±mcÄ± olabilir misiniz?",
"comment": [
    "",
    "-> Merhaba,Lack of Meaningful Relations Between Vectors, Sparse representation'da oluÅŸabilecek problemlerden biridir. Ã–rneÄŸin siz RGB kanallarÄ±nÄ±n piksel deÄŸerlerini image sÄ±nÄ±flandÄ±rÄ±cÄ±sna sokarsanÄ±z vektÃ¶rlerin yakÄ±nlÄ±klarÄ±ndan sÃ¶z etmek mantÄ±klÄ± olur. Ã–rneÄŸin kÄ±rmÄ±zÄ±msÄ± mavi saf maviye daha yakÄ±n olur. Bu yakÄ±nlÄ±k hem anlamsal bir yakÄ±nlÄ±k hemde dÃ¼zlemdeki geometrik yakÄ±nlÄ±ktÄ±r.Ancak \"at\" iÃ§in 1247. indeksi 1 olan bir vektÃ¶r, \"antilop\" iÃ§in 50.430. indeksi 1 olan bir vektÃ¶re \"televizyon\" iÃ§in 238. indeksinde 1 olan bir vektÃ¶re yakÄ±n olduÄŸu kadar olmayacaktÄ±r. Yani at, televizyona daha yakÄ±n olacaktÄ±r ama antilopa daha yakÄ±n olmasÄ± gerkiyordu mantÄ±k olarak.BunlarÄ± da embedding yaparak aÅŸabiliriz. Embeddingde kendi belirlediÄŸimiz boyut kadar dÃ¼zleme tÃ¼m eÄŸitim Ã¶rneklerimizi oturtturup yakÄ±nlÄ±klarÄ±na gÃ¶re tahminlerde bulunuyoruz. Burada kendi belirlediÄŸimiz dÃ¼zlem boyutlarÄ± sayesinde filmleri daha sistematik ÅŸekilde daha kÃ¼Ã§Ã¼k boyutlu bir dÃ¼zleme oturtuyoruz.Ä°yi Ã§alÄ±ÅŸmalar.4 weeks ago 7 people like this.Like ReportReply",
    " ->  ->  TeÅŸekkÃ¼r ederim, bÃ¶yle daha aÃ§Ä±k oldu4 weeks ago Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Herkese Merhaba!  Biraz gecikmeli, 3. hafta soru cevaplarÄ±na aÅŸaÄŸÄ±daki linkten ulaÅŸabilirsiniz ğŸ˜Š  Son haftaya girdik, hepinize keyifli haftalar, iyi Ã§alÄ±ÅŸmalarğŸ™ŒğŸŒŸ  ğŸ‘‰ğŸ‘‰https://community.globalaihub.com/mlcc_week3-qas/",
"comment": [
    "",
    "->   Elinize saÄŸlÄ±k, teÅŸekkÃ¼rler4 weeks ago 1 person likes thisLike ReportReply",
    "-> -> TeÅŸekkÃ¼rler3 weeks ago Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar herkese , embeddings kÄ±sÄ±mÄ±nÄ± kafamda tam oturtamadÄ±m . AnladÄ±ÄŸÄ±m kadarÄ± ile daha iyi bir prediction iÃ§in uzay Ã¼zerinde aÄŸÄ±rlÄ±klarÄ±na gÃ¶re vektÃ¶rler belirliyoruz . BÃ¶ylelikle daha rahat sÄ±nÄ±flandÄ±rabiliyor ve feature'lar arasÄ±ndaki iliÅŸkiyi daha net gÃ¶rebiliyoruz. Bundan sonrasÄ±nda bunu yapmak iÃ§in modelimizde tam olarak ne yaptÄ±ÄŸÄ±mÄ±zÄ± ve Ã¶zellikle \"Embeddings: Translating to a Lower-Dimensional Space\" , \"Embeddings: Translating to a Lower-Dimensional Space\" kÄ±sÄ±mlarÄ±nÄ± tam olarak oturtamadÄ±m yardÄ±mcÄ± olabilirseniz Ã§ok sevinirim , ÅŸimdiden teÅŸekkÃ¼r ederim...",
"comment": [
    "",
    "-> Merhaba,Embedding kullanÄ±lan senaryolarda input deÄŸerlerimiz continuosu bir valur deÄŸil discrete bir deÄŸerdir. Yani inputlarÄ±mÄ±zÄ±n Ã§eÅŸitliliÄŸi sÄ±nÄ±rlÄ±dÄ±r Ã¶rneÄŸin kullanÄ±cÄ±nÄ±n izlediÄŸi filmlere gÃ¶re bir Ã¶neri yapma modelimizde inputlarÄ±mÄ±z bizim izlediÄŸimiz filmler olacaktÄ±r ve bu filmler de sistemde tanÄ±mlÄ± olan filmlerden biri olmak zorundadÄ±r.Burada bu Ã¶neri sistemini kullanabilmek adÄ±na elimizdeki filmleri bir dÃ¼zleme oturtup farklÄ± Ã¶zelliklere gÃ¶re kategorilendirmemiz daha saÄŸlÄ±klÄ± olacaktÄ±r. TÃ¼m bu kategoriler bir boyutu temsil eder Ã¶rneÄŸim filmlerimizi (YaÅŸ kategorisi, ve filmin korku olup olmadÄ±ÄŸÄ±) bu iki kategoride ele almak istersek iki boyutlu bir dÃ¼zlemde filmlerimizi yerleÅŸtirmiÅŸ oluruz. Burada yaptÄ±ÄŸÄ±mÄ±z elimizdeki input deÄŸerlerini daha az boyutlu (2,3 veya daha fazla boyut sayÄ±sÄ± size kalmÄ±ÅŸ) bir dÃ¼zlemde inceleyebilmek ve birbirilerine yakÄ±nlÄ±klarÄ±na gÃ¶re aynÄ± kefeye koyabilmek. Burada birbirine yakÄ±n olarak konumlandÄ±rÄ±lan filmleri Ã¶nerebilirsiniz. Ã–rneÄŸin Silent Hill filmi korku tÃ¼rÃ¼nde ve yaÅŸ sÄ±nÄ±rlamasÄ± +18 olan bir filmdir. Star Wars ise Fantastik ve Silent Hill filmine gÃ¶re hiÃ§ korkunÃ§ deÄŸildir bu yÃ¼zden dÃ¼zlemimizde ilgili eksenin korku tarafÄ±na gÃ¶re negatif tarafÄ±nda olacaktÄ±r. (https://developers.google.com/machine-learning/crash-course/embeddings/motivation-from-collaborative-filtering#arrange-movies-in-a-two-dimensional-space altÄ±ndaki resmi 2 boyutlu olarak Ã¶rnek alabilirsiniz.) Bu yÃ¼zden de Silent Hill filmini izlemiÅŸ birine Star Wars filmini Ã¶nermezsiniz. GerÃ§ek dÃ¼nyada bu saydÄ±ÄŸÄ±m iki kriterden Ã§ok daha fazla kriter vardÄ±r hatta filmin aÃ§Ä±klamasÄ± bile bir kriter sayÄ±labilir. KÄ±sacasÄ± embedding dediÄŸimiz ÅŸey bÃ¼yÃ¼k sparse (iÃ§inde Ã§ok 0 ve az 1 bulunan vektÃ¶rler) vektÃ¶rleri aralarÄ±ndaki semantic iliÅŸkiyi koruyarak daha dÃ¼ÅŸÃ¼k boyutlu bir dÃ¼zlemde gÃ¶sterir. Bir diÄŸer tanÄ±mÄ± ise kategorik inputlarÄ± continuous valuelara Ã§evirir diye yapabiliriz. Ã‡Ã¼nkÃ¼ dÃ¼zlemdeki konumlarÄ± bir nokta ifade edecek ve bu noktalar artÄ±k ilgili kategorik verimizi tanÄ±mlayan deÄŸer olacaktÄ±r. (Boyut sayÄ±sÄ± ve kadar fazlaysa noktanÄ±n bileÅŸenleri daha fazladÄ±r Ã¶rneÄŸin 2 boyutlu embeddingde bir input deÄŸerimizi x1,x2 ile tanÄ±mlayabiliyorken 3 boyutlu embeddingde bu x1,x2,x3 olacaktÄ±r.)Embeddings: Translating to a Lower-Dimensional Space kÄ±smÄ±nda ise yukarÄ±da bahsettiÄŸim gibi yÃ¼ksek boyutlu verilerinizi daha dÃ¼ÅŸÃ¼k boyutlu bir alana eÅŸleyerek sparsity sorunlarÄ±nÄ± Ã§Ã¶zebilirsiniz. Bu yeni oluÅŸacak dÃ¼zlemde artÄ±k bulunan noktalarÄ±mÄ±zÄ±n (eÄŸitim setimizden Ã¶rnekler Ã¶rneÄŸin film eÄŸitim setimizden Braveheart) birbirilerine olan uzaklÄ±klarÄ± baz alÄ±narak iÅŸlem yapÄ±lacaktÄ±r. Ã–rneÄŸin Silent Hill ve Star Wars filmlerinin birbirine bu dÃ¼zlemde yakÄ±n olmalarÄ±nÄ± beklemeyiz. Pozisyon, semantiÄŸe gÃ¶re verileri ayÄ±rabilir. Bu semantik ayÄ±rmasÄ± da makine Ã¶ÄŸrenmesi algoritmamÄ±zÄ±n Ã¶ÄŸrenmeye yararÄ± bÃ¼yÃ¼k olan belli patternleri de tespit etmesine yardÄ±mcÄ± olur. YalnÄ±z burada dimension sayÄ±sÄ±na dikkat etmemiz lazÄ±m ne Ã§ok bÃ¼yÃ¼k ne de Ã§ok az olmalÄ±. Ã‡ok bÃ¼yÃ¼k olmasÄ± Ã¶ÄŸrenmeyi daha da iyileÅŸitirirken sÃ¼reden ve kaynaktan gÃ¶tÃ¼rÃ¼r, Ã‡ok kÃ¼Ã§Ã¼k olmaÄ±s ise hÄ±zÄ± arttÄ±rÄ±r ama eÄŸitim tam anlamÄ±yla performanslÄ± olmaz. Her bir embedding aslÄ±nda iÃ§indeki deÄŸerlerin vektÃ¶r hallerini kapsar. Ã–rneÄŸin 2 boyutlu dÃ¼zlemimizde spider man filmi bizim film listemizde 2.sÄ±radaysa ve bizim 9999 filmimiz varsa [[0.2,1.2],[1.3,4],,....[-17,17.6] olacaktÄ±r. (Spider-man [1.3,4] noktasÄ±ndadÄ±r. Elinizde birden fazla film iÃ§eren bir sprase vektÃ¶r varsa buradaki 1 olan deÄŸerlerin hepsi iÃ§in ayrÄ± ayrÄ± embedding alÄ±p bunlarÄ± toplayabilirsiniz.EÄŸer yanlÄ±ÅŸÄ±m varsa dÃ¼zeltilmesinden memnun olurum.Ä°yi Ã§alÄ±ÅŸmalar dilerim.4 weeks ago 15 people like this.Like ReportReply",
    "->  AyrÄ±ntÄ±lÄ± ve anlaÅŸÄ±lÄ±r bir aÃ§Ä±klama olmuÅŸ . Ã‡ok TeÅŸekkÃ¼r ederim , iyi Ã§alÄ±ÅŸmalar dilerim4 weeks ago 2 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba arkadaÅŸlar, sizin iÃ§inde faydalÄ± olacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼ndÃ¼yÃ¼m makaleyi paylaÅŸÄ±yorum. Ä°yi okumalar ğŸ™‚   <a class=\"ps-media-link\" href=\"https://hackernoon.com/memorizing-is-not-learning-6-tricks-to-prevent-overfitting-in-machine-learning-820b091dc42\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">https://hackernoon.com/memorizing-is-not-learning-6-tricks-to-prevent-overfitting-in-machine-learning-820b091dc42</a>",
"comment": [
    "",
    " -> TeÅŸekkÃ¼rler ğŸ™‚ B-> 4 weeks ago 1 person likes thisLike ReportReply",
    "->   -> ğŸ™‚4 weeks ago Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "merhaba, programming exercise kÄ±sÄ±mlarÄ±nÄ± uygulamakta zorlanÄ±yorum yani ne yapacaÄŸÄ±mÄ±zÄ± anlayamadÄ±m, yardÄ±mcÄ± olabilir misiniz?",
"comment": [
    "",
    "->  verilen kodlarÄ± Ã§alÄ±ÅŸtÄ±rÄ±p sonuÃ§larÄ± gÃ¶rÃ¼p kodlarÄ± gÃ¶revlere uygun bir ÅŸekilde yeniden yazman isteniyo4 weeks ago 1 person likes thisLike ReportReply",
    "->  Merhaba,Bu kÄ±sÄ±mlarda kodun mantÄ±ÄŸÄ±nÄ± anlayÄ±p kurs boyunca Ã¶ÄŸrendiklerimizin koda dÃ¶kÃ¼lmÃ¼ÅŸ halini gÃ¶rÃ¼yoruz. Ã–rneÄŸin o sectionda Feature Crosses konusunu iÅŸlediysek o konunun teorisinn yanÄ±nda pratiÄŸinde de veriler ve makine Ã¶ÄŸrenmesi modelimiz Ã¼zerindeki etkilerini gerÃ§ek zamanlÄ± gÃ¶rebiliyoruz. Bazen bazÄ± boÅŸluklar bizim tarafÄ±mÄ±zdan doldurulmak isteniyor biz de bu boÅŸluklarÄ± farklÄ± deÄŸerlerle doldurup o deÄŸerlerin modelimize etkisini Ã¶lÃ§ebilme imkanÄ±na sahip olabiliyoruz.Ä°yi Ã§alÄ±ÅŸmalar.4 weeks ago 1 person likes thisLike ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba, Embedding'i tam olarak oturmadÄ±. YardÄ±mcÄ± olabilir misiniz?",
"comment": [
    "",
    "-> Evet beni de Ã§ok zorladÄ±. Bu konuda biraz aÃ§Ä±klama yapÄ±lÄ±rsa memnun olurum.4 weeks ago 1 person likes thisLike ReportReply",
    "->  1xN bir sparse vector'Ã¼ NxM bir embedding table ile Ã§arpÄ±p 1xM dense vector elde ederiz diyor ama bu embedding table'Ä±n dnn'de nasÄ±l hesaplandÄ±ÄŸÄ±nÄ± anlayamadÄ±m.4 weeks ago Like ReportReply",
    "->  Embedding konusunu ben de anlayamadÄ±m. FarklÄ± kaynaklardan yararlanmamÄ±z gerekecek.4 weeks ago Like ReportReply",
    "->  Embeddings temelde bir kategorik deÄŸiÅŸkenin mappingini ifade ediyor. AslÄ±nda olay manaya matematik katabilmek. Ã–rneÄŸin; King - Man + Women = Queen demek gibi aslÄ±nda. Bu yÃ¶ntemi One-hot encode vs ile yaparsam anlam iÅŸin iÃ§inde olmuyor. Ben basitÃ§e bÃ¶yle anladÄ±m. YanlÄ±ÅŸ anladÄ±ysam dÃ¼zeltirseniz sevinirim.4 weeks ago 2 people like this.Like ReportReply",
    " -> Merhaba, embedding veya gÃ¶mme iÅŸlemini yapay sinir aÄŸlarÄ±nda Ã¼Ã§ temel iÅŸ iÃ§in kullanÄ±yoruz. Bunlar;1- \"Embedding space\" dediÄŸimiz bu dÃ¼zlemde en yakÄ±n komÅŸuyu bulup, \"Ã¶neri\" sistemlerinin daha efektif Ã§alÄ±ÅŸmasÄ±nÄ± saÄŸlayabilmek.2- denetimli Ã¶ÄŸrenimde bir girdi olarak kullanabilme.3- Kategoriler arasÄ±ndaki iliÅŸkileri ve konseptleri gÃ¶rselleÅŸtirebilme.Neden one-hot encoding kullanmÄ±yoruz sorusunun da iki temel cevabÄ± var ;1-YÃ¼ksek kardinalite deÄŸiÅŸkenleri iÃ§in (birÃ§ok benzersiz kategoriye sahip olanlar) one-hot vektÃ¶rÃ¼n boyutlarÄ± yÃ¶netilemez hale gelir.2- One-hot encoding'te, gÃ¶mme kategorilerinde olduÄŸu gibi birbirine yakÄ±n deÄŸerler, yakÄ±n yerlere yerleÅŸmiyor.Temel mantÄ±ÄŸÄ± bu, ileri okuma iÃ§in bakabilirsiniz. https://towardsdatascience.com/neural-network-embeddings-explained-4d028e6f0526",
    "Neural Network Embeddings Explainedtowardsdatascience.comHow deep learning can represent War and Peace as a vector4 weeks ago 10 people like this.Like ReportReply",
    "->  YorumlarÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederim. OlayÄ±n mantÄ±ÄŸÄ±nÄ± bir nebze kavradÄ±m. Bu iÅŸlemin nasÄ±l yapÄ±ldÄ±ÄŸÄ±nÄ± araÅŸtÄ±rdÄ±ÄŸÄ±mda iÅŸin iÃ§ine co-occurence, co-variance gibi matrixler girdi ve sanÄ±rÄ±m bir de prediction yoluyla(ki kursta bu yol anlatÄ±lÄ±yor sanÄ±rÄ±m) hesaplama yapÄ±lÄ±yor ben bu iÅŸlemi anlayamadÄ±m.4 weeks ago Like ReportReply",
    " "
]
},
{
"question_isim": "->",
"quest": "Neural Networks bolumu, playground exercise, Task 3 yanitinda gecen su ifade ile ilgili: \"3 neurons are enough because the XOR function can be expressed as a combination of 3 half-planes (ReLU activation).\" Ornegin bu task'da tek hidden layer'da filtreler gorsellestirilmis. her bir filtre gorunumu, ogrenilen weigth'ler kullanilarak b+w1*x1+w2*x2 linear kombinasyonu hesaplandiginda elde edilen ciktiya ReLu uygulandiginda elde edilen goruntu, degil mi? Burada bahsedilen XOR islemi nedir? Neden XOR anlamadim, bilginiz var mi?  Ikinci olarak, Task 4 yanitinda: \"A single hidden layer with 3 neurons can model the data, but there is no redundancy, so on many runs it will effectively lose a neuron and not learn a good model. A single layer with more than 3 neurons has more redundancy, and thus is more likely to converge to a good model.\" neden pek cok run yapildiginda bazi neuron'lar silinsin (regularization kullanmiyorum) ? neuron sayisinda redundancy olmasi istenenâ€¦ <a class=\"ps-stream-post-more ps-js-content-excerpt-toggle\" href=\"#\">Read more</a></div><div class=\"ps-js-content-full\" style=\"\">Neural Networks bolumu, playground exercise, Task 3 yanitinda gecen su ifade ile ilgili: \"3 neurons are enough because the XOR function can be expressed as a combination of 3 half-planes (ReLU activation).\" Ornegin bu task'da tek hidden layer'da filtreler gorsellestirilmis. her bir filtre gorunumu, ogrenilen weigth'ler kullanilarak b+w1*x1+w2*x2 linear kombinasyonu hesaplandiginda elde edilen ciktiya ReLu uygulandiginda elde edilen goruntu, degil mi? Burada bahsedilen XOR islemi nedir? Neden XOR anlamadim, bilginiz var mi?  Ikinci olarak, Task 4 yanitinda: \"A single hidden layer with 3 neurons can model the data, but there is no redundancy, so on many runs it will effectively lose a neuron and not learn a good model. A single layer with more than 3 neurons has more redundancy, and thus is more likely to converge to a good model.\" neden pek cok run yapildiginda bazi neuron'lar silinsin (regularization kullanmiyorum) ? neuron sayisinda redundancy olmasi istenen birsey mi? optimal neuran ve hidden layer sayisina nasil karar verecegiz?  Cok tesekkur ederim. </div></div>",
"comment": [
    "",
    "->  XOR iÅŸlemi doÄŸrusal olmayan bir iÅŸlemdir. AND,OR iÅŸlemleri doÄŸrusal iÅŸlemlerdir. XOR iÅŸleminde 1,0=0 0,1=0 1,1=1 0,0=1 deÄŸerleri vardÄ±r. BunlarÄ± grafiÄŸe dÃ¶ktÃ¼ÄŸÃ¼mÃ¼z zaman iki sÄ±nÄ±fa ayÄ±rmak iÃ§in linear bir Ã§izgi Ã§izemiyoruz. Yani bu problem linear bir modelle Ã§Ã¶zÃ¼lemez. DoÄŸrusal bir model inÅŸa ederek bu problem Ã§Ã¶zÃ¼lebilir. Bu yÃ¼zden gizli katmanlara gelen linear giriÅŸleri doÄŸrusal olmayan Ã§Ä±kÄ±ÅŸa dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in aktivasyon fonksiyonlarÄ±(ReLu gibi) kullanÄ±lÄ±r. Bu sayede verinin doÄŸrusal olmayan Ã¶zelliklerini Ã¶ÄŸrenmiÅŸ olur.4 weeks ago 1 person likes thisLike ReportReply",
    "-> ->  DoÄŸrusal 'olmayan' bir model inÅŸa ederek bu problem Ã§Ã¶zÃ¼lebilir. mi olucak? fakat relu islemi ile XOR islemi ayni sey degil. ReLu ile surece nonlinear'lik katildigini anliyorum. XOR'un buradaki fonksyonu nedir? lineer combination yerine XOR ile mi onceki layer'in ciktilari birlestirilip sonraki layer'a iletiliyor?4 weeks ago Like ReportReply",
    "Oguz Onuk -> eÄŸer simulator'Ä± Ã§alÄ±ÅŸtÄ±rmadan datanÄ±n daÄŸÄ±lÄ±mÄ±na bakarsan, noise 0 iken daha da net gÃ¶zÃ¼kÃ¼yor, sorun aslÄ±nda bu datanÄ±n daÄŸÄ±lÄ±mÄ±nÄ±n bir XOR problemi olmasÄ±. XOR linear olmadÄ±ÄŸÄ± iÃ§in onun nonlinear bir biÃ§imde modellenmesi gerekiyor. Senin de dediÄŸin gibi ReLU modele nonlinearity katmak iÃ§in kullanÄ±lÄ±yor. Zaten senin soru iÃ§inde paylaÅŸtÄ±ÄŸÄ±n ingilizce textte de bundan bahsedilmiÅŸ. XOR fonksiyonu ReLU aktivasyonu olarak ifade edilebilir diyor. Tekrar Ã¶zetlemek gerekirse linear olan layerlardan, XOR fonksiyonunu temsil edebilecek nonlinear bir network oluÅŸturabilmek iÃ§in ReLU aktivasyonu kullanÄ±lÄ±yor.4 weeks ago 1 person likes thisLike ReportReply",
    "->  XOR sadece non-lineariteyi anlatmak icin kullaniliyor.Grafikte degerleri yerine koyup tek bir dogruyla iki farkli data grubunu ayiramadigini goruyorsun.Non lineariteyi perceptronla cozemeyecegini acikliyor. Ve artik non_linear olan problemini neural network olusturarak cozuyorsun.4 weeks ago 1 person likes thisLike ReportReply",
    "-> ->  siz ne dusunuyorsunuz?4 weeks ago Like ReportReply",
    "-> -> Merhaba,Burada her hidden layer kendisinden Ã¶nceki layerdaki nodelarÄ± daha da komplike ve nonlineer hale getirir. Yani 1 hidden layerÄ±mÄ±z var ise kendisinden Ã¶nceki input layer'Ä±ndaki nodelarÄ± (bu nodelar bizim feature deÄŸerlerimiz olur. Bu feature deÄŸerleri ile birlikte weight deÄŸerleri olur.) Burada bizim fonksiyon eÅŸleÅŸmesini (nodelarÄ±n her biri bir fonksiyon olduÄŸu iÃ§in aslÄ±nda node eÅŸleÅŸmesi) kontrol eden weight matrisleri olur. Bu matirsleri feature deÄŸerlerimizle Ã§arptÄ±ÄŸÄ±mÄ±zda o layer iÃ§in ilgili node Ã§Ä±ktÄ±larÄ±nÄ± elde ederiz. (Resim ile ekledim.) Burada bu lineer baÄŸÄ±ntÄ±larda aslÄ±nda sigmoidi alÄ±nmÄ±ÅŸ bir fonksiyonun tekrar sigmoidi alÄ±ndÄ±ÄŸÄ±nda daha komplike bir fonksioyon elde edeceÄŸimiz gÃ¶rÃ¼lebilir. (Ã–rneÄŸin a1,a2,a3 sigmoid bir fonksiyondur. h(x) fonksiyonunda ise bu sigmoid fonksiyonlarÄ±n direk olarak olmasa da tekrar sigmoidlerinin alÄ±ndÄ±ÄŸÄ± gÃ¶rÃ¼lebilir.)XOR olmasÄ±nÄ± sebebi aslÄ±nda ÅŸu, XOR'un bizim dÃ¼zlemimizi ayÄ±rÄ±ÅŸ ÅŸekli bizim problemimize uyuyor bu yÃ¼zden de Ã§Ã¶zÃ¼mÃ¼mÃ¼zÃ¼ XOR'a gÃ¶re uyarlamak istedik. Burada AND yÃ¶ntemiyle Ã§Ã¶zebileceÄŸimzi bir problem olsaydÄ± nÃ¶ronlarÄ±mÄ±zÄ± AND problemini implemente edebilecek ÅŸekilde tanÄ±mlayacaktÄ±k. Bunu yapmanÄ±n bir yolu ise tek hidden layerda 3 nÃ¶ron kullanmaktÄ±. Bu nÃ¶ronlardan her biri aynÄ± Ã§Ä±ktÄ±yÄ± Ã¼retmez bunun sebebi ilgili weight matrixleri ve ilgili nÃ¶ronun feature deÄŸerinin Ã§arpÄ±mlarÄ±dÄ±r. (Resmdeki denklemde theta2n 2.nÃ¶rÃ¼n iÃ§in, theta3n(n burada herhaangi bir sayÄ±) 3.nÃ¶ron iÃ§in iÅŸleme sokulacak weight deÄŸeridir.)2. ÅŸÄ±k iÃ§in ise ÅŸunu sÃ¶yleyebilrim. NÃ¶ronlarÄ±nÄ±z ve layerlarÄ±nÄ±z arttÄ±ÄŸÄ±nda kompleksiteniz artar ve modeliniz Ã§ÄŸrenmekten Ã§ok ezber yapar yani overfit olur.Burada 3 nÃ¶ronun problemi Ã§Ã¶zmeye eyetebileceÄŸini, fazlasÄ±nÄ±n overfittinge yol aÃ§arak fazlalÄ±k oalcaÄŸÄ±nÄ± sÃ¶ylemek istemiÅŸ.Problemlerin bÃ¼yÃ¼k Ã§oÄŸunluÄŸu tek katman kullanÄ±larak yapÄ±labilir ama modelinizin loss deÄŸeri tek katmanla azalmÄ±yorsa daha komplike bir yapÄ±ya yani ekstra bir layera ihtiyacÄ±nÄ±z vardÄ±r. NÃ¶ron sayÄ±sÄ± ise genelde input ve output nÃ¶ron adetleri arasÄ±nda olur. Bu nÃ¶ron ve layer deÄŸerlerini bir anda kafamÄ±zdan belirleyemeyiz problemimizin kompleksitesine gÃ¶re problemimizi bazÄ± metriklerle analiz edip bu analizlere gÃ¶re layer ve nÃ¶ron deÄŸerlerimizi belirleyebilriz ama belirlerken yukarÄ±da sÃ¶ylediÄŸim kÄ±sÄ±mlara dikkat etmeliyiz.Kaynak: https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netwAnlamadÄ±ÄŸÄ±nÄ±z bir yer olursa sorabilirsiniz.Ä°yi Ã§alÄ±ÅŸmalar.",
    "How to choose the number of hidden layers and nodes in a feedforward neural network?stats.stackexchange.comIs there a standard and accepted method for selecting the number of layers, and the number of nodes in each layer, in a feed-forward neural network? I'm interested in automated ways of building neu...4 weeks ago 1 person likes thisLike ReportReply",
    "-> ->  Cok tesekkur ederim.3 weeks ago Like ReportReply",
    " "
]
},
{
"question_isim": "->",
"quest": "Merhaba, hangi durumlarda L1, ve hangi durumlarda L2 regularization sececegimizin bir kurali var mi? Feature dimension cok buyukse her zaman L1 regularization mi seciyoruz?",
"comment": [
    "",
    "->  Benim fikrime gÃ¶re hayÄ±r herhangi bir kural yok. L1 ve L2 modelden modele farklÄ± sonuÃ§lar sergileyebilir. Her ikisinide deneyip optimum sonuca ulaÅŸÄ±labilir diye dÃ¼ÅŸÃ¼nÃ¼yorum. Burada bizim hedeflerimizde Ã¶nemli, Ã¶rneÄŸin hesaplama aÃ§Ä±sÄ±nda RAM kullanÄ±mÄ± fazla olmayacak bir model hedefliyorsak elbette L1 daha uygun bir seÃ§enek olacaktÄ±r.4 weeks ago Like ReportReply",
    "-> ->  tesekkurler.4 weeks ago 1 person likes thisLike ReportReply",
    " "
]
},
{
"question_isim": " -> ",
"quest": "Merhabalar, bu haftaya tamamlarken tam olarak hidden layer in modellerimize eklendiÄŸinde ne iÅŸe yaradÄ±ÄŸÄ±nÄ± kavrayamadÄ±m. Ben modele hangi durumda hidden  layer ekliyorum? Hangi durumlarda hidden layer lara  neuron ekliyorum? TeÅŸekkÃ¼rler ÅŸimdiden",
"comment": [
    "",
    "-> Merhaba,SÄ±nÄ±flandÄ±rma problemlerimizde lineerlik kullanamÄ±yoruz bunun nedenini Modelimizin inputlarÄ±nÄ± nonlineer olarak hesaplamak iÃ§in https://medium.com/@ftfethi/makine-%C3%B6%C4%9Frenmesinde-s%C4%B1n%C4%B1fland%C4%B1rma-problemlerine-neden-lineer-regresyon-i%CC%87le-yakla%C5%9Fm%C4%B1yoruz-5ede1e3b12d4 yazÄ±mda anlatmaya Ã§alÄ±ÅŸtÄ±m. Bu yÃ¼zden nonlineer yÃ¶ntemlere baÅŸvurmak zorundayÄ±z. Modelimiz Ã§ok karmaÅŸÄ±k nonlineeritelik iÃ§erebilir. Bunun iÃ§in neural networklere baÅŸvururuz. Neural networklerin amacÄ± InputlarÄ±mÄ±zÄ± karmaÅŸÄ±k nonlineer hale getirerek belli nonlineer problemleri Ã§Ã¶zebilmek. Input ve output arasÄ±na lineeritemizi nonlineer yapacak hidden layerlar ekliyoruz.(nerual networkte input ve output layerlarÄ± dÄ±ÅŸÄ±ndaki her layer hidden layerdÄ±r). Bu hidden layer'da nÃ¶ronlar bulunur ve bu nÃ¶ronlar farklÄ± nonlineer iÅŸlemler yapabilirler (ReLU, Sigmod vs) NÃ¶ronlarÄ±mÄ±zÄ±n artmasÄ± ilgili layerdan Ã¶nceli layerdaki nÃ¶ronlarÄ±n bilgilerinin daha komplike bir ÅŸekilde yorumlanmasÄ±na neden olur, fazladan hidden layer eklersek de modelimizin karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± arttÄ±rmÄ±ÅŸ oluruz. Yani modelimizin karmaÅŸÄ±klÄ±ÄŸÄ± o problemi Ã§Ã¶zmeye yetmiyorsa neuron ve hidden layer eklemeyi dÃ¼ÅŸÃ¼nebiliriz. Resimde hidden layer ve nÃ¶ronu anlatmaya Ã§alÄ±ÅŸtÄ±m.Ä°yi Ã§alÄ±ÅŸmalar.",
    "Makine Ã–ÄŸrenmesinde SÄ±nÄ±flandÄ±rma Problemlerine Neden Lineer Regresyon Ä°le YaklaÅŸmÄ±yoruz?medium.comMerhabalar, Malum bu sÄ±ralar Covid-19 yÃ¼zÃ¼nden evdeyiz. Ben de kendimi nasÄ±l geliÅŸtirebilirim diye dÃ¼ÅŸÃ¼nmeye baÅŸladÄ±ÄŸÄ±mda senelerdirâ€¦4 weeks ago 2 people like this.Like ReportReply",
    "->  Hidden layerlar modelin daha kompleks featurelarÄ± Ã¶ÄŸrenmesine yardÄ±mcÄ± olur. Normal bir XOR datasÄ±nÄ± Ã¶ÄŸrenirken 1 tane hidden layer iÅŸ gÃ¶recektir. Ama modele Ã¶ÄŸretmeye Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z veri seti daha karmaÅŸÄ±ksa (https://developers.google.com/machine-learning/crash-course/introduction-to-neural-networks/playground-exercises buradaki spiral data gibi) 1 hidden layer Ã¶ÄŸrenmeye yeterli olmayacaktÄ±r. Daha kompleks Ã¶zellikler Ã¶ÄŸrenmek iÃ§in daha derin nÃ¶ron katmanlarÄ± gerekiyor kÄ±saca.Ama gereÄŸinden fazla hidden layer kullanÄ±rsak ve/veya hidden layerlara gereÄŸinden fazla node eklersek de modelimiz veri setine overfit olacaktÄ±r. O yÃ¼zden veriyi inceleyerek gerekli sayÄ±daki hidden layer-node ayarÄ±nÄ± tutturmak gerekiyor. (az kullanÄ±p underfit kalmamak ve Ã§ok kullanÄ±p overfit olmamak iÃ§in)4 weeks ago 1 person likes thisLike ReportReply",
    "->  Hidden layer Ä±n amacÄ± verideki Ã¶nemli Ã¶zellikleri ortaya Ã§Ä±karmaktÄ±r. Ã–rneÄŸin bir kÃ¶pek resmimiz olsun. Modelimizde sadece bir gizli katman varsa modelimiz Ã¶ÄŸrenemez. 50 tane gizli katman olursa kÃ¶peÄŸin burnunu,kuyruÄŸunu,gÃ¶zÃ¼nÃ¼,gÃ¶vdesini vb. Ã¶zelliklerini Ã¶ÄŸrenir. Gizli katmanlara aktivasyon fonkisyonlarÄ± uygulanarak doÄŸrusal gelen giriÅŸleri doÄŸrusal olmayan Ã§Ä±kÄ±ÅŸlara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.4 weeks ago 4 people like this.Like ReportReply",
    " ->  ->  teÅŸekkÃ¼r ederim4 weeks ago Like ReportReply",
    " ->  ->  ->  ->  aÃ§Ä±klamalar iÃ§in Ã§ok teÅŸekkÃ¼r ederim ÅŸimdi daha iyi anladÄ±m4 weeks ago 1 person likes thisLike ReportReply",
    " "
]
},
{
"question_isim": "->",
"quest": "Merhaba, Accuracy icin derste sorulan su soruyu anlamadim: In which of the following scenarios would a high accuracy value suggest that the ML model is doing a good job?  Neden asagidaki secenek dogru? In the game of roulette, a ball is dropped on a spinning wheel and eventually lands in one of 38 slots. Using visual features (the spin of the ball, the position of the wheel when the ball was dropped, the height of the ball over the wheel), an ML model can predict the slot that the ball will land in with an accuracy of 4%.",
"comment": [
    "",
    "->  Merhaba,--> Hangi senaryoda saÄŸlanmÄ±ÅŸ olan yÃ¼ksek accuracy(doÄŸruluk) deÄŸeri, modelimizin iyi bir iÅŸ Ã§Ä±kardÄ±ÄŸÄ±nÄ± gÃ¶sterir?DoÄŸru olan seÃ§enek: Rulet oyunu Ã¶rnek olarak verilmiÅŸ, ortada dÃ¶nmekte olan bir bir tekerliÄŸin iÃ§erisine bÄ±rakÄ±lan bir topun 38 hazneden birine dÃ¼ÅŸmesidir. GÃ¶rsel Ã¶zelliklerin kullanÄ±lmasÄ± ile bir ML modelinin %4 lÃ¼k bir accuracy ile topun nereye dÃ¼ÅŸeceÄŸini tahmin edebilmektedir.Sebebi ise normal de herhangi bir iÅŸlem yapÄ±lmaksÄ±zÄ±n bir tahmin yapacak olsak doÄŸru olarak tahmin etme oranÄ±mÄ±z: 1/38 olacak ki bu da yaklaÅŸÄ±k 2.63% deÄŸerine kaÅŸÄ±lÄ±k gelmektedir. ML %4 'lÃ¼k bir oran ile herhangi bir iÅŸlem yapÄ±lmaksÄ±zÄ±n yapÄ±lacak olan bir tahminden daha iyi sonuÃ§ vermektedir.. Burada 2.63% deÄŸerinden daha bÃ¼yÃ¼k oranlara sahip olan her ML modeli iÃ§in iyi bir iÅŸ Ã§Ä±karmÄ±ÅŸtÄ±r diyebiliriz.Ä°yi Ã§alÄ±ÅŸmalar.4 weeks ago 5 people like this.Like ReportReply",
    "-> Merhaba,Burada Ã¶ncelikle neden %99.99 accuracy oranÄ± olan modelimizin her zaman iyi bir iÅŸ yapamayacaÄŸÄ±nÄ± aÃ§Ä±klamaya Ã§alÄ±ÅŸalÄ±m. Siz hastalÄ±klarÄ±n %99.99'unu iyi tahmin edebilen bir modele sahipsiniz fakat belki modeliniz bÃ¼tÃ¼n hastalÄ±k ihtimallerini hasta deÄŸil olarak tahmin ettiÄŸinde de %99.99luk bir accuracy baÅŸarÄ±sÄ± elde edeceksiniz.Buradaki mantÄ±k https://community.globalaihub.com/?status/1133-1133-1587498846/ linkindeki soru altÄ±nda konuÅŸuldu.Burada eÄŸer hasta olan birine modelimiz hasta deÄŸil derse (%99.99 accuracy oranlÄ± hep hasta deÄŸil tahmini yapan modelimiz var.) hasta Ã¶lecektir.Rulet oyununda ise bir topun bir slota gelme oranÄ± %2.6'dir. Yani accuracy deÄŸerimiz %2.6'dir. Bu baÄŸlamda bir tahminin gerÃ§ekleÅŸme oranÄ± her seferinde 1/38'dir. Ancak burada modelimizin accuracy'si %4 olduÄŸu iÃ§in ve beklediÄŸimiz acuracy'den(%2.6) daha bÃ¼yÃ¼k bir tahmin accuracy'sine sahip olduÄŸu iÃ§in modelin doÄŸruluÄŸu \"sadece\"% 4 olmasÄ±na raÄŸmen, baÅŸarÄ±nÄ±n faydalarÄ± baÅŸarÄ±sÄ±zlÄ±ÄŸÄ±n dezavantajlarÄ±ndan Ã§ok daha aÄŸÄ±r basacaktÄ±r.Ä°yi Ã§alÄ±ÅŸmalar.Community4 weeks ago 3 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar Precision ile Recall arasÄ±nda tam olarak fark nedir ?  TeÅŸekkÃ¼rler",
"comment": [
    "",
    "->  Merhaba,https://community.globalaihub.com/?status/1482-1482-1587492075/#comment.4714.4568.4568 linkinde bunu aÃ§Ä±klamaya Ã§alÄ±ÅŸtÄ±m. Sorunuz olursa yanÄ±tlamaktan memnuniyet duyarÄ±m.Ä°yi Ã§alÄ±ÅŸmalar.Community4 weeks ago 2 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Herkese Merhaba!  Bu haftaki quiz sorularÄ±nÄ± aÅŸaÄŸÄ±daki linkte bulabilirsiniz. Bir kere daha hatÄ±rlatmak isterim; TR saati ile 22:00'den sonra gelen formlar ne yazÄ±k ki deÄŸerlendirmeye alÄ±nmayacaktÄ±r.  ğŸ‘‰ğŸ‘‰https://forms.gle/rAR5viCAAwS7uryX9   BaÅŸarÄ±larğŸŒŸâœ¨",
"comment": [
    "",
    "->  Az Ã¶nce sÄ±navÄ± tamamladÄ±m, soruyu doÄŸru okuyup yanlÄ±ÅŸ anlama problemim olduÄŸunu keÅŸfettim ğŸ™‚ Sorular gerÃ§ekten gÃ¼zeldi, hazÄ±rlayan herkese teÅŸekkÃ¼rlerimi sunarÄ±m. Herkese baÅŸarÄ±lar ğŸ™‚4 weeks ago 8 people like this.Like ReportReply",
    " -> ->  SÄ±nava baÅŸlamadan Ã¶nce yorumunuzu okumuÅŸtum, ÅŸu an sÄ±navÄ± tamamladÄ±m ve ne demek istediÄŸinizi Ã§ok iyi anlÄ±yorum ğŸ™‚4 weeks ago 2 people like this.Like ReportReply",
    "->   -> AramÄ±za hoÅŸ geldiniz ğŸ™‚4 weeks ago 1 person likes thisLike ReportReply",
    " ->  ->  Ben de bu ekibe katÄ±lÄ±yorum. Gitti 1 soru ğŸ˜€4 weeks ago 1 person likes thisLike ReportReply",
    "->  ->  2. sorudaki anlam karmaÅŸasÄ±ndan bahsediyorsunuz sanÄ±rÄ±m altta comment olarak belirttim4 weeks ago Like ReportReply",
    "->  Ant Dikkatli okunmasÄ± gereken sorular var . Herkese baÅŸarÄ±lar.4 weeks ago 1 person likes thisLike ReportReply",
    "->  Merhabalar, ben de sÄ±navÄ±mÄ± tamamladÄ±m. Sorular Ã§ok gÃ¼zel ğŸ˜€ SorularÄ±n aÃ§Ä±klamalarÄ±nÄ± bekliyorum, herkese baÅŸarÄ±lar.4 weeks ago 1 person likes thisLike ReportReply",
    "-> Ben de sÄ±navÄ± bitirdim. GÃ¼zel bir sÄ±navdÄ±. SorularÄ± dikkatlica okumak gerekiyordu. BazÄ±larÄ±nÄ± bu nedenle yanlÄ±ÅŸ yaptÄ±m.4 weeks ago 1 person likes thisLike ReportReply",
    "->  Merhabalar testi bitirdim sorular gayet gÃ¼zeldi ancak 2. soruda anlam karmaÅŸasÄ± vardÄ±, ÅŸÃ¶yle aÃ§Ä±klayayÄ±m bildiÄŸimiz Ã¼zere her layer ancak ve ancak tek bir activation functiona sahip olabilir fakat her layer birbirinden farklÄ± tipte activation functionlara sahip olabilir. Soruda \" Different layers should have only one type activation function. \" diyince burada anlaÅŸÄ±lan ÅŸey evet her layer ancak bir tip activation functiona sahip olabilir oldu ve doÄŸru dedim, hatayÄ± giderirseniz sevinirim, her ÅŸey iÃ§in teÅŸekkÃ¼rler ğŸ™‚4 weeks ago 1 person likes thisLike ReportReply",
    "-> ->  Merhaba, sanÄ±rÄ±m soruda anlatÄ±lmak istenen farklÄ± katmanlarÄ±n hepsinin aynÄ± fonksiyonu almasÄ± gerektiÄŸi Ã¼zerine.4 weeks ago Like ReportReply",
    "->  -> AnlatÄ±lmak istenen o evet ama anlatÄ±lamamÄ±ÅŸ sanÄ±rÄ±m4 weeks ago Like ReportReply",
    "->  SÄ±nav sorularÄ± mantÄ±k Ã¼zerine ve etkiliydi. HazÄ±rlayanlarÄ±n emeÄŸine saÄŸlÄ±k. Herkese Ã§ok teÅŸekkÃ¼rler.4 weeks ago 1 person likes thisLike ReportReply",
    " ->  Merhaba. SÄ±navÄ± bitirdim. MantÄ±ÄŸÄ±nÄ± anlayÄ±p anlamadÄ±ÄŸÄ±mÄ±zÄ± Ã¶lÃ§en Ã§ok gÃ¼zel bir sÄ±navdÄ±. Ä°lk hafta 7/10, geÃ§en hafta ve ÅŸimdi 9/10. Genel deÄŸerlendirme sÄ±navÄ±na adÄ±m adÄ±m. EmeÄŸi geÃ§en herkese teÅŸekkÃ¼rler, Ã§alÄ±ÅŸmaya devam.4 weeks ago 1 person likes thisLike ReportReply",
    " ->  Merhabalar ben de sÄ±navÄ± tamamladÄ±m ÅŸimdi. Bu haftanÄ±n konularÄ± Ã§ok gÃ¼zeldi. Tabi sorular da bir o kadar gÃ¼zeldi, ÅŸahsen bir kaÃ§Ä±nda tamamen mantÄ±k yÃ¼rÃ¼tÃ¼lmesi lazÄ±mdÄ± ve aÃ§Ä±kcasÄ± Ã§->ken biraz zorlanmÄ±ÅŸ olsam da 10/10 yapabildim. EmeÄŸiniz iÃ§in hepinize teÅŸekkÃ¼rler.4 weeks ago 1 person likes thisLike ReportReply",
    " ->  Merhabalar, ben ilik iki hafta dÃ¼zensiz baÅŸlamÄ±ÅŸtÄ±m ve yavaÅŸ yavaÅŸ dÃ¼zenli bir ÅŸekilde ilerliyorum. Ä°lk haftalar Ã§ok moral bozucu sonuÃ§lar alsam da bu hafta meyvesini aldÄ±ÄŸÄ±mÄ± dÃ¼ÅŸÃ¼nÃ¼yorum. EmeÄŸinize saÄŸlÄ±k teÅŸekkÃ¼r ediyorum.4 weeks ago 1 person likes thisLike ReportReply",
    "->  SÄ±nav sorularÄ± gayet gÃ¼zeldi. Herkese baÅŸarÄ±lar, iyi eÄŸlenceler.4 weeks ago 1 person likes thisLike ReportReply",
    "->  SorularÄ±n zorluk daÄŸÄ±lÄ±mÄ± iyiydi, dikkatlerden kaÃ§an birkaÃ§ soru olabilir dikkatli Ã§Ã¶zÃ¼lmesi lazÄ±m,k onularÄ±n daha zevkli hale gelmesi beni heyecanlandÄ±rÄ±yor4 weeks ago 1 person likes thisLike ReportReply",
    "->  Merhaba, ilk sorudaki V. numaralÄ± seÃ§enek tÃ¼m ÅŸÄ±klarda doÄŸru olarak yer alÄ±yordu ama \"A good classifier should have both a high precision and high recall on the cross validation set.\" bu ifade her zaman doÄŸru mudur ?4 weeks ago Like ReportReply",
    " ->  ->  bende o sorunun yanlÄ±ÅŸ olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yorum.4 weeks ago Like ReportReply",
    "->  AslÄ± HanÄ±m size ve tÃ¼m ekip arkadaÅŸlarÄ±nÄ±za Ã§ok teÅŸekkÃ¼r ederim. Sorular Ã§ok iyiydi. CevaplarÄ± sÄ±caÄŸÄ± sÄ±caÄŸÄ±na gÃ¶rebilmemiz de Ã§ok iyi olmuÅŸ. Ä°yi Ã§alÄ±ÅŸmalar.4 weeks ago 1 person likes thisLike ReportReply",
    " ->  SÄ±navÄ± tamamladÄ±m fakat son soruda ÅŸÄ±klarÄ±n ikisi de bana doÄŸru gibi geldi.AÃ§Ä±klamasÄ±nÄ± merak ediyorum. TeÅŸekkÃ¼rler, kolay gelsin.4 weeks ago 1 person likes thisLike ReportReply",
    "->  AslÄ± hanÄ±m, Ã¶ncelikle siz ve ekip arkadaÅŸlarÄ±nÄ±zÄ±n emeklerine saÄŸlÄ±k. SorularÄ±n aÄŸÄ±rlÄ±klarÄ± Ã§ok yerindeydi, bir kaÃ§ soru ise fazlaca dikkat gerektiriyordu. DÃ¼ÅŸÃ¼ndÃ¼rÃ¼cÃ¼ sorularÄ±n olmasÄ± her zaman gerekli bir ÅŸey bence. DolayÄ±sÄ±yla bÃ¶yle bir testten 10/10 yapabilmek Ã§ok kÄ±ymetli oldu. TeÅŸekkÃ¼rler, herkese baÅŸarÄ±lar.4 weeks ago 1 person likes thisLike ReportReply",
    "-> Merhaba, sÄ±navÄ± az Ã¶nce tamamladÄ±m. 1 soruyu bir anlÄ±k dikkatsizlikle yanlÄ±ÅŸ cevaplandÄ±rmÄ±ÅŸ olsam da genel sonucum beni mutlu etti. Bu sayede hem dikkatimizi hem de kavrayÄ±ÅŸÄ±mÄ±zÄ± Ã¶lÃ§en bir testle nelere daha Ã§ok dikkat etmemiz gerektiÄŸini anlamÄ±ÅŸ olduk. Motivasyonum her geÃ§en gÃ¼n daha da artÄ±yor. EmeÄŸi geÃ§en herkese teÅŸekkÃ¼r ederim.4 weeks ago 1 person likes thisLike ReportReply",
    "->  Merhabalar herkese ben de yeni bitirdim sÄ±navÄ±mÄ±. Yine Ã¶ncekiler gibi teoriye Ã¶ncelik verilen bir sÄ±nav olmuÅŸ, benim de beklediÄŸim gibi. Her geÃ§en sÄ±navda baÅŸarÄ±mÄ±n artmasÄ± beni mutlu etti. UmarÄ±m herkes hedeflediÄŸi baÅŸarÄ±ya ulaÅŸmÄ±ÅŸtÄ±r. EmeÄŸi geÃ§en herkese teÅŸekkÃ¼r ederim.4 weeks ago 1 person likes thisLike ReportReply",
        ->  AslÄ± merhaba, gruba bir post girdim. GÃ¶zÃ¼nden kaÃ§masÄ± adÄ±na linkini bÄ±rakÄ±yorum: https://community.globalaihub.com/?status/605-605-1587916465/Community4 weeks ago 1 person likes thisLike ReportReply",
    "->  Elif AkalÄ±n Mail de gÃ¶rÃ¼ÅŸmÃ¼ÅŸtÃ¼k konuyu ğŸ™‚4 weeks ago 1 person likes thisLike ReportReply",
    "->  Merhabalar, sÄ±navÄ± tamamladÄ±m. Yine gÃ¼zel ve eksiklerimizi anlamaya yardÄ±mcÄ± bir sÄ±nav olmuÅŸtu. EmeÄŸi geÃ§enlere teÅŸekkÃ¼rler ğŸ™‚4 weeks ago 1 person likes thisLike ReportReply",
    "->  GÃ¼zel sorulardÄ± ellerinize saÄŸlÄ±k. Girecek arkadaÅŸlarÄ±n biraz daha dikkatli olmalarÄ±nÄ± Ã¶neririm. BaÅŸarÄ±lar.4 weeks ago 1 person likes thisLike ReportReply",
    "->  Merhabalar, sÄ±navÄ± tamamladÄ±m. GÃ¼zel sorularda emeÄŸi geÃ§en herkese Ã§ok teÅŸekkÃ¼rler. BaÅŸarÄ±lar. ğŸ™‚4 weeks ago 1 person likes thisLike ReportReply",
    "-> \"GÃ¶nder\" dediÄŸimde beyaz bi sayfa geldi ve sayfa aÃ§Ä±lmadÄ±, cevaplar size ulaÅŸtÄ± mÄ± acaba? Sorular gÃ¼zeldi. Yine her zamanki gibi eksiklerimiz bitmiyorduu -> 4 weeks ago 1 person likes thisLike ReportReply",
    "-> TeÅŸekkÃ¼rler sÄ±nav gayet gÃ¼zeldi. ğŸ™‚ Ã‡->ken biraz dikkat vermek gerekiyor.4 weeks ago 1 person likes thisLike ReportReply",
    "->  Merhabalar, sÄ±navÄ± bitirdim sorular net ve gÃ¼zeldi. EmeÄŸi geÃ§en herkese teÅŸekkÃ¼r ederim. BaÅŸarÄ±lar ğŸ™‚4 weeks ago 1 person likes thisLike ReportReply",
    "->  Ä°nce GeÃ§en haftaki sÄ±nav sonucumdan sonra, \"baÅŸaramÄ±yor muyum ?\" diye sorarken, bu sÄ±nav Ã§ok iyi geldi. SÄ±nav sadece Ã¶lÃ§me aracÄ± deÄŸil, aynÄ± zamanda en bÃ¼yÃ¼k Ã¶ÄŸrenme aracÄ±dÄ±r. HazÄ±rlamada ve cevaplamada emeÄŸi geÃ§en herkese Ã§ok teÅŸekkÃ¼rler. ğŸ™‚4 weeks ago 1 person likes thisLike ReportReply",
    "-> Tesekkurler..ANN hic kolay konu degil ama sayenizde eksiklerimi gormus oldum ğŸ™‚4 weeks ago 1 person likes thisLike ReportReply",
    "->  8/10 fena deÄŸil, teÅŸekkÃ¼rler4 weeks ago 1 person likes thisLike ReportReply",
    " ->  Sorular Ã§ok iyiydi biraz daha dÃ¼ÅŸÃ¼nme istiyordu. PuanÄ±m beni mutlu etti. TeÅŸekkÃ¼rler emekleriniz iÃ§in4 weeks ago 1 person likes thisLike ReportReply",
    "->  Ãœniversitedeki online sÄ±navlarÄ±n yoÄŸunluÄŸundan bu haftaki quizi kaÃ§Ä±rdÄ±m. SorularÄ± en yakÄ±n fÄ±rsatta inceleyeceÄŸim. EmeÄŸi geÃ§enlere teÅŸekkÃ¼rler.4 weeks ago 1 person likes thisLike ReportReply",
    "->  Bu haftaki sorular iÃ§in emekleriniz teÅŸekkÃ¼rler, bu hafta da gÃ¼zel bir tekrar oldu.4 weeks ago 1 person likes thisLike ReportReply",
    "-> bu haftaki sorularÄ± fazlasÄ±yla beÄŸendim. mantÄ±k gerektiren sorulardÄ±. tam oturtamadÄ±ÄŸÄ±m kÄ±smÄ± Ã§ok net bir ÅŸekilde belirtti. teÅŸekkÃ¼rler.4 weeks ago 2 people like this.Like ReportReply",
    "->  Ellerinize saÄŸlÄ±k , Ã§ok gÃ¼zel bir sÄ±nav olmuÅŸ.4 weeks ago 2 people like this.Like ReportReply",
    " ->  GÃ¼zel bir sÄ±nav daha. TeÅŸekkÃ¼r ederim emeÄŸi geÃ§enlere4 weeks ago 1 person likes thisLike ReportReply",
    "-> Merhabalar, bu haftaki sorularÄ±n cevaplarÄ±nÄ±n aÃ§Ä±klamalarÄ± paylaÅŸÄ±ldÄ± mÄ± acaba? Yoksa ben mi kaÃ§Ä±rdÄ±m. Ä°yi Ã§alÄ±ÅŸmalar herkese4 weeks ago Like ReportReply",
    "->  -> Merhaba, bu hafta biraz geciktik, bu gece paylaÅŸmÄ±ÅŸ olurum ğŸ˜‰4 weeks ago 1 person likes thisLike ReportReply",
    "-> ->  Bende kaÃ§Ä±rdÄ±ÄŸÄ±mÄ± dÃ¼ÅŸÃ¼nmÃ¼ÅŸtÃ¼m, teÅŸekkÃ¼r ederim ğŸ™‚4 weeks ago Like ReportReply",
    " "
]
},
{
"question_isim": "-> uploaded 2 photos",
"quest": "Merhabalar,   - Ä°lk sorum neden test ve eÄŸitim setlerini neden ayÄ±rmÄ±ÅŸtÄ±k x ve y olarak yani 4 deÄŸiÅŸkene...    - Bir diÄŸer sorum da Flatten ve Dense layerler arasÄ±ndaki fark nedir?  (Resimler ektedir.)  Åimdiden teÅŸekkÃ¼rler! ğŸ™‚",
"comment": [
    "",
    "->  GÃ¼naydÄ±n,ilk soru ile baÅŸlayayÄ±m. Verimizi ilk gÃ¶rselde 2 grup olarak DÃœÅÃœNÃœYORUZ aslÄ±nda.Train ve test seti. Oradaki kodda MNIST setini yÃ¼klerken bize 4 adet array dÃ¶nÃ¼yor; 1-)Train verisetinin Ã¶rnekleri (Example) yani x_train deÄŸiÅŸkeni , 2-)Train setinin etiketleri (labels yani ne olduklarÄ± kedi kÃ¶pek vs.) yani x_test deÄŸiÅŸkeni 3-)Test setinin Ã¶rnekleri (Predict edilmesini istediÄŸimiz Ã¶rnekler) 4-)Test setinin etiketleri (labels-yani predict/true deÄŸerlerin kontrolÃ¼ iÃ§in kullanÄ±lacak liste) y_test. Modelin eÄŸitimi ve deÄŸerlendirilmesi iÃ§in gerekli veriler ayrÄ±lmÄ±ÅŸ kÄ±saca ğŸ™‚4 weeks ago 3 people like this.Like ReportReply",
    "->  Ä°kinci soru iÃ§in; Gizli Katman (Hidden Layer) dediÄŸimiz yapÄ±nÄ±n tf.keras modÃ¼lÃ¼ndeki adÄ± Dense.Modelimize bir katman eklemek iÃ§in Dense modÃ¼lÃ¼nÃ¼ Ã§aÄŸÄ±rÄ±yoruz.Zaten aldÄ±ÄŸÄ± parametrelerden de anlaÅŸÄ±labiliyor. Flatten ise , N-boyutlu olarak gelen matrisin tek boyuta indirgeyerek (Height * Weight) tek boyutlu bir vektÃ¶r matrise Ã§evrilmesini saÄŸlar.Åu linkten (https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-step-3-flattening) nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± inceleyebilirsin.4 weeks ago 6 people like this.Like ReportReply",
    "-> Ã‡ok teÅŸekkÃ¼r ederim4 weeks ago Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Herkese merhabalar,  Playground Exercises : A First Neural Network : Task 3 cevabÄ± olarak verilmiÅŸ aÅŸaÄŸÄ±daki ifadenin ne anlatmak istediÄŸini tam olarak anlayamadÄ±m. YardÄ±mcÄ± olursanÄ±z sevinirim. TeÅŸekkÃ¼rler. :) \"3 neurons are enough because the XOR function can be expressed as a combination of 3 half-planes (ReLU activation). You can see this from looking at the neuron images, which show the output of the individual neurons. In a good model with 3 neurons and ReLU activation, there will be 1 image with an almost vertical line, detecting X1 being positive (or negative; the sign may be switched), 1 image with an almost horizontal line, detecting the sign of X2, and 1 image with a diagonal line, detecting their interaction.\"",
"comment": [
    "",
    "-> Merhaba,Burada modelimizin nonlinear fonksiyonunu ReLU ve 3 nÃ¶ronlu tek bir hidden layer ile oluÅŸturabileceÄŸimizi ama loss aÃ§Ä±sÄ±ndan efektif olmayacaÄŸÄ±nÄ± sÃ¶ylemiÅŸ. Hidden Layer'Ä±mÄ±zÄ±n XOR fonksiyonunu ifade etmek istemesinin sebebi lineer fonksiyonumuzu bu sayede daha karmaÅŸÄ±k nonlinear bir yapÄ±ya Ã§evirmek. (XOR Ã§Ã¶zÃ¼mÃ¼nÃ¼ kullanarak yapmÄ±ÅŸ. Burada her mantÄ±ksal operatÃ¶r farklÄ± Ã§Ä±ktÄ±lar Ã¼retir Ã¶rneÄŸin AND, NAND, XOR gibi operatÃ¶rler. Burada bu problemin tanÄ±mÄ±na uyan operatÃ¶rÃ¼mÃ¼z ise XOR poeratÃ¶rÃ¼dÃ¼r ve 3 yarÄ± dÃ¼zlem ÅŸeklinde (her nÃ¶ron bir yarÄ± dÃ¼zlemi ifade eder.Her bir nÃ¶ronumuz farklÄ± bir fonksiyondur ve farklÄ± bir iÅŸ yapar.Hidden layerdaki ilk nÃ¶ronumuz x1 input'unun pozitif veya negatif olduÄŸunu algÄ±layan, neredeyse dikey bir Ã§izgiyi output olarak verir.Hidden layerdaki 2. nÃ¶ronumuz x2 inputunun pozitif veya negatif olduÄŸunu algÄ±layan neredeyse yatay bir Ã§izgiyi output olarak verir.Hidden layerdaki 3.nÃ¶ron ise bu iki inputun etkileÅŸimlerini algÄ±layan Ã§apraz bir Ã§izgi dÃ¶ndÃ¼rÃ¼r. Bu 3 nÃ¶ron output'u ise bizim output layer'ImÄ±za gÃ¶nderilir. Modelimizde loss oranÄ± optimum yakÄ±nsamayacaktÄ±r Ã§Ã¼nkÃ¼ daha Ã§ok nonlinearity iÃ§eren bir problemle karÅŸÄ± karÅŸÄ±yayÄ±z.Ä°yi Ã§alÄ±ÅŸmalar.4 weeks ago 8 people like this.Like ReportReply",
    "->  ->  TeÅŸekkÃ¼r ederim.4 weeks ago Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar, Neural Networks kÄ±smÄ±ndaki hem Playground hem de Programming egzersizlerinden sonra sormak istediÄŸim problem iÃ§in hidden layer sayÄ±sÄ± ve bu layer'lardaki nÃ¶ron sayÄ±sÄ± deneme yanÄ±malar sonucu mu saptanabilir ? Tabi ki overfitting ile karÅŸÄ±laÅŸmamak iÃ§in Ã§ok kompleks modeller tercih etmeyebiliriz ama daha iyi test loss yaratan kombinasyonu bulmak iÃ§in deneme-yanÄ±lma mÄ± yapÄ±lmalÄ± ? Ã‡ok teÅŸekkÃ¼rler.",
"comment": [
    "",
    "->  Malesef kitapta yazÄ±lÄ± olan bir kuralÄ± yoktur bu iÅŸin,gÃ¼zel yanÄ± da o zaten.AraÅŸtÄ±rmalarÄ±n amacÄ± aslÄ±nda dediÄŸiniz konuda bir yol oluÅŸturmak ancak,dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼mÃ¼z zaman 'overfitting','underfitting','gradient vanish' vs gibi durumlarÄ±n hepsi araÅŸtÄ±rmalar yani deneme yanÄ±lmalar sonrasÄ±nda bulunmuÅŸtur.Ã–rneÄŸin Programming Exercise kÄ±smÄ±ndaki eÄŸitim sÃ¼reci 2-3 dakika bile sÃ¼rmÃ¼yorken,daha yÃ¼ksek Ã§Ã¶zÃ¼nÃ¼rlÃ¼k ve Ã¶zellikli (RGB-dimensions) gÃ¶rÃ¼ntÃ¼lerde,donanÄ±m gÃ¼cÃ¼ne ve veriseti boyutuna gÃ¶re saatlerce hatta gÃ¼nlerce sÃ¼ren eÄŸitim sÃ¼reÃ§leri vardÄ±r.Bu gibi durumlarda, deneme-yanÄ±lma aÅŸÄ±rÄ± verimsiz bir yÃ¶ntem olur. Åahsen en mantÄ±klÄ±sÄ±, benzer problemler Ã¼zerinde Ã§alÄ±ÅŸÄ±lmÄ±ÅŸ Ã§alÄ±ÅŸmalarÄ± inceleyerek,kendi yol haritanÄ±zÄ± Ã§Ä±karmanÄ±zdÄ±r.4 weeks ago 5 people like this.Like ReportReply",
    "->  Gizli katman sayÄ±sÄ±, neuron sayÄ±sÄ± ve Ã¶ÄŸrenme katsayÄ±sÄ± gibi bÃ¼tÃ¼n hiper parametreler denem yanÄ±lma yÃ¶ntemiyle optimum seviyeye Ã§Ä±karÄ±lÄ±r. Zaten \"tuning\" ile kastettiÄŸimiz de bir nevi deneme yanÄ±lmadÄ±r. Fakat bu tuning iÅŸlemini daha organize ve sistematik bir hale getirmek iÃ§in Ã§eÅŸitli yÃ¶ntemler mevcut. (bkz. Grid Search) Bununla birlikte daha Ã§ok model geliÅŸtirerek tecrÃ¼be edindiÄŸinizde, yeni bir model oluÅŸtuturken nasÄ±l hiper parametreler seÃ§meniz gerektiÄŸine dair zihninizde bir takÄ±m sezgiler oluÅŸacaktÄ±r, bu da tuning kÄ±smÄ±nÄ± hÄ±zlandÄ±racaktÄ±r.4 weeks ago 3 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar,   Regularization: Sparsity konusunda L0 regularization'Ä±n tam olarak ne yaptÄ±ÄŸÄ±nÄ± ve neden kullanamadÄ±ÄŸÄ±mÄ±zÄ± anlayamadÄ±m. YardÄ±mcÄ± olabilir misiniz?   Åimdiden teÅŸekkÃ¼rler.",
"comment": [
    "",
    "->  L0, L1'in daha ilkel hali olarak dÃ¼ÅŸÃ¼nebiliriz. L0 modelimizde sÄ±fÄ±r olmayan weightleri sÃ¼rekli sayÄ±yor ve bunlarÄ± bir ÅŸekilde sÄ±fÄ±rlamaya Ã§alÄ±ÅŸÄ±yor. Bu tarzda bir metod ancak modelimizde belli bir kazanÃ§ varsa, iyi fit ediyorsa, mantÄ±klÄ± olabilir. Fakat sezgisel olarak mantÄ±klÄ± gÃ¶rÃ¼nen bu durum, pratikte modelimizi dÄ±ÅŸ bÃ¼key olmayan (non-convex) bir hale sokuyor ve dÄ±ÅŸ bÃ¼key olmayan modelleri optimize etmek diÄŸerlerine oranla daha zor. Ã‡Ã¼nkÃ¼ maliyet fonksiyonunda global minimum noktayÄ± bulmak zorlaÅŸÄ±yor, bunun yerine modelimiz yerel minimum noktaya yakÄ±nsayabiliyor. Bu sebeble L0'a nispeten yakÄ±n bir metod olan L1'Ä± kullanmak daha mantÄ±klÄ±. L1 her gÃ¶rdÃ¼ÄŸÃ¼ weighti sÄ±fÄ±rlamaya Ã§alÄ±ÅŸmak yerine bilgi Ã§ekemediÄŸi weightleri sÄ±fÄ±rlÄ±yor.4 weeks ago 12 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba,  \"Multi-Class Neural Networks: Softmax\" baÅŸlÄ±klÄ± konuda \"Softmax layer must have same number of nodes as output layer.\" ifadesi geÃ§iyor.  Burada softmax layer, output layer'Ä±n kendisi deÄŸil mi? Zaten resimde de ayrÄ± bir output layer gÃ¶sterimi yok, son layer olarak softmax Ã§izilmiÅŸ.  Neden bu ÅŸekilde ifade etmiÅŸ olabilirler?",
"comment": [
    "",
    "-> 4 weeks ago Like ReportReply",
    "->  Merhaba,Softmax layerÄ±mÄ±z tipik olarak son layerÄ±mÄ±zdÄ±r. Burada benim anladÄ±ÄŸÄ±m ÅŸey oluÅŸturacaÄŸÄ±mÄ±z ihtimaller dizisi(sÄ±nÄ±f diye geÃ§er) kadar (Kedi mi?HayÄ±r. - KÃ¶pek mi? Evet. -Yumurta mÄ±?HayÄ±r gibi) node a sahip olmalÄ± Ã§Ã¼nkÃ¼ her sÄ±nÄ±f iÃ§in bir deÄŸer hesaplamasÄ± yapÄ±yoruz. (Ã–rnekte 5 node var Ã§Ã¼nkÃ¼ 5 sÄ±nÄ±fÄ±mÄ±z var)Ä°yi Ã§alÄ±ÅŸmalar.4 weeks ago 4 people like this.Like ReportReply",
    "-> ->  AnladÄ±m. AyrÄ± bir output layer sÃ¶zkonusu deÄŸil. Ã–nceki Ã¶rneklerdeki output layer'a iÅŸaret etmiÅŸler muhtemelen. TeÅŸekkÃ¼rler.4 weeks ago Like ReportReply",
    "->  Ornekle aciklayayim.Classification yapacagiz.Classes = {agac : 0, insan : 1, araba: 2} olsun.Yani 3 tane sinifimiz olsun.Son layer da 3 tane node a ihtiyacim var cunku 3 tane output var.Kac tane sinifin varsa son layerda o kadar node a ihtiyacin var.Cok cok yaygin olarak networkteki diger layerlarda RELU activation function kullanilip, son layer da Softmax kullaniliyor cunku Softmax bize probabilistic distrubition sagliyor.Boylece siniflandirma yapilmis oluyor.4 weeks ago 5 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar herkese,  Benim sorum multi-class neural networklerde candidate sampling ile softmax yapÄ±lmasÄ± Ã¼zerine olacak. AnladÄ±ÄŸÄ±m kadarÄ±yla Ã§ok fazla class Ä±n olduÄŸu bir classification probleminde tÃ¼m class lar iÃ§in softmax iÅŸlemi yapmak Ã§ok uzun sÃ¼rÃ¼yor ve computational cost yÃ¼ksek oluyor. Bunu Ã¶nlemek iÃ§in training esnasÄ±nda bir sample iÃ§in train ederken o sample a ait class Ä±n output nÃ¶ronunu ve random seÃ§tiÄŸimiz diÄŸer classlardan bazÄ± nÃ¶ronlarÄ± alarak softmax iÅŸlemi yapÄ±yoruz.  Burada random seÃ§tiÄŸimiz  classlarÄ±n  sayÄ±sÄ±nÄ± biz mi belirliyoruz, bu da bir hyper parametre midir?  TeÅŸekkÃ¼rler ğŸ™‚",
"comment": [
    "",
    "->  Sizinde bahsettiÄŸiniz Ã¼zere, softmax, sÄ±nÄ±f sayÄ±sÄ± az olduÄŸunda oldukÃ§a maliyetsiz bir yÃ¶ntem, ancak sÄ±nÄ±f sayÄ±sÄ± arttÄ±kÃ§a aÅŸÄ±rÄ± derecede pahalÄ± hale gelebiliyor. Candidate Sampling eÄŸitim metodu, Ã§ok sayÄ±da sÄ±nÄ±fa sahip problemlerde verimliliÄŸi artÄ±rabilir. Candidate Sampling metodunda olasÄ±lÄ±klar pozitif etiketlerin hepsi iÃ§in hesaplanÄ±rken, negatif etiketlerden rastgele seÃ§ilenler iÃ§in hesaplanÄ±r. Ä°ncelediÄŸim dÃ¶kÃ¼manda (bkz. https://www.tensorflow.org/extras/candidate_sampling.pdf ) bu sÄ±nÄ±flarÄ±n nasÄ±l belirlendiÄŸine dair Ã§eÅŸitli formÃ¼ller verilmiÅŸ. KÄ±saca sÄ±nÄ±flarÄ±n sayÄ±sÄ±nÄ± biz belirlemiyoruz, bunu algoritma toplam sÄ±nÄ±f sayÄ±sÄ±na gÃ¶re belirliyor. Bunun yanÄ±nda candidate sampling metodunu kullanan alt algoritmalar mevcut, bunlarÄ±n her birinde farklÄ± formÃ¼ller kullanÄ±lÄ±yor olabilir.https://www.tensorflow.org/extras/candidate_sampling.pdfwww.tensorflow.orghttps://www.tensorflow.org/extras/candidate_sampling.pdf4 weeks ago Like ReportReply",
    "->  ->  BahsettiÄŸiniz dÃ¶kÃ¼manÄ± ben de incelemiÅŸtim ama orada class larÄ±n seÃ§ilme probabilitysi ile ilgili formÃ¼ller var, kaÃ§ adet seÃ§ildiÄŸine dair herhangi bir bilgi yok. Sizin gÃ¶rdÃ¼ÄŸÃ¼nÃ¼z bir kÄ±sÄ±m varsa paylaÅŸabilirseniz sevinirim. TeÅŸekkÃ¼rler.4 weeks ago Like ReportReply",
    "->  ->  Net bir biÃ§imde belirtmemiÅŸ olsalarda kaÃ§ adet seÃ§ildiÄŸini bu formÃ¼lÃ¼n ifade ettiÄŸini dÃ¼ÅŸÃ¼nÃ¼yorum. (Ci = Ti â‹ƒ S) Burada Ci: Adaylar KÃ¼mesi (KÃ¼me elemanÄ± sayÄ±sÄ± kadar rastgele sÄ±nÄ±f seÃ§iliyor), Ti: Hedef SÄ±nÄ±flar, S: DiÄŸer SÄ±nÄ±flar olarak belirtilmiÅŸ. AnladÄ±ÄŸÄ±m kadarÄ± ile aÃ§Ä±klamaya Ã§alÄ±ÅŸtÄ±m, zira bende sizinle beraber Ã¶ÄŸreniyorum umarÄ±m yardÄ±mÄ± dokunmuÅŸtur, ben teÅŸekkÃ¼r ederim4 weeks ago 1 person likes thisLike ReportReply",
    "->  ->  AnladÄ±m, benim gÃ¶zÃ¼mden kaÃ§an bir kÄ±sÄ±m olabilir, varsa paylaÅŸabilir misiniz anlamÄ±nda sordum. BahsettiÄŸiniz kÄ±sÄ±ma tekrar bakacaÄŸÄ±m. YardÄ±mlarÄ±nÄ±z iÃ§in Ã§ok teÅŸekkÃ¼rler. Ä°yi Ã§alÄ±ÅŸmalar ğŸ™‚4 weeks ago Like ReportReply",
    "->  Normalde multi- class problemlerde modelimiz her mumkun sinifin olasiligini hesapliyor.Ancak candidate sampling sirasinda sadece iliskili olan siniflarin olasiligini hesaplayip karar veriyor.Bir ornek verecek olursak siniflarimiz agac, kalem, masa, kopek, kedi, kamyon ve tir olsun. Biz modelimize kamyon resmini verip siniflandirmasini istedigimizde ilgisiz siniflarin olasiligini hesaplamakla ugrasmayip kamyon ve tiri hesaplayacaktir.Hangi siniflarin gozonune alinacagina modelimiz karar verecek ve gozonune alacagi class sayisi classlarin birbiriyle icinde bulundugu yakinliga ve bizim modele neyi verdigimize gore degisir.4 weeks ago 1 person likes thisLike ReportReply",
    "->  ->  PaylaÅŸÄ±m iÃ§in teÅŸekkÃ¼rler ğŸ™ Peki bahsettiÄŸiniz Ã¶rnekte tÄ±rÄ±n yanÄ±nda kÃ¶peÄŸi almamasÄ± gerektiÄŸine nasÄ±l karar veriyor, classlarÄ±n birbirine yakÄ±nlÄ±ÄŸÄ±nÄ± nasÄ±l hesaplÄ±yor ve thresholda nasÄ±l karar veriyor, neden kÃ¶peÄŸi de dahil etmiyor? Onun dÄ±ÅŸÄ±nda training iÅŸleminde ilk sample Ä± eÄŸittiÄŸini dÃ¼ÅŸÃ¼nÃ¼n, hiÃ§bir class Ä±n weigthleri belirli deÄŸil, kamyon iÃ§in bir tane tÄ±r class Ä± ile softmax yapacaÄŸÄ±na nasÄ±l karar veriyor? Sizin bahsettiÄŸiniz random candidate sampling olmuyor gibi, doÄŸrudan candidate seÃ§iyorsunuz.4 weeks ago 3 people like this.Like ReportReply",
    "->  -> Verdigim ornek senin icin kafa karistirici olmus gibi gorunuyor.Ornegi degistirelim.Mesela siniflar hayvanlar olsun.Kedi, maymun, zurafa, fil, guvercin, kopek, muhabbet kusu.Kus resmi verdigimizde guvercin ve muhabbet kusu icin olasilik hesaplayacak.Digerleriyle ugrasmayacak.Mantigi bu ancak teknik olarak neyin nasil oldugunu anlamak icin modelin mimarisini gormeliyiz.GIthub a baktim bir iki ornek bulabilir miyim diye bulamadim.Konuyla ilgilisin gordugum kadariyla iyi bir ornek bulursan modeli beraber aciklamaya calisiriz.Bu arada upsampling ya downsampling gibi kavramlar bildik kavramlar ancak candidate sampling enteresan ybir kavram benim icin. de.4 weeks ago 1 person likes thisLike ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba ArkadaÅŸlar, Backpropagation'un hata caselerinin birisi olan \"Dead ReLU Units\" i anlayamadÄ±m. YardÄ±mcÄ± olur musunuz? TeÅŸekkÃ¼rler",
"comment": [
    "",
    "->  ReLu fonksiyonunun doÄŸasÄ± gereÄŸi negatif girdi deÄŸerleri sÄ±fÄ±r Ã§Ä±ktÄ±sÄ±nÄ± Ã¼retiyor. Bu durum ReLu iÃ§in negatif girdi olacak olan aÄŸÄ±rlÄ±klÄ± Ã¶zelliklerin toplamÄ±nÄ±n modele hiÃ§ bir katkÄ±da bulunmamasÄ±na sebeb oluyor dolayÄ±sÄ±yla geri yayÄ±lÄ±m algoritmasÄ± gradient hesabÄ± sÃ¼resince bu girdi deÄŸerleri Ã¼zerinden bir akÄ±ÅŸ saÄŸlayamÄ±yor. Ã‡Ã¼nkÃ¼ sÄ±fÄ±rÄ±n tÃ¼revi yine sÄ±fÄ±rdÄ±r. Bu durumu Ã§Ã¶zmek iÃ§in daha kÃ¼Ã§Ã¼k bir Ã¶ÄŸrenme katsayÄ±sÄ± veya \"Leaky ReLu\" aktivasyon fonksiyonu kullanÄ±labilir. Leaky ReLu'nun orjinalin ReLu'dan farkÄ± negatif deÄŸerler iÃ§im direk sÄ±fÄ±r Ã§Ä±ktÄ±sÄ± Ã¼retmeyip, nispeten sÄ±fÄ±ra yakÄ±n fakat sÄ±fÄ±r olmayan Ã§Ä±ktÄ±lar Ã¼retmesidir. BÃ¶ylece aÄŸÄ±rlÄ±klÄ± toplamlarÄ± negatif olan Ã¶zelliklerin de azda olsa modele bir katkÄ±sÄ± olabiliyor. UmarÄ±m yardÄ±mÄ± dokunur. Ä°yi Ã§alÄ±ÅŸmalar.4 weeks ago 3 people like this.Like ReportReply",
    "->  ->  Learning rate i degistirmek Dead RELU units sorununu cozmez.4 weeks ago 1 person likes thisLike ReportReply",
    "->  -> 4 weeks ago Like ReportReply",
    "->  Ders iÃ§eriÄŸinde en altta bÃ¶yle bir aÃ§Ä±klama yapÄ±lmÄ±ÅŸ4 weeks ago Like ReportReply",
    "->  ->  Dead RELU Unit sorunu activation functioni degistirerek cozulebilir.Ilk akla gelenler sigmoid ya da tanh activation functions.Tabiki bunlarda neuronlar olmesede vanishing gradients ya da exploding gradients problemleriinden kurtalamayacagiz.Leaky RELU cozum olabilir.Yada Leky RELU nun gelistirilmis sekli olan SELU kullanilabilir.Yalniz SELU yu lecun_normal initialization ve Alpha Dropout ile kullanmalisiniz.4 weeks ago 2 people like this.Like ReportReply",
    "->  ->  Ä°nternet Ã¼zerinde birden fazla kaynakta learning rate'in dead relu iÃ§in Ã§Ã¶zÃ¼m olabileceÄŸi yazÄ±lmÄ±ÅŸ. Learning rate'in weightleri gÃ¼ncellemeye doÄŸrudan etkisi bulunduÄŸu aÃ§Ä±k bir durum. Bu noktada dÃ¼ÅŸÃ¼k bir gÃ¼ncelleme oranÄ±nÄ±n aÄŸÄ±rlÄ±klÄ± toplamlarÄ±n belli bir seviyenin Ã¼stÃ¼nde olmasÄ±na, dolayÄ±sÄ±yla sÄ±fÄ±rÄ±n altÄ±nda negatif deÄŸerlere dÃ¼ÅŸmesini engelleyebileceÄŸini dÃ¼ÅŸÃ¼nÃ¼yorum.4 weeks ago 1 person likes thisLike ReportReply",
    "-> Merhabalar,BildiÄŸimiz gibi relu nun esprisi Ã¶nceki katmandan gelen input sÄ±fÄ±rdan bÃ¼yÃ¼kse o inputu doÄŸrudan bir sonraki katmana aktarÄ±yor, sÄ±fÄ±rdan kÃ¼Ã§Ã¼kse sÄ±fÄ±r Ã§Ä±kÄ±ÅŸÄ± veriyor yani sonraki katmana bir Ã§Ä±kÄ±ÅŸ vermiyor.EÄŸer olur da training sÄ±rasÄ±nda reluya Ã¶nceki katmandan gelen input deÄŸeri sÄ±fÄ±rÄ±n altÄ±na dÃ¼ÅŸÃ¼rse relu sonraki katmana Ã§Ä±kÄ±ÅŸ vermiyor. Ã‡Ä±kÄ±ÅŸ vermediÄŸi iÃ§in de final outputta o relu nÃ¶ronunun bir etkisi olmuyor. Weightleri update etme iÅŸlemi back propagation ile yapÄ±ldÄ±ÄŸÄ± iÃ§in (output katmanÄ±ndan baÅŸlanÄ±p tÃ¼rev alÄ±narak katmanlardan geriye doÄŸru weightler update ediliyor) ve Ã§Ä±kÄ±ÅŸ vermeyen relunun outputta hiÃ§ etkisi olmadÄ±ÄŸÄ± iÃ§in back propogation iÅŸleminde o relu nÃ¶ronunun sonrasÄ±ndaki ve Ã¶ncesindeki weightler hiÃ§ deÄŸiÅŸmiyor, deÄŸiÅŸmediÄŸi iÃ§in de ona gelen input deÄŸeri sÄ±fÄ±rdan kÃ¼Ã§Ã¼k kalmaya devam ediyor, bu yÃ¼zden de nÃ¶ron hiÃ§ Ã§Ä±kÄ±ÅŸ veremiyor. BÃ¶ylece o nÃ¶ron sonraki iterasyonlarda hep Ã¶lÃ¼ kalÄ±yor :)Ã‡Ã¶zÃ¼m olarak learning rate i azaltabilirsiniz deniyor.4 weeks ago 9 people like this.Like ReportReply",
    "->  TeÅŸekkÃ¼rler arkadaÅŸlar deÄŸerli bilgileriniz iÃ§in. Ä°yi Ã§alÄ±ÅŸmalar.4 weeks ago Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba , Neural Networks kÄ±smÄ±nda ki playground exercises bÃ¶lÃ¼mÃ¼ndeki A First Neural Network alÄ±ÅŸtÄ±rmalarÄ±nÄ± tam anlayamadÄ±m. YardÄ±mcÄ± olur musunuz ğŸ™‚",
"comment": [
    "",
    "->  Merhaba Duygu, bu alistirmalarda neuron sayilarini ve hidden layer sayilarini arttirip azaltarak farkli activation functions lari sectigimiz ya da secili dataya gore degistirerek, L1 veya L2 regularizasyon tekniklerini deneyerek gozlem yapiyoruz.Oyun gibi.Degerleri degistir, farkli kombinasyonlari dene ve gozlem yap.4 weeks ago 3 people like this.Like ReportReply",
    "->  TamamdÄ±r teÅŸekkÃ¼r ederim ğŸ™‚4 weeks ago 1 person likes thisLike ReportReply",
    "-> Merhaba,Neural Networks bizim daha komplike nonlinear modelleri eÄŸitmemizde kullanÄ±lÄ±r. Neural networks'te input ve output layerlarÄ± arasÄ±nda koyacaÄŸÄ±mÄ±z hiddden layerlar vardÄ±r. Bu layerlar isteÄŸimize gÃ¶re activation layer yani nonliner iÅŸlem yapan layerlar olabilir. (Bir layerda nodelar -neuron diye de geÃ§ebilir- bulunur ve bunodelarÄ±n lineer mi non lineer mi olduÄŸunu seÃ§ebilirsiniz. Activation layer iÃ§ideki inputla output arasÄ±nda matematiksel kÃ¶prÃ¼ gÃ¶ren bir layer diyebiliriz.) Activation layer'daki nodelar ReLU, Sigmoid benzeri fonksiyonlardÄ±r ve lineerliÄŸi nonlineerliÄŸe Ã§evirebilir. BÃ¶ylece daha karmaÅŸÄ±k veri daÄŸÄ±lÄ±mlarÄ±na sahip bir eÄŸitim setini Ã¶ÄŸrenebilir.Task 1: Modelimizde lineer olan hidden(input ve output layer'I arasÄ±nda kalan her layer) bir layerÄ±mÄ±z var. Bu model doÄŸal olarak hiÃ§bir nonlinearity Ã¶ÄŸrenemez ve veri daÄŸÄ±lÄ±mÄ± daha komplike olan eÄŸitimleri efektif gerÃ§ekleÅŸtiremez.Task 2: Burada hidden layer'daki nÃ¶ron sayÄ±sÄ±nÄ± arttÄ±rmanÄ±z bir anlam ifade etmeyecektir Ã§Ã¼nkÃ¼ yine nonlinearlÄ±ÄŸÄ± saÄŸlayamÄ±yorsunuz.Task 3: Burada hidden layerÄ±mÄ±zdaki nÃ¶ron sayÄ±sÄ±nÄ± arttÄ±rÄ±p 3 yapmamÄ±z ve activation function olarak ReLU kullanmamÄ±z modelimizi lineerlikten Ã§Ä±karÄ±p nonlineerliÄŸe sokacaktÄ±r.(Burada 3 nÃ¶ronun XOR iÅŸlemi yaptÄ±ÄŸÄ±ndan bahseder. 1. nÃ¶ron x1 deÄŸerini dÃ¼zlemde ayÄ±rÄ±r, 2.nÃ¶ron x2 deÄŸerini dÃ¼zlemde ayÄ±rÄ±r, 3.nÃ¶ron ise bunlarÄ±n arasÄ±ndaki iliÅŸkiyi belirler.) Burada verilerin nondeterminisitk olmasÄ± sebebiyle her Ã§alÄ±ÅŸtÄ±rma esnasÄ±nda aynÄ± sonucu elde edemeyiz. Ancak burada nonlineerliÄŸe eriÅŸmek sadece bir baÅŸlangÄ±Ã§. Bu nonlineerliÄŸi modelimizin hatalarÄ±nÄ± minimize edecek ÅŸekilde efektif olarak bulmalÄ±yÄ±z. Burada layer arttÄ±kÃ§a modelimiz daha komplike iÅŸlemleri gerÃ§ekleÅŸtirip modelimizi daha komplike hale getirir. (Modelimiz komplike oldukÃ§a overfitting riski artar) Åu anda tek hidden layerÄ±mÄ±z var ve bu layerdaki 3 nÃ¶ron lineer inputlarÄ±mÄ±zÄ±n toplam aÄŸÄ±rlÄ±klarÄ±nÄ±n ReLU fonksiyon deÄŸerini hesaplar.Task 4: Burada hidden layer ve bu layerlara nÃ¶ron ekleyerek optimum lossu saÄŸlayacak modeli oluÅŸturmamÄ±zdan bahsediyor. Burada bilmemiz gereken ÅŸey hidden layer arttÄ±kÃ§a problemimizin outputunun daha da komplike olacaÄŸÄ±dÄ±r. Activaton Layerlar'daki nÃ¶ronlardan her biri bir Ã¶nceki layerda hesaplanmÄ±ÅŸ olan toplam weight deÄŸerlerini alÄ±p o deÄŸerleri akyivasyon tipi ne ise (sigmoid, lineer, ReLu vs) o iÅŸleme tabi tutmaktadÄ±r. Modelimizde kullandÄ±ÄŸÄ±mÄ±z layerlar ve iÃ§indeki nodelar sayesinde modelimizin bir Ã§ok ÅŸekli gÃ¶z Ã¶nÃ¼nde bulundurmasÄ±nda yardÄ±mcÄ± olduk. (Åekilden kastÄ±mÄ±z dÃ¼zlemde verileri ayÄ±rÄ±rken oluÅŸan ÅŸekil.) Bu bilgileri kullanarak hidden layer ve bu layerlardaki nÃ¶ron sayÄ±larÄ±mÄ±zÄ± azaltÄ±p/ArttÄ±rarak optimum modelimizdeki hidden layer, nÃ¶ron sayÄ±larÄ± ne olur?Ä°yi Ã§alÄ±ÅŸmalar.4 weeks ago 9 people like this.Like ReportReply",
    "->  AnladÄ±m teÅŸekkÃ¼r ederim ğŸ™‚4 weeks ago 1 person likes thisLike ReportReply",
    " "
]
},
{
"question_isim": "->  uploaded 2 photos",
"quest": "ArkadaÅŸlar Merhaba,   Sigmoid activation function ile ReLU arasÄ±nda farkÄ± tam olarak anlayamadÄ±m. YardÄ±mcÄ± olabilir misiniz? TeÅŸekkÃ¼rler.",
"comment": [
    "",
    "-> Merhaba,Neural Network'te non-linear iÅŸlemleri activation fonksiyonlarÄ± yardÄ±mÄ±yla yaparÄ±z sigmoid ve ReLU iki farklÄ± aktivasyon fonksyonudur.Sigmoid fonksiyonumuzu bir ihtimal elde etmeye Ã§alÄ±ÅŸÄ±rken kullanÄ±yoruz Ã§Ã¼nkÃ¼ Ã§Ä±kacak output deÄŸerimiz 0-1 arasÄ±ndadÄ±r.ReLU'da ise eÄŸer deÄŸerimiz negatif ise bizde dÃ¶necek ReLU deÄŸeri 0 olur, eÄŸer pozitif ise sayÄ±nÄ±n kendisini dÃ¶ndÃ¼rÃ¼r. Yani pozitifse inputu olduÄŸu gibi output Ã¼zerinden dÃ¶ndÃ¼rÃ¼r.ReLU'nun daha Ã§ok tercih edilmesinin sebebi:-Sigmoid backpropagation esnasÄ±nda modelimizin vanishing gradient sorununu yaÅŸamasÄ±na neden olabilir Ã§Ã¼nkÃ¼ her adÄ±mda hatamÄ±zÄ± Ã¶nemli Ã¶lÃ§Ã¼de azaltÄ±r.Vanishing gradient inputa yakÄ±n olan nÃ¶ronlarÄ±n weight deÄŸerlerinin Ã§ok kÃ¼Ã§Ã¼k olmasÄ± demektir ki bu da ilgili layeÄ±rÄ±n Ã§ok yavaÅŸ veya hiÃ§ eÄŸitilmemesine yol aÃ§ar.- BÃ¼yÃ¼k nÃ¶ral networklerde sigmoid'e gÃ¶re daha hÄ±zlÄ±dÄ±r.Ancak ReLU'da negatif x deÄŸerinin sÄ±fÄ±ra eÅŸitlenmesi ReLU'nun negatif deÄŸerleri Ã§ok iyi maplemeyip eÄŸitemediÄŸi anlamÄ±na gelir.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 7 people like this.Like ReportReply",
    " ->  Ä°lk fark ReLU'nun Sigmoide gÃ¶re daha az hesaplama gerektirmesi. Ä°kinci fark Sigmoid fonksiyonunun gradient tabanlÄ± modellerde Gradient Vanishing diye adlandÄ±rÄ±lan bir probleme sebep olmasÄ±. Bu problemin sebebi Sigmoidin yÃ¼ksek deÄŸerli negatif ve pozitif inputlarda (weightler) dÃ¼ÅŸÃ¼k tÃ¼rev deÄŸerlerine sahip olmasÄ±. Ä°nputlar yÃ¼ksek deÄŸere sahip olmasa bile layerlarda aktivasyon fonksiyonu olarak Sigmoid kullanÄ±rsak layer sayÄ±sÄ± arttÄ±kÃ§a yine Sigmoidin tÃ¼rev deÄŸerlerinin kÃ¼Ã§Ã¼k olmasÄ±ndan dolayÄ± deÄŸerler gittikÃ§e kÃ¼Ã§Ã¼lÃ¼p anlamsÄ±zlaÅŸacak. ReLUâ€™da Gradient Vanishing problemi olmadÄ±ÄŸÄ± iÃ§in tercih ediliyor. Fakat ReLUâ€™da da negatif deÄŸerlerde 0 deÄŸeri verdiÄŸi iÃ§in weight kaybÄ± oluyor. EÄŸer olur da bir Ã§ok negatif weightimiz olursa bir Ã§ok kayÄ±p oluyor. ReLUâ€™nun bu sÄ±kÄ±ntÄ±sÄ± iÃ§in de Leaky ReLU diye adlandÄ±rÄ±lan bir fonksiyon tercih ediliyor :D. AÅŸaÄŸÄ±daki grafik Leaky ReLU'ya ait.1 month ago 7 people like this.Like ReportReply",
    " ->  Sigmoid ve tÃ¼revinin grafiÄŸi:1 month ago 5 people like this.Like ReportReply",
    "->  Oncelikle activation functioni matematiksel bir gecis kapisi ya da esik gibi de dusunebilirsin.Diyelimki 10 tane layerimiz var.Her birinde 10 tane neuron olsun.Ilk layerimiza inputlarimizi girdik.Bunlar weight degerleriyle carpiliyor ve activation function dan elde ettigimiz outputlar bir sonraki layerin noronlarina input olarak aktariliyor. Sigmoid ve Relu non linear activation fonksiyonlardir.Her ne kadar RELU nun grafigi linear gibi gorunsede non-lineardir.Non linear activation functions arificial neural network ve deep neural network te kullanilir.Bunun sebebi turevleri vardir ve bu durum backpropagationa olanak saglayarak ogrenmeyi gerceklestirir..Linear bir functionin turevi bir sabittir dolayisiyla neural networku tek bir layer a donustureceginden kullanilmaz..Sigmoid binary classification yapmak icin logistic regression da kullanilir.Softmax ise sigmoid in ozel bir halidir.Cok onemlidir.4 weeks ago 9 people like this.Like ReportReply",
    "->  YardÄ±mlarÄ±nÄ±z iÃ§in Ã§ok teÅŸekkÃ¼rler arkadaÅŸlar.4 weeks ago 2 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar , ben MentorlarÄ±mÄ±za ÅŸunu sormak istiyorum. Bu kursa hergÃ¼n 1 saatte bakÄ±labilir veya 1 gÃ¼n de 1 haftalÄ±k konular da bitirilebilir  saÃ§ma gelebilir ama siz bu olayÄ± iÅŸ olarak yapÄ±yorsunuz ve gÃ¼nlÃ¼k nasÄ±l bir Ã§alÄ±ÅŸma dÃ¼zeniniz var. Bir Ã¶neri sorusu olarak soruyorum sadece kurs iÃ§in deÄŸil gÃ¼nlÃ¼k hayatta iÅŸ olarak yaptÄ±ÄŸÄ±nÄ±z iÃ§in soruyorum VerimliliÄŸi arttÄ±rmak adÄ±na nasÄ±l bir yol Ã¶nerirsiniz ya da siz nasÄ±l bir yol izliyorsunuz kaÃ§ saatinizi hangi konuya ayÄ±rÄ±yorsunuz ?",
"comment": [
    "",
    "->  bende ÅŸunu merak ediyorum detaylarla uÄŸralÄ±rken Ã§okzaman harcÄ±yorum bu seferde normalden Ã§ok geri kalÄ±yorum alt yapÄ± eksikliÄŸimde var bize bi yol gÃ¶sterin lÃ¼tfen4 weeks ago 2 people like this.Like ReportReply",
    "->  Merhabalar,Nacizane kendi fikrimi belirtmek istersem sadece bu konuda deÄŸil hayatÄ±nÄ±za tatbik edeceÄŸiniz her iÅŸ iÃ§in Ã¶nerim ÅŸu olurdu. \"TaÅŸÄ± Delen Suyun GÃ¼cÃ¼ DeÄŸil, DamlalarÄ±n SÃ¼rekliliÄŸidir\".SaygÄ±larÄ±mla4 weeks ago 3 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "->",
"quest": "Merhabalar, sanÄ±rÄ±m sitedeki bir deÄŸiÅŸiklikten dolayÄ± sorularÄ±m kendi profilimde paylaÅŸÄ±yormuÅŸum hep, dolayÄ±sÄ±yla gÃ¶rÃ¼nmediÄŸi iÃ§in cevap alamadÄ±m. BazÄ±larÄ±nÄ± kendim hallettim fakat bazÄ±larÄ±nÄ± hala anlamÄ±ÅŸ deÄŸilim.  Yorumlara ekliyorum.   Åimdiden teÅŸekkÃ¼r ederim..",
"comment": [
    "",
    "-> L1 ve L2 regularizationu kafamda tam oturamÄ±yorum. Ama anladÄ±m yÃ¼zeysel olarak...** Mesela regularization sparse kÄ±smÄ±nÄ±n exercise kÄ±smÄ±nda iÅŸaretlediÄŸim deÄŸeri L1 neden sÄ±fÄ±rlamamÄ±ÅŸ, yanÄ±ndaki weightte sÄ±fÄ±rlama olmuÅŸ. SanÄ±rÄ±m anlamadÄ±m :/.",
    "->  -> Merhaba,L1 regÃ¼larizasyonu weight deÄŸerlerini sÄ±fÄ±rlar. her adÄ±mda weight deÄŸerinden sabit bir deÄŸeri Ã§Ä±karÄ±r. Gereksiz feature deÄŸerlerinin (genelde sparse matrixteki 0 olan featuerlarÄ± dÃ¼ÅŸÃ¼nebilirsiniz) weight oranlarÄ±nÄ± sÄ±fÄ±rlarÄ±p onlarÄ± yok etmek iÃ§in kullanÄ±lÄ±r.L2 regÃ¼larizasyon overfit olmayÄ± Ã¶nlemek iÃ§in vardÄ±r ve weight deÄŸerlerini sÄ±fÄ±rlamaz. Ã‡Ã¼nkÃ¼ weight deÄŸerlerini sÄ±fÄ±rlarsa o weight'e baÄŸlÄ± feature'Ä± da yok etmiÅŸ olur.1 month ago 4 people like this.Like ReportReply",
    "->  ->  Sadece L2 degil, L1, L2 ve Dropout her ucu de overfitting probleminin onune gecmek icin uygulanan regularization tekniklerdir.L1 i L2 ile karsilastirirsak, L2 weightslerin degerini cok kucultur ve bir kismini ihmal ederken, L1 weightsleri sifir yapar, daha radikaldir.Bunun icin cok genis datasetleriyle kullanmak yerinde olacaktir.Tensorflow dan emin degilim ancak Keras L1 ve L2 yu birlikte kullanmayi mumkun kiliyor.Hatta birde Dropout bile ekleyebilirsin ancak beraber kullanilmasi tavsiye edilmez.Regulerize edelim derken cok fazla feature kaybetmek istemeyiz..4 weeks ago 3 people like this.Like ReportReply",
    "->  ->  evet pratikte baktÄ±ÄŸÄ±nÄ±z zaman hepsi weight deÄŸerlerini dÃ¼ÅŸÃ¼rdÃ¼ÄŸÃ¼ iÃ§in overfiti Ã¶nleyen bir seÃ§enektir. Burada dikkat Ã§ekmek istediÄŸim nokta L2 regÃ¼larizasyonunun feature kaybÄ± olmadan regÃ¼larize etmesi, L1 regÃ¼larizasyonunun ise gereksiz feature deÄŸerleirni sÄ±fÄ±rladÄ±ÄŸÄ±ydÄ±. Bilgilendirme iÃ§in teÅŸekkÃ¼r ederim.Ä°yi Ã§alÄ±ÅŸmalar.4 weeks ago 4 people like this.Like ReportReply",
    "-> -> Yukarida ben de Fethi de L1 ve L2 hakkinda birseyler soyledigimizi ama senin sorunu cevaplamadigimizi farkettim.Aslinda 2 soru var.Neden 0.39 olan weight degerini sifirlarken 0.37 degerini sifirlamayip 0.31 e indirgemis ? Oncelikle L1 in degeri kucuk olan etkisi az olan weightsleri sifirlamasini bekliyoruz.Ancak ya weightslerin cok buyuk kisminin degeri kucukse o zaman hepsini sifirlayacak mi? Hayir.Belli bir kismini, modelin ezberlemsinin onune gececek kadar olanini sifirlasa yeter.Dropout da bu orani belirliyorsun.Mesela diyorsun ki % 50 sini etkisiz hale getir.Demekki ilk olarak bazi dusuk degerli weightslerin kalmaya devam etmesi normal.Peki eger dusuk degerli bir weight kalacaksa kotunun iyisi olsun yani dusuk degerlilerin en buyuk degerlisi kalmali dusuncesi mantikli geliyor.Dolayisiyla neden L1 in hepsini sifirlamadigini anliyoruz ancak neden sifirlamak icin 0.37 degerini degil de 0.39 u sectigini tam olarak anlayamiyorum.Belki soyle dusunebiliriz.Birbirinee cok yakin degerler dolayisiyla birini secmis. diyebiliriz:)4 weeks ago 3 people like this.Like ReportReply",
    "-> ->  Evet aslÄ±nda iki soru vardÄ± bir de resimli olarak sormuÅŸtum ğŸ™‚ Ama benim soruÅŸ tarzÄ±mla alakalÄ± anlayamamÄ±ÅŸ olmanÄ±z Ã§ok normal, karÄ±ÅŸÄ±k sormuÅŸum ikinize de ayrÄ± ayrÄ± cevaplarÄ±nÄ±z iÃ§in Ã§ok teÅŸekkÃ¼r ederim. ÅŸimdi daha iyi oturdu kafamda... -> 4 weeks ago Like ReportReply",
    "->  Merhaba. Buradan sormak daha doÄŸru geldi. Peki L1 ve L2 DÃ¼zenlemelerinin hangilerini hangi datasetlerde kullanmak daha mantÄ±klÄ±? Yani ÅŸÃ¶yle diyebilir miyiz; eÄŸer datasetiniz bÃ¼yÃ¼k, ayrÄ±k verileri iÃ§eriyor, Ã§oÄŸunluÄŸu 0 ise L1 dÃ¼zenleme kullanÄ±n4 weeks ago 1 person likes thisLike ReportReply",
    "->  ->  Oncelikle L1, L2 ve Dropout cok katmanli neural network lerde overfitting i engellemek icin kullaniyoruz.Eger datasetin buyukse den ziyade soyle ifade etmek istiyorum:Feature larinin sayisi fazla ise L1 ile bunlarin bir kisminin gitmesinde cok sakinca yok geriye hala yeteri kadar feature kalacaktir diye dusunebilirsin.Ama sunu bilmelisin L1 in sifirladigi feature lari kaybediyorsun.Ancak L2 bu feature lari zero yapmiyor sadece daha da kucultup ignore ediyor.Dolayisiyla L2 daha guvenli gorunuyor..Multi Class programing orneklerinde MNIST dataseti icin verilen ornek uzerinde regulator lari degistirerek sonuclari karsilastirabilirsin.4 weeks ago 1 person likes thisLike ReportReply",
    "->  ->  TeÅŸekkÃ¼r ederim4 weeks ago 1 person likes thisLike ReportReply",
    "-> AUC eÄŸrisi Ã§izilirken farklÄ± Thresholds deÄŸerleri alÄ±narak Ã§iziliyor. Peki, buradaki koda baktÄ±ÄŸÄ±mÄ±zda bu kÄ±smÄ± oluÅŸturan kod blogu hangisidir? (Classification Programlama Egzersizi KÄ±smÄ±nda Son Task).",
    "->  -> Merhaba,tf.keras.metrics.AUC metodunda auc u hesaplamak iÃ§n kullanÄ±lan True Positive, True Negative, Falpse Positive ve False Negative deÄŸerleri oluÅŸturuluyor. Bu threshold sayÄ±sÄ±nÄ± da num_of_thresholds parametresi belirliyor. Thresholdlar auc metodu tarafÄ±ndan otomatik belirlendiÄŸi gibi thresholds parametresiyle de siz belirleyebilirsiniz.Kaynak: https://www.tensorflow.org/api_docs/python/tf/keras/metrics/AUCÄ°yi Ã§alÄ±ÅŸmalar.tf.keras.metrics.AUC Â |Â  TensorFlow Core v2.1.0www.tensorflow.orghttps://www.tensorflow.org/api_docs/python/tf/keras/metrics/AUC1 month ago 3 people like this.Like ReportReply",
    "-> 3- Yine regularization playground exercise kÄ±smÄ±nda weight deÄŸerlerine baktÄ±ÄŸÄ±mÄ±zda sorulara cevap verirken kafam karÄ±ÅŸtÄ± (-) deÄŸerlerden dolayÄ±, yani eksi olan weight deÄŸerlerinin artÄ±p azalmasÄ± ile alakalÄ± - deÄŸerden 0'lanmasÄ± ya da 0'a yakÄ±nsamasÄ± acaba azalma olarak mÄ± deÄŸerlendiriliyor? Bir yeri kaÃ§Ä±rdÄ±m galiba.",
    "->  -> Merhaba,Weightler azaldÄ±ÄŸÄ±nda veya arttÄ±ÄŸÄ±nda durumundan ziyade en optimum weight deÄŸerlerinde modelimiz efektif Ã§alÄ±ÅŸÄ±r. Weight deÄŸeri sÄ±fÄ±ra yakÄ±nsarsa bu weighte baÄŸlÄ± feature deÄŸerinin modelimizde o kadar az etkisi olur.Sorunuzu yanlÄ±ÅŸ anladÄ±ysam beni aydÄ±nlatÄ±n lÃ¼tfen.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 4 people like this.Like ReportReply",
    "->  -> Merhabalar,(-) weight deÄŸerleri 0'a yakÄ±nsarken deÄŸerleri artmaktadÄ±r. Bu matematiksel olarak bÃ¶yledir. Ancak weightler iÃ§in negatif veya pozitif olmalarÄ± farketmeksizin 0'a yakÄ±nsadÄ±kÃ§a etkinlikleri azalÄ±r. Burada negatifliÄŸi, etkinin yÃ¶nÃ¼ olarak dÃ¼ÅŸÃ¼nebilirsiniz.DolayÄ±sÄ±yla sorunuzun cevabÄ± da (-) deÄŸerli bir weight'in 0'a yakÄ±nsamasÄ± etkinliÄŸinin azaldÄ±ÄŸÄ±nÄ±n gÃ¶stergesidir.Edit: ->  uyarÄ±sÄ± Ã¼zerine, ilk cÃ¼mleden \"mutlak\" kelimesi Ã§Ä±karÄ±ldÄ±.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 3 people like this.Like ReportReply",
    "->  ->  Matematiksel olarak negative degerler 0 a yaklastikca mutlak degeri artmaz,0 dan uzaklastikca mutlak degeri artar..",
    "->  ->  TeÅŸekkÃ¼rler, yazarken dikkatsizliÄŸime gelmiÅŸ..",
    "->  ->  Rica ederim ğŸ™‚.",
    "->  Eger weights leri hesaplarken kullandigimiz formulu gozonune alirsak weight degerinin negative olmasi, bir onceki weight degerinin yani formuldeki eski, update edilmemis weight degerinin learning rate ile loss degerinin carpimindan kucuk olmasi demektir.Bu durum bizi su soruya goturuyor.Negative weight degerinden sonra update edilen weight degerleri hep negative mi olur? Evet deseydik, loss degerinin her zaman pozitif bir deger oldugunu soyluyor olurduk ki loss negative olabilir.ornek:Negative Log Loss1 month ago 2 people like this.Like ReportReply",
    "-> L2'den L1'e geÃ§iÅŸi yorumlayamadÄ±m aslÄ±nda... Åu kÄ±sÄ±m.. ->  ->  ->  (-) deÄŸerler kafamÄ± karÄ±ÅŸtÄ±rdÄ±.. (-) deÄŸerden 0'a yakÄ±nsamÄ±ÅŸ, etkinlik azaldÄ± dememiz mi gerekiyor sonuÃ§ olarak.",
    "->  L1 regÃ¼larizasyonunda siz weight deÄŸerinizin mutlak deÄŸerinden bir k sabiti Ã§Ä±karÄ±rsÄ±nÄ±z bu da L2 regÃ¼larizasyonuna gÃ¶re daha Ã§abuk 0'a yakÄ±nsamasÄ± demek. Mutlak deÄŸerden k sabiti Ã§Ä±kardÄ±ÄŸÄ±mÄ±z iÃ§in negatiflik pozitiflik L1 regÃ¼larizasyonunda fark oluÅŸturan bir etmen deÄŸildir yani negatiften yakÄ±nsamasÄ± ile pozitiften yakÄ±nsamasÄ± arasÄ±nda etkinlik farkÄ± yoktur.DolayÄ±sÄ±yla L2'den L1'e geÃ§erseniz Ã¶ÄŸrenilen tÃ¼m aÄŸÄ±rlÄ±klar azalÄ±r. Bunun yanÄ±nda L2'den L1'e geÃ§iÅŸ test kaybÄ± ve eÄŸitim kaybÄ± arasÄ±ndaki aralÄ±ÄŸÄ± da oldukÃ§a azaltÄ±r.L1 regularization rate'inin arttÄ±rÄ±lmasÄ± Ã¶ÄŸrenilen weight deÄŸerlerini azaltÄ±r ancak, dÃ¼zenlenme oranÄ± Ã§ok yÃ¼kselirse, model yakÄ±nsama yapamaz ve buna baÄŸlÄ± olarak loss deÄŸerleri Ã§ok yÃ¼ksek olur.1 month ago 2 people like this.Like ReportReply",
    "-> Ã§ok teÅŸekkÃ¼r ederim4 weeks ago Like ReportReply",
    " "
]
},
{
"question_isim": "->  uploaded 1 photo",
"quest": "Merhaba GrafiÄŸi yorumlamakta gÃ¼Ã§lÃ¼k Ã§ektim yardÄ±mcÄ± olursanÄ±z sevinirim.  3 Ã§izgi neyi temsil ediyor x ve y eksenleri aÃ§Ä±klanmÄ±ÅŸ. -7 olarak tahmin edilmiÅŸ ortalama skor aslÄ±nda datada -8 e mi denk geliyormuÅŸ ? bunu anlamlandÄ±ramÄ±yorum bu benim iÃ§in ne ifade ediyor eksenlerin logaritmik oldugu sÃ¶ylenmiÅŸ fakat herhangi logitmik artÄ±ÅŸta gÃ¶remiyorum belkide gÃ¶zden kaÃ§Ä±rÄ±yorum. Bu kÃ¶tÃ¼ sÄ±nÄ±flandÄ±rmaya ait bir grafikse iyi bir sÄ±nÄ±flandÄ±rmaya grafigi neye benzemeliydi teÅŸekkÃ¼rler.",
"comment": [
    "",
    "-> Ã–ncelikle ÅŸunu sÃ¶yleyeyim ki; eksenler logaritmik olarak Ã¶lÃ§eklendirilmiÅŸ. Herhangi bir logaritmik artÄ±ÅŸtan bahsetmemizi gerektirecek bir grafik deÄŸil, yalnÄ±zca modelin tahminleri ile gerÃ§ek deÄŸerler arasÄ±ndaki Ã¶rtÃ¼ÅŸmeye baktÄ±ÄŸÄ±mÄ±z bir grafik.X ekseni modelin yaptÄ±ÄŸÄ± tahmini, Y ekseni ise gerÃ§ekteki deÄŸeri gÃ¶stermekte. Ortada yer alan pembemsi lineer Ã§izgi bizim tahminimiz ile gerÃ§ekteki (actual) deÄŸerinin tam Ã¶rtÃ¼ÅŸtÃ¼ÄŸÃ¼ durumda Ã§izilecek Ã§izgidir. Yani tahmin -6.000'da iken gerÃ§ek deÄŸeri de -6.000'da ise o point tam olarak pembemsi Ã§izginin Ã¼zerine dÃ¼ÅŸer. Ãœst ve altÄ±ndaki aÃ§Ä±k mavi ve yeÅŸilimsi Ã§izgiler ise tahmin ediyorum ki Ã¼st ve alt gÃ¼ven aralÄ±ÄŸÄ± limitleri. Tabiki her noktayÄ± hatasÄ±z olarak tahmin edemeyebiliriz bir miktar (%1, 5 belki 10) hata kabul edilebilir. Bu mavi ve yeÅŸil Ã§izgiler de bu gÃ¼ven aralÄ±ÄŸÄ±nÄ± temsil ediyor diye dÃ¼ÅŸÃ¼nÃ¼yorum. Tahmin verilerinin daha dÃ¼ÅŸÃ¼k olduÄŸu (-6.000 ve daha dÃ¼ÅŸÃ¼k) noktalarda Ã§izgilerin dÄ±ÅŸÄ±nda yer alma durumu sÃ¶z konusu. Bunlar bizim veriyi -en azÄ±ndan bir kÄ±smÄ±nÄ±- iyi tahmin edemediÄŸimizi gÃ¶steriyor. Bunun birkaÃ§ sebebi olabilir: Ä°lk sebebi heteroscedasticity, yani deÄŸiÅŸken varyans. Verinin belli bir kÄ±smÄ± daha fazla gÃ¼rÃ¼ltÃ¼ iÃ§eriyor olabilir. Lambda deÄŸerini olmasÄ± gerekenden yÃ¼ksek tutarak fazla regÃ¼larize etmiÅŸ olabilir ve training setimiz ana verimizin belli alt kÃ¼melerini yeteri kadar iyi temsil etmiyor olabilir.1 month ago 3 people like this.Like ReportReply",
    "->  -> eksenlerin logaritmik olarak Ã¶lÃ§eklendirildiÄŸini nasÄ±l belirlediniz?4 weeks ago Like ReportReply",
    "->  ->  eksenlerin logaritmik Ã¶lÃ§eklendirildiÄŸi crash course iÃ§erisinde yer alÄ±yor fakat eksenlerdeki deÄŸerlere bakÄ±nca logaritmik artÄ±ÅŸ gÃ¶remediÄŸim iÃ§in anlamada gÃ¼Ã§lÃ¼k Ã§ektim. 64 49 36 olarak yazÄ±lsaydÄ± mantÄ±klÄ± olurdu gibi ?4 weeks ago Like ReportReply",
    "->  ->  Eksenler 10 100 1000 10000 ÅŸeklinde olsa idi logaritmik olur du.4 weeks ago 1 person likes thisLike ReportReply",
    "-> -> Burada Lambda cok kucukse de, yani model training set'e overfit olduysa, yine prediction bias fazla olmaz miydi? (yani over-regularization'in tam zitti da bu soruna yol acmaz mi?) Neden sadece Lambda'nin cok buyuk olmus olabilecegi dusunuluyor?4 weeks ago Like ReportReply",
    "-> -> YaklaÅŸÄ±m doÄŸru lambda olmasÄ± gerekenden fazla kÃ¼Ã§Ã¼k olursa overfit olur fakat prediction bias'Ä±n tanÄ±mÄ± ile alakalÄ± bir durum sÃ¶z konusu. FormÃ¼lÃ¼ bize ÅŸunu sÃ¶ylÃ¼yor:Tahminlerin ortalamasÄ± - Actual deÄŸerlerin ortalamasÄ± deÄŸerinin olabildiÄŸince az olmasÄ±ndan bahsediyor. LambdayÄ± olmasÄ± gerekenden Ã§ok bÃ¼yÃ¼k seÃ§ersek underfitting olacaÄŸÄ±ndan bizim modelin tahmin deÄŸerleri actual deÄŸerlerden uzak kalacaktÄ±r ve bu prediction bias'a sebep olacaktÄ±r. Fakat lambdayÄ± fazlaca kÃ¼Ã§Ã¼k seÃ§ersek overfitting olacak ve bizim modelin tahmin deÄŸerleri actual deÄŸerlere oldukÃ§a yakÄ±n olacaktÄ±r.Bu noktada dolaylÄ± bir problem sÃ¶z konusu olabilir. O da overfitting'den dolayÄ± test verisinin prediction bias'Ä±nÄ±n istenenden fazla olmasÄ±. DolaylÄ± bir etki olarak lambdayÄ± kÃ¼Ã§Ã¼k de seÃ§mek training verisi iÃ§in deÄŸil ancak test verisi iÃ§in prediction bias yaratabilir diyebiliriz.4 weeks ago Like ReportReply",
    " "
]
},
{
"question_isim": "->  uploaded 1 photo",
"quest": "Merhaba arkadaÅŸlar. Burada kutucuk iÃ§erisine aldÄ±ÄŸÄ±m yeri anlayamadÄ±m . Muhtemelen bir yeri kaÃ§Ä±rdÄ±m , yardÄ±mcÄ± olabilirseniz Ã§ok sevinirim.",
"comment": [
    "",
    "->  Merhaba,Kutucuk iÃ§erisine aldÄ±ÄŸÄ±nÄ±z ifade ReLU fonksiyonu, max(0, x)-> 0 ile x'den hangisi bÃ¼yÃ¼kse onu geri dÃ¶ndÃ¼rÃ¼r.1 month ago 5 people like this.Like ReportReply",
    "->  ->  Ã§ok teÅŸekkÃ¼r ederim ÅŸimdi anladÄ±m..",
    "->  ReLU fonksiyonu 0'a kadar (negatif deÄŸerlerden 0'a kadar) 0 deÄŸeri, 0'dan sonra da kendi deÄŸerini (x deÄŸerini) verir.Ã¶rn: x=-2 olsun f(x)=0 olur.x=3 olsun f(x)=3 olur.1 month ago 3 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba, konularla tam baÄŸlantÄ±lÄ± olmasa da bir ÅŸey takÄ±ldÄ± kafama. Bu kurs sÃ¼recinde, temel kavramlar gÃ¶rdÃ¼k. Epoch, learning rate, batch size gibi.. Bunlar, makine Ã¶ÄŸrenmesinin temeli diyebilir miyiz? Demek istediÄŸim, flapy bird veya snake oynayan/Ã¶ÄŸrenen bir yapÄ± ile spam mail ayÄ±ran yapÄ±da benzer kavramlar bulunuyor mu? Yoksa, baÅŸka alanlarda baÅŸka kavramlar, baÅŸka temeller mi giriyor?",
"comment": [
    "",
    " -> Tabii dÃ¼ÅŸÃ¼nÃ¼nce, veri seti olmazsa neyi batchlere ayÄ±racaÄŸÄ±z gibi bir soru da Ã§Ä±kabiliyor ortaya ama genel olarak anlaÅŸÄ±ldÄ±ÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum..",
    "->  Flapy bird oynayan yaoiyi bilmiyorum ğŸ™‚ Ancak spam mail ayiran yapi olarak tarif ettigin sey binary classification yapiyor,.",
    "-> Flappy Bird/Snake gibi oyunlarÄ± Ã¶ÄŸretmek iÃ§in kullandÄ±ÄŸÄ±nÄ±z metoda gÃ¶re, temel kavramlar deÄŸiÅŸiklik gÃ¶sterecektir. Ã–rneÄŸin, yÄ±lan oyununu kendi kendine oynayan bir yazÄ±lÄ±m iÃ§in farklÄ± Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± olabilir.1 - Algoritmik yaklaÅŸÄ±m: Oyunun state'ine gÃ¶re bir sonraki hamleyi verecek algoritmayÄ± kendiniz kodlarsÄ±nÄ±z. Burada herhangi bir makine Ã¶ÄŸrenmesi sÃ¶zkonusu deÄŸil.2 - Supervised Learning: Modelinize yÃ¼zbinlerce etiketlenmiÅŸ training data verirsiniz. Burada inputlar farklÄ± oyun state'leri, label'lar da ilgili state iÃ§in oynanmasÄ± gereken doÄŸru hamle olabilir. Ã–nceden oynanmÄ±ÅŸ oyunlar ile model eÄŸitilebilir.3 - Reinforcement Learning: YapÄ±lan hamle serilerinin sonucunda Ã¶dÃ¼l/ceza sistemi uygulayarak modelin kendi kendine oynayarak Ã¶ÄŸrenmesi saÄŸlanabilir.4- Genetik Algoritmalar: Bir neural network'Ã¼n parametrelerini (weights & biases) yÄ±lanÄ±n genetiÄŸi olarak dÃ¼ÅŸÃ¼nebiliriz. Mutasyonlar ve crossoverlar ile yeni nesil yÄ±lanlar tÃ¼retilir ve en iyi performansÄ± gÃ¶sterenler seÃ§ilir. Bu bir dÃ¶ngÃ¼ halinde tekrar edilir ve giderek daha baÅŸarÄ±lÄ± (fit) yÄ±lanlar elde edilmiÅŸ olur.Bu baÅŸlÄ±klar iÃ§in benzer kavramlar mutlaka vardÄ±r ama hepsinin kendine Ã¶zgÃ¼ temel kavramlara sahip olduÄŸu aÅŸikar.1 month ago 3 people like this.Like ReportReply",
    " -> -> Ã‡ok teÅŸekkÃ¼r ederim, Ã§ok aÃ§Ä±klayÄ±cÄ± yorum olmuÅŸ..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar, ROC curve ve Auc 'un iÅŸlevini pek anlayamadÄ±m biz bunlarÄ± nede kullanÄ±yoruz bu bir zorunluluk mudur acaba?",
"comment": [
    "",
    "->  Merhaba,https://community.globalaihub.com/?status/1482-1482-1587629584/#comment.4782.4624.4624 yorumumda bunlarÄ± aÃ§Ä±klamaya Ã§alÄ±ÅŸtÄ±m. Zorunlu deÄŸillerdir ama yapmamÄ±z modelin performansÄ±nÄ± Ã¶lÃ§memiz aÃ§Ä±sÄ±ndan Ã¶nemlidir.Ä°yi Ã§alÄ±ÅŸmalar.Community.",
    "->  Precision/recall, F1-score, error rate, accuracy , ROC curve ve AUC classification icin kullanilan performans metriclerdir.Burada classification kisminin altini cizmek istiyorum cunku amacimiz prediction iyapmaksa RMSE, Pearson's correlate coefficient ve coefficient of determination kullanilir.Bu performans metrikleri genel olarak error analizi yapip modelimizi gelistirmeye yarar.1 month ago 5 people like this.Like ReportReply",
    "->  Specifik olarak ROC curves en iyi thereshold degerinin karar verilmesini kolaylastirirken, AUC hangi siniflandirma methodunun daha iyi olduguna karar vermemize yardim eder.1 month ago 7 people like this.Like ReportReply",
    "->  teÅŸekkÃ¼rler.",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba arkadaÅŸlar,  Roc curve'de neden TPR ve FPR adÄ± verilen iki parametreyi kullanÄ±yoruz? ve bir de FPR 'de neden True negativ'i hesaplamak yerine False positive'i hesaplÄ±yoruz?",
"comment": [
    "",
    "->  Merhaba,TPR dediÄŸimiz parametre Recall metriÄŸidir aslÄ±nda. Recall ÅŸunu sorar True Positivelerin kaÃ§ tanesi modelimiz tarafÄ±ndan tahmin edildi? TPR deÄŸerimizin kullanÄ±m amacÄ± budur.TPR ve FPR deÄŸerleri birbirileri ile korelasyonludur ve curve'Ã¼mÃ¼zÃ¼ (1,1) noktasÄ±nda sÄ±nÄ±rlayabiliyoruz. FarklÄ± threshold deÄŸerlerinde bir deÄŸer(TRP Ã¶rnreÄŸin) artarken diÄŸer deÄŸer de (FPR Ã¶rneÄŸin) buna baÄŸlÄ± olarak artÄ±ÅŸ gÃ¶sterecektir. Bu deÄŸerleri kullandÄ±ÄŸÄ±mÄ±zda aynÄ± tahmin setinin tpr ve fpr deÄŸerlerini gÃ¶rebilmek, eÄŸer modelimizde bir problem var ise ( https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5 linkindeki How to speculate the performance of the model? kÄ±smÄ±nda bunlara deÄŸiniliyor ) bu kolayca tespit edilebilir.Ä°yi Ã§alÄ±ÅŸmalar.",
    "Understanding AUC - ROC Curvetowardsdatascience.comIn Machine Learning, performance measurement is an essential task. So when it comes to a classification problem, we can count on an AUC â€¦.",
    " ->  ->  merhaba, https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5 ÅŸu linkte tpr ve fpr deÄŸerlerinin birbirlerini pozitif yÃ¶nde etkilediÄŸi ifade edilmiÅŸ. Bu deÄŸerler birbirlerini hangi yÃ¶nde etkiliyor. AyrÄ±ca FPR =1-specifity olarak tanimlanmiÅŸ. Specifity kavramÄ± crash courseta aÃ§Ä±klanmamÄ±ÅŸ ama. Specifityden ne anlamalÄ±yÄ±z? TeÅŸekkÃ¼r ederim.",
    "Understanding AUC - ROC Curvetowardsdatascience.comIn Machine Learning, performance measurement is an essential task. So when it comes to a classification problem, we can count on an AUC â€¦4 weeks ago 1 person likes thisLike ReportReply",
    "->   ->  Merhaba,Evet orada ufak bir anlaÅŸmazlÄ±k olmuÅŸ.TPR deÄŸeri sizin Recall deÄŸeriniz. Specifity deÄŸeriniz ise Recall deÄŸerinizin Positive classlar iÃ§in deÄŸil negative classlar iÃ§in hesaplanmÄ±ÅŸ deÄŸeridir.FPR deÄŸeriniz 1-Specifity'dir. Bu baÄŸlamda biz thresholdu arttÄ±rdÄ±ÄŸÄ±mÄ±zda TPR zaten artacaktÄ±r, specifity deÄŸerimiz dÃ¼ÅŸeceÄŸi iÃ§in FPR deÄŸerimiz artacaktÄ±r. Oradaki anlam karmaÅŸasÄ±nÄ± da dÃ¼zelttim. UyarÄ± iÃ§in teÅŸekkÃ¼rler.Ä°yi Ã§alÄ±ÅŸmalar.4 weeks ago 1 person likes thisLike ReportReply",
    "-> True Positive Rate = TPR = Recall =TP/(TP+FN) False False Positive Rate = FPR = FP / (FP+TN) = 1-(True Negative Rate) True Negative Rate = TNR = TN/(FP+TN) Roc Curve, True Positive Rate ile False Positive Rate arasindaki iliskiyi ifade ediyor.Ne yaptigimizi iyi anlayalim.Classification yapiyoruz.Bunun icin Precision/recall, F1-score, error rate, accuracy ve ROC curve performance metriklerimiz ve bunlardan yararlanarak hata analizi yapip modelimizi gelistirecegiz.Classification yaparken labellar probabilistic distrubition sonucunda belirleniyor.Roc curve icin true ya da false farketmez kesinlikle pozitif degerlerle ilgileniyoruz ve True, false olasiliklarin degisimine bakiyoruz.Ve tabiki TPR ve FNR 0 ve1 arasinda degerler aliyor.Son olarak sordugun soruya geldigimde FPR yi hesaplarken True Negative Rate i hesapliyorsun, false negativi degil..",
    "->  https://youtu.be/4jRBRDbJemMROC and AUC, Clearly Explained!youtu.beROC (Receiver Operator Characteristic) graphs and AUC (the area under the curve), are useful for consolidating the information from a ton of confusion matric...1 month ago 8 people like this.Like ReportReply",
    "->  ->  Videonun ozetle kismi cok iyi aciklamis.Roc corves threshold degerini belirlemeyi kolaylastiriyor.AUC ise hangi classification methodunun daha iyi oldugu konusunda karar vermemize yardim ediyor..",
    "->  teÅŸekkÃ¼rler1 month ago 2 people like this.Like ReportReply",
    "-> Yalniz ROC egrisinden hangi threshold degerinin hangi sonuca vardigini cikarsayamiyoruz (thr degerine gore sirali degiller). O zaman bu egri uzerindeki noktalar bize threshold degerinin ne oldugu bilgisini vermiyor. degil mi? -> 4 weeks ago Like ReportReply",
    "->  ->Evet, burada eÄŸri noktalar bize threshold deÄŸerini vermez. Burada AUC ile hesapladÄ±ÄŸÄ±mÄ±z zaten bÃ¼tÃ¼n threshold deÄŸerlerinde nasÄ±l bir performans elde edebileceÄŸimiz. ROC curve'Ã¼nde ise TPR ve FPR deÄŸerleriyle threshold'u elde edemeyiz.4 weeks ago Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar, birkaÃ§ sorum var onlarÄ± sÄ±rayla sormak istiyorum. Her soruyu yorum olarak atÄ±yorum.",
"comment": [
    "",
    " -> DiÄŸer Metriclerde, â€œclassification_thresholdâ€ deÄŸerini kullanÄ±rken (ki bu deÄŸer de 0.52) neden AUC iÃ§in kendimiz bir deÄŸer atadÄ±k? AyrÄ±ca bu deÄŸeri neye gÃ¶re belirledik?.",
    " -> Burada, model.add diye baÅŸlayarak yeni katmanlar ekliyoruz ve unitsâ€™de de katmanlarÄ±n ne kadar nÃ¶ron iÃ§ereceÄŸini belirliyoruz. Peki, neye gÃ¶re belirliyoruz? KaÃ§ katman olacaÄŸÄ±nÄ±, kaÃ§ nÃ¶ron olacaÄŸÄ±nÄ± neye gÃ¶re belirliyoruz?.",
    "->   -> Oncelikle novel bir model yaratirken kac layer ekleyecegini kimse sana soyleyemez.Mesela Oxford tarafindan yayinlanan vgg16 modelini dusun.Neye gore layer sayisini belirlediklerinin belli bir cevabi yok.Ayni sekilde 50 layerdan olusan Resnet 50 ya da Resnet 101.Ancak layer sayisi arttikca ve azaldikca neler oluyor sorusunun cevabi var.Layer sayisi arttikca modelin derinlesir komplex hale gelir.Overfitting probleminin ortaya cikma olasiligi artar..",
    " -> ->  Peki ama ÅŸu da var, overfittingden kaÃ§Ä±nma yollarÄ±mÄ±z; learning ratei ayarlamak, Ã¶ÄŸrenmeyi erken bÄ±rakmak gibi yÃ¶ntemler.. Yani optimum noktaya ulaÅŸana kadar, elimizdeki her ÅŸeyi ayarlayarak ilerleyeceÄŸiz, kimse bize neyin ne olduÄŸunu sÃ¶ylemiyor diyorsunuz, Ã¶yle mi?.",
    "->  -> Kimse sana kac layer kullanacagini ya da kac tane kullanman gerektigini soyleyemez cunku kimse bilmiyor.Sadece cok layer eklenince ne oluyor az sayida layer ile ne oluyor kismini tecrube ederek ogreniyorsun.Dedigin gibi overfitting problemleri icin regularization tekniklerini kullaniyorsun.Son olarak, fazla sayida layer daha iyi model anlami tasimaz.Bazen daha basit bir modelle iyi sonuclar alirsin..",
    " -> Belki kaÃ§ kez soruldu amaâ€¦ SorularÄ±mÄ±zÄ± cevaplayan mentÃ¶rlerimiz ve diÄŸer yazÄ±larda da gÃ¶rÃ¼yorum, bu deÄŸerleri tecrÃ¼be edindikÃ§e ve benzer Ã§alÄ±ÅŸmalarÄ± inceledikÃ§e neler vereceÄŸimizi anlÄ±yoruz diyorlar. Fakat, Ã¶rneÄŸin learning rateâ€™in aÅŸÄ±rÄ± veya Ã§ok dÃ¼ÅŸÃ¼k olduÄŸunu lossâ€™taki sapmalardan veya hiÃ§ dÃ¼ÅŸmemesinden anlayabiliyorum. Fakat Epoch, batch sizeâ€™larÄ± gerÃ§ekten neye belirleyeceÄŸiz? Bu noktaya geldim hala kafam almÄ±yor...",
    "->  Oguzhan epochs ve batch_size konusunda ne kadar zamanin oldugu , en az kullanacagin datsetinin genisligi kadar onemli.Oncelikle epboch ve batch_ size in anlamini kavradigindan emin olmalisin.Bunun icin sunun gibi bir sorulara rahatlikla cevap vermelisin.Mesela training dataseti=32000 olsun.Eger batch_size = 32 ise training sirasinda kac iterasyon olacak? 1000 olacak.1000 iterasyonun tamamlamasi 1 epoch oldu demek degil mi? Daha hizlica 1 epoch tamamlansin modelimin performansi hakkinda hizlica fikir edinmek istiyorum dersen batch_size ini arttir. Training sirasinda total kaybini ve accuracy yi goreceksin.Traininge devam ederek kaybini azaltmaya accuracy i arttirmaya modelini gelistirmeye devam edebilirsin.epeochs = 10 yap ne kadar zaman aldigina bak.See zaman!1 month ago 7 people like this.Like ReportReply",
    " -> ->  AnladÄ±m, Ã§ok teÅŸekkÃ¼r ederim ğŸ™‚.",
    "->  ğŸ™‚.",
    "->  ->  training dataset/batch_size = 1 epoch mu ediyor yani4 weeks ago Like ReportReply",
    "->  ->  Yukarida verdigim ornege gore yazayim.Training_dataset / batch_size = 1000 iterasyon. Bu 1000 iterasyon tamamlandiginda yani training datasetindeki tum veriler bir kez training safhasindan gecip tamamlandiginda 1 epoch ediyor.4 weeks ago Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Hi everyone,  I try to improve a novel model for the keypoint detection.If you are interested in machine vision, please have a look at my model.Do you think the changes or a particular change would be problematic on it when it comes to training?If you share your opinions and suggestions, I would be pleased.  Thanks,   import torch  import torchvision  import torch.nn as nn  from torchvision.models.detection.rpn import AnchorGenerator  from torchvision.models.detection import KeypointRCNN    <a href=\"https://community.globalaihub.com/community/hashtag/Change/\"><span class=\"ps-stream-hashtag\">#Change</span></a> fixed features extractor as resnet 101 and freeze parameters     resnet101 = torchvision.models.resnet101(pretrained=True)  for param in resnet101.parameters():  â€¦ <a class=\"ps-stream-post-more ps-js-content-excerpt-toggle\" href=\"#\" data-single-act=\"1\">Read more</a></div><div class=\"ps-js-content-full\" style=\"display:none\">Hi everyone,  I try to improve a novel model for the keypoint detection.If you are interested in machine vision, please have a look at my model.Do you think the changes or a particular change would be problematic on it when it comes to training?If you share your opinions and suggestions, I would be pleased.  Thanks,   import torch  import torchvision  import torch.nn as nn  from torchvision.models.detection.rpn import AnchorGenerator  from torchvision.models.detection import KeypointRCNN    <a href=\"https://community.globalaihub.com/community/hashtag/Change/\"><span class=\"ps-stream-hashtag\">#Change</span></a> fixed features extractor as resnet 101 and freeze parameters     resnet101 = torchvision.models.resnet101(pretrained=True)  for param in resnet101.parameters():      param.requires_grad = False        modules = list(resnet101.children())[:-2] #it takes all layers except for last two ones  new_backbone_body = nn.Sequential(*modules)  <a href=\"https://community.globalaihub.com/community/hashtag/print/\"><span class=\"ps-stream-hashtag\">#print</span></a>(new_backbone_body)    model = torchvision.models.detection.keypointrcnn_resnet50_fpn()  model.backbone.body = new_backbone_body  <a href=\"https://community.globalaihub.com/community/hashtag/print/\"><span class=\"ps-stream-hashtag\">#print</span></a>(model)      # Added 5 more Conv layers to layer_blocks of the fpn   new_layerk  = nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  for k in range(5):      model.backbone.fpn.layer_blocks.append(new_layerk)  <a href=\"https://community.globalaihub.com/community/hashtag/print/\"><span class=\"ps-stream-hashtag\">#print</span></a>(model)        backbone = model.backbone  <a href=\"https://community.globalaihub.com/community/hashtag/print/\"><span class=\"ps-stream-hashtag\">#print</span></a>(backbone)      <a href=\"https://community.globalaihub.com/community/hashtag/Changes/\"><span class=\"ps-stream-hashtag\">#Changes</span></a> on RPN   anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),                                     aspect_ratios=((0.5, 1.0, 2.0),))  <a href=\"https://community.globalaihub.com/community/hashtag/Added/\"><span class=\"ps-stream-hashtag\">#Added</span></a> two conv layers more to head of RPN   new_rpn_head=nn.Sequential(nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),                       nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),#NEW                       nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),#NEW                       nn.Conv2d(256, 3, kernel_size = (1,1), stride = (1,1)),#cls_logits                       nn.Conv2d(256, 12, kernel_size =(1,1), stride =(1,1))#bbox_pred                       )    box_roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=[0],                                                      output_size=7,                                                      sampling_ratio=2)    keypoint_roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=[0],                                                           output_size=14,                                                           sampling_ratio=2)  <a href=\"https://community.globalaihub.com/community/hashtag/put/\"><span class=\"ps-stream-hashtag\">#put</span></a> the pieces together  deeper_model = KeypointRCNN(backbone,                              num_classes=2,                              rpn_anchor_generator=anchor_generator,                              rpn_head = new_rpn_head,                              box_roi_pool = box_roi_pooler,                              keypoint_roi_pool = keypoint_roi_pooler)    print(deeper_model)</div></div>",
"comment": [
    "",
    "->  ->  eger yardimci olursaniz sevinirm.Cunku mentorlar arasinda sizin haricinizde machine vision konusunda calisan kimse yok .Simdiden tesekkurler..",
    "->  ->  -> 4 weeks ago 1 person likes thisLike ReportReply",
    "->  ->  Tesekkur ederim4 weeks ago 1 person likes thisLike ReportReply",
    " "
]
},
{
"question_isim": "->  uploaded 1 photo",
"quest": "auc'un diÄŸer metriklerle mi yoksa yalnÄ±z baÅŸÄ±na konmasÄ± mÄ± daha mantÄ±klÄ± olur? ayrÄ±ca auc ve roc kavramlarÄ±nÄ± anlayamadÄ±m. TeÅŸekkÃ¼rler.",
"comment": [
    "",
    "-> Merhaba,Positive Rate curve'Ã¼ Ã§eÅŸitli threshold deÄŸerlerinde precision ve recall arasÄ±ndaki dengeyi gÃ¶sterir. AUC'ta ise True Positive Rate(zaten recall oluyor, TP/TP+FN) ve False Positive Rate (FP/FP+TN) arasÄ±ndaki iliÅŸki grafiÄŸinin alanÄ± alÄ±narak her threshold deÄŸeri iÃ§in performans Ã¶lÃ§Ã¼lmeye Ã§alÄ±ÅŸÄ±lÄ±r.(Yani modelin toplam performansÄ±). Bu yÃ¼zden AUC'u kullandÄ±ÄŸÄ±nÄ±zda precision ve recall kullanmayabilirsiniz.Precision ve recall metrikleri sÄ±nÄ±flandÄ±rma modelimizin performansÄ±nÄ± farklÄ± aÃ§Ä±lardan Ã¶lÃ§er. Herhangi biri diÄŸerinden daha iyi diyemeyiz iki metriÄŸin de performansÄ± farklÄ± aÃ§Ä±lardan Ã¶lÃ§tÃ¼ÄŸÃ¼nÃ¼ bildiÄŸimizden threshold deÄŸerini ikisini de optimum dÃ¼zeyde tutacak ÅŸekilde ayarlayabiliriz.ROC grafiÄŸi her threshold deÄŸeri modelimizin iÃ§in True Positive Rate (namÄ± diÄŸer recall) ve False Positive Rate (negatif Ã¶rnekler iÃ§indeki yanlÄ±ÅŸ pozitiflerin oranÄ±nÄ± Ã¶lÃ§er) deÄŸerlerinin plot edildiÄŸi bir grafiktir. Bu grafikte TPR deÄŸerlerinin FPR edÄŸerlerine gÃ¶re daha bÃ¼yÃ¼k olmasÄ±nÄ± bekleriz nedenini https://community.globalaihub.com/?status/1133-1133-1587507559/#comment.4733.4585.4585 linkinde aÃ§Ä±klamaya Ã§alÄ±ÅŸtÄ±m. En performanslÄ± durum TRP deÄŸerinin 1, FPR deÄŸerinin 0 olmasÄ±yken en performanssÄ±z durum tam tersidir.( TPR 0, FPR 1 burada negatifleri pozitif, pozitifleri negatif diye tahmin eder.)AUC ise bu grafiÄŸin altÄ±nda kalan alanÄ± integral ile hesaplayarak aslÄ±nda her threshold deÄŸeri iÃ§in TPR ve FPR hesaplamasÄ±nÄ±n yapÄ±lmasÄ±nÄ± kolaylaÅŸtÄ±rmÄ±ÅŸ olur. Her threshold iÃ§in bu hesaplamalarÄ± tek tek yapmaktansa AUC (Area Under the Curve) kullanarak bu hesaplamayaÄ± integral ile kolayca yapar. Bu linkte de bazÄ± yararlÄ± aÃ§Ä±klamalar bulabileceÄŸinize inanÄ±yorum. https://community.globalaihub.com/?status/875-875-1587486608/#comment.4706.4558.4558Ä°yi Ã§alÄ±ÅŸmalar.Community1 month ago 7 people like this.Like ReportReply",
    "->  ->  aÃ§Ä±klamanÄ±z iÃ§in teÅŸekkÃ¼r ederim..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar,  Alttaki L2 regularisation konusu ile ilgili olarak, sayet feature'lardan birisi label ile korrole ise, regularisation olmasa bile bu feature'un weight'i yuksek cikmayacak mi? Yani baska bir deyisle non-informative feature'larin learning modelde weight'inin yuksek cikmasinin nedeni L2 regularisation mu yoksa aslinda zaten bu feature'larin label'lar ile korrole olmasi mi? Bu durumda \"non-informative ama label ile korrole feature'larin weight'inin L2 regularisation nedeniyle yukselmesi\" ifadesi dogru olur mu?  Tesekkurler,  L2 regularization may cause the model to learn a moderate weight for some non-informative features. Surprisingly, this can happen when a non-informative feature happens to be correlated with the label. In this case, the model incorrectly gives such non-informative features some of the \"credit\" that should have gone to informative features.",
"comment": [
    "",
    "-> Merhabalar, label Ile korrole olan non informative feature in katsayÄ±sÄ± L2 regularization olmadan da yÃ¼ksek Ã§Ä±kacaktÄ±r. Ancak L2 ile korrole olmayan featurelarin katsayÄ±larÄ± sÄ±fÄ±ra yaklaÅŸÄ±rken , korrole olan non informative featureimizinda katsaysi korrole olmasÄ± sebebiyle artacaktÄ±r. Yani baÅŸlangÄ±Ã§ta dÃ¼ÅŸÃ¼k bir katsayiya sahip olup L2 sebebiyle yÃ¼kselmiyor. Korrole olmasÄ± nedeniyle zaten diÄŸer korrole olmayan featurelardan yÃ¼ksek bir katsayiya sahip oluyor. EÄŸitim sonunda da label Ile arasÄ±nda bulunan korrelasyondan dolayÄ± katsayÄ±sÄ± artiyor.Edit: but durum spurious correlation (sahte korelasyon) olarak tanÄ±mlanmaktadÄ±r. Mesela yazin dondurma tÃ¼ketimi artmaktadÄ±r, aynÄ± ÅŸekilde denizde boÄŸularak olmelerde artmaktadÄ±r. BoÄŸularak Ã¶lmeleri arastirdigimiz modelimize dondurma tuketiminide ekledigimizi dÃ¼ÅŸÃ¼necek olursak bu durumda dondurma tÃ¼ketimi yazÄ±n gerÃ§ekleÅŸen Ã¶lÃ¼mler iÃ§in etkin bir deÄŸiÅŸken gibi gÃ¶rÃ¼necektir ve yÃ¼ksek bir weight'e sahip olacaktÄ±r.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 5 people like this.Like ReportReply",
    "-> ->  Merhaba,Bunu 1 hafta kadar Ã¶nce sormuÅŸtum fakat yanÄ±t alamamÄ±ÅŸtÄ±m. Benzer bir konu olduÄŸundan hazÄ±r sizi bulmuÅŸken tekrar sorayÄ±m. YukarÄ±da x deÄŸiÅŸkenleri ile y arasÄ±ndaki bir korelasyondan sÃ¶z edilmiÅŸ. EÄŸer modelimizdeki x deÄŸiÅŸkenleri kendi arasÄ±nda 0.7 veya 0.8'den daha bÃ¼yÃ¼k bir korelasyona sahipse hiÃ§bir ÅŸey yokmuÅŸ gibi modeli Ã§alÄ±ÅŸtÄ±rmaya devam mÄ± etmeliyiz?.",
    "->  -> Bu problem MultiCollinearity problemi olarak tanÄ±mlanÄ±r. AÃ§Ä±klayÄ±cÄ± deÄŸiÅŸkenlerin(X'lerin) arasÄ±nda yÃ¼ksek korelasyon olmasÄ± sebebiyle karÅŸÄ±mÄ±za Ã§Ä±kar. Bu sorunu gÃ¶rmezden gelerek Ã§alÄ±ÅŸmamÄ±za devam edebiliriz. Ya da soruna sebep olan deÄŸiÅŸkenlerden birini modelden Ã§Ä±kartabiliriz. Hangisi olacaÄŸÄ±na karar vermek iÃ§in her deÄŸiÅŸkenle deneyerek model performansÄ±mÄ±za bakabiliriz. Ya da Temel BileÅŸen Analizi, FaktÃ¶r Analizi gibi bir yÃ¶ntemler ile bu Ã§oklu doÄŸrusal baÄŸlantÄ± sorununu ortadan kaldÄ±rmaya Ã§alÄ±ÅŸabiliriz.Ã–zetle ne modelimizi optimal formuna getirmek iÃ§in her tÃ¼rlÃ¼ yaklaÅŸÄ±mÄ± deneyip Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z model iÃ§in en uygun yÃ¶ntemi tespit edip, bu ÅŸekilde Ã§alÄ±ÅŸmaya devam etmeliyiz..",
    "-> ->  VIF skorlarÄ± gÃ¶zetilerek Ln veya sqrt gibi bir dÃ¶nÃ¼ÅŸÃ¼m veyahut faktÃ¶r analizi yapmanÄ±n mÃ¼mkÃ¼n doÄŸru ama benim yukarÄ±da asÄ±l sormak istediÄŸim (Bunu net sormadÄ±m Ã¼stÃ¼ kapalÄ± olarak sormak istemiÅŸtim) niÃ§im multicollinearity durumunu derslerdeki hiÃ§bir videoda veya dÃ¶kÃ¼manda gÃ¶rmÃ¼yoruz. Bu durum niÃ§in es geÃ§iliyor? AynÄ± ÅŸekilde stationary durumu da birÃ§ok Ã¶rnekle es geÃ§ilmiÅŸ. Normalde istatistiksel bir analizin temeli olan heteroscedasticity, multicollinearity ve autocorrelation gibi durumlar sÄ±rf analizi devam ettirilmek adÄ±na gÃ¶rmezden geliniyor gibi geldi. Bu ne derece anlamlÄ±?.",
    "->  -> ML ile Ä°statistiksel Analiz birbirlerinden ince bir Ã§izgi ile ayrÄ±lÄ±r. Bu noktada amacÄ±na gÃ¶re bahsettiÄŸiniz yaklaÅŸÄ±mlardan birini ya da bir kaÃ§Ä±nÄ± tercih ederiz. AmacÄ±mÄ±z tahmin deÄŸil yorumlamak ise, multicollinearity, heteroscedasticity/ homoscedasticity, stationarity gibi faktÃ¶rler dikkate alÄ±nmak durumunda iken, bÃ¼tÃ¼n bunlaramacÄ±mÄ±z tahmin olduÄŸunda model etkinliÄŸimizi artÄ±rabilecek bileÅŸenler haline gelebilmekte.EÄŸitim iÃ§eriÄŸi makina Ã¶ÄŸrenimi Ã¼zerine olmasÄ± sebebi ile, verinin iÅŸlenmesi model iÃ§in feature seÃ§imi, bunlarÄ±n anlamlÄ±lÄ±k testleri ve bahsettiÄŸiniz durumlarÄ±n testleri gibi istatistiksel yaklaÅŸÄ±mlara yer verilmemiÅŸ. BÃ¼tÃ¼n bunlar, gÃ¶rmezden geliniyor gibi deÄŸil de farklÄ± bir eÄŸitim konusu olarak dÃ¼ÅŸÃ¼nÃ¼lebilir.1 month ago 3 people like this.Like ReportReply",
    "-> ->  AnladÄ±m teÅŸekkÃ¼rler..",
    " "
]
},
{
"question_isim": " -> ",
"quest": "ArkadaÅŸlar merhaba ben L1 Regularization'Ä± ve feature cross larÄ±n ne olduÄŸunu tam anlamadÄ±m galiba. YardÄ±mlarÄ±nÄ±zÄ± bekliyorum. Ã‡ok teÅŸekkÃ¼r ederim ğŸ™‚",
"comment": [
    "",
    "-> Merhaba, https://community.globalaihub.com/?status/774-774-1586937745/#comment.4123.4009.4009 linkinde feature cross kÄ±smÄ±nÄ± aÃ§Ä±klamaya Ã§alÄ±ÅŸtÄ±m ama ulaÅŸamazsanÄ±z aÅŸaÄŸÄ±ya alÄ±ntÄ±lÄ±yorum.\"Merhaba,Ã–ncelikle Feature Cross yapmamÄ±zÄ±n sebebi modelimizin verileri tek bir lineer Ã§izgiyle ayÄ±ramamasÄ±dÄ±r. Bu yÃ¶ntemle yeni bir feature elde edip bu yeni feature modelimizin eÄŸitim sÄ±rasÄ±nda verileri daha etkili ayÄ±rÄ±p daha etkili bir hipotez fonksiyonu elde etmesinde yardÄ±mcÄ± oluyor. Ã–rneÄŸin elinizde \"dil\" ve \"Ã¼lke\" kategorik featurelarÄ± olsun.Ã–rneÄŸin dil feature deÄŸerleri: \"TÃ¼rkÃ§e, Ä°ngilizce, Japonca\"Ãœlke deÄŸerleri de: \"TÃ¼rkiye, Ä°spanya, Kanada\" olsun.Bu iki kategorik veriyi One Hot Encoding kullanarak binary vector'e Ã§evirdiniz ki modelimiz numerik veri Ã¼zerinde Ã§alÄ±ÅŸabilsin.EÄŸer siz bu iki feature'Ä± yani iki binary vector deÄŸerini Ã§arparsanÄ±z elinizde 9 elemanlÄ± bir binary vector olur. Bu binary vector deÄŸerlerinden her biri bir ihtimali temsil eder. Ã–rneÄŸin:[TÃ¼rkÃ§e ve TÃ¼rkiye,TÃ¼rkÃ§e ve Ä°spanya,TÃ¼rkÃ§e ve Kanada, Ä°ngilizce ve TÃ¼rkÃ§e,.......] gibi.Siz ilgili ihtimalin olduÄŸu indeksteki deÄŸere 1 koyduÄŸunuz anda artÄ±k o eÄŸitim Ã¶rneÄŸi iÃ§in o deÄŸer geÃ§erlidir. Ã–rneÄŸin [1,0,0,0,0,0,0,0,0] yaptÄ±ÄŸÄ±nÄ±zda artÄ±k TÃ¼rkÃ§e ve TÃ¼rkiye deÄŸerini o eÄŸitim Ã¶rneÄŸi iÃ§in deÄŸer belirlemiÅŸ olursunuz. Buradaki amaÃ§ featurelarÄ±n tek tek tahmine katkÄ±sÄ±ndan daha Ã§ok katkÄ± saÄŸlamalarÄ±nÄ± saÄŸlayabilmek. Ã–rneÄŸin dil ve Ã¼lke featurelarÄ± kend baÅŸlarÄ±na feature olarak katkÄ± saÄŸlarlar ama iki feature'Ä± Ã§arpÄ±p elde ettiÄŸimiz yeni feature tahminde daha Ã§ok katkÄ± saÄŸlayacaktÄ±r.\"L1 regÃ¼larizasyon yapmamÄ±zÄ±n sebebi feature cross sonrasÄ± oluÅŸacak sparse matrixlerdeki 0 olan feature deÄŸerlerinin weightlerini 0layÄ±p onlarÄ± ortadan kaldÄ±rmaktÄ±r. L1 regÃ¼larizasyon weight deÄŸerlerimizden her adÄ±mda sabit bir k deÄŸerini Ã§Ä±karÄ±r ve sÄ±fÄ±rlar. L2 ile karÄ±ÅŸtÄ±rÄ±lmamalÄ±dÄ±r L2 overfit olmayÄ± engellemek iÃ§in her adÄ±mda weightten kendisinin belli bir yÃ¼zdelik dilimini Ã§Ä±karÄ±p onu 0'a yakÄ±nsatÄ±r ama asla sÄ±fÄ±rlamaz. L1 ise sparse matrixteki 0 deÄŸerindeki featurelarÄ±n weight deÄŸerlerini sÄ±fÄ±rlarlar.Sorunuz olursa sorabilrsiniz.Ä°yi Ã§alÄ±ÅŸmalar.Community1 month ago 6 people like this.Like ReportReply",
    "-> MerhabalarFeature Cross: En basit hali ile elimizde bulunan featurelarÄ±mÄ±zÄ± Ã§arpmak anlamÄ±na geliyor. Mesela:OdaSayÄ±sÄ± = [3,5,6,3] ve Konum = [12,25,9,8] olsun: Feature Cross, bu iki feature'mizi eleman dÃ¼zeyinde Ã§arparak : KonumaGÃ¶reOdaSayÄ±sÄ± = [3x12, 5x25, 6x9, 3x8] olarak yeni bir sentetik feature elde etmiÅŸ oluyoruz. AslÄ±nda yaptÄ±ÄŸÄ±mÄ±z iÅŸlem her iki diziden aynÄ± indise sahip olan elemanlarÄ± alÄ±p Ã§arparak yeni bir diziye atamak oluyor.L1 Regularization ise, modelimize bir ceza parametresi olarak eklediÄŸimiz katsayÄ±sÄ± LAMBDA olan yeni bir parametre. Ve matematiksel formÃ¼lÃ¼: model katsayÄ±larÄ±mÄ±zÄ±n mutlak deÄŸerlerinin toplamÄ± olarak ifade edilmekte.(sum(abs(W_i)), i = 1,2,... p, p= feature sayÄ±sÄ±.) AMACIMIZ optimal bir ceza ile modelimizi en sade ve en etkin formuna getirebilmek. Optimal cezayÄ± uygulayabilmek iÃ§in LAMBDA parametresinin optimum deÄŸerini tahmin etmemiz gerekmektedir.Lambda'yÄ± 0 almamÄ±z halinde kurduÄŸumuz model ile Ã§alÄ±ÅŸmaya devam etmiÅŸ oluruz. Ã‡ok bÃ¼yÃ¼k bir deÄŸer seÃ§ersek bu sefer de underfit gibi bir sorun ile karÅŸÄ±laÅŸmÄ±ÅŸ oluruz. Bunlara dikkat ederek optimal deÄŸeri bulup modelimizi kuruyor olacaÄŸÄ±z.UmarÄ±m yeterince aÃ§Ä±k olmuÅŸtur ğŸ™‚Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 5 people like this.Like ReportReply",
    "->  ->  Hocam burada yapmaya Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z ÅŸey ÅŸu mu? Yani Ã¶rneÄŸin amacÄ±mÄ±z dÃ¼nya Ã¼zerindeki yerleÅŸim yerlerindeki median_house_value deÄŸerlerini tahmin etmek olsun. Bunun iÃ§in Ã¶rneÄŸin latitude deÄŸerleri iÃ§in 200 bucket oluÅŸturalÄ±m, longitude deÄŸerleri iÃ§in de 300 bucket oluÅŸturursak. Toplamda 200x300 = 60000 hash_bucket Ä±mÄ±z olacak. DÃ¼nyanÄ±n % 70inin su olduÄŸunu(kara parÃ§asÄ± olmadÄ±ÄŸÄ±nÄ±) varsayarsak burada bir yerleÅŸim olmayacaÄŸÄ± iÃ§in bunlarÄ±n neredeyse 60000x0.7=42000 gereksiz bu yÃ¼zden bunlarÄ±n weight deÄŸerini 0 yapmayÄ± amaÃ§lÄ±yoruz. DoÄŸru mudur acaba ? Ã‡ok saÃ§ma bir soru olmuÅŸsa kusura bakmayÄ±n ben de kafamda tam oturtamadÄ±ÄŸÄ±m iÃ§in sordum..",
    "->  ->  merhabalar, evet dediÄŸiniz gibi modelimizde bulunan gereksiz deÄŸiÅŸkenlerin weightlerini sÄ±fÄ±rlamak amaÃ§.1 month ago 2 people like this.Like ReportReply",
    "->  ->  TeÅŸekkÃ¼r ederim..",
    " ->  Ã‡ok teÅŸekkÃ¼r ederim ğŸ™‚.",
    " "
]
},
{
"question_isim": "->  uploaded 1 photo",
"quest": "Merhaba ArkadaÅŸlar, EklediÄŸim kÄ±smÄ± anlayamadÄ±m. YardÄ±mcÄ± olur musunuz? TeÅŸekkÃ¼rler",
"comment": [
    "",
    "-> Merhaba,Ã–ncelikle scale invariant ÅŸu demek; Ã¶zelliklerden birini Ã¶lÃ§eklendirmek(Ã¶rneÄŸin 0'dan farklÄ± bir sayÄ± ile Ã§arpmak) tahmin deÄŸerini deÄŸiÅŸtirmez. AUC'un scale invariant olmasÄ±nÄ±n Ã¶zelliÄŸi AUC'un hesapladÄ±ÄŸÄ± deÄŸer bizim tahminlerimizin mertebe sÄ±rasÄ±, Ã¶rneÄŸin Ã¼st kÄ±sÄ±mdaki output of log reg kÄ±smÄ±na bakarsanÄ±z burada hesaplanÄ±lan seÃ§ilen herhangi bir pozitif deÄŸerin seÃ§ilen herhangi bir negatif deÄŸerin saÄŸÄ±nda olmasÄ±dÄ±r.(modelin rastgele bir pozitif Ã¶rneÄŸi rastgele bir negatif Ã¶rnekten daha yÃ¼ksek sÄ±ralamasÄ± olasÄ±lÄ±ÄŸÄ±dÄ±r.) Bunu aÃ§Ä±klamam gerekirse;https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5 linkindeki resimler Ã¼zerinden anlatÄ±mÄ±mÄ± yapayÄ±m. Bu linkteki Image 6 ve 7'ye bakarsanÄ±z bizim istediÄŸimiz en performanslÄ± model yaklaÅŸÄ±mÄ± budur. TN ve TP deÄŸerlerimizin Threshold deÄŸeri itibariyle TN solda TP saÄŸda olacak ÅŸekilde ayrÄ±lmasÄ±dÄ±r. Ama biz genelde Image 8 ve 9'daki bir curve ve plot elde ederiz. Bunun nedeni iÅŸin iÃ§ine FP ve FN girmesidir yani false tahminlerimizin girmesidir. AUC'un en optimum olduÄŸ zaman predictionlarÄ±n TN ve TP olarakl sÄ±ralandÄ±ÄŸÄ± zamandÄ±r ve bu yÃ¼zden predictionlarÄ±mÄ±zÄ± prediction deÄŸerine gÃ¶re sÄ±raladÄ±ÄŸÄ±mÄ±zda TN deÄŸerinin TP deÄŸerinin solunda kalmasÄ± beklenir. AUC zaten bunu hesaplar.1.AUC scale-invariant'tÄ±r Ã§Ã¼nkÃ¼ burada biz bir prediction deÄŸerlerinin mutlak deÄŸerleriyle deÄŸil dizilim sÄ±ralarÄ±yla ilgileniyoruz. Tekrar hatÄ±rlatmam gerekirse istediÄŸimz ÅŸey TN deÄŸerlerinin TP deÄŸerlerinin solunda olmasÄ± (rank olarak TP'den dÃ¼ÅŸÃ¼k olmasÄ±) bÃ¶ylece TN ve TP deÄŸerlerimiz iyice ayrÄ±lÄ±p AUC deÄŸerimiz 1 olabilsin.2.AUC classification-threshold-invarianttÄ±r Ã§Ã¼nkÃ¼ burada hangi threshold'un seÃ§ildiÄŸine bakÄ±lmaksÄ±zÄ±n modelin tahminlerinin kalitesini Ã¶lÃ§er.Ancak bu iki durum da bazÄ± zamanlarda AUC'un kullanÄ±labilirliÄŸini kÄ±sÄ±tlamaktadÄ±r.1.Scale invariant olmasÄ± her zaman istenen bir durum deÄŸildir Ã§Ã¼nkÃ¼ probability outputlarÄ±mÄ±zÄ±n iyi bir ÅŸekilde kalibre edilmesini isteyebilirz. Bu da ranklerden ziyade absolute valuelarÄ±na ihtiyaÃ§ duyduÄŸumuz anlamÄ±na gelit ama AUC absolute valuelar ile deÄŸil TN ve TP deÄŸerlerinin dizilim rankÄ±yla ilgileniyordu.2.Classification-threshold-invariant da her zaman istenen bir durum deÄŸildir. Bunun nedeni ise FN ve FPler arasÄ±nda fazla bir cost aÃ§Ä±ÄŸÄ± olan durumlarda bir tip classification error deÄŸerinini(Ã–rneÄŸin sadece FP) mimize etmenin kritik olabileceÄŸindendir. azaltmak kritik olabilir. Bu minimize iÅŸlemini thresholdu yeniden ayarlayarak yapabilrisiniz ama burada hatÄ±rlarsak classification-threshold-invariant sayesinde modelin performansÄ± seÃ§ilen threshold deÄŸerine bakÄ±lmaksÄ±zÄ±n Ã¶lÃ§Ã¼lÃ¼yordu. O yÃ¼zden classification-threshold-invariant Ã¶zelliÄŸi bu tÃ¼r optimizasyonlar iÃ§in pek kullanÄ±ÅŸlÄ± olmayacaktÄ±r.Ä°yi Ã§alÄ±ÅŸmalar.",
    "Understanding AUC - ROC Curvetowardsdatascience.comIn Machine Learning, performance measurement is an essential task. So when it comes to a classification problem, we can count on an AUC â€¦1 month ago 11 people like this.Like ReportReply",
    "->  ->  aÃ§Ä±klayÄ±cÄ± yazÄ± iÃ§in Ã§ok teÅŸekkÃ¼rler.",
    " ->  ->  Biz threshold deÄŸerini deÄŸiÅŸtirdiÄŸimizde TPR ve FPR'i dolayÄ±sÄ±yla ROC'i grafiÄŸinin ÅŸeklini deÄŸiÅŸtirmiÅŸ oluyoruz. Mesela threshold deÄŸerini arttÄ±rdÄ±ÄŸÄ±mÄ±zda yanlÄ±ÅŸ hesaplamÄ±yorsam TPR'nin de FPR'nin dÃ¼ÅŸmesini, en iyi ihtimal sabit kalmasÄ±nÄ± bekliyoruz. Ä°kisindeki deÄŸiÅŸim oranÄ±nÄ±n aynÄ± olmasÄ± Ã§ok zor olduÄŸu iÃ§in (yani deÄŸiÅŸim oranlarÄ± farklÄ±ysa birbirlerini kompanse etmeleri zor olduÄŸu iÃ§in) grafiÄŸinin integrali yani AUC de aynÄ± kalamazmÄ±ÅŸ gibi geliyor. Bu dÃ¼ÅŸÃ¼nÃ¼ÅŸteki hata nereden kaynaklanÄ±yor, Ã§eliÅŸkinin sebebi nedir bir tÃ¼rlÃ¼ bulamadÄ±m. YardÄ±mcÄ± olabilirseniz sevinirim.4 weeks ago Like ReportReply",
    "->  ->  Merhaba,ROC curve'unu farklÄ± TPR ve FPR deÄŸerleri iÃ§in Ã§iziyoruz. Bu deÄŸerler fakrlÄ± thresholdlarda deÄŸiÅŸen deÄŸerlerdir. Threshold arttÄ±ÄŸÄ± zaman TPR deÄŸerimiz azalÄ±r. Bunu nedeni TP/(TP+FN) formÃ¼lÃ¼ndeki FN deÄŸerinin threshold deÄŸeri ile artmasÄ± olacaktÄ±r. FPR de 1-TPR olduÄŸu iÃ§in TPR dÃ¼ÅŸerken FPR'nin artmasÄ±nÄ± bekleriz ama bu artÄ±ÅŸ iki tarafta da aynÄ± ÅŸekilde olmaz (simple lineer bir artÄ±ÅŸ sergilemez.) ROC, farklÄ± threshold deÄŸerleri iÃ§in belirlenen bu TPR ve FPR deÄŸerlerinin Ã§izildiÄŸi bir grafik bu grafikte de TPR ile FPR'nin deÄŸiÅŸim oranlarÄ± aynÄ± olmadÄ±ÄŸÄ± ve hata oranÄ± (FP,FN) iÃ§eren bir modelimiz olduÄŸunu varsayarsa ROC curve'Ã¼mÃ¼z parabolik bir gÃ¶rÃ¼ntÃ¼ alacaktÄ±r. Her threshold deÄŸeri iÃ§in farklÄ± bir ROC curve'Ã¼ Ã§izilmez, ROC curve'Ã¼ her threshold deÄŸeri iÃ§in TPR ve FPR deÄŸerlerini iÃ§erir. Bu mantÄ±kla ROC curve'Ã¼ sabit kalacaÄŸÄ±ndan AUC deÄŸeri de sabit kalacaktÄ±r.Ä°yi Ã§alÄ±ÅŸmalar.4 weeks ago 1 person likes thisLike ReportReply",
    " ->  ->  ROC curve zaten farklÄ± thresholdlar iÃ§in bÃ¼tÃ¼n senaryolarÄ± Ã¼zerinde barÄ±ndÄ±rÄ±yor. KavramlarÄ± karÄ±ÅŸtÄ±rmÄ±ÅŸÄ±m bir an. AnladÄ±m, Ã§ok teÅŸekkÃ¼r ederim.4 weeks ago 1 person likes thisLike ReportReply",
    "->  Ã‡ok net aÃ§Ä±klayÄ±cÄ± bilgilerin iÃ§in Ã§ok teÅŸekkÃ¼rler ->  iyi Ã§alÄ±ÅŸmalar1 month ago 4 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "->  uploaded 1 photo",
"quest": "Merhaba ArkadaÅŸlar, Accuracy kÄ±smÄ±nda eklediÄŸim yeri tam olarak anlayamadÄ±m. YardÄ±mcÄ± olabilir misiniz? TeÅŸekkÃ¼rler",
"comment": [
    "",
    "-> Merhaba,Burada demek istediÄŸi %91 accuracy deÄŸerinizin olmasÄ± ilk baÅŸta gÃ¼zel gÃ¶rÃ¼nebilir ama her seferinde benign tahmin eden bir modelin de %91 accuracy deÄŸeri olur. YukarÄ±sÄ±ndaki Ã¶rneÄŸe bakacak olursak elimizdeki tablo ÅŸu ÅŸekilde olacak;- M - BM 1 1B 8 90Bu kÄ±smÄ±n accuracy deÄŸeri 90+1/90+1+1+8=91/100Hepsi benign tahmin edilseydi oluÅŸacak tablo:- M - BM 0 0B 9 91Ã‡Ã¼nkÃ¼ 100 tane tahminimiz vardÄ± 100'Ã¼nÃ¼ benign olarak tahmin ettik ve bunlarÄ±n 9 tanesi malignanttÄ± yani false negative oldu. 91 tanesi ise true negative oldu. Bu durumda 91+0/91+9=91/100 olur yani burada accuracy'nin veri daÄŸÄ±lÄ±mÄ±nÄ±n dengesiz olduÄŸu(negatif ve pozitif deÄŸerler arasÄ±nda ayrÄ±klÄ±k olduÄŸunda) veri setlerinde tek baÅŸÄ±na yeterli olmayacaÄŸÄ±nÄ± sÃ¶ylemekte.HatalÄ± gÃ¶rdÃ¼ÄŸÃ¼nÃ¼z yer olursa dÃ¼zeltmekten Ã§ekinmeyin.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 5 people like this.Like ReportReply",
    "->  Accuracy hesaplandÄ±ÄŸÄ±nda %91 Ã§Ä±kÄ±yor. Buna bakarak sÄ±nÄ±flandÄ±rmanÄ±n baÅŸarÄ±lÄ± olduÄŸunu dÃ¼ÅŸÃ¼nebiliriz ama confusion matrixi incelediÄŸimizde daha farklÄ± bir tabloyla karÅŸÄ± karÅŸÄ±ya kalÄ±yoruz. FP ve TN deÄŸerlerine bakarsak, iyi huylu tÃ¼mÃ¶re(benign) sahip 91 hastamÄ±z var ve 90 kiÅŸide benign olduÄŸu tahmin edilmiÅŸ. 1 kiÅŸi yanlÄ±ÅŸ tahmin edilmiÅŸ. Bu baÅŸarÄ±lÄ± bir tahmin. Ancak, TP ve FN deÄŸerlerine bakarsak toplam 9 kiÅŸide kÃ¶tÃ¼ huylu tÃ¼mÃ¶r(malignant) var fakat modelimiz sadece 1 kiÅŸide olduÄŸunu tahmin etmiÅŸ. Kalan 8 kiÅŸide kÃ¶tÃ¼ huylu tÃ¼mÃ¶r tespit edilememesi oldukÃ§a kÃ¶tÃ¼ bir tahmin olduÄŸunu gÃ¶sterir. Burada da diyor ki dengesiz sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸ veri setlerinde(class-imbalanced dataset) yalnÄ±zca accuracy e bakmak ve buna gÃ¶re modelin iyi tahmin yapÄ±p yapmadÄ±ÄŸÄ±na karar vermek yeterli deÄŸildir. Bu veri setimiz de oldukÃ§a dengesiz, pozitif ve negatif etiket sayÄ±sÄ± arasÄ±nda Ã¶nemli derecede bir eÅŸitsizlik var.1 month ago 6 people like this.Like ReportReply",
    "->  Ã‡ok teÅŸekkÃ¼rler ->  ->  arkadaÅŸlar ÅŸimdi gayet iyi anladÄ±m ğŸ™‚1 month ago 2 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "->  uploaded 1 photo",
"quest": "Burada prediction ve identifie arasÄ±ndaki fark nedir? TeÅŸekkÃ¼r ederim.",
"comment": [
    "",
    "->  Before/After aralarÄ±ndaki fark.Yani sonuÃ§lar Ã§Ä±kmadan Ã¶nce \"predict\" kelimesi kullanÄ±lÄ±rken, sonuÃ§larÄ± alÄ±p yorumladÄ±ktan sonra \"identified, addressed, classified\" vb. daha net anlamÄ± olan kelimeler kullanÄ±rÄ±z. Ki bu ÅŸekilde sonuÃ§larÄ±n elimizde olduÄŸunu onlara gÃ¶re yorum yaptÄ±ÄŸÄ±mÄ±zÄ± belirtmiÅŸ oluruz.Edit: Pardon dikkatsizliÄŸime geldi, Recall sonucu iÃ§in yorum yapÄ±lÄ±yormuÅŸ orada.Modelin etkinliÄŸinden bahsederken x% doÄŸru tahmin ediyor ÅŸeklinde ifade edilir. Ancak Recall bir Ã¶lÃ§Ã¼m birimidir. amacÄ± da What proportion of actual positives was identified correctly? sorusuna cevap vermektir. Yani tahmin ile ilgili deÄŸil de sonuÃ§ ile ilgilidir. Hali ile elimizde bulunan bilinen birÅŸeyi yorumlarken x% doÄŸru tahmin etmiÅŸ gibi bir ÅŸey kullanmayÄ±z. YukarÄ±da yazmÄ±ÅŸ olduÄŸum ilk paragraf kÄ±smi olarak doÄŸruydu.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 7 people like this.Like ReportReply",
    "->  ->  TeÅŸekkÃ¼r ederim..",
    "-> Kesinlik (Precision) ise Positive olarak tahminlediÄŸimiz deÄŸerlerin gerÃ§ekten kaÃ§ adedinin Positive olduÄŸunu gÃ¶stermektedir.DuyarlÄ±lÄ±k (Recall) ise Positive olarak tahmin etmemiz gereken iÅŸlemlerin ne kadarÄ±nÄ± Positive olarak tahmin ettiÄŸimizi gÃ¶steren bir metriktir.Ä°lk cÃ¼mlede eÄŸer bizim modelimiz 0.5 precision deÄŸerine sahipse bir tÃ¼mÃ¶rÃ¼n kÃ¶tÃ¼ huylu olduÄŸunu %50 oranÄ±nda doÄŸru \"tahmin\" eder demiÅŸ.Ä°kinci cÃ¼mlede ise eÄŸer modelimiz 0.11 recall deÄŸerine sahipse tÃ¼m kÃ¶tÃ¼ huylu tÃ¼mÃ¶rlerin %11'ini doÄŸru \"teÅŸhis etmiÅŸ\" demektir demiÅŸ.Burada aslÄ±nda anlam olarak kelimeler arasÄ±nda bir fark yok. Buradak fark precision ve recall arasÄ±ndaki farktÄ±r.Precision ÅŸunu sorar, olumlu tanÄ±mlarÄ±n ne kadarÄ± gerÃ§ekten doÄŸruydu?Ne demek istiyorum?Ã–rneÄŸin positive deÄŸerimiz kurdun tehdit oluÅŸturmasÄ± olsun. Biz kurdun tehdit oluÅŸturuÅŸunu kaÃ§ kere tahmin etmiÅŸiz ve bu tahminlerin kaÃ§Ä± doÄŸruydu bunun oranÄ±nÄ± yakaladÄ±ÄŸÄ±mÄ±zda precision'I bulmuÅŸ oluyoruz. Ã–rneÄŸin biz 7 kez kurdun tehdit oluÅŸunu doÄŸru tahmin edip, 5 kez de kurt tehdit oluÅŸturmuyorken tehdit oluÅŸunu tahmin edersek precision oranÄ±mÄ±z 7/7+5'ten 7/12 olur. Yani benim kurt benim iÃ§in tehdit oluÅŸturuyor dediklerimin kaÃ§Ä±nda kurt gerÃ§ekten bizim iÃ§in tehdit oluÅŸturuyordu?Recall ise ÅŸunu sorar, gerÃ§ek pozitiflerin ne kadarÄ± doÄŸru bir ÅŸekilde tahmin edildi? Ã–rneÄŸin kurt gerÃ§ekten tehdit oluÅŸturuyorken ben bu tehditlerin kaÃ§ tanesini doÄŸru tahmin edebildim. Kurdumuz bize 20 kez tehdit oluÅŸturuyor olsun. Biz bunlarÄ±n 13 tanesini doÄŸru bir ÅŸekilde kurt tehdit oluÅŸturuyor olarak tahmin edip, 7 kez yanlÄ±ÅŸ kurt tehdit oluÅŸturmuyor dersek bizim recall oranÄ±mÄ±z (13/13+7=13/20) olur. Yani kurdun benim iÃ§in her tehdit oluÅŸturuÅŸunda ben bunlarÄ±n kaÃ§ tanesini doÄŸru bir ÅŸekilde tahmin edebildim?Daha faydalÄ± bir link iÃ§in: https://medium.com/@gulcanogundur/do%C4%9Fruluk-accuracy-kesinlik-precision-duyarl%C4%B1l%C4%B1k-recall-ya-da-f1-score-300c925feb38Ä°yi Ã§alÄ±ÅŸmalar.",
    "DoÄŸruluk (Accuracy)Â , Kesinlik(Precision)Â , DuyarlÄ±lÄ±k(Recall) ya da F1 ScoreÂ ?medium.comVeri bilimi projelerinde en doÄŸru modelin hangisi olmasÄ± gerektiÄŸine karar vermek iÃ§in iÅŸ birimlerinden gelen talepleri iyiâ€¦1 month ago 13 people like this.Like ReportReply",
    "->  ->  TeÅŸekkÃ¼r ederim..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba, Genel olarak classification modelleri hakkÄ±nda birkaÃ§ sorum var. 1) AUC ve ROC Curve modelimizde tam olarak nasÄ±l kullanÄ±lÄ±yor? FarklÄ± thresholdlara gÃ¶re tp rate ve fp ratelerimizi hesaplayÄ±p ROC curve'Ã¼ oluÅŸturuyoruz. ROC Curve'Ã¼n altÄ±nda kalan alan da AUC oluyor. Bu alan bize modelin pozitif ve negatif Ã¶rnekleri ne kadar iyi ayÄ±rt ettiÄŸini veriyor. F-score'u en yÃ¼ksek threshold da en iyi threshold oluyor. Ancak bu threshold modele nasÄ±l dÃ¶nÃ¼yor? Yani gradient descentin weightleri deÄŸiÅŸtirdiÄŸi gibi bir mekanizma var mÄ± yoksa thresholdu kendimizin mi belirlemesi gerekiyor? (ki programlama Ã¶rneÄŸinde kendimiz belirliyorduk) 2) Lojistik regresyonun hata fonksiyonu neye gÃ¶re belirlendi? Ã‡alÄ±ÅŸma mantÄ±ÄŸÄ±nÄ± tam anlayamadÄ±m. 3) Regularization kÄ±smÄ±nÄ± eklemeden Ã¶nce weightleri  kendisinden learning rate * kayÄ±p fonksiyonunun tÃ¼revini Ã§Ä±kartarak deÄŸiÅŸtiriyorduk. Regularization kÄ±smÄ±nÄ±â€¦ <a class=\"ps-stream-post-more ps-js-content-excerpt-toggle\" href=\"#\">Read more</a></div><div class=\"ps-js-content-full\" style=\"\">Merhaba, Genel olarak classification modelleri hakkÄ±nda birkaÃ§ sorum var. 1) AUC ve ROC Curve modelimizde tam olarak nasÄ±l kullanÄ±lÄ±yor? FarklÄ± thresholdlara gÃ¶re tp rate ve fp ratelerimizi hesaplayÄ±p ROC curve'Ã¼ oluÅŸturuyoruz. ROC Curve'Ã¼n altÄ±nda kalan alan da AUC oluyor. Bu alan bize modelin pozitif ve negatif Ã¶rnekleri ne kadar iyi ayÄ±rt ettiÄŸini veriyor. F-score'u en yÃ¼ksek threshold da en iyi threshold oluyor. Ancak bu threshold modele nasÄ±l dÃ¶nÃ¼yor? Yani gradient descentin weightleri deÄŸiÅŸtirdiÄŸi gibi bir mekanizma var mÄ± yoksa thresholdu kendimizin mi belirlemesi gerekiyor? (ki programlama Ã¶rneÄŸinde kendimiz belirliyorduk) 2) Lojistik regresyonun hata fonksiyonu neye gÃ¶re belirlendi? Ã‡alÄ±ÅŸma mantÄ±ÄŸÄ±nÄ± tam anlayamadÄ±m. 3) Regularization kÄ±smÄ±nÄ± eklemeden Ã¶nce weightleri  kendisinden learning rate * kayÄ±p fonksiyonunun tÃ¼revini Ã§Ä±kartarak deÄŸiÅŸtiriyorduk. Regularization kÄ±smÄ±nÄ± ekleyince weightlerden bir de ilaveten lambda * regularizationun tÃ¼revini Ã§Ä±kartarak mÄ± gÃ¼ncelliyoruz? UmarÄ±m aÃ§Ä±k olmuÅŸtur. CevaplarÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederim.</div></div>",
"comment": [
    "",
    "-> Merhaba,AnladÄ±ÄŸÄ±m kadarÄ±yla:1. Threshold modele dÃ¶nÃ¼yor derken biz numerik bir verimizi alÄ±p, bu numerik verimizi threshold deÄŸerinden bÃ¼yÃ¼k kÃ¼Ã§Ã¼k olma durumlarÄ±na gÃ¶re yeni sentetik bir feature Ã¼zerinden ayÄ±rÄ±yoruz. (Yeni featureÄ±mÄ±z deÄŸer>threshold ise 1, deÄŸilse 0). Biz her gradient descent yaptÄ±ÄŸÄ±mÄ±zda aynÄ± threshold Ã¼zerinden modelimiz bu tahminleri Ã¶ÄŸreniyor ve test set Ã¼zerinde yaptÄ±ÄŸÄ± tahminlerini gÃ¼Ã§lendiriyor. Programlama egzersizinde de accuracy deÄŸeri 0.8 Ã§Ä±kÄ±yordu. Burada ROC, AUC ve F skorlarÄ±nÄ±n amacÄ± sÄ±nÄ±flandÄ±rma modelimizin performansÄ±nÄ± Ã¶lÃ§Ã¼p optimum threshold deÄŸerini bulmamÄ±za yardÄ±m etmek. Burada belli threshold deÄŸerlerine gÃ¶re accuracy, recall, precision, ROC, AUC ve F skoru deÄŸerlerimiz deÄŸiÅŸiklik gÃ¶sterecektir. Burada yapmamÄ±z gereken uygun threshold deÄŸerini bu metriklere bakarak bulabilmek.2.Hata fonksiyonundan kastÄ±nÄ±zÄ± L1 ve L2 regÃ¼lariazsyonu olarak anladÄ±ÄŸÄ±m iÃ§in soruya bu ÅŸekilde cevap vereceÄŸim.L1 regÃ¼larizasyonu sparsity matrix gibi (iÃ§inde milyonlarca trilyonlarca 0 olup az sayÄ±da 1 olan matrixler) RAM'de fazlasÄ±yla yer kaplayan matrixlerin weight deÄŸerlerini sÄ±fÄ±rlamaya yarar bÃ¶ylece gereksiz 0 deÄŸerlerini RAM'de tutmak zorunda kalmayÄ±z. Yani Ã¶nemsiz feature deÄŸerlerini de bÃ¶ylece yok etmiÅŸ olur. Ã‡Ã¼nkÃ¼ L1 regÃ¼larizasyon her adÄ±mda theta'nÄ±n mutlak deÄŸerinden sabit bir deÄŸer Ã§Ä±karÄ±r. Bu metodu feature selection iÃ§in kullanabiliriz.L2 regÃ¼larizasyonu ise theta deÄŸerlerini 0'a yaklaÅŸtÄ±rÄ±r fakat tamamen sÄ±fÄ±rlamaz. Her adÄ±mda theta deÄŸerinin belli bir yÃ¼zdesini eksiltir bu nedenle theta deÄŸeri asla 0 olamaz (0'a Ã§ok yaklaÅŸsa bile) L2'yi ise overfitting durumunu Ã¶nlemek amacÄ±yla theta deÄŸerlerini cezalandÄ±rmak iÃ§in kullanabiliriz. L2'de hiÃ§bir weight sÄ±fÄ±rlanmayacaÄŸÄ± iÃ§in feature deÄŸerleri eksilmez.3. Link yÃ¶nlendirmeleri Ã§alÄ±ÅŸÄ±yor mu emin olmadÄ±ÄŸÄ±m iÃ§in ekteki resmi ekledim. Regularizasyon yaptÄ±ÄŸÄ±nÄ±zda (L2) normalde cost function'Ä±nÄ±zÄ±n sonuna theta0 dÄ±ÅŸÄ±ndaki (Ã§Ã¼nkÃ¼ onun feature deÄŸeri yok) tÃ¼m theta deÄŸerlerinin karelerinin ortalamasÄ±*lambda ekliyordunuz. Gradient descent'te de her adÄ±mda cost function'Ä±n tÃ¼revini her theta deÄŸeri iÃ§in aldÄ±ÄŸÄ±nÄ±zdan dolayÄ± formÃ¼lde Repeat kÄ±smÄ±nÄ±n altÄ±nda kalan ÅŸekle dÃ¶ner ver aslÄ±ndaa lambdamÄ±z thetamÄ±zÄ± cezalandÄ±rmÄ±ÅŸ olur.HatalÄ± kÄ±sÄ±mlarÄ±m varsa dÃ¼zeltmelere aÃ§Ä±ÄŸÄ±m.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 3 people like this.Like ReportReply",
    "->  ->  GÃ¶rseldeki alpha learning rate mi?.",
    "->  ->  Evet, alpha deÄŸeri learning rate..",
    "->  Hata fonksiyonundan kastÄ±m Log Loss idi..",
    "-> ->  Hata fonksiyonunun log loss olmasÄ±nn sebebi ÅŸu(binary classification mantÄ±ÄŸÄ±nda yani iki farklÄ± label Ã§Ä±ktÄ±mÄ±zÄ±n olduÄŸnu dÃ¼ÅŸÃ¼nerek anlatacaÄŸÄ±m. Ã–rnek iyi huylu veya kÃ¶tÃ¼ huylu tÃ¼mÃ¶r.):Lojistik regresyon 0 veya 1 arasÄ±nda olur Ã§Ã¼nkÃ¼ tahmin deÄŸeri dÃ¶ndÃ¼rÃ¼r. Sigmoid fonksiyondur. Buna istinaden de log loss fonksiyonumuz hatayÄ± tespit ederken label deÄŸeriyle tahmin deÄŸerini karÅŸÄ±laÅŸtÄ±rÄ±r, bir deÄŸerin doÄŸru tahmin edilip edilmediÄŸini kontrol eder. AÅŸaÄŸÄ±daki resimde log loss ve sigmoid fonksiyonlarÄ±nÄ±n 1 ve 0 arasÄ±nda olduÄŸunu gÃ¶rebilirsiniz. label deÄŸeriniz 1 ise ve siz 1 tahmin etmiÅŸseniz cost 0 olur, aksi halde -sonsuza kadar gider. Burad istediÄŸimiz label deÄŸerimizin doÄŸru tahmin edildiÄŸindeki ve edilmediÄŸindeki costu hesaplamak. EÄŸer siz continuous ve sonsuz bir deÄŸer kÃ¼mesi iÃ§erisindeki costu hesaplamak isteseydiniz deÄŸerlerinizi 1-0 ile kÄ±yaslamanÄ±z mantÄ±ksÄ±z olacaktÄ±.UmarÄ±m aÃ§Ä±klayÄ±cÄ± olabilmiÅŸimdir.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 2 people like this.Like ReportReply",
    "->  Merhaba, resimdeki yi'ler gerÃ§ek deÄŸerlerimiz. p(yi) ise tahminimiz (0 ile 1 arasÄ±nda). Dikkat ederseniz bizim gerÃ§ek y deÄŸerimiz yani label = 1 ise eÅŸitliÄŸin saÄŸ tarafÄ± tamamen 0 oluyor(1-y). label = 0 ise sol taraf tamamen 0 oluyor. Yani aynÄ± anda sadece bir taraf aktif oluyor. Tahminimiz de sol taraf iÃ§in 1 olma olasÄ±lÄ±ÄŸÄ± saÄŸ taraf iÃ§in 0 olma olasÄ±lÄ±ÄŸÄ±. Tahminimiz label'dan ne kadar uzaksa hatayÄ± ona gÃ¶re buluyoruz.1 month ago 2 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar,  2. hafta quizinde aldÄ±ÄŸÄ±nÄ±z puanlar iÃ§in, aÅŸaÄŸÄ±daki linke tÄ±kladÄ±ÄŸÄ±nÄ±zda aÃ§Ä±lan sayfada yine \"Week2-Scores\" a tÄ±klarsanÄ±z direkt masaÃ¼stÃ¼nÃ¼ze indirmiÅŸ olacaksÄ±nÄ±z.  ???????? <a class=\"ps-media-link\" href=\"http://community.globalaihub.com/week2-scores/\" rel=\"nofollow\" target=\"_blank\">http://community.globalaihub.com/week2-scores/</a>  Saat 22:00 sonrasÄ± gelen cevaplarÄ± ne yazÄ±k ki deÄŸerlendirmeye alamayacaÄŸÄ±mÄ±zÄ± belirtmiÅŸtik. Bir kere daha hatÄ±rlatmak isterim, bu ara sÄ±navlar tamamen kendiniz iÃ§in; haftalÄ±k konulardaki eksiklerinizi gÃ¶zlemlemek, kendinizi Ã¶lÃ§mek ve final sÄ±navÄ±na hazÄ±rlÄ±k amaÃ§lÄ± hazÄ±rladÄ±ÄŸÄ±mÄ±z sÄ±navlar. FarklÄ± fake mail ve isimlerle sorularÄ± Ã¶nden gÃ¶rÃ¼p birden fazla kez sisteme cevap iletmeniz, bizler bir yana, kendiniz iÃ§in hiÃ§ bir anlam ifade etmeyecektir :)  Soru ve cevaplara da aÅŸaÄŸÄ±daki linktenâ€¦ <a class=\"ps-stream-post-more ps-js-content-excerpt-toggle\" href=\"#\">Read more</a></div><div class=\"ps-js-content-full\" style=\"\">Merhabalar,  2. hafta quizinde aldÄ±ÄŸÄ±nÄ±z puanlar iÃ§in, aÅŸaÄŸÄ±daki linke tÄ±kladÄ±ÄŸÄ±nÄ±zda aÃ§Ä±lan sayfada yine \"Week2-Scores\" a tÄ±klarsanÄ±z direkt masaÃ¼stÃ¼nÃ¼ze indirmiÅŸ olacaksÄ±nÄ±z.  ???????? <a class=\"ps-media-link\" href=\"http://community.globalaihub.com/week2-scores/\" rel=\"nofollow\" target=\"_blank\">http://community.globalaihub.com/week2-scores/</a>  Saat 22:00 sonrasÄ± gelen cevaplarÄ± ne yazÄ±k ki deÄŸerlendirmeye alamayacaÄŸÄ±mÄ±zÄ± belirtmiÅŸtik. Bir kere daha hatÄ±rlatmak isterim, bu ara sÄ±navlar tamamen kendiniz iÃ§in; haftalÄ±k konulardaki eksiklerinizi gÃ¶zlemlemek, kendinizi Ã¶lÃ§mek ve final sÄ±navÄ±na hazÄ±rlÄ±k amaÃ§lÄ± hazÄ±rladÄ±ÄŸÄ±mÄ±z sÄ±navlar. FarklÄ± fake mail ve isimlerle sorularÄ± Ã¶nden gÃ¶rÃ¼p birden fazla kez sisteme cevap iletmeniz, bizler bir yana, kendiniz iÃ§in hiÃ§ bir anlam ifade etmeyecektir :)  Soru ve cevaplara da aÅŸaÄŸÄ±daki linkten ulaÅŸabilirsiniz.  ????????http://community.globalaihub.com/mlcc_week2-qas/  Tekrar belirteyim; sÄ±nav soru ve cevaplarÄ±nda emeÄŸi geÃ§en mentorlarÄ±mÄ±za tekrar teÅŸekkÃ¼rler:)  Herkese iyi haftalar, saÄŸlÄ±klÄ± gÃ¼nler âœ¨âœ¨</div></div>",
"comment": [
    "",
    "->  Merhaba, 8. sorunun cevabÄ± a ÅŸÄ±kkÄ± olarak verilmiÅŸ ancak b olmasÄ± gerekmiyor mu?Q8- Why and when do we use sparse representation?- When data size is large and most of feature value that we are interested in is zero. (doÄŸru olarak iÅŸaretlenmiÅŸ)- When data size is large and most of feature value that we are interested in is non-zero. (bence doÄŸru olmasÄ± gereken)1 month ago 9 people like this.Like ReportReply",
    "->  ->  AynÄ± ÅŸekilde ben de yazacaktÄ±m.",
    " ->  ->  cevap ta bir yanlÄ±ÅŸlÄ±k yok. data da 0 deÄŸeri Ã§ok fazla ise, bellekten ve performanstan kazanmak iÃ§in bu 0 deÄŸerlerini atmak gerekiyor..",
    "->  ->  Feature Engineering baÅŸlÄ±ÄŸÄ± altÄ±nda: Sparse RepresentationSuppose that you had 1,000,000 different street names in your data set that you wanted to include as values for street_name. Explicitly creating a binary vector of 1,000,000 elements where only 1 or 2 elements are true is a very inefficient representation in terms of both storage and computation time when processing these vectors. In this situation, a common approach is to use a sparse representation in which only nonzero values are stored. Burdaki aÃ§Ä±klama diyor ki 1 milyon datanÄ±z var ve sadece 1-2 deÄŸeriniz True yani non-zero. Sparse representationÄ± 0 larÄ±n Ã§oÄŸunlukta, 1 lerin ise seyrek oldupu yerde kullandÄ±ÄŸÄ±mÄ±zÄ± sÃ¶ylÃ¼yor. SanÄ±rÄ±m \"value that we are interested\" kÄ±smÄ±na takÄ±ldÄ±nÄ±z.1 month ago 2 people like this.Like ReportReply",
    "-> ->  BildiÄŸim kadarÄ±yla sparse representation vektÃ¶rÃ¼mÃ¼zdeki deÄŸerlerin Ã§oÄŸu 0 olduÄŸunda sadece 1 olanlarÄ± tutarak verimizi daha anlaÅŸÄ±labilir hale getirdiÄŸimiz gÃ¶sterim. Resminden daha iyi anlayablirsiniz.1 month ago 3 people like this.Like ReportReply",
    "->  ->  Merhaba, ben de tam olarak \"value that we are interested\" kÄ±smÄ±na takÄ±ldÄ±m. Evet Sparse Representation'Ä± Ã§ok fazla 0 Ä±n olduÄŸu zaman kullanÄ±yoruz, ben de ÅŸu ÅŸekilde dÃ¼ÅŸÃ¼ndÃ¼m bizim ilgilendiÄŸimiz bu 0'lar deÄŸil, yani \"feature value that we are interested in is non-zero.\"1 month ago 7 people like this.Like ReportReply",
    "->  -> Åimdi daha iyi anladÄ±m. TÃ¼rkÃ§e'ye Ã§evirirken yanlÄ±ÅŸ yÃ¶nden bakmÄ±ÅŸÄ±m bende. Ã‡ok teÅŸekkÃ¼rler..",
    "-> ->  Bende value that we are interested kÄ±smÄ±na takÄ±ldÄ±m cevaplarken. A daha doÄŸru geliyor ama ilgilendiÄŸimiz kÄ±sÄ±mlar 0'lar deÄŸil, 1'ler diye dÃ¼ÅŸÃ¼nÃ¼p B iÅŸaretlemiÅŸtim. En azÄ±ndan bana biraz aÃ§Ä±k deÄŸil gibi geldi bu iki ÅŸÄ±k ve kastedilen..",
    "->  ->  TeÅŸekkÃ¼r ederim, evet sanÄ±rÄ±m bir \"lost in translation\" durumu yaÅŸadÄ±m ğŸ™‚.",
    "->  Merhaba ->  hocam, Ã¶ncelikle teÅŸekkÃ¼r ederim. ???? Ara sÄ±navlar gerÃ§ekten Ã¶ÄŸrendiÄŸimiz veya Ã¶ÄŸrenemediÄŸimiz ÅŸeyleri gÃ¶rmemizde etkili oluyor. SÄ±nav sorularÄ± ve cevaplarÄ± aÃ§Ä±klandÄ± ama kafama takÄ±lan bir ÅŸey var. 8. soruda sÄ±fÄ±r olmayanlarÄ± bir grup yaparsak iÅŸimiz daha kolay olacak. Ama cevap seÃ§eneÄŸi neden large, non-zero deÄŸil de large, zero? AnlayamadÄ±m, aÃ§Ä±klayabilir misiniz?.",
    "-> 5. sorunun 2. maddesindeki \"The lenght of the one-hot encode vector is equal to number of observations in the data.\" ifadesinin yanlÄ±ÅŸ olduÄŸu sÃ¶ylenmiÅŸ fakat Ã¶rneÄŸin benim elimde 5 tane sokak ismi olsun ve sÄ±rasÄ±yla isimleri: Papatya, GÃ¼l, Papatya, Nergis, GÃ¼l olsun. (Ã–zellikle tekrarlÄ± yaptÄ±m ki verilen aÃ§Ä±klamayÄ± karÅŸÄ±lasÄ±n diye.) Papatyaya 1, gÃ¼le 2, nergise de 3 olarak kodlama yaptÄ±ÄŸÄ±mÄ±zÄ± farzedelim o halde vektÃ¶rÃ¼mÃ¼z: [1 2 1 3 2] ÅŸeklinde olmaz mÄ±? Verilen aÃ§Ä±klamaya vektÃ¶rÃ¼n uzunluÄŸu yalnÄ±zca unique olanlarla alakalÄ± diyor. NiÃ§in bÃ¶yle? YukarÄ±daki verdiÄŸim vektÃ¶r yanlÄ±ÅŸ mÄ± oluyor o halde?1 month ago 2 people like this.Like ReportReply",
    "->  -> One-Hot Encode, verinin binary formda ifade edilmesidir. GÃ¶zlem sayÄ±sÄ±na deÄŸil gÃ¶zlem de bulunan ayrÄ±k deÄŸer sayÄ±sÄ±na eÅŸittir. Ã–rneÄŸinden dÃ¼ÅŸÃ¼necek olursak:[Papatya, GÃ¼l, Papatya, Nergis, GÃ¼l]Papatya iÃ§in: [1,0,1,0,0]GÃ¼l iÃ§in: [0,1,0,0,1].. vs. One-Hot Encode sayÄ±sÄ± : Papatya, GÃ¼l, Nergis: 3 olacak.1 month ago 2 people like this.Like ReportReply",
    "->  -> ->  merhaba arkadaÅŸlar,VerdiÄŸiniz Ã¶rneÄŸin one-hot encoding uygulanmÄ±ÅŸ halini aÅŸaÄŸÄ±daki resimde gÃ¶rselleÅŸtirdim. SaÄŸ tarafta one-hot encoding altÄ±nda gÃ¶rÃ¼len kolonlar bu iÅŸlem sonrasÄ±nda oluÅŸturulan kolon ya da featurelar oluyor.Elimizde 5 sample ve 3 adet unique feature varken one-hot encoding ile oluÅŸturulan vektÃ¶rÃ¼n uzunluÄŸu 3 olmuÅŸ oluyor.1 month ago 2 people like this.Like ReportReply",
    "->  ->  TeÅŸekkÃ¼rler ğŸ™‚.",
    "->  Merak edenler iÃ§in 617 kiÅŸinin not ortalamasÄ± : 65,15397083.1 month ago 5 people like this.Like ReportReply",
    " ->  GeÃ§en haftaki quizden 70/100, bu haftakinden 90/100. Herkese teÅŸekkÃ¼rler, Ã§alÄ±ÅŸmaya devam..",
    " ->  1. soruda \"logistic reggression is a linear model\" ifadesine doÄŸru denilmiÅŸ. BildiÄŸim kadarÄ±yla sadece birinci dereceden ifadeler iÃ§in lineer diyebiliriz. Burada da logistic reggression da ikinci dereceden ifadeler kullanÄ±labilir olduÄŸundan -ki ders iÃ§eriÄŸinde kullandÄ±k- logistic regression' Ä±n non-linear olmasÄ± gerekmez mi?.",
    "->   ->  herhangi bir regresyonda 2. dereceden ifadelerin olmasÄ± o regresyonun non-linear olmasÄ±nÄ± gerektirmez. Lineerlik regresyonu oluÅŸturan deÄŸiÅŸkenlerin katsayÄ±larÄ±(w)'larÄ±na gÃ¶re tÃ¼revi sonucu incelenerek Ã¶lÃ§Ã¼lÃ¼r. EÄŸer bu tÃ¼rev sonunda katsayÄ±lara iliÅŸkin bir deÄŸer bulunmaz iise sonuÃ§larda bu fonksiyona lineer denir.Yani lineerliÄŸimizi belirleyen katsayÄ±larÄ±mÄ±z oluyor. X deÄŸiÅŸkenleri deÄŸil. Bu yÃ¼zden logistic regression non-linear olabilir.1 month ago 2 people like this.Like ReportReply",
    "->   ->  Merhaba, AslÄ±nda anladÄ±ÄŸÄ±m kadarÄ±yla sigmoid fonksiyonunda hipotez fonksiyonu uygulandÄ±ÄŸÄ±ndan(formÃ¼ldeki e Ã¼zerindeki multiple Linear Regression hipotezi uygulanÄ±r) karar sÄ±nÄ±rÄ±nda linear olacaktÄ±r. Hipotez fonksiyonuna ifadelerin kareleri eklenirse non-linear elde edebiliriz..",
    " ->  ->  aÃ§Ä±klama iÃ§in teÅŸekkÃ¼r ederim. Peki bu tÃ¼rev sonucunda katsayÄ±lara iliÅŸkin bir deÄŸer bulma ihtimalimiz yok mu? Bu deÄŸeri bulduÄŸumuz zaman da non-linear olduÄŸunu da gÃ¶stermiÅŸ olmaz mÄ±yÄ±z?.",
    "->   ->  Evet dediÄŸiniz gibi sonuÃ§ katsayÄ± baÄŸÄ±mlÄ± ise non-linear olduÄŸunu gÃ¶stermiÅŸ oluyoruz..",
    " ->  ->  ben de buna Ã§ok benzer dÃ¼ÅŸÃ¼nmÃ¼ÅŸtÃ¼m. SonuÃ§ olarak bazÄ± koÅŸullar altÄ±nda non-linear olma ihtimali var. Bu da sorunun doÄŸru cevabÄ±nÄ± yanlÄ±ÅŸ yapmaz mÄ±? ????1 month ago 2 people like this.Like ReportReply",
    "->   ->  HayÄ±r yapmaz, soruda Logistic Regresyon non-linear'dir. denilmiÅŸ, olabilir denilmemiÅŸ..",
    "->   ->  https://sebastianraschka.com/faq/docs/logistic_regression_linear.htmlWhy is logistic regression considered a linear model?sebastianraschka.comThe short answer is: Logistic regression is considered a generalized linear model because the outcome always depends on the sum of the inputs and parameters.....",
    "->  ->  Furkan hocam \"Lineerlik regresyonu oluÅŸturan deÄŸiÅŸkenlerin katsayÄ±larÄ±(w)'larÄ±na gÃ¶re tÃ¼revi sonucu incelenerek Ã¶lÃ§Ã¼lÃ¼r.\" demiÅŸsiniz. Bu ÅŸekilde lineerlik belirlemeyle ilk defa karÅŸÄ±laÅŸÄ±yorum. Bunu biraz aÃ§Ä±klar mÄ±sÄ±nÄ±z ?.",
    "->  ->  Tabii ki,A model or relationship is termed as linear if it is linear in parameters and nonlinear, if it is not linear in parameters. In other words, if all the partial derivatives of y with respect to each of the parameters are independent of the parameters,thenthe modelis calledas a linearmodel.bu cÃ¼mle Dr. Shalabh'Ä±n notlarÄ±ndan(http://home.iitk.ac.in/~shalab/). modelimiz, parametleri(X deÄŸiÅŸkenlerinin katsayÄ±larÄ±- burada w olarak bildiÄŸimiz weight deÄŸerleri oluyor.) lineer olmasÄ± haline lineer aksi takdirde non-lineer olarak sÄ±nÄ±flandÄ±rÄ±lmakta. Bu da, modelimizin(y = b + w1X1 + w2X2+...) w1,w2... parametrelerine gÃ¶re kÄ±smi tÃ¼revleri alÄ±narak belirlenmektedir.1 month ago 3 people like this.Like ReportReply",
    "->  ->  Ã‡ok teÅŸekkÃ¼r ederim.",
    " ->  EmeÄŸiniz iÃ§in Ã§ok teÅŸekkÃ¼rler ????.",
    "-> Merhaba, 5. soruda, (I) no'lu maddede one-hot-encoded feature'a Ã¶rnek olarak \"serial number\" verildiÄŸi iÃ§in ÅŸÃ¼phe ile yaklaÅŸtÄ±m. Teorik olarak mÃ¼mkÃ¼n fakat veri setinde unique deÄŸere sahip feature'larÄ±n kullanÄ±lmasÄ±nÄ±n iyi bir seÃ§im olmadÄ±ÄŸÄ±nÄ± dÃ¼ÅŸÃ¼ndÃ¼m. (Bkz: Qualities of Good Features - unique_house_id)Madde (IV) kesinlikle doÄŸru, madde (III) de kesinlikle yanlÄ±ÅŸ olduÄŸu iÃ§in, geriye II-IV seÃ§eneÄŸi kalÄ±yordu. (II) maddesini okuyunca da \"number of observation\" ifadesini de gÃ¶zlenen kategorik deÄŸerler olarak yorumladÄ±m.1 month ago 3 people like this.Like ReportReply",
    "->  -> ben de sizin gibi dÃ¼ÅŸÃ¼nmÃ¼ÅŸtÃ¼m ve II-IV demiÅŸtim..",
    "->  Merhaba, ben dÃ¼nkÃ¼ sÄ±navÄ± kaÃ§Ä±rdÄ±m iÅŸle ilgili bir yoÄŸunluk oldu hiÃ§ bakamadÄ±m ğŸ™ devam etmek istiyorum hala ama sorun olmaz deÄŸil mi?.",
    "->  ->  Merhaba, devam edebilirsiniz tabii ki, ama 10 MayÄ±s taki final sÄ±navÄ±nÄ± kaÃ§Ä±rmayÄ±n derim ğŸ˜‰.",
    "->  -> ->  Ben de aynÄ± ÅŸekilde dÃ¼ÅŸÃ¼ndÃ¼m. Ã–nceki haftanÄ±n dersinde unique_id gibi kesinlikle tekrarlamayan featurelarÄ± kullanmanÄ±n yanlÄ±ÅŸ olduÄŸu Ã¼zerinde durulmuÅŸtu. Seri numarasÄ± da tek bir Ã¼rÃ¼ne ve sample a ait olacaÄŸÄ± iÃ§in feature olarak kullanmak doÄŸru olmaz diye dÃ¼ÅŸÃ¼nÃ¼p doÄŸru olmasÄ± daha olasÄ± II-IV dedim.1 month ago 2 people like this.Like ReportReply",
    "->  Merhaba,Merak edenlere SÄ±navÄ± tamamlama saatine ve notlara gÃ¶re kiÅŸi daÄŸÄ±lÄ±mlarÄ±.Standart Sapma = 21.1753031 month ago 12 people like this.Like ReportReply",
    "-> bu hafta karantina da olduÄŸumuzan dolayÄ± sÄ±nav notum dÃ¼ÅŸÃ¼k geldi gereken deÄŸeri veremedim umarÄ±m bu gÃ¼nleri en kÄ±sa zamanda atlatÄ±rÄ±z ,umarÄ±m bu notlar final sÄ±navÄ±na etki etmiyordur.",
    "->  merhaba cevaplara baktÄ±ÄŸÄ±mda kendi hesapladÄ±ÄŸÄ±m puanla paylaÅŸtÄ±ÄŸÄ±nÄ±z linkteki puan arasÄ±nda tutarsÄ±zlÄ±k gÃ¶rdÃ¼m belkide ben yanlÄ±ÅŸ iÅŸaretledim ama hatÄ±rladÄ±ÄŸÄ±m kadarÄ±yla bile olsa yine de kendi hesaplamamda puanÄ±m yÃ¼ksek Ã§Ä±kÄ±yor acaba sÄ±navda iÅŸaretlediÄŸimiz cevaplarÄ± nasÄ±l Ã¶ÄŸrenebilirz?.",
    "->  ->  Merhaba, Google verdiÄŸiniz yanÄ±tlara gÃ¶re otomatik olarak puanÄ±nÄ±zÄ± hesaplÄ±yor, bir herhangi manuel bir mÃ¼dahalede bulunmuyoruz. Mail adresinize yanÄ±tlarÄ±nÄ±zÄ± iletiyorum, iyi Ã§alÄ±ÅŸmalar..",
    "->  merhaba, sinavda notasyon hatasi olabilir mi? I-III demek 1. ve 3. ÅŸÄ±klar arasÄ± demek deÄŸil mi? I,III yazÄ±lmasÄ± gerekiyordu1 month ago 3 people like this.Like ReportReply",
    "->  ->  Sehven bu ÅŸekilde belirtilmiÅŸ, sonraki sÄ±navlarda dikkat edeceÄŸiz bu konuya, teÅŸekkÃ¼rler..",
    "->  Merhaba, sinav sonucumu goremiyorum. Yardimci olabilir misiniz? Email adresim  fakat listede yokum. Amerika'da yasadigim icin Turkiye'ye aramizda 8 saat fark var. Cevaplarimi buranin saatine gore 16 sularinda ilettim, bulabildigim ilk firsat buydu. Bunu goz onunda bulundurursaniz cok sevinirim. -> .",
    "->  ->  Merhaba, siz 23:11 de submit etmiÅŸ gÃ¶rÃ¼nÃ¼yorsunuz, dolayÄ±sÄ±yla deÄŸerlendirmeye almamÄ±ÅŸ. Mail adresinize yanÄ±tlarÄ±nÄ±zÄ± iletiyorum, iyi Ã§alÄ±ÅŸmalar..",
    "->  ->  Saat farkindan oturu oyle olmus. Cok tesekkur ederim..",
    "->  ->  merhaba AslÄ± hanÄ±m, ben ogle vakitlerinde submit etmistim ama ben de goremedim, acaba submit edemedim mi , bir problem mi oldu? size zahmet benim skorum neden gorulmemis bir kontrol edebilir misiniz?.",
    "-> Merhaba, bir onceki sinavda, yanitlarimizi gonderir gondermez her bir soru izerinden dogru ve yanlis cevapladigimiz siklari gorebilmistik. Bu hafta farkli bir yontem izlendi. Bence kendi yanitlarimiz uzerinden dogru ve yanlis siklari gormek faydaliydi. Mesela uzerinden yaklasik 3 gun gecti ve ben aldigim puandan 1 yanlisim oldugunu gordum ama hangi soruda yanlis yaptigimi hatirlamak icin epey ugrastim. Acaba ilk sisteme donmek mumkun olabilir mi?1 month ago 8 people like this.Like ReportReply",
    "->  -> Merhaba, suistimal durumlarÄ±nÄ±n Ã¶nÃ¼ne biraz olsun geÃ§ebilmek adÄ±na bu hafta bÃ¶yle bir yol izlemiÅŸtik. Ä°lk sisteme dÃ¶nÃ¼ÅŸ konusunu, ekibimle tekrar deÄŸerlendireceÄŸiz;) teÅŸekkÃ¼rler.",
    "-> ->  merhaba, tesekkurler. Ya da sinav yanitlari aciklandiginda acaba herkese kendi isaretlemelerinin eposta ile gonderilmesinin imkani olabilir mi? Yani ilk sisteme donmeye alternatif olarak?.",
    "->  ->'Ä±n fikrine katÄ±lÄ±yorum, ilk hafta daha iyi bir yÃ¶ntemdi. -> .",
    "->  AslÄ± hanÄ±mÄ±n dediÄŸi gibi suistimal olabilir bÃ¶yle kalmasÄ± daha mantÄ±klÄ±..",
    "->  Suistimal durumlarÄ±na sebep olanlar sadece kendilerini kandÄ±rÄ±yor. Bu nedenle Sinem hanÄ±mÄ±n dediklerine katÄ±lÄ±yorum..",
    "->  MÃ¼lakatta ortaya Ã§Ä±kar kimin ne olduÄŸu ğŸ™‚ AslÄ±nda basit bir Ã§Ã¶zÃ¼mÃ¼ var google forms da elinizdeki excel dosyasÄ±nÄ± kullanarak, formda sadece isim soyisim mail bilgisini doÄŸru dolduran insanlara eriÅŸim verirsiniz ve formu her pazar 21.40 - 22.00 arasÄ±nda yayÄ±nlarsÄ±nÄ±z ve kapatÄ±rsÄ±nÄ±z yirmi dakika gayet yeterli hatta fazla bile sorular coktan secmeli zaten bÃ¶yle bir seÃ§enek var eÄŸer yaparsanÄ±z ğŸ™‚ YapÄ±lmalÄ± diyenler beÄŸen butonunu Ã§Ã¶kertsin ğŸ˜€1 month ago 4 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "->  uploaded 1 photo",
"quest": "Merhaba. Classification: True vs. False and Positive vs. Negative kÄ±smÄ±nda, pozitif ve negatif durumlara gÃ¶re hikaye gÃ¶z Ã¶nÃ¼ne alÄ±ndÄ±ÄŸÄ±nda False positive(FP) ve False negative(FN) durumlarÄ±nÄ±n yer deÄŸiÅŸtirmesi gerekmez mi ?  TeÅŸekkÃ¼rler.",
"comment": [
    "",
    "->  Burada negatiflik kafa karÄ±ÅŸtÄ±rÄ±yor olabilir. Kanser testi yaparken kanserli hÃ¼cre bulunursa sonuÃ§ Pozitif Ã§Ä±kar. Bulunmazsa Negatif Ã§Ä±kar. Bu Ã¶rnekten daha iyi anlaÅŸÄ±labilir anlamlar ğŸ™‚ DoÄŸru kanserli teÅŸhis : True Positive. Kanser olmayana Kanser TeÅŸhisi : False Positive. Kanser olup da Kanser deÄŸil teÅŸhisi : False Negative. Burada testin pozitif Ã§Ä±kmasÄ± gerekirken negatif Ã§Ä±kÄ±yor. Kanser olmayana da Kanser deÄŸil sonucu : True Negative. SonuÃ§ olarak : False Positive, normalde olmamasÄ± gereken ÅŸeyi olmuÅŸ gibi tahmin etmek. False Negative ise, olmasÄ± gereken ÅŸeyi olmamÄ±ÅŸ gibi tahmin etmek.Yerine gÃ¶re FP yerine gÃ¶re de FN'ler tehlikeli olabiliyor.1 month ago 2 people like this.Like ReportReply",
    "->  ->  TeÅŸekkÃ¼r ederim..",
    "->  Confusion matrix oluÅŸturulurken modelin sonuÃ§larÄ± ile gerÃ§ek durumun uyumuna gÃ¶re Ã§Ä±ktÄ±lar isimlendirilir.Positive --> Wolf (Pozitif sÄ±nÄ±f)Negative --> No Wolf (Negatif sÄ±nÄ±f)True ve False etiketi de gerÃ§ek durumla modelin uyumuna gÃ¶re atanÄ±r. EÄŸer uyum varsa True yoksa False etiketi atanÄ±r. Shepherd(model) No Wolf dediÄŸinde Negative ve yanlÄ±ÅŸ karar olduÄŸu iÃ§in False yani False NegativeShepher Wolf dediÄŸinde Positive ve yanlÄ±ÅŸ karar olduÄŸu iÃ§in False yani False PositiveBu ÅŸekilde dÃ¼ÅŸÃ¼nmen Confusion matrisini doÄŸru bir ÅŸekilde oluÅŸturmana yardÄ±mcÄ± olabilir.1 month ago 2 people like this.Like ReportReply",
    "->  ->  Pozitiflik ve negatiflik durumu modelin sÃ¶ylediÄŸine mi baÄŸlÄ± yoksa reality'ye mi ?.",
    "->  ->  ->  un cevabi yeterli oldu sanirim.",
    "->  ->  Evet teÅŸekkÃ¼r ederim..",
    "-> Confusion matrix'te kendimize y=1 deÄŸeri seÃ§eriz bu da true olur. Ã–rneÄŸin y=1 deÄŸeri kurdun tehdidi (positive) olsun. y=0 kurdun tehdit etmiyor oluÅŸu (negative) olsun.EÄŸer kurt tehdit ediyorsa ve modelimiz bunu doÄŸru tahmin etmiÅŸse true positive olur. (gerÃ§ek deÄŸer y=1, tahmin edilen y=1)EÄŸer kurt tehdit etmiÅŸse ve modelimiz kurdun tehdit etmediÄŸini tahmin etmiÅŸse false negative. (gerÃ§ek deÄŸer y=1, tahmin edilen y=0. Negatif tahmin edlmÅŸ ama yanlÄ±ÅŸ)EÄŸer kurt tehdit etmiyorsa ve modelimiz bunu yanlÄ±ÅŸ tahmin edip kurdun tehdidini tahmin etmiÅŸse false positive olur. (gerÃ§ek y=0, tahmin edilen y=1. Positive tahmin edilmiÅŸ ama yanlÄ±ÅŸ )EÄŸer kurt tehdit etmiyorsa ve modelimiz bunu doÄŸru tahmin etmiÅŸse true negative olur. (gerÃ§ek deÄŸer y=0, tahmin edilen y=0)Yani y=1 olma durumu positive, y=0 olma durumu negative.Tahmin ile gerÃ§ek deÄŸerin eÅŸleÅŸme durumu true, tahmin ile gerÃ§ek durumun eÅŸleÅŸmeme durumu false olur.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 5 people like this.Like ReportReply",
    "->  ->  MantÄ±ÄŸÄ±nda yanlÄ±ÅŸlÄ±k yok ancak en son paragrafÄ±nda belirttiÄŸin \"Tahmin ile gerÃ§ek deÄŸerin eÅŸleÅŸme durumu positive, tahmin ile gerÃ§ek durumun eÅŸleÅŸmeme durumu negatif olur.\" Ã¶nermesi tam olarak doÄŸru deÄŸil Ã§Ã¼nkÃ¼ positive ve negative burada label ya da classlarÄ±mÄ±z oluyor. Tahmin ile eÅŸleÅŸip eÅŸleÅŸmeme durumuna gÃ¶re True veya False olarak adlandÄ±rÄ±lÄ±yor.Ä°yi Ã§alÄ±ÅŸmalar, kolay gelsin..",
    "->  ->  DÃ¼zeltme iÃ§in teÅŸekkÃ¼rler, ilgili dÃ¼zeltmeleri yapÄ±yorum.Ä°yi Ã§alÄ±ÅŸmalar..",
    "->  ->  EÄŸer kurt tehdit etmiÅŸse ve modelimiz kurdun tehdit etmediÄŸini tahmin etmiÅŸse false positive. demiÅŸsiniz ancak tabloda bu durum false negative olarak gÃ¶sterilmiÅŸ. Ben de sizin dediÄŸiniz gibi dÃ¼ÅŸÃ¼nmÃ¼ÅŸtÃ¼m. Galiba yanlÄ±ÅŸ dÃ¼ÅŸÃ¼nmÃ¼ÅŸÃ¼z..",
    "->  ->  HayÄ±r tabloda yanlÄ±ÅŸlÄ±k yok. ÅÃ¶yle aÃ§Ä±klayayÄ±m:- shepherd kurt var derse positive, kurt yok derse negative.- shepherd kurt gerÃ§ekten varken kurt var derse true positive, kurt yok derse false negative.- shepherd kurt gerÃ§ekten yokken kurt var derse false positive, kurt yok derse true negative.Buradaki yanlÄ±ÅŸ anlaÅŸÄ±lmaya tabloya reality aÃ§Ä±sÄ±ndan bakmanÄ±z yol aÃ§Ä±yor. Reality deÄŸil shepherd'Ä±n sÃ¶ylediÄŸine gÃ¶re positive ve negative'i yerleÅŸtirmelisiniz..",
    "->  ->  TeÅŸekkÃ¼r ederim. Åimdi anladÄ±m..",
    "->  Buradaki yazÄ±yÄ± okuyabilirsiniz, yararlÄ± olacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum. https://medium.com/@sengul_krdrl/hata-matrisini-anlamak-7035b7921c0f",
    "Hata Matrisini Anlamakmedium.comVeri aldÄ±ÄŸÄ±mÄ±zda Ã¶n iÅŸleme , veri temizleme ve kurulduktan sonra ilk adÄ±m onu bitmemiÅŸ bir modele beslemek ve tabii ki olasÄ±lÄ±klarda Ã§Ä±ktÄ±â€¦1 month ago 3 people like this.Like ReportReply",
    "->  ->  TeÅŸekkÃ¼r ederim..",
    " "
]
},
{
"question_isim": "->  uploaded 1 photo",
"quest": "Merhaba, tf.keras Linear Regression egzersizlerinin kodlamalarÄ±na Ã§alÄ±ÅŸÄ±rken bu hatayÄ± alÄ±yorum. Versiyonumu da kontrol ettim 2.1.  tf.keras.metrics'ler arasÄ±nda RootMeanSquaredError Ã§Ä±kmÄ±yor. Bu durumu nasÄ±l Ã§Ã¶zebilirim ? Bunun yanÄ±nda diÄŸer hatayÄ± da aÃ§Ä±klayabilirseniz sevinirim. Sayfadaki kodda da aynen bu ÅŸekilde yazÄ±yor. Åimdiden teÅŸekkÃ¼rler.",
"comment": [
    "",
    "->  Import ettiÄŸiniz paketlerinizi gÃ¶zden geÃ§irin muhtemelen importlarÄ±nÄ±zda bir hata olabilir.Edit: kodunuzu paylaÅŸÄ±rsanÄ±z daha saÄŸlÄ±klÄ± Ã§Ã¶zÃ¼m yolu sunulabilir.1 month ago 2 people like this.Like ReportReply",
    "-> import pandas as pdimport tensorflow as tffrom matplotlib import pyplot as pltdef build_model(my_learning_rate):model= tf.keras.models.Sequential()model.add(tf.keras.layers.Dense(units=1, input_shape=(1,)))model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate), loss=\"mean_squared_error\", metrics=[tf.keras.metrics.RootMeanSquaredError()])return modeldef train_model(model,feature,label,epochs,batch_size):history=model.fit(x=feature, y=label, batch_size=None, epochs=epochs)trained_weight=model.get_weights()[0]trained_bias=model.get_weights()[1]epochs=history.epochhist=pd.DataFrame(history.history)rmse=hist[\"root_mean_squared_error\"]return trained_weight, trained_bias, epochs, rmseprint(\"Defined create_model and train_model\")def plot_the_model(trained_weight, trained_bias, feature, label):plt.xlabel(\"feature\")plt.ylabel(\"label\")plt.scatter(feature, label)x0=0y0= trained_biasx1=my_feature[-1]y1=trained_bias + (trained_weight*x1)plt.plot([x0,x1], [y0,y1], c='r')plt.show()def plot_the_loss_curve(epochs, rmse):plt.figure()plt.xlabel(\"Epoch\")plt.ylabel(\"Root Mean Squared Error\")plt.plot(epochs, rmse, label=\"Loss\")plt.legend()plt.ylim([rmse.min()*0.97, rmse.max()])plt.show()print(\"Defined the plot_the_model and plot_the_loss_curve functions.\")my_feature = ([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0])my_label = ([5.0, 8.8, 9.6, 14.2, 18.8, 19.5, 21.4, 26.8, 28.9, 32.0, 33.8, 38.2])learning_rate=0.01epochs=10my_batch_size=12my_model = build_model(learning_rate)trained_weight, trained_bias, epochs, rmse = train_model(my_model, my_feature,my_label, epochs,my_batch_size)plot_the_model(trained_weight, trained_bias, my_feature, my_label)plot_the_loss_curve(epochs, rmse).",
    "->  ->  Kodunuz sorunsuz Ã§alÄ±ÅŸmakta, herhangi bir sÄ±kÄ±ntÄ± yok, paketlerinizi manuel kurmuÅŸ iseniz versiyon sorunu yaÅŸÄ±yor olabilirsiniz, paketlerinizi kaldÄ±rÄ±p yeniden kurmayÄ± deneyebilirsiniz..",
    "->  ->  Ä°lginiz iÃ§in teÅŸekkÃ¼r ederim. Tensorflow 1.12'ydi onu 2.1 olarak da gÃ¼ncelledim ama sorunum Ã§Ã¶zÃ¼lmedi. KaldÄ±rmayÄ± tekrar denerim..",
    "->  Pycharm kullaniyor iseniz , keras kÃ¼tÃ¼phanesini ayrÄ± yÃ¼klemeyi deneyin. Nedense tensorflow dan import edince saÃ§ma hatalarÄ± bende alÄ±yordum. AyrÄ± ayrÄ± kÃ¼tÃ¼phaneleri yÃ¼klenince ortadan kalktÄ±..",
    "->  ->  merhaba , muhtemelen ben de bu problemi yasiyorum fakat pycharm da keras kutuphanesini nasil ayrica yukleyecegmi bilmiyorum. nasil yukleyebilirim? teÅŸekkurler.",
    "->  BugÃ¼ne kadar Google Colab,Spyder(Anaconda Distributed) ve Jupyter Notebook (Anaconda Distributed) platformlarÄ±nda Ã§alÄ±ÅŸÄ±p bir hata ile karÅŸÄ±laÅŸmadÄ±m.Bu platformlardan birinde Ã§alÄ±ÅŸÄ±yorsanÄ±z ve tensorflow versiyonunuzda herhangi bi sÄ±kÄ±ntÄ± yok ise, https://keras.io/ sitesinden optimizer modÃ¼llerini inceleyip sorununuzu Ã§Ã¶zebilirsiniz.Home - Keras Documentationkeras.ioDocumentation for Keras, the Python Deep Learning library..",
    " "
]
},
{
"question_isim": "->  uploaded 1 photo",
"quest": "Merhaba ArkadaÅŸlar, Genel bir tekrar yaparken ekteki Ã¶rneÄŸi tam anlayamamÄ±ÅŸÄ±m. YardÄ±mlarÄ±nÄ±zÄ± rica ediyorum. TeÅŸekkÃ¼rler.",
"comment": [
    "",
    "-> RegÃ¼larizasyonda deÄŸiÅŸkenlere atanan aÄŸÄ±rlÄ±klarÄ±n karelerinin toplamÄ±nÄ±n olabildiÄŸince dÃ¼ÅŸÃ¼k tutulmasÄ± hedeflenir. Ancak bunu yaparken aÄŸÄ±rlÄ±klarÄ± olmasÄ± gerektiÄŸinden fazlasÄ±yla dÃ¼ÅŸÃ¼rmek underfitting'e; olmasÄ± gerekenden az dÃ¼ÅŸÃ¼rmek (yani regÃ¼larisyonda kullanÄ±lan lambda deÄŸerini 0 veya 0'a yakÄ±n seÃ§mek) overfitting'e sebep olur. Bu Ã¶rnekte ilk ÅŸÄ±kta bir tane feature'Ä±n aÄŸÄ±rlÄ±ÄŸÄ±nÄ± bÃ¼yÃ¼k seÃ§mekten bahsediyor. YukarÄ±daki aÃ§Ä±klamama gÃ¶re bu istenmeyen bir durum. AyrÄ±ca diÄŸer feature'larÄ±n aÄŸÄ±rlÄ±klarÄ±nÄ± 0 deÄŸerine eÅŸitlemek onlarÄ± regresyon denkleminden Ã§Ä±kartmak anlamÄ±na gelir. Yani denklemimiz y = B0 + w1* b1 olmakla kalÄ±r ki bu da istemediÄŸimiz bir durum. DiÄŸer deÄŸiÅŸkenleri boÅŸuna denklemde kullanmamÄ±ÅŸtÄ±k. BÃ¶yle yaparak muhtemel bir underfitting'e sebep olduk. Ä°kinci ÅŸÄ±k da ilk ÅŸÄ±kka benzer. 1 feature yÃ¼ksek aÄŸÄ±rlÄ±ÄŸa sahipken diÄŸerlerinin aÄŸÄ±rlÄ±ÄŸÄ± 0'a yakÄ±nsak durumda. Tek farkÄ± feature'larÄ± direkt denklemden atmaktansa dÃ¼ÅŸÃ¼k aÄŸÄ±rlÄ±klar vererek model Ã¶ÄŸrenme kapasitesini sÄ±nÄ±rlandÄ±rmÄ±ÅŸ oluyoruz. Bu da yine bir underfitting ile karÅŸÄ±laÅŸmamÄ±zÄ± muhtemel kÄ±lÄ±yor.Genel manada dÃ¼ÅŸÃ¼nÃ¼rsek; anlamlÄ± bir regÃ¼larizasyon iÃ§in tek ve/veya birden fazla (ancak tÃ¼m featurelar deÄŸil) feature'a odaklanmak yeterli bir regÃ¼larisyon saÄŸlamÄ±yor. KÄ±sa bir Ã¶rnek ile bitireyim. Ä°lk ÅŸÄ±k iÃ§in 4 feature ile aÃ§Ä±kladÄ±ÄŸÄ±mÄ±z bir denklemimiz olsun ve ilkinin aÄŸÄ±rlÄ±ÄŸÄ± 5 iken diÄŸerleri 0 olsun. Kareler toplamÄ± 25 edecektir. 3. ÅŸÄ±k iÃ§in yine 4 feature'umuz olsun fakat aÄŸÄ±rlÄ±klarÄ± sÄ±rasÄ±yla 0.2, 0.5, 0.1 ve 0.2 olsun. Bu durumda kareler toplamÄ±mÄ±z yalnÄ±zca 0.34 edecektir. 3. ÅŸÄ±kkÄ±n doÄŸru olmasÄ±nÄ±n mantÄ±ÄŸÄ± da budur.1 month ago 4 people like this.Like ReportReply",
    "-> Merhaba,Soruda bir modelimiz ve bu modelimizde birbirine karakteristik olarak benzeyen, korelasyonlu ama birinin kÃ¼Ã§Ã¼k miktarda rastgele noise iÃ§erdiÄŸi feature'Ä±mÄ±z olduÄŸunu sÃ¶ylemiÅŸ. EÄŸer bu modeli L2 regulazosyonu ile eÄŸitrsek bu iki feature'In weight deÄŸerleri ne olur demiÅŸ.1.ÅŸÄ±k iÃ§in: Bir feature bÃ¼yÃ¼k weight deÄŸerine sahip olurken diÄŸer feature'In weight'Ä° 0 olur demiÅŸ. Bu ÅŸu yÃ¼zden yanlÄ±ÅŸtÄ±r:L2 regularizasyonumuz aÄŸÄ±rlÄ±klarÄ± neredeyse 0'a yakÄ±nsamaya zorlar. Bu yÃ¼zden diÄŸer weight 0 olmaycakaÄŸÄ±ndan bu cevap elendi.2.ÅŸÄ±k iÃ§in: l2 regularizasyonumuz bÃ¼yÃ¼k weightleri kÃ¼Ã§Ã¼k weightlere gÃ¶re daha Ã§ok cezalandÄ±rÄ±r ve 0'a yakÄ±nsatÄ±r. ( http://community.globalaihub.com/community/status/1191-1191-1587125026/#comment.4315.4196.4196 ) linkindeki yorumumdaki resimde gradient descent formÃ¼lÃ¼ne bakarsanÄ±z thetaj ne kadar bÃ¼yÃ¼k olursa dÃ¼ÅŸÃ¼ÅŸÃ¼ o kadar fazla olur. (1-alpha rate*(lambda/m)) theta j ile Ã§arpÄ±lÄ±r thetaj ne kadar bÃ¼yÃ¼kse kÃ¼Ã§Ã¼lme o kadar fazla olur. Bu yÃ¼zden kÃ¼Ã§Ã¼k weight deÄŸerleriyle bÃ¼yÃ¼k weight deÄŸerlerinin sÄ±fÄ±ra yakÄ±nsadÄ±klarÄ± deÄŸerler arasÄ±nda uÃ§urum olmaz.3.ÅŸÄ±k iÃ§in: Bu sorunun cevabÄ±nÄ± 2.ÅŸÄ±kta verdim. BÃ¼yÃ¼k weight deÄŸerleri kÃ¼Ã§Ã¼k weight deÄŸerlerine gÃ¶re daha Ã§ok ezalandÄ±rÄ±lacaÄŸÄ± iÃ§in 0'a yakÄ±nsadÄ±klarÄ± deÄŸer aynÄ± olacak birbirine fazlasÄ±yla yakÄ±ndÄ±r.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 6 people like this.Like ReportReply",
    "->  Åimdi kavramlar net oldu bende arkadaÅŸlar Ã§ok teÅŸekkÃ¼rler ->  -> 1 month ago 2 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "->  uploaded 1 photo",
"quest": "Bu denklemdeki log(x) in amacÄ± nedir yani iÃ§indeki deÄŸiÅŸkene ne yaptÄ±ÄŸÄ± iÃ§in Ã§ok fazla kullanÄ±yorlar. EÄŸer logaritmayla alakalÄ± bi ÅŸeyse logaritmanÄ±n machine learningdeki iÅŸlevinide kÄ±saca aÃ§Ä±klayabilir misiniz?. TeÅŸekkÃ¼rler.",
"comment": [
    "",
    "->  Merhaba,Burada log kullanmamÄ±zÄ±n sebebini aÅŸaÄŸÄ±daki resimdeki log loss fonksiyonlarÄ±mÄ±zÄ±n grafikte gÃ¶steriminden gÃ¶rebiliriz. Resmimizde kÄ±rmÄ±zÄ± ile altÄ±nÄ± Ã§izdiÄŸim kÄ±smÄ± alÄ±rsak y=1 ve y=0 iken neden cost function farklÄ±lÄ±ÄŸÄ± olduÄŸunu gÃ¶rebilriz. Lojistik regresyonda amacÄ±mÄ±z 1 ve 0 arasÄ± bir olasÄ±lÄ±k elde etmek olduÄŸu iÃ§in cost function'Ä±mÄ±zda da 0-1 arasÄ±ndaki logaritmik bir doÄŸru elde etmeliyiz.(0-1 Ã§Ã¼nkÃ¼ sigmoid fonksiyonumuz y ekseninde 0-1 arasÄ±nda ). Lojistik regresyonda y=1 iÃ§in sonucu iÃ§in h(x) sonucumuzun da 1 olmasÄ±nÄ± bekleriz yani tahmini doÄŸru gerÃ§ekleÅŸtirmesini bekleriz, eÄŸer h(x) 0 olursa costumuz -sonsuza yaklaÅŸÄ±r yani costumuz oldukÃ§a artar. Lojisik regresyon problemlerimizi lineer regresyonla Ã§Ã¶zemeyeceÄŸimiz iÃ§in farklÄ± bir yaklaÅŸÄ±m sergilememiz gerekti. AklÄ±nÄ±za takÄ±lan bir ÅŸey olursa sormaktan Ã§ekinmeyin.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 5 people like this.Like ReportReply",
    "->  ->  Merhaba, Niye squared loss oldugunu anlamadim.",
    "->  ->  Merhaba,Squared loss derken nereyi kastettiniz? Sorunuzu tam anlayamadÄ±m. Loss function'da 0-1 arasÄ± bir Ã§Ä±ktÄ± Ã¼reteceÄŸimiz iÃ§in log kullanÄ±yoruz..",
    "-> Modelin tahmin etmesini istediÄŸimiz deÄŸerler 0 ve 1 olduÄŸu iÃ§in log loss kullanÄ±yoruz.Ã–rneÄŸin, bir input iÃ§in beklenen output 0 ise ve model 1 tahmininde bulunduysa, log loss'un bÃ¼yÃ¼k bir deÄŸer Ã¼retmesini bekliyoruz. (model kÃ¶tÃ¼ bir tahminde bulunmuÅŸ.)Bir input iÃ§in beklenen output 0 ise ve model 0 tahmininde bulunduysa, log loss'un kÃ¼Ã§Ã¼k bir deÄŸer Ã¼retmesini bekliyoruz. (model iyi bir tahminde bulunmuÅŸ.)Benzer ÅŸekilde, beklenen output 1 ise ve model 0.8 tahminini yaptÄ±ysa, log loss nispeten kÃ¼Ã§Ã¼k olacak ancak 1 tahmininde bulunsaydÄ± log loss daha da kÃ¼Ã§Ã¼k olacaktÄ±.1 month ago 7 people like this.Like ReportReply",
    "-> Bunun ana temelini merak ediyorsan matematiksel olarak aynÄ± sonuca Ã§Ä±kmalarÄ±. Olay kÄ±saca ÅŸuModelinin tahmin ettiÄŸi deÄŸerlerin doÄŸruluÄŸunu Ã¶lÃ§men iÃ§in ÅŸÃ¶yle bir Ã¶rnek vereyimElinde kÄ±rmÄ±zÄ± ve mavi noktalar var. Bu noktalarÄ± bulunan bir dikdÃ¶rtgende mavi ve kÄ±rmÄ±zÄ± noktalara yerleÅŸtirmesini istiyorsun. Yani kÄ±z ve erkek var diyelim kÄ±zlarÄ± kÄ±zlarla gruplandÄ±rmak erkekleri erkeklerle gruplandÄ±rmak istiyorsun veya.Model 1 ve Model 2 aÅŸaÄŸÄ±da ki gibi tahminler Ã¼retiyor.( Tahmini Ã‡izgi olarak dÃ¼ÅŸÃ¼n kÄ±rmÄ±zÄ± ve mavi alanÄ± ayÄ±ran)Buna gÃ¶re kÄ±rmÄ±zÄ± noktalarÄ±n gerÃ§ekten kÄ±rmÄ±zÄ±da olma olasÄ±lÄ±ÄŸÄ± ve mavi noktalarÄ±n doÄŸru yerde olma olasÄ±klarÄ± verilmiÅŸ. Bu modelin doÄŸruluÄŸunu anlamak iÃ§in tÃ¼m olasÄ±lÄ±klarÄ± Ã§arpman ve Ã§Ä±kan sayÄ±ya bakman lazÄ±m. Ã–rneÄŸin saÄŸda ki modelde kÄ±rmÄ±zÄ± iki nokta iÃ§in kÄ±rmÄ±zÄ± alanda olma olasÄ±lklarÄ± , ve mavi noktalarÄ±n mavi alanda olma olasÄ±lÄ±klarÄ± verilmiÅŸ ( Bu model Ã§Ä±ktÄ±larÄ± olasÄ±lÄ±klarÄ±)Burda gÃ¶rdÃ¼ÄŸÃ¼n Ã¼zere daha dÃ¼zgÃ¼n modelde bu Ã§arpÄ±m daha yÃ¼ksek Ã§Ä±kÄ±yor , daha kÃ¶tÃ¼ tahmin eden modelde daha dÃ¼ÅŸÃ¼k. Eee hala niye log yapÄ±yoruz dersen olay ÅŸu ki burda 4 tane Ã¶rneÄŸimiz var ve bu Ã¶rnek normal bir model kat kat fazla ve bu Ã§arpÄ±m iÅŸlemi bilgisayarÄ± / iÅŸlem gÃ¼cÃ¼nÃ¼ gereksiz yorar. Bunun yerine matematiksel olarak aynÄ± iÅŸlemi veren log yapÄ±yoruz. Ã‡arpÄ±m iÅŸleriminin logunu alÄ±nca toplama iÅŸlemi olur ( Lise matematiÄŸi ğŸ™‚ ) ve bu iÅŸlemi Ã§arpmadan loga Ã§evirdiÄŸimizde logloss ve crossentropy loss gibi kavramlar ortaya Ã§Ä±kÄ±yor (cross entropide log loss'un binary classification dÄ±ÅŸÄ±nda kullanmak iÃ§in) Tabi olasÄ±lÄ±klar 1 ile 0 arasÄ±nda olduÄŸu iÃ§in bunlarÄ±n loglarÄ± - sayÄ±lar olucak malum log 1 = 0 log 0 = tanÄ±msÄ±z , log 1 ile log 0 arasÄ±nda ki deÄŸerler negatif deÄŸerler. Åimdi olasÄ±lÄ±klarÄ±n logunu alÄ±unca misal log(0.8) ( bunlar 10 tabanÄ±nda veya 2 tabanÄ±nda farketmiyor Ã§ok ben 10 diye dÃ¼ÅŸÃ¼nÃ¼yorum ÅŸuan)log (0.8) = -0.096log ( 0.2) = -0.69gÃ¶rdÃ¼ÄŸÃ¼n Ã¼zere sayÄ± deÄŸeri dÃ¼ÅŸÃ¼k olan log , gene daha kÃ¼Ã§Ã¼k Ã§Ä±kÄ±yor ( negatif sayÄ±larda - (sayÄ± bÃ¼yÃ¼dÃ¼kÃ§e - sonsuza yaklaÅŸÄ±r )bu sebeple bunlarÄ±n Ã§Ä±ktÄ±larÄ±nÄ± direk karÅŸÄ±laÅŸtÄ±rÄ±rmak zor oluyor negatiflerini alÄ±yoruz ve log'un negatifliÄŸinden kurtuluyoruz. Burdan da toplama yapÄ±lÄ±nca daha demin gÃ¶sterdiÄŸim Ã§arpma iÅŸleminin benzeri olayla Log sayÄ±larÄ±nÄ±n negatif alÄ±nmÄ±ÅŸ toplamÄ± bÃ¼yÃ¼k olanlar yÃ¼ksek Ã§Ä±kÄ±yor buda kÃ¶tÃ¼ demek yani . Misal log0.2 negatifi alÄ±nca 0.69 , bu tarz kÃ¶tÃ¼ tahminler sayÄ±yÄ± yÃ¼kseltip yÃ¼ksek bir loss yani fazla hata olmuÅŸ oluyorBiraz uzun oldu ama ğŸ™‚1 month ago 3 people like this.Like ReportReply",
    "-> .",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar :)  ML Crash Course 2. hafta ara sÄ±navÄ±na aÅŸaÄŸÄ±daki linkten ulaÅŸabilirsiniz. GeÃ§en haftaki kurallar geÃ§erlidir; bu akÅŸam 22:00'ye kadar sÄ±navÄ± tamamlayabilirsiniz.  22:00'den sonra gelen yanÄ±tlar deÄŸerlendirmeye alÄ±nmayacaktÄ±r.  ????????https://forms.gle/E6NrS8f4ZDG8hcBH7  BaÅŸarÄ±lar ????????",
"comment": [
    "",
    "->  Bu hafta puanlar daha sonra aÃ§Ä±klanacak anladÄ±ÄŸÄ±m Ã¼zere, doÄŸru mu?.",
    "->  Merhabalar, Kac puan aldigimizi ne zaman ogrenebilecegiz? Gecen sinavda anlik gostermisti..",
    "->  ->  SÄ±nav sÃ¼resi bittikten sonra liste olarak paylaÅŸacaÄŸÄ±m sizlerle ğŸ™‚1 month ago 10 people like this.Like ReportReply",
    "->  ->  Merhaba, sonuclari email olarak mi paylasacaktiniz? Henuz bana bir email gelmedi de.Tesekkurler..",
    "->  Ant Bitirdim . Gelecek hafta daha fazla konu var bence biraz erken baÅŸlayÄ±n Ã§alÄ±ÅŸmaya . Herkese baÅŸarÄ±lar ..",
    "->  Bitirdim, gÃ¼zeldi. BirkaÃ§ soru aklÄ±ma takÄ±ldÄ±..",
    "->  Herkese merhaba arkadaÅŸlar, bende bitirdim sÄ±navÄ±. BaÅŸarÄ±lar...",
    " ->  GeÃ§en hafta kaÃ§ puan aldÄ±ÄŸÄ±mÄ±z yazÄ±yordu ancak bunda yoktu sanÄ±rÄ±m gÃ¶remedim.",
    "->  ???? Bitirdim. Herkese baÅŸarÄ±lar..",
    "->  Merhaba,SÄ±navdan ÅŸimdi Ã§Ä±ktÄ±m sorular gerÃ§ekten Ã§ok gÃ¼zel ve tamamen iÅŸin mantÄ±ÄŸÄ±nÄ± anlayÄ±p anlamadÄ±ÄŸÄ±mÄ±zÄ± Ã¶lÃ§Ã¼yordu. SonuÃ§larÄ± bekliyor olacaÄŸÄ±z, herkese baÅŸarÄ±lar ğŸ™‚.",
    "->  Ã‡ok teÅŸekkÃ¼rler,tÃ¼m arkadaÅŸlara baÅŸarÄ±lar..",
    "->  SonuÃ§lar ne zaman aÃ§Ä±klanÄ±r?.",
    "-> Sorulara baktÄ±ÄŸÄ±mÄ±z zaman eksiklerimizi gÃ¶rmek aÃ§Ä±sÄ±ndan Ã§ok faydalanÄ±yoruz. DÃ¼ÅŸÃ¼nen, Ã¼reten ve yardÄ±m eden herkese Ã§ok teÅŸekkÃ¼r ederiz. SÄ±navÄ± ÅŸimdi bitirdim. SonuclarÄ± bekliyor olacaÄŸÄ±m ğŸ™‚.",
    " ->  ben de ÅŸimdi tamamladÄ±m sÄ±navÄ±, sonuÃ§larÄ± merakla bekliyorum. emekleriniz iÃ§in teÅŸekkÃ¼rler ğŸ™‚.",
    "->  Ã‡alÄ±ÅŸtÄ±klarÄ±mÄ±zÄ± test etmek ve eksikliklerimizi gÃ¶rmek aÃ§Ä±sÄ±ndan bu sÄ±navlar Ã§ok verimli oluyor, emeÄŸi geÃ§en herkese teÅŸekkÃ¼rler..",
    " ->  SÄ±navÄ± ÅŸimdi tamamladÄ±m, mantÄ±ÄŸÄ± kavrayÄ±p kavrayamadÄ±ÄŸÄ±mÄ±zÄ± Ã¶lÃ§en ve eksiklerimizi gÃ¶steren gÃ¼zel bir sÄ±nav olmuÅŸ. SonuÃ§larÄ± merakla bekliyorum, herkese teÅŸekkÃ¼rler..",
    "->  Ben de tamamladÄ±m sÄ±navÄ±. Gireceklere baÅŸarÄ±lar. Emekleriniz iÃ§in Ã§ok teÅŸekkÃ¼rler. Sonucu merakla bekliyorum..",
    " ->  SÄ±navÄ± tamamladÄ±m. SÄ±navÄ±n ÅŸÄ±klarÄ± net ve anlaÅŸÄ±lÄ±rdÄ± ve bu haftaki konulara Ã§alÄ±ÅŸÄ±rken geÃ§en haftaya gÃ¶re daha Ã§ok keyif aldÄ±m. EmeÄŸi geÃ§en herkese ve anlamadÄ±ÄŸÄ±m kÄ±sÄ±mlarda yardÄ±mcÄ± olan ->  'e ayrÄ±ca teÅŸekkÃ¼r ederim. Ä°yi Ã§alÄ±ÅŸmalar..",
    "->   -> AsÄ±l ben teÅŸekkÃ¼r ederim ğŸ™‚ Bildiklerimi ve Ã¶ÄŸrendiklerimi burada paylaÅŸÄ±p sizlere yardÄ±mcÄ± olabilmek beni Ã§ok mutlu ediyor Ã§Ã¼nkÃ¼ bilgi paylaÅŸtÄ±kÃ§a deÄŸerlidir. GÃ¼zel ve verimli bir pazar gÃ¼nÃ¼ diliyorum. Ä°yi Ã§alÄ±ÅŸmalar ğŸ™‚1 month ago 4 people like this.Like ReportReply",
    "->  Merhaba sÄ±navÄ± tamamladÄ±m ancak formu ilk kez gÃ¶nderiÅŸimde form gÃ¶nderildi yazÄ±sÄ± Ã§Ä±ktÄ± sonra bir anda sayfada hata verdi emin olamadÄ±ÄŸÄ±m iÃ§in tekrar iÅŸaretleyip gÃ¶nderdim. AynÄ± cevaplar var ikisinde de ama formu ilkinde gÃ¶nderip gÃ¶ndermediÄŸimden hala emin deÄŸilim..",
    "->  Yine gÃ¼zel bir quiz olmuÅŸ, teÅŸekkÃ¼r ederim.",
    "->  Herkese merhaba, ben de sÄ±navÄ±mÄ± tamamladÄ±m. Sorular gayet gÃ¼zel ve eksik yanlarÄ±mÄ±zÄ± yansÄ±tacak nitelikte olmuÅŸ. Ã‡Ã¶zÃ¼mleri merakla bekliyorum ğŸ™‚ Ã–nÃ¼mÃ¼zdeki hafta konularÄ±mÄ±z biraz aÄŸÄ±r ve yoÄŸun olacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼m iÃ§in erken Ã§alÄ±ÅŸmaya baÅŸlamak lazÄ±m diye dÃ¼ÅŸÃ¼nÃ¼yorum, AyrÄ±ca Ã¶zellikle haftaya olan sÄ±navÄ±n soru sayÄ±sÄ± artarsa hatalarÄ±mÄ±zÄ± ve eksiklerimizi daha iyi gÃ¶rebiliriz diye dÃ¼ÅŸÃ¼nÃ¼yorum. Malum Ã¶ÄŸrenme yaptÄ±ktan sonraki test setteki veriyi arttÄ±rmak elde edeceÄŸimiz sonuca olan gÃ¼veni de arttÄ±racaktÄ±r ğŸ˜€ Herkese teÅŸekkÃ¼rler..",
    "->  Åimdi sÄ±navÄ± bitirdim ve sorular gerÃ§ekten iyiydi ve eksiklerimi gÃ¶rmÃ¼ÅŸ oldum teÅŸekkÃ¼r ederim..",
    "->  Bir soru hala kafamÄ± kurcalÄ±yor cevaplar ve aÃ§Ä±klamalarÄ± sabÄ±rsÄ±zlÄ±kla bekliyorum. herkese baÅŸarÄ±lar..",
    "-> -> SÄ±navÄ± yolladÄ±m, Ã¶nceki sÄ±navda puanÄ±mÄ±zÄ± gÃ¶nderdikten sonra gÃ¶rmÃ¼ÅŸtÃ¼k bu hafta sistem deÄŸiÅŸti sanÄ±rÄ±m. Herkese baÅŸarÄ±lar.",
    "-> SÄ±navÄ± ben de tamamladÄ±m. Sorular gayet kaliteli ve iÅŸin mantÄ±ÄŸÄ±na dair sorulardÄ±..",
    " ->  SÄ±nav Ã§ok gÃ¼zeldi eksiklerimi gÃ¶rme fÄ±rsatÄ±m oldu biraz onlarÄ±n Ã¼stÃ¼ne Ã§alÄ±ÅŸmam gerektiÄŸini anladÄ±m teÅŸekkÃ¼rler..",
    "->  merhabalar, ikinci hafta da cok gÃ¼zel geÃ§ti. sorularÄ± cevaplarken zorlanmÄ±yorum ama anlamamÄ±ÅŸÄ±m gibi hissediyorum.sanÄ±rÄ±m konular arasÄ±nda baÄŸlantÄ± kurmakta zorlanÄ±yorum. emekleriniz iÃ§in teÅŸekkÃ¼rler ğŸ™‚1 month ago 2 people like this.Like ReportReply",
    "->  SÄ±navÄ± tamamladÄ±m. Herkese iyi eÄŸlenceler, baÅŸarÄ±lar..",
    "-> Merhabalar arkadaÅŸlar gecen hafta sorularÄ± cozdukte den sonra dogru cevaplarÄ± vermiÅŸti. 2 hafta formunda cevaplarÄ± vermedimi yoksa ben mi birsey atladÄ±m.",
    "-> Merhaba, sinavi yapip gonderdim. Ancak puan gosterilmedi. Sonuclari eposta ile mi duyuracaksiniz?1 month ago 4 people like this.Like ReportReply",
    "->  SÄ±navÄ± tamamladÄ±m. Emekleriniz iÃ§in teÅŸekkÃ¼rler..",
    "->  GÃ¼zel ve Ã¶ÄŸrenme odaklÄ± sorular vardÄ±..",
    "->  SÄ±navÄ± ÅŸimdi tamamladÄ±m. Emeklerinize saÄŸlÄ±k Ã§ok verimli oluyor ğŸ™‚.",
    "->  Dikkat gerektirici bir sÄ±nav oldu. EmeÄŸi geÃ§en herkese teÅŸekkÃ¼r ederim. UmarÄ±m bu sÄ±navda da gÃ¼zel bir sonuÃ§ ile karÅŸÄ±laÅŸÄ±rÄ±m â˜ºï¸.",
    "->  SÄ±nav gÃ¼zeldi teÅŸekkÃ¼rler. Herkesin sonuÃ§larÄ±nÄ± aÃ§Ä±klayacak olmanÄ±z durum analizi iÃ§in daha gÃ¼zel olacaktÄ±r bÃ¶yle bir karar vermeniz gÃ¼zel oldu..",
    "->  Ã¼nlÃ¼ Merhaba ben de gÃ¶nderdim, bu hafta sonuÃ§larÄ± gÃ¶remiyor muyuz?.",
    "->  Merhaba Engin Bey, bende de cevaplar gÃ¶zÃ¼kmedi..",
    " ->  SÄ±navÄ± ÅŸimdi tamamladÄ±m. Sorular Ã§ok gÃ¼zeldi. Emeklerinize saÄŸlÄ±k..",
    "->  SÄ±navÄ± az Ã¶nce tamamladÄ±m. KararsÄ±z kaldÄ±ÄŸÄ±m sorular oldu. Ã‡Ã¶zÃ¼mleri merakla bekliyorum. Emek veren herkese teÅŸekkÃ¼rler..",
    "->  SÄ±navÄ± yeni tamamladÄ±m. BaÅŸarÄ± ile tamamladÄ±ÄŸÄ±mÄ± dÃ¼ÅŸÃ¼nÃ¼yorum. AyrÄ±ca sÄ±navlarÄ±n bizlere nerelere daha Ã§ok odaklanmamÄ±z gerektiÄŸini iÅŸaret ettiÄŸini dÃ¼ÅŸÃ¼nÃ¼yorum. Sonucun hemen aÃ§Ä±klanmamasÄ± da ayrÄ± bir heyecan kattÄ±. EmeÄŸi geÃ§en herkese teÅŸekkÃ¼r ederim..",
    "-> SÄ±navÄ± tamamladÄ±m. SonuÃ§larÄ± ve Ã§Ã¶zÃ¼mleri sabÄ±rsÄ±zlÄ±kla bekliyorum. Sorular konularÄ±n mantÄ±ÄŸÄ±nÄ± kavramayÄ± Ã¶lÃ§mesi aÃ§Ä±sÄ±ndan Ã§ok baÅŸarÄ±lÄ± olmuÅŸ, emeÄŸi geÃ§en herkese teÅŸekkÃ¼rler. BÃ¶ylesi bilgi dolu ve Ã¶ÄŸrenmenin keyif verdiÄŸi bir platformu bize kazandÄ±rdÄ±ÄŸÄ±nÄ±z iÃ§in de ayrÄ±ca teÅŸekkÃ¼r ederim..",
    "->  SÄ±navÄ± tamamladÄ±m ve gÃ¶nderdim ancak gÃ¶nderildi iletisini gÃ¶remedim, baÄŸlantÄ±da bir hata oldu sanÄ±rÄ±m, size ulaÅŸtÄ± mÄ±? OlmadÄ± tekrar yapayÄ±m? A-> .",
    "->  ->  Bize iletilmiÅŸ ğŸ˜‰.",
    "->  ->  TeÅŸekkÃ¼r ederim ğŸ™‚.",
    "->  Merhabalar sÄ±navÄ± az Ã¶nce tamamladÄ±m.GÃ¼zel sÄ±navdÄ±.EmeÄŸiniz ve ilginiz iÃ§in teÅŸekkÃ¼rler.",
    "->  SÄ±navÄ± az Ã¶nce tamamladÄ±m. BirkaÃ§ soruda zorlansam da sorularÄ± faydalÄ± buldum. Ã‡Ã¶zÃ¼mlerin ve puanlarÄ±mÄ±zÄ±n yayÄ±nlanmasÄ±nÄ± heyecanla bekliyorum. Emekleriniz iÃ§in Ã§ok teÅŸekkÃ¼rler, oldukÃ§a verimli bir program oluyor ğŸ™‚.",
    "->  SÄ±navÄ± tamamlayÄ±p gÃ¶nderirken internet baÄŸlantÄ±m sorunluydu,aynÄ± yanÄ±tlarla yeniden gÃ¶ndermeye Ã§alÄ±ÅŸtÄ±m umarÄ±m sorun olmaz .EmeÄŸi geÃ§en herkesin emeklerine saÄŸlÄ±k..",
    "->  Selamlar, sonuÃ§lar ne zaman aÃ§Ä±klanÄ±r?:).",
    "->  ->  SÄ±nav zamanÄ± birazdan sona erecek, akabinde iletmiÅŸ olurum sizlere.1 month ago 2 people like this.Like ReportReply",
    "->  Ä°nce ->  Ã–zÃ¼r dileyerek, sÄ±nav sonuÃ§larÄ± iletildi mi yoksa yarÄ±n mÄ± aÃ§Ä±klanacak mailimde de community postda da bir sonuÃ§ ulaÅŸmadÄ± henÃ¼z ?.",
    "->  ->  Ã‡ok teÅŸekkÃ¼rler.",
    " ->  Q1 (logistic regression) sorusunu yanlÄ±ÅŸ yaptÄ±m galiba, 2. defa yollayabiliyor muyuz?.",
    "->   ->  Ne yazÄ±k ki, ilk gÃ¶nderdiÄŸinizi deÄŸerlendirmeye alÄ±yoruz, gÃ¶nderim saatleriniz kayÄ±tlÄ± oluyor..",
    "->  Selamlar, testi bitirdim, geÃ§en haftaki test sonucum gayet iyiydi lakin bir iki sorunun dili biraz karmaÅŸÄ±ktÄ± ancak bugÃ¼nkÃ¼ test gayet netti, umarÄ±m bunda hatasÄ±z bir skor alÄ±rÄ±m sonucumu bekliyorum, emeÄŸinize saÄŸlÄ±k, teÅŸekkÃ¼rler..",
    "->  Merhaba,sÄ±navÄ±mÄ± tamamladÄ±m.EmeÄŸiniz iÃ§in gerÃ§ekten Ã§ok teÅŸekkÃ¼r ederiz.OldukÃ§a faydalÄ± bir kurs ğŸ™‚.",
    "->  SÄ±navÄ± az Ã¶nce tamamladÄ±m. Sorular gÃ¼zeldi. SonuÃ§larÄ±n aÃ§Ä±klanmasÄ±nÄ± bekliyorum. ğŸ™‚.",
    "->  SÄ±navlar pekiÅŸtirmek iÃ§in Ã§ok faydalÄ± oluyor. Herkese teÅŸekkÃ¼rler..",
    "->  Sorular sayesinde eksik kalan yer varsa direk gÃ¶rebiliyoruz teÅŸekkÃ¼rler,.",
    "-> Merhaba ben sÄ±nav sonucumu gÃ¶remedim bu sefer neden acaba.",
    "->  -> SonuÃ§larÄ± en son paylaÅŸacaÄŸÄ±z liste olarak..",
    "->  Bu haftaki sÄ±navÄ±n da sonuna geldik, bu sÄ±navda kendimden Ã§ok daha emin bir ÅŸekilde cevapladÄ±m sorularÄ±. UmarÄ±m iyi bir not almÄ±ÅŸÄ±mdÄ±r. Herkese baÅŸarÄ±lar. ğŸ™‚.",
    "-> TeÅŸekkÃ¼rler gayet gÃ¼zel bir sÄ±navdÄ± ????.",
    "->  Sorular bilgi Ã¶lÃ§Ã¼cÃ¼ ve netti. BazÄ±larÄ±nÄ± dikkat Ã¶lÃ§Ã¼yodu. Bu sefer dikkatli bir ÅŸekilde Ã§Ã¶zdÃ¼m. Herkese baÅŸarÄ±lar, sÄ±nav iÃ§in teÅŸekkÃ¼rler ????????.",
    " ->  SorularÄ± hazÄ±rlayanlarÄ±n emeÄŸine saÄŸlÄ±k. Yine dÃ¼ÅŸÃ¼nmeye teÅŸvik eden bir sÄ±navdÄ±. Ã–ÄŸrendiklerimizi iyice kavramamÄ±zÄ± saÄŸladÄ±. ğŸ™‚.",
    "->  Ã–nceki hafta cevaplarÄ± gÃ¶nderdikten sonra puanÄ±mÄ±zÄ± otomatik olarak hesaplamÄ±ÅŸtÄ±. Åimdi gÃ¶remedim puanÄ±mÄ±. Bilgisi olan var mÄ± ?.",
    "->  ->  SÄ±nav sonunda liste olarak ileteceÄŸiz sonuÃ§larÄ±nÄ±zÄ±..",
    "->  ->  SÄ±nav bitmedi mi hocam? Ne zaman aÃ§Ä±klanacak acaba?.",
    "->  sÄ±nav gÃ¼zeldi , Ã¶zellikle bazÄ± konularÄ± tam anlamÄ±yla anlamadÄ±ÄŸÄ±mÄ± farkettim..",
    "->  SÄ±nav keyifli geÃ§ti, ilginiz iÃ§in teÅŸekkÃ¼r ederim ğŸ™‚.",
    "->  ÅŸÃ¼kÃ¼r sÄ±navÄ± ÅŸuan bitirip gÃ¶nderdim ğŸ™‚.",
    "->  SÄ±navlar sayesinde konular cok daha iyi pekiÅŸiyor. Tamamen mantÄ±ÄŸa dayalÄ± olmasÄ± benim gibi yeni baÅŸlayanlar iÃ§in Ã§ok faydalÄ± oluyor. EmeÄŸinize saÄŸlÄ±k..",
    "->  TeÅŸekkÃ¼rler ->  gerÃ§ekten Ã§ok Ã¶ÄŸretici olmuÅŸ sorular ğŸ™‚.",
    "->  Yine Ã§ok gÃ¼zel ve kapsamlÄ± bir sÄ±navdÄ± , eksiklikleri gÃ¶rmek iÃ§in gÃ¼zel bir fÄ±rsat. TeÅŸekkÃ¼rler ->  ve herkese..",
    "->  Bizi dÃ¼ÅŸÃ¼ndÃ¼rmeye sevk eden, Ã¶ÄŸrendiklerimizi pekiÅŸtirme fÄ±rsatÄ± veren deÄŸerli bir sÄ±navdÄ±. EmeÄŸinize saÄŸlÄ±k..",
    "->  SÄ±nav Ã§ok Ã¶ÄŸretici ve konularÄ±n Ã¼stÃ¼nden gÃ¼zel geÃ§ilmiÅŸ olmayÄ± gerektiriyordu emeÄŸinize saÄŸlÄ±k. Ancak sonucumu sÄ±nav bitiminde Ã¶ÄŸrenemedim deÄŸerlendirme sonrasÄ± mÄ± Ã¶ÄŸreneceÄŸiz? Sanki geÃ§en hafta sÄ±navdan hemen sonra gÃ¶rmÃ¼ÅŸtÃ¼k puanÄ±mÄ±zÄ±1 month ago 11 people like this.Like ReportReply",
    "->  SonuÃ§lar aÃ§Ä±klandÄ± mÄ± acaba?.",
    " ->  ->  Zannediyorum sorularÄ±n Ã§Ã¶zÃ¼mleriyle beraber aÃ§Ä±klayacaklar. O yÃ¼zden gecikmiÅŸ olabilir.",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Quiz gayet gÃ¼zel ve seviyeli olmuÅŸ kod kÄ±smÄ±ndan ziyade mantÄ±k odaklÄ± olmuÅŸ ki iÅŸin en Ã¶nemli kÄ±smÄ± olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yorum. KodlarÄ±n arkadÄ±nda neler olduÄŸunu anlamak iÃ§in makine Ã¶ÄŸrenmesini matematiÄŸini anlamak adÄ±na YouTube da Ä°lker Birbil HocanÄ±n \"Makine Ã–ÄŸrenmesi\" dersleri var. Ã‡ok fayalÄ± olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yorum. Linkini burdan paylaÅŸÄ±yorum \"Google Machine Learning Crash Course\" beraber takip ederseniz Ã§ok faydalÄ± olacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum. Herkese iyi Ã§alÄ±ÅŸmalar diliyorum.  <a class=\"ps-media-link\" href=\"https://www.youtube.com/watch?v=eKrnMr--bDY&amp;list=PLZcbvMjrj9DVU6g2A5e6voeigUtSMsAJH\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">https://www.youtube.com/watch?v=eKrnMr--bDY&amp;list=PLZcbvMjrj9DVU6g2A5e6voeigUtSMsAJH</a>",
"comment": [
    "",
    "->  Ã§ok teÅŸekkÃ¼rler, Ã§ok gÃ¼zel bir iÃ§erik..",
    "->  ->  iyi Ã§alÄ±ÅŸmalar.",
    "->  Kaynak iÃ§in teÅŸekkÃ¼r ederim, Ã§ok yararlÄ± bir paylaÅŸÄ±m olmuÅŸ..",
    "->  ->  iyi Ã§alÄ±ÅŸmalar.",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar. Lojistik regresyonda  regularization un extrem Ã¶nemli olduÄŸu sÃ¶ylenmiÅŸ fakat Ã¶nemini kavrayamadÄ±m. \"Without regularization, the asymptotic nature of logistic regression would keep driving loss towards 0 in high dimensions. \" Åu cÃ¼mleyi matematiksel olarak aÃ§Ä±klayabilir misiniz?",
"comment": [
    "",
    "->  Merhaba,Lojistik regresyonda hipotez fonksiyonumuz lineer deÄŸil sigmoid bir fonksiyon olur. (Resimde gÃ¶rebilirsiniz.) Asimptode fonksiyon olan sigmoid fonksiyonumuz 1 ve 0'a yakÄ±nsayarak x ekseni boyunca sonsuza gider. Burada doÄŸasÄ± gereÄŸi yÃ¼ksek boyutlarda 0'a yaklaÅŸmaya devam eder dediÄŸi budur. YÃ¼ksek boyut dediÄŸi fazla feature olmasÄ±dÄ±r ve fazla feature demek weight deÄŸerlerinin fazla ve komplikeye yakÄ±n olmasÄ± demek. RegÃ¼larizasyonun weight deÄŸerlerini azalttÄ±ÄŸÄ±nÄ± biliyoruz bu yÃ¼zden kritik bir Ã¶neme sahiptir. http://community.globalaihub.com/community/status/1191-1191-1587125026/#comment.4315.4196.4196 linkindeki gradient descent fonksiyonu lojistik regresyon iÃ§in de geÃ§erlidir YalnÄ±z tek fark hipotez fonksiyonumuz artÄ±k 1/1+e^(-thetatranspose*X vector) yani sigmoid fonksiyonumuzdur.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 5 people like this.Like ReportReply",
    "->  ->  TeÅŸekkÃ¼r ederim. Ben yÃ¼ksek boyuttan 2 ve daha fazla featurelÄ± datalar yani uzayda Ã§ok boyutlu vektÃ¶rler oluÅŸturan datalar olduÄŸunu anlamÄ±ÅŸtÄ±m.",
    "->  ->  Merhaba,AslÄ±nda orada demek istediÄŸim adet olarak yÃ¼ksek weight deÄŸerleriydi ama yanlÄ±ÅŸ anlaÅŸÄ±lmaya mahal vermemek iÃ§in dÃ¼zelttim. DÃ¼zeltme iÃ§in teÅŸekkÃ¼r ederim. YÃ¼ksek boyu tdediÄŸimiz fazla feature deÄŸerimiz buna baÄŸlÄ± olarak fazla ve yÃ¼ksek sayÄ±da weight deÄŸerlerimizin olmasÄ±dÄ±r..",
    "-> ->  high dimensions durumunda loss'un 0'a gitmesini engellemek icin regularization yapilmasinin onemli oldugu belirtiliyor. Training'in amaci loss'u minimize etmek iken (normalde loss'un 0'a yaklasmasini isterken), burada loss'un kontrolsuzce 0'a gitmesini istemiyoruz, cunku bu senaryoda loss 0'a giderken ogrenme yapilamiyor, diyebilir miyiz?.",
    "->  -> Regularizasyon bizim modelimizin basitlik ile karmaÅŸÄ±klÄ±ÄŸÄ± arasÄ±ndaki dengeyi saÄŸlamalÄ±dÄ±r. Loss 0'a giderken Ã¶ÄŸrenme yapÄ±lÄ±rken overfit olur ve modelimiz eÄŸitim setini ezberler bÃ¶ylece artÄ±k test loss'umuz artmaya baÅŸlar.Ä°yi Ã§alÄ±ÅŸmalar..",
    " "
]
},
{
"question_isim": "-> uploaded 1 photo",
"quest": "Regularization for Simplicity: Playground Exercise (L2 Regularization)'da bu sonuca nasÄ±l vardÄ±k?",
"comment": [
    "",
    "->  Merhaba,Modeli eÄŸittikten sonra featurelar ile output arasÄ±ndaki baÄŸlantÄ±larÄ±n Ã¼zerine mouse ile gelirsen her bir feature iÃ§in weight deÄŸerini gÃ¶sterecektir. Verilen task 1'i Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±nda regularization kullanmÄ±yorsun, 500 epoch sonra her bir feature iÃ§in weight deÄŸerlerini bir yere not al. Task2'de regularization rate deÄŸeri 0.3 olarak verip 500 epoch sonrasÄ± weight deÄŸerlerini kontrol et. Weight deÄŸerlerinin task 1'e gÃ¶re 0'a yakÄ±n olarak konumlandÄ±ÄŸÄ±nÄ± gÃ¶receksin.Bunun sebebi L2 regularization iÅŸleminin modeldeki kompleksliÄŸi azaltmasÄ± yani weight deÄŸerlerini 0'a yaklaÅŸtÄ±rmasÄ±dÄ±r.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 5 people like this.Like ReportReply",
    "-> TeÅŸekkÃ¼r ederim.",
    " "
]
},
{
"question_isim": "->  uploaded 3 photos",
"quest": "Merhaba ArkadaÅŸlar,  Regularization for Simplicity: Playground Exercise bÃ¶lÃ¼mÃ¼nÃ¼n Task 3'Ã¼nÃ¼n cevabÄ±nda :  \"Given the randomness in the data set, it is impossible to predict which regularization rate produced the best results for you. For us, a regularization rate of either 0.3 or 1 generally produced the lowest Test loss.\" demiÅŸ.  Ama ben regularization rate'i 0.1 yaptÄ±ÄŸÄ±mda 0.3 ve 1'e gÃ¶re daha dÃ¼ÅŸÃ¼k test loss'u elde ettim. Ekte gÃ¶rebilirsiniz. Acaba ben mi bir yerlerde hata yaptÄ±m. YardÄ±mcÄ± olursanÄ±z sevinirim. Ã‡ok teÅŸekkÃ¼rler.",
"comment": [
    "",
    "->  Merhaba,Bende de 0.1 lambda deÄŸeri en optimum test loss deÄŸerine sahip. Bir hata yaptÄ±ÄŸÄ±nÄ±zÄ± dÃ¼ÅŸÃ¼nmÃ¼yorum, Bunun kontrolÃ¼nÃ¼ ben de yaptÄ±m ve sanÄ±rÄ±m o kÄ±sma yanlÄ±ÅŸ yazÄ±lmÄ±ÅŸ. EÄŸer bunun bir hata olduÄŸunu dÃ¼ÅŸÃ¼nen varsa bizi dÃ¼zeltebilir.Ä°yi Ã§alÄ±ÅŸmalar..",
    "->  Bende de Ã¶yle, KullandÄ±klarÄ± dataset ile ilgili olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yorum mesela sol Ã¼stteki dataset iÃ§in dedikleri doÄŸru.",
    "->  tÄ±rnak iÃ§erisinde belirttiÄŸin ifadeden anlayabildiÄŸim kadarÄ±yla playground exerciselerda generate edilen herbir dataset iÃ§in belirli oranda bir rastgelelik sÃ¶zkonusu. o nedenle optimum parametre deÄŸerleri deÄŸiÅŸebiliyor. bende de 0.3 lambda deÄŸeri optimum sonucu veriyordu mesela..",
    "->  Merhabalar, lamda deÄŸerini biraz daha kÃ¼Ã§Ã¼ltmen lazÄ±m, gÃ¶rselde farklÄ± lambda deÄŸerleri iÃ§in elde edilen sonuÃ§larÄ± ekledim,yeÅŸil olanlardan herhangi biri iyi sonuÃ§ veriyor,aradaki fark 0.01 civarÄ±nda.",
    "->  Ã‡ok teÅŸekkÃ¼rler arkadaÅŸlar. Ä°yi Ã§alÄ±ÅŸmalar..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba. Regularization kÄ±smÄ±nda, lambda deÄŸerinin bÃ¼yÃ¼k olmasÄ± durumunda modelin underfit olmasÄ±nÄ±n ve tersi durumda overfit olmasÄ±nÄ±n sebebini kafamda oturtamadÄ±m. AÃ§Ä±klayabilir misiniz ? TeÅŸekkÃ¼rler.",
"comment": [
    "",
    "->  Merhaba Furkan,Lambda deÄŸeri L2 regularization iÅŸleminin sonuca ne kadar fazla etki edeceÄŸini belirleyen hiperparametredir. Lambda deÄŸerini genellikle 0 ile 1 arasÄ±nda konumlandÄ±rÄ±yoruz. EÄŸer lambda deÄŸeri 0 olursa regularization uygulanmayacak demektir. Bizim regularization ile amacÄ±mÄ±z overfitting engellemek, dolayÄ±sÄ±yla Ã§ok dÃ¼ÅŸÃ¼k lambda deÄŸeri overfittingi engellemeyecektir. Ã‡ok yÃ¼ksek bir deÄŸer seÃ§ersek de bu sefer modeldeki Ã§oÄŸu weight hÄ±zlÄ±ca baskÄ±lanacaktÄ±r ve Ã¶ÄŸrenme tam anlamÄ±yla gerÃ§ekleÅŸemeyecektir, bundan dolayÄ± underfitting oluÅŸabilir.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 10 people like this.Like ReportReply",
    "->  ->  TeÅŸekkÃ¼r ederim..",
    "->  anladÄ±ÄŸÄ±m kadarÄ± ile regularization iÃ§in loss ve complexity deÄŸerleri arasÄ±nda bir denge sÃ¶zkonusu. bu dengeyi lambda deÄŸeri ile saÄŸlamaya Ã§alÄ±ÅŸÄ±yoruz. lambda deÄŸerini yÃ¼ksek vermemiz durumunda model complexitysini azaltmaya odaklanÄ±yoruz ancak daha basit bir model tahmin deÄŸerlerinin istenilenden dÃ¼ÅŸÃ¼k olmasÄ±na (underfit) neden olabiliyor. aksi durumda, yani lambda deÄŸerini dÃ¼ÅŸÃ¼k verdiÄŸimiz durumda bu kez basit bir modelden ziyade daha doÄŸru tahmini veriler verebilecek bir modeli Ã¶nceliklendirmiÅŸ oluyoruz. bu da daha kompleks, overfitting nedeni ile test verileri ile daha uyumlu ancak yeni veriler ile tahminde muhtemelen daha baÅŸarÄ±sÄ±z olacak bir modele neden oluyor. bu nedenle lambda deÄŸerini optimize etmek gerekiyor diye anladÄ±m. yanlÄ±ÅŸ anladÄ±ysam dÃ¼zeltme gelirse sevinirim.1 month ago 2 people like this.Like ReportReply",
    "->  ->  TeÅŸekkÃ¼r ederim..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba,  Regularization 'da playground exercise kÄ±smÄ±nda task2'de aÃ§Ä±klama kÄ±smÄ±nda cok fazla feature cross kullanmak eÄŸitim verisindeki gÃ¼rÃ¼ltÃ¼ye uyma fÄ±rsatÄ± olur buda testte kÃ¶tÃ¼ baÅŸarÄ±ya neden olur mu demek istiyor?Yani training yaparken training verisindeki gÃ¼rÃ¼ltÃ¼ye uymamasÄ± mÄ± lazÄ±m modelin?  TeÅŸekkÃ¼rler",
"comment": [
    "",
    "->  Merhaba,Modelimiz ne kadar fazla feature iÃ§erirse o kadar weight iÃ§erir ve daha da komplike olur. Komplike oldukÃ§a hipotez fonksiyonumuz eÄŸitim setindeki noise datalarÄ± bile ezberler bÃ¶ylece eÄŸitim lossumuz Ã§ok dÃ¼ÅŸÃ¼k olur. YalnÄ±z bu eÄŸitim setimizi Ã§ok iyi ezberleyen ve karmaÅŸÄ±k olan modelimiz yeni gelen veri tahminini yapamayacaktÄ±r Ã§Ã¼nkÃ¼ sadece eÄŸitim verisini ezberleyip hipotez fonksiyonunu sadece eÄŸitim setini bilecek gibi oluÅŸturmuÅŸtur. (Grafikte eÄŸitim setini Ã§ok gÃ¼zel ve hatasÄ±z ÅŸekilde ayÄ±rmÄ±ÅŸtÄ±r ama yeni gelen veriyi grafikte konumlandÄ±rmakta ve analiz etmekte baÅŸarÄ±lÄ± olamayacaktÄ±r.)Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 8 people like this.Like ReportReply",
    "->  ->  TeÅŸekkÃ¼rler:).",
    " "
]
},
{
"question_isim": "->  uploaded 2 photos",
"quest": "Regularization kÄ±smÄ±nda playgroundda regularization ratei arttÄ±rdÄ±ÄŸÄ±mda nedense test loss artmaya baÅŸladÄ±. Cevapta 0 dan 0.3 e Ã§ektiÄŸinde test lossda gÃ¶zle gÃ¶rÃ¼lÃ¼r bir azalma gÃ¶receksin diyor.",
"comment": [
    "",
    "->  Merhaba,Modeli her eÄŸittinizde aynÄ± training ve test loss deÄŸerlerini almazsÄ±nÄ±z. Muhtemelen tekrar eÄŸittiÄŸinizde bu sonucun deÄŸiÅŸtiÄŸini gÃ¶receksiniz. hger Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±ndaki test ve training loss deÄŸiÅŸiminin sebebi modelimizdeki verilerin test,train ve validation olarak ayrÄ±lmadan Ã¶nce shuffle edilmesidir.Regularization her gradient descent adÄ±mÄ±nda weight deÄŸerlerini daha da 0'a yakÄ±ndattÄ±ÄŸÄ± iÃ§in loss deÄŸerleri daha da dÃ¼ÅŸÃ¼klÃ¼k gÃ¶sterecektir.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 3 people like this.Like ReportReply",
    "->  Merhabalar,HatalÄ± deÄŸilsem training data size ve batch size gibi deÄŸerlerde deÄŸiÅŸiklik yaparak test etmiÅŸsiniz.Sonucunuzun beklenen ÅŸekilde olmayÄ±ÅŸÄ± bu parametrelerin hatalÄ± seÃ§iminden olabilir, varsayÄ±lan olarak gelen deÄŸerler ile testinizi yaparsanÄ±z azalma olduÄŸunu gÃ¶rebilirsiniz.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 4 people like this.Like ReportReply",
    "->  Merhaba,aÅŸaÄŸÄ±daki gÃ¶rsel ile lambda parametresini aÃ§Ä±klamaya Ã§alÄ±ÅŸtÄ±m.1 month ago 5 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "->  uploaded 1 photo",
"quest": "Merhaba ArkadaÅŸlar, Lower Learning rate (with early stopping), gÃ¼Ã§lÃ¼ L2 regularization ile aynÄ± etki yarattÄ±ÄŸÄ±nÄ± anladÄ±m. Ama eklediÄŸim 2 paragrafta tam ne anlatÄ±lmak isteniyor anlayamadÄ±m. YardÄ±m olabilirseniz Ã§ok sevinirim. Ã‡ok teÅŸekkÃ¼rler.",
"comment": [
    "",
    "->  Merhaba,Datasetine sÃ¼rekli olarak bir data akÄ±ÅŸÄ± varsa yani sÃ¼rekli yeni example'lar ekleniyorsa datanÄ±n trendi zamanla deÄŸiÅŸebileceÄŸi iÃ§in elinizdeki datayla hatayÄ± iyice dÃ¼ÅŸÃ¼recek (converge edecek) kadar train etmiyoruz, training i erken bitiriyoruz Ã§Ã¼nkÃ¼ yeni trendi anlayacak kadar elimizde data yok diyor. Bir de yeni gelen data iÃ§in daha genel bir modelimiz olmuÅŸ oluyor ve test loss azalÄ±yor.Ä°kinci sÃ¶ylediÄŸi de early stopping ve regularization rate benzer etkilere sahip. Siz optimum regularization rate i bulmak istiyorsanÄ±z early stopping etkisi olmamalÄ±, sadece regularization rate etkisi olmalÄ±. Bu yÃ¼zden iterasyon sayÄ±sÄ±nÄ± bÃ¼yÃ¼k seÃ§in ki early stopping olmasÄ±n sadece regularization rate in etkisini gÃ¶rÃ¼n diyor anladÄ±ÄŸÄ±m kadarÄ±yla ğŸ™‚1 month ago 5 people like this.Like ReportReply",
    "-> Merhaba,Burada early stopping yani erken durdurmadan bahsetmiÅŸ. Erken durdurmak modelimiz eÄŸitilirken modelimiz tam yakÄ±nsamadan eÄŸitimi durdurmak demektir. YazdÄ±ÄŸÄ±nÄ±z gibi lower learning rate kullanÄ±p modelinizin eÄŸitmini tam yakÄ±nsamadan durdurursanÄ±z lambdanÄ±n oluÅŸturacaÄŸÄ± etkiyi oluÅŸturur. Nerede durduracaÄŸÄ±mÄ±zÄ± da ÅŸÃ¶yle bilebiliriz: validasyon setimizin loss oranÄ± artÄ±yorsa eÄŸitimi orada bitirirsiniz ki tahminleri optimum bir ÅŸekilde yapabilecek overfit olmayan bir model elde edebilelim.Lambda ile learning rate parametrelerinin etkilerini karÅŸÄ±laÅŸtÄ±rabilirsiniz. Bunu gÃ¶zlemleyebilmek iÃ§in ben ÅŸÃ¶yle bir ÅŸey yaptÄ±m(Her iki adÄ±mda da 1000 epoch ile eÄŸittim):1.Playground'da Regularization:None dedim ve learning rate deÄŸerini 0.1'e ayarlayarak eÄŸitim iÅŸlemini baÅŸlattÄ±m. Test ve Training loss deÄŸerleri Ã¶nce dÃ¼ÅŸmeye baÅŸladÄ± ama epoch sayÄ±sÄ± arttÄ±kÃ§a training loss deÄŸeri minimum deÄŸerde sabit kalÄ±yorken test loss deÄŸeri sÃ¼rekli artmaya baÅŸladÄ±. EÄŸer training loss en minimum deÄŸere gelmeden biraz Ã¶nce early stopping yapsaydÄ±k ve eÄŸitimi yarÄ±da kesseydik hem test hem de training loss deÄŸerleri optimum seviyede olacaktÄ±.2.Learning rate deÄŸerimi 0.1'den deÄŸiÅŸtirmeden regularization:L2 seÃ§tim ve regularization rate deÄŸerimizi 0.1 olarak ayarladÄ±m. EÄŸitimi baÅŸlatÄ±p beklediÄŸimde hem test hem training datanÄ±n deÄŸerlerinin 0'a olabildiÄŸince yakÄ±nsadÄ±ktan sonra minimum deÄŸerde kaldÄ±klarÄ±nÄ± ve 1.adÄ±mÄ±mÄ±n aksine test loss deÄŸerinin artmadÄ±ÄŸÄ±nÄ± gÃ¶zlemledim. Buradan Ã§Ä±karacaÄŸÄ±mÄ±z sonuÃ§ learning rate eÄŸer eÄŸitimi erken durdurursak lambda ile aynÄ± etkiyi oluÅŸturur.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 7 people like this.Like ReportReply",
    "->  Ã‡ok teÅŸekkÃ¼rler arkadaÅŸlar ->  ->  . Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 2 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": " ->  uploaded 1 photo",
"quest": "Merhaba, ÅŸurada anlatÄ±lan aÃ§Ä±klamalarÄ± tam anlayamadÄ±m. YardÄ±mcÄ± olabilir misiniz?",
"comment": [
    "",
    "->  Merhaba,Burada bu model karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± iki ÅŸekilde ele aldÄ±ÄŸÄ±ndan bahsediyor.-Modelimizdeki weightler model karmaÅŸÄ±klÄ±ÄŸÄ±mÄ±zdÄ±r. Modelimizdeki weightlerin mutlak deÄŸeri ne kadar bÃ¼yÃ¼kse o kadar karmaÅŸÄ±ktÄ±r. Ã–rneÄŸin 25x1+7x2 olduÄŸunu varsayarsak x1 feature'Ä±mÄ±zÄ±n weight deÄŸeri x2 feature'Ä±mÄ±zÄ±n weight deÄŸerinden daha karmaÅŸÄ±ktÄ±r diyebiliriz.BaÅŸka bir Ã¶rnek olarak -150x1+77x2 dersek yine x1'in weight'i x2'nin weight deÄŸerine gÃ¶re daha karmaÅŸÄ±k olacaktÄ±r. Zaten regÃ¼larizasyon iÅŸlemimiz de karmaÅŸÄ±klÄ±ÄŸÄ± azaltmak yani weight deÄŸerlerini olabildiÄŸince 0'a yaklaÅŸtÄ±rmak. Weight ne kadar 0'a yaklaÅŸtÄ±rsa o kadar basit olur. (Fazla basit olursa underfitting, fazla komplike olursa overfitting olur.)-DiÄŸer karmaÅŸÄ±klÄ±k yaklaÅŸÄ±mÄ± ise sÄ±fÄ±rdan farklÄ± weight deÄŸerlerine sahip feature sayÄ±sÄ± modelimizin karmaÅŸÄ±klÄ±ÄŸÄ± olur.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 13 people like this.Like ReportReply",
    " ->  ->  TeÅŸekkÃ¼r ederim ÅŸimdi anladÄ±m.1 month ago 2 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "-> uploaded 1 photo",
"quest": "Bucket enlem ve boylarÄ±mÄ±zÄ± bÃ¶ldÃ¼ÄŸÃ¼mÃ¼z zaman binnning yaptÄ±ÄŸÄ±mÄ±zda karÅŸÄ±mÄ±za Ã§Ä±kan [0,0,0,1,0,0,0] grubunun adÄ± deÄŸil mi ya da bu iÅŸlemin adÄ±? Åu kÄ±smÄ± ben tam anlayamadÄ±m. Bucket ve Crosses Feature arasÄ±ndaki fark...  Bucket'te mi ayrÄ± bir yÃ¶ntem yani? UmarÄ±m derdimi anlatabilmiÅŸimdir. Åimdiden teÅŸekkÃ¼rler.",
"comment": [
    "",
    "->  Merhaba,Evet, bucket sizin yazdÄ±ÄŸÄ±nÄ±z her bir binary vectordÃ¼r. AralarÄ±ndaki farkÄ± http://community.globalaihub.com/community/status/519-519-1587052575/#comment.4259.4239.4239 linkinde bunu anlatmaya Ã§alÄ±ÅŸtÄ±m. Sorunuz olursa tekrar sorabilirsiniz.Ä°yi Ã§alÄ±ÅŸmalar..",
    " "
]
},
{
"question_isim": "->  uploaded 1 photo",
"quest": "Merhaba ArkadaÅŸlar, Feature Crosses - Playground Exercises kÄ±smÄ±nda neden X1 ve X2 yerine X12 ve X22'yi seÃ§tiÄŸimizi anlayamadÄ±m. Ve X12 ve X22 neyi ifade ediyor tam anlayamadÄ±m.  DiÄŸer bir sorum :  \"If you enter a negative value for the feature cross, the model will separate the blue dots from the orange dots but the predictions will be completely wrong. \" ifadesinde neden negatif deÄŸer girersek tahminler yanlÄ±ÅŸ olur kÄ±smÄ± tam net oturmadÄ±.  Ã‡ok teÅŸekkÃ¼rler",
"comment": [
    "",
    "-> Merhaba,Burada verimizin daÄŸÄ±lÄ±mÄ±na bakarsak bu problemimiz lineer regresyonla Ã§Ã¶zÃ¼lemez yani y=w0+w1x1+w2x2+...+wmxm tarzÄ±nda bir yaklaÅŸÄ±m kullanamayÄ±z. Peki bunun iÃ§in ne yapabiliriz? Elimizdeki feature deÄŸerlerindenm sentetik deÄŸerler Ã¼retmeyi deneyebiliriz veya elimizdeki feature deÄŸerlerini evaluate edebiliriz. Ama ben burada biraz matematiksel bir hileye kaÃ§acaÄŸÄ±m.(KaÃ§mayacaksam de elimdeki featurelar Ã¼zerinden yeni featurelar ve feature deÄŸerleri elde etmeye Ã§alÄ±ÅŸacaktÄ±m tabi bunu bir anda yapmayacak hangi feature verilerinin bu iÅŸlemlere gireceÄŸini analiz ile belirleyecektim.) Veri daÄŸÄ±lÄ±mlarÄ±nÄ± incelediÄŸimizde mavilerin ortada dairesel ÅŸekilde toplandÄ±ÄŸnÄ± ve turuncularÄ±n da Ã§evresinde toplandÄ±klarÄ±nÄ± gÃ¶rebiliyorum. AÅŸaÄŸÄ±daki resimde dairenin formÃ¼lÃ¼nÃ¼n x^2+y^2=r^2 olduÄŸunu biliyorum. Bu yÃ¼zden elde edeceÄŸim yeni feature deÄŸeri kareli bir deÄŸer olmalÄ±. Burada x12 x1'in karesi, x22 ise x2'nin karesi demek oluyor. Bu nedenle bizim de bu outputta dairesel bir Ã§Ä±ktÄ± elde edebilmemiz iÃ§in featurelarÄ±mÄ±zÄ±n karesini alÄ±p bu problemi linear regresyondan polynomial regression'a Ã§evirmemiz gerekiyor. Bu yÃ¼zden x1^2 ve x2^2 kullandÄ±k.\"If you enter a negative value for the feature cross, the model will separate the blue dots from the orange dots but the predictions will be completely wrong. \" kÄ±smÄ±nda ise ÅŸunu demek istemiÅŸ: Siz eÄŸer x1x2 feature'Ä±na negatif bir deÄŸer verirseniz verileriniz yine dÃ¼zgÃ¼n ayrÄ±lacaktÄ±r. Ama negatif deÄŸer verdiÄŸinz iÃ§in grafikte gÃ¶rÃ¼nen turuncu deÄŸerleri mavi deÄŸerler olarak, grafikte gÃ¶rdÃ¼ÄŸÃ¼nÃ¼z mavi deÄŸerleri de turuncu deÄŸer olarak tahmin edecektir.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 25 people like this.Like ReportReply",
    "->  Ã‡ok teÅŸekkÃ¼rler ->  Ã§ok net anladÄ±m. Ä°yi Ã§alÄ±ÅŸmalar.",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar, Feature Crosses : Playground Exercises : More Complex Feature Crosses : Task2 de cevabÄ±n neden \"Using both x1^2 and x2^2 as feature crosses. (Adding x1x2 as a feature cross doesn't appear to help.)\" olduÄŸunu anlayamadÄ±m. YardÄ±mcÄ± olabilirseniz sevinirim.",
"comment": [
    "",
    "->  Merhaba,http://community.globalaihub.com/community/status/1133-1133-1587160937/#comment.4376.4241.4241 linkinde bunu aÃ§Ä±klamaya Ã§alÄ±ÅŸtÄ±m. Sorunuz olursa sormaktan Ã§ekinmeyin.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 2 people like this.Like ReportReply",
    "->  ->  TeÅŸekkÃ¼rler, anlamama yardÄ±mcÄ± oldunuz..",
    " "
]
},
{
"question_isim": "->  uploaded 1 photo",
"quest": "Merhaba.  Bu histogramÄ± tam olarak anlayamadÄ±m. Weight Frequency kavramÄ± ile ne temsil ediliyor ?",
"comment": [
    "",
    "->  Merhaba,Ã–ncelikle lambda'nÄ±n weight deÄŸerileri Ã¼zerine etkisini anlamak iÃ§in http://community.globalaihub.com/community/status/1191-1191-1587125026/#comment.4315.4196.4196 yorumunu okuyabilirsiniz.Lambda deÄŸeri ne kadar bÃ¼yÃ¼k olursa weight deÄŸerleri o kadar kÃ¼Ã§Ã¼lÃ¼r yani 0'a o kadar yaklaÅŸÄ±r. AÅŸaÄŸÄ±da kÃ¼Ã§Ã¼k bir kÄ±smÄ± Ã§Ä±kmÄ±ÅŸ resimde de lambda deÄŸerini kÃ¼Ã§Ã¼ltÃ¼rseniz histogramÄ±nÄ±z dikleÅŸmeye baÅŸlar Ã§Ã¼nkÃ¼ weight deÄŸerleriniz Ã§ok az bir kÃ¼Ã§Ã¼lme gÃ¶sterir yani 0'a Ã§ok az yaklaÅŸÄ±m gÃ¶sterir.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 4 people like this.Like ReportReply",
    "-> Her Ã§ubuk belli bir deÄŸer aralÄ±ÄŸÄ±nÄ± (min_deÄŸer, max_deÄŸer) temsil ediyor. Ã‡ubuÄŸun uzunluÄŸu ise, weight'lerin kaÃ§ tanesinin o deÄŸer aralÄ±ÄŸÄ±nda olduÄŸunu ifade ediyor.1 month ago 4 people like this.Like ReportReply",
    "->  TeÅŸekkÃ¼r ederim..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Herkese Merhaba!  Bu haftaki quiz i de geÃ§en hafta olduÄŸu gibi Google form Ã¼zerinden gerÃ§ekleÅŸtireceÄŸiz. Pazar gÃ¼nÃ¼ sabah buradan sizlerle paylaÅŸmÄ±ÅŸ olurum. Åimdiden baÅŸarÄ±lar!",
"comment": [
    "",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba ben feature crosses kÄ±smÄ±nÄ± tamamen anladÄ±ÄŸÄ±mÄ± dÃ¼ÅŸÃ¼nÃ¼yorum ama aklÄ±ma takÄ±lan bir konu var. Åu linkte <a class=\"ps-media-link\" href=\"https://developers.google.com/machine-learning/crash-course/feature-crosses/crossing-one-hot-vectors\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">https://developers.google.com/machine-learning/crash-course/feature-crosses/crossing-one-hot-vectors</a> binned_latitude ve binned_longtitudede her ikisininde 5 elemanÄ± var. ve bunlarÄ±n cross productÄ±nÄ±n sonucu 25 elemanlÄ± bir vektÃ¶r olmuÅŸ oluyor cross product sonucunda normalde aynÄ± boyutta bir vektÃ¶r bulmamÄ±z gerekmezmiydi burda nasÄ±l bir istisna oluÅŸtu.",
"comment": [
    "",
    "->  a = [0,1,2,3,4]b = [0,1,2,3,4]a x b = [(0,0),(0,1),(0,2),(0,3),(0,4),(1,0), ... ,(1,4),..(4,0), ... ,(4,4)]Ã§arpÄ±m bu ÅŸekilde olduÄŸundan 25 elemanlÄ± vektÃ¶r oluÅŸuyor.1 month ago 2 people like this.Like ReportReply",
    "->  ->  VerdiÄŸim linkte ÅŸÃ¶yle bir ÅŸey geÃ§iyordu. The term cross comes from cross product. Ben aslÄ±nda bu yaptÄ±ÄŸÄ±mÄ±z iÅŸlem 3 boyutlu vektÃ¶rlerin cross productÄ±yla bir ilgisi olup olmadÄ±ÄŸÄ±nÄ± merak etmiÅŸtim. Ã‡Ã¼nkÃ¼ bildiÄŸim kadarÄ±yla 3 boyutlu vektÃ¶rÃ¼n Ã¶tesinde cross product alamÄ±yoruz ve iki vektÃ¶rÃ¼n cross productÄ± bize yine 3 boyutlu bu iki vektÃ¶re dik bir vektÃ¶r daha veriyordu..",
    "->  The term cross comes from cross product ifadesinin geÃ§tiÄŸi yerin ss'ini gÃ¶nderebilirmisin ?.",
    "->  YanlÄ±ÅŸ link yollamÄ±ÅŸÄ±m pardon. https://developers.google.com/machine-learning/crash-course/feature-crosses/encoding-nonlinearity",
    "Feature Crosses: Encoding Nonlinearity Â |Â  Machine Learning Crash Coursedevelopers.google.comhttps://developers.google.com/machine-learning/crash-course/feature-crosses/encoding-nonlinearity.",
    "->  ->  Burada Ã¼Ã§Ã¼ncÃ¼ deÄŸiÅŸkenin ilk iki deÄŸiÅŸkenin cross product'Ä± ile elde edildiÄŸini sÃ¶ylÃ¼yor..",
    "->  \"Ã‡Ã¼nkÃ¼ bildiÄŸim kadarÄ±yla 3 boyutlu vektÃ¶rÃ¼n Ã¶tesinde cross product alamÄ±yoruz \" kanÄ±sÄ±na nereden vardÄ±n..",
    "-> AslÄ±nda bin'ler arasÄ±ndaki iÅŸlem kartezyen Ã§arpÄ±m (cartesian product). Bence \"The term cross comes from cross product.\" ifadesindeki \"cross product\" referansÄ± yanÄ±ltÄ±cÄ± olmuÅŸ. Zira burada matematikte bildiÄŸimiz anlamÄ±yla \"cross product\" iÅŸlemi gerÃ§ekleÅŸmiyor..",
    " "
]
},
{
"question_isim": " ->  uploaded 1 photo",
"quest": "Merhaba, ÅŸu kÄ±smÄ± anlayamadÄ±m, neden binlere ayÄ±rÄ±yoruz ve neden o ÅŸekilde encode ediyoruz?",
"comment": [
    "",
    "->  Merhaba,http://community.globalaihub.com/community/status/875-875-1586778150/#comment.3974.3871.3871 bu yorumda binning'Ä° anlatmaya Ã§alÄ±ÅŸtÄ±m. AklÄ±nÄ±za hala soru takÄ±lÄ±rsa sorabilirsiniz.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 4 people like this.Like ReportReply",
    " ->  ->  teÅŸekkÃ¼r ederim.",
    " "
]
},
{
"question_isim": " -> ",
"quest": "Merhaba arkadaÅŸlar. Ben L2 Regularization ve Lambda kÄ±smÄ±nÄ± tam anladÄ±ÄŸÄ±mÄ± dÃ¼ÅŸÃ¼nmÃ¼yorum. YardÄ±mcÄ± olabilir misiniz? TeÅŸekkÃ¼rler ????",
"comment": [
    "",
    "-> Merhaba,Ã–ncelikle regÃ¼larizasyon yapmamÄ±zÄ±n sebebi overfit durumunu Ã¶nlemek. Gradient descent algoritmamÄ±z her seferinde optimum deÄŸere yaklaÅŸmak iÃ§in eÄŸitim modelini validation modele gÃ¶re ayarlar (yani ilgili weight deÄŸerlerinin ayarlamasÄ±nÄ± yapar.) Burada regularizasyonun gÃ¶revi komplex modeli cezalandÄ±rmak.Kompleks model ne demek?Biz kompleks modelin iki tanÄ±mÄ±yla ilgileneceÄŸiz:1. Modeldeki tÃ¼m featurelarÄ±n aÄŸÄ±rlÄ±klarÄ±(weight deÄŸerleri)2. DeÄŸeri 0'dan farklÄ± olan feature sayÄ±sÄ±mÄ±z.Kompleks modelimizi nasÄ±l cezalandÄ±racaÄŸÄ±z?YukarÄ±daki kompleks model tanÄ±mÄ±ndan da anlayacaÄŸÄ±mÄ±z Ã¼zere burada weight deÄŸerlerini azaltarak modelin karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± azaltmaya Ã§alÄ±ÅŸacaÄŸÄ±z. Weight deÄŸeri yÃ¼ksek olan featurelar modeli daha da karmaÅŸÄ±klaÅŸtÄ±rÄ±r. Bu yÃ¼zden weight deÄŸerleri 0'a ne kadar yakÄ±nsa model o kadar az kompleks yani basittir. Ama burada ÅŸÃ¶yle bir husus var. Weight deÄŸerlerinin 0'a acayip yakÄ±n olmasÄ± y=w0+w1x1+w2x2+....+wmxm denkleminde tÃ¼m w deÄŸerlerini 0'a yakÄ±nsatacaÄŸÄ±ndan bu denklemi sadece y=w0 ele alÄ±rsak burada high bias durumu yani underfitting oluÅŸur. Tam tersi durumu dÃ¼ÅŸÃ¼nÃ¼rsek de weight deÄŸerleri training seti ezberleyecek kadar karmaÅŸÄ±k olacaÄŸÄ±ndan overfitting (high variance) olur yani tahmin iÃ§in yeni gelen datanÄ±n tahmininde baÅŸarÄ±sÄ±z olur.CezalandÄ±rma iÅŸlemi iÃ§in cost function denklemimize regularization term dediÄŸimiz denklemi ekliyoruz. Yani yeni cost function'Ä±mÄ±z resimdeki gibi oluyor.Burada her bir weight deÄŸerinin karelerinin toplamÄ±nÄ±n ortlamasÄ±nÄ± alÄ±p regularization parametremizle Ã§arpÄ±yoruz yalnÄ±z w0'Ä± eklemiyoruz Ã§Ã¼nkÃ¼ w0 deÄŸerimiz herhangi bir feature'a ait bir weight deÄŸil, bias deÄŸeri. Bu parametrenin Ã¶nemi gradient descent adÄ±mÄ±mÄ±za baktÄ±ÄŸÄ±mÄ±zda ortaya Ã§Ä±kÄ±yor. Burada hweight0 dÄ±ÅŸÄ±ndaki tÃ¼m weightlere regularization uygulanÄ±yor. EÄŸer yeÅŸil kutucuÄŸa aldÄ±ÄŸÄ±m yerde learning rate'i iÃ§eri daÄŸÄ±tÄ±p thetaj parantezine alÄ±rsanÄ±z thetaj'nin kaysayÄ±sÄ±nÄ±n (1-learningrate*(lambda/m)) olduÄŸunu gÃ¶rebilirsiniz. Burada regularization parametresi Ã§ok Ã¶nemli Ã§Ã¼nkÃ¼ thetaj'yi 0'a fazla yakÄ±n veya fazla uzak bir deÄŸer yaparsanÄ±z yukarÄ±da bahsettiÄŸim overfitting ve underfitting problemlerine kapÄ± aÃ§mÄ±ÅŸ olursunuz. O yÃ¼zden burada lambdayÄ± optimum seÃ§ebilmek Ã§ok Ã¶nemli.UmarÄ±m resim ve anlatÄ±mÄ±m aÃ§Ä±klayÄ±cÄ±dÄ±r :)Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 23 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "->  uploaded 1 photo",
"quest": "Bu koddaki -tf.feature_column.numeric_colum()- gibi fonksiyonlarÄ±n kullanÄ±mÄ±nÄ± ve mantÄ±ÄŸÄ±nÄ± bilmemiz ÅŸuanlÄ±k yeterli midir yoksa fonksiyonlarÄ± tamamen ezberleyip bu ÅŸekilde yazmamÄ±z mÄ± gereklidir. TeÅŸekkÃ¼rler.",
"comment": [
    "",
    "->  MantÄ±ÄŸÄ±nÄ± ve kullanÄ±mÄ±nÄ± bilmeniz ÅŸimdilik yeterli. Zamanla kullandÄ±kÃ§a mutlaka ezbere yapabileceksiniz..",
    " "
]
},
{
"question_isim": "-> uploaded 1 photo",
"quest": "Merhaba, burada posta kodu nasÄ±l daha iyi bir feature oluyor? Arada linear iliÅŸki olmamasÄ±na raÄŸmen posta kodlarÄ±nÄ± kullanÄ±rsak linear bir iliÅŸki oluÅŸturmaz mÄ±yÄ±z?",
"comment": [
    "",
    "-> Merhaba,AnladÄ±ÄŸÄ±m kadarÄ±yla biz latitude ve longitude deÄŸerlerinden spesifik bir koordinat Ã¼retmeye Ã§alÄ±ÅŸÄ±yoruz ama bu koordinat deÄŸerleri aslÄ±nda binlenmiÅŸ deÄŸerler ve Ã¶rnek anlamlarÄ± ÅŸu ÅŸekilde:0<lat<60 ve 25<long<77Yani iki feature'Ä± (latitude ve longitude) birbiri ile Ã§arptÄ±k ve yeni bir feature elde ettik. Yeni bir feature elde etmemiz demek yeni bir weight deÄŸeri elde etmemiz demek ve bu da modelimizin daha karmaÅŸÄ±k olmasÄ± demek. (Model kompleksitemiz weight sayÄ±sÄ± ve deÄŸerleriyle doÄŸru orantÄ±lÄ±dÄ±r.) EÄŸer siz aynÄ± iÅŸlevi gÃ¶recek ve binlenmeye (yani kategorize edilmeye) ihtiyaÃ§ duymayan numerik bir deÄŸer bulabilirseniz hem bu verileri binlemenize gerek kalmaz (ki bunun hem zaman hem space kompleksitesinden de kurtulmuÅŸ olursunuz) hem de model kompleksiteniz daha az olur. Neticede posta kodu her mahalle iÃ§in unique'tir. Burada posta kodu kullanacaksanÄ±z ve sizin eviniz iki sokaÄŸÄ±n kÃ¶ÅŸesindeyse multi-hot encoding yapÄ±p bu deÄŸerleri binary vector'e alabilme imkanÄ±nÄ±z vardÄ±r veya tek yerdeyse one hot encoding ile de binary vector feature deÄŸerleri elde edebilirsiniz. YalnÄ±z Ã¶nceki Ã¶rneÄŸe nazaran iki feature deÄŸeri Ã§arpÄ±p 3.bir feature elde edip bu iÅŸlemlerimi ona gÃ¶re yapmaktansa verisetimdeki posta kodu feature'Ä±nÄ± yaparak tÃ¼m bu iÅŸlemleri gerÃ§ekleÅŸtirebildim.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 10 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "-> uploaded 1 photo",
"quest": "Ben crossing one-hot vectors kÄ±smÄ±nda verilen Ã¶rneÄŸi anlayamadÄ±m. Feature Crosses kÄ±smÄ±nda biraz zorlandÄ±m galiba...   CevaplarÄ±nÄ±z iÃ§in ÅŸimdiden teÅŸekkÃ¼r ederim.",
"comment": [
    "",
    "->  binned_latitude ve binned_longitude deÄŸerleri belirli aralÄ±ktaki enlem ve boylamlarÄ± temsil ediyor. Bunlara feature cross uyguladÄ±ÄŸÄ±mÄ±zda ise, AND operatorÃ¼ uygulamÄ±ÅŸ oluyoruz. Yani fiyatÄ±nÄ± tahmin etmek istediÄŸimiz evimizin enlem deÄŸeri 15 derece ve boylam deÄŸeri 13 derece olsun. Feature cross kullanarak tÃ¼m olasÄ± enlem ve boylam aralÄ±klarÄ±nÄ± yazÄ±yoruz ve bizim Ã¶rneÄŸimizin iÃ§inde bulunduÄŸu aralÄ±ÄŸÄ± 1, diÄŸerlerini 0 yapÄ±yoruz. Ã–rneÄŸimiz; 10 < lat <=20 VE 0 < lon <=15 aralÄ±ÄŸÄ±nda bulunuyor. Bunu aynÄ± ÅŸekilde one-hot temsili ile gÃ¶sterip tahmin oranÄ±(predictive power) daha iyi bir feature oluÅŸturmuÅŸ oluyoruz.1 month ago 5 people like this.Like ReportReply",
    "->  AnladÄ±ÄŸÄ±m kadarÄ±yla Feature Crosses kÄ±smÄ±nda yapmaya Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z ÅŸey ÅŸuna benziyor; Ã¶rneÄŸin birinin boy ve kilo verisi var elimizde bu kiÅŸinin obezite olup olmadÄ±ÄŸÄ±nÄ± tahmin etmeye Ã§alÄ±sÄ±yoruz bunun iÃ§in direk boy ve kiloyu kullanarak oluÅŸturulcak model yerine bu 2 feature'Ä± kullanarak vÃ¼cut kitle indexi olan sentetikbir feature oluÅŸturup daha gÃ¼zel bir temsil yapmayÄ± istiyoruz. AynÄ± ÅŸekilde Feature Crosses kÄ±smÄ±nda da Ã¶rnek Ã¼zerinde latitude ve longitude tek tek kullanmak yerine crosslayÄ±p iÅŸlem yaparak daha iyi bir temsil yapmayÄ± amaÃ§lÄ±yoruz. Hatam varsa dÃ¼zeltirseniz sevinirm.1 month ago 9 people like this.Like ReportReply",
    "-> Åimdi anladÄ±m cevaplar iÃ§in Ã§ok teÅŸekkÃ¼r ederim ğŸ™‚.",
    " "
]
},
{
"question_isim": "->",
"quest": "Merhaba, Neden train ve validation loss egrilerinin birbirine cok yakin olmasini saglamamiz gerektigi konusunda bir yerde takiliyorum. Bana cok yakin olmamalari generalization icin daha iyi bir sey gibi geliyor. Yani loss farki fazlayda iki kumenin birbirine daha az benzedigi gibi bir dusuncem oluyor. Bu da generalization icin istenen birsey olamaz mi? Validation set dersindeki programlama egzersizinde train, val, test hatalarinin birbirine cok yakin oldugu bulunuyor. Bu saglanmasi gereken ve ideal bir durum mu?",
"comment": [
    "",
    " ->  Merhaba. Modelimizi train veri kÃ¼mesi ile eÄŸitirken, validation ve test setlerinde test ediyoruz. EÄŸer train lossâ€™u dÃ¼ÅŸÃ¼k, validation lossâ€™u yÃ¼ksekse ve aralarÄ±nda Ã§ok fark varsa, modelimizin hiÃ§ gÃ¶rmediÄŸi bir veri kÃ¼mesinde kÃ¶tÃ¼ performans sergilediÄŸi iÃ§in overfit olduÄŸu ve kÃ¶tÃ¼ bir model olduÄŸunu gÃ¶rÃ¼rÃ¼z, test setinde test etmemize gerek kalmaz. AsÄ±l amaÃ§, modeli train ettikten sonra val ve train loss curvelerinin yakÄ±n olmasÄ±, ardÄ±ndan test loss curveâ€™nin diÄŸer iki curveâ€™e yakÄ±n olmasÄ±dÄ±r, generalizationda asÄ±l istediÄŸimiz de bu zaten, overfitting olmamasÄ±. Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 10 people like this.Like ReportReply",
    "->  ->  tesekkurler.",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Herkese merhaba  Ben Representation with a Feature Crossda kod parÃ§acÄ±ÄŸÄ±na yazÄ±lan resolution_in_degrees deÄŸiÅŸkenini neden kullandÄ±ÄŸÄ±mÄ±zÄ± anlayamadÄ±m",
"comment": [
    "",
    "->  Merhaba,Binning yapma iÅŸlemi sÄ±rasÄ±nda verdiÄŸiniz boundaries listesine gÃ¶re numerik deÄŸerleri gruplandÄ±rma iÅŸlemi yapar. Ã–rneÄŸin elinizde yaÅŸlar verileri var ve bunlarÄ± binning ile gruplamak istiyorsunuz. Sizin boundaries listeniz: [10,20,30,40,50,60,70,80,90] olursa bu sÄ±nÄ±rlar iÃ§in gruplandÄ±rmalar yapar. Buna gÃ¶re 76 ile 77 aynÄ± grupta olacaktÄ±r. Bunun iÃ§in ise numpy'In arange metodu kullanÄ±lmÄ±ÅŸtÄ±r. np.arange(minimum deÄŸer, maksimum deÄŸer, minimumdan maksimuma giderken kaÃ§ar kaÃ§ar artacaÄŸÄ±) buradaki resolution_in_degrees deÄŸiÅŸkeni ise bu artÄ±ÅŸÄ±n kaÃ§ar olacaÄŸÄ±nÄ± belirlemek iÃ§in kullanÄ±lmÄ±ÅŸtÄ±r. VerdiÄŸim yaÅŸ Ã¶rneÄŸinde bu deÄŸer 10 iken, Representation with a Feature Cross Ã¶rneÄŸimizde 1'dir.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 12 people like this.Like ReportReply",
    "->  ->  Ã§ok teÅŸekkÃ¼r ederim ğŸ˜€.",
    "-> ->  Merhaba, anlamadÄ±ÄŸÄ±m ÅŸey ÅŸu,Bu gruplara bucket denmiyor mu? Åu TASK 4'te takÄ±ldÄ±m. TeÅŸekkÃ¼rler ğŸ™‚1 month ago 2 people like this.Like ReportReply",
    "->  Merhaba,SanÄ±rÄ±m burada bucket olarak bahsettiÄŸi ÅŸey iki feature'Ä±n ayrÄ± ayrÄ± binning yapÄ±lÄ±p oluÅŸturduÄŸu bucketlar yani binningden sonra oluÅŸan binary vectorler. (Longitude ve latitude featurelarÄ± ayrÄ± ayrÄ± binning yapÄ±ldÄ±lar.) Feature cross dediÄŸi ÅŸey ise longitude ve latitude iÃ§in bu ayrÄ± yapÄ±lan binning featurelarÄ±nÄ±n Ã§arpÄ±lmasÄ± ve ortaya Ã§Ä±kan yeni binary vector deÄŸeri. Burada sormak istediÄŸi ÅŸey ise siz bu featurelarÄ± Ã§arpmadan ikisini de binning yaparsanÄ±z performans ne olur (featurelar ayrÄ± weight deÄŸerlerine sahip olursa ne olur?), iki feature'Ä±n binninglerini Ã§arparsanÄ±z ne olur? (Ä°ki feature'Ä± Ã§arpÄ±p sentetik bir feature elde ederseniz ve tek bir weight deÄŸeriniz olursa performans ne olur?).UmarÄ±m aÃ§Ä±klayÄ±cÄ± olabilmiÅŸimdir :)Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 8 people like this.Like ReportReply",
    "-> ->  Ã‡okk teÅŸekkÃ¼r ederim Fethi bey....",
    "->  -> Ben teÅŸekkÃ¼r ederim iyi Ã§alÄ±ÅŸmalar..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar , Representation kÄ±smÄ±nda one-hot encoding ile multi-hot encoding arasÄ±nda farkÄ± anlayamadÄ±.Bunun dÄ±ÅŸÄ±nda bir de mesela one hot encoding yaparken bÃ¼tÃ¼n streetleri sÄ±fÄ±r yapÄ±pÄ± sadece bizim kendi feature olarak seÃ§tiÄŸimiz street'i mi 1 yapÄ±yoruz mesela iki tane street verilirse iki tane mi 1 koyuyoruz?",
"comment": [
    "",
    "-> Merhaba,Bunu bir Ã¶rnek Ã¼zerinden anlatmam gerekirse: Elimizde bir veriseti var ve verisetinde sokak isminde bir feature'Ä±mÄ±z var. Sokak isimlerimiz string yani kategorik bir veridir. Kategorik verileri modelimizin anlayabilmesi iÃ§in numerik veriye sokmamÄ±z gerekir. YalnÄ±z burada ÅŸuna dikkat etmeliyiz. EÄŸer iki tane sokak ismi iÃ§eren bir veri Ã¶rneÄŸimiz varsa? O zaman iÅŸin iÃ§ine Multi-Hot Encoding giriyor.SokaklarÄ±mÄ±zÄ±n hepsini One Hot encoding Ã§evirme yÃ¶ntemimizi kullanarak tekrar numerik veriye Ã§evirdiÄŸimizde bu sefer o sokak isimlerine karÅŸÄ±lÄ±k gelen feature alanlarÄ± 1 olmalÄ±dÄ±r. Multi Hot Encoding'de One-Hot Encoding'in aksine birden fazla feature deÄŸeri 1 olabilir. Yani bir kiÅŸinin evi aynÄ± anda iki sokakta da olabilir.Multi-Hot Encoding Ã–rneÄŸi(Tek bir kategori seti iÃ§in Ã¶rneÄŸin yaÅŸ aralÄ±klarÄ±):[1, 0, 0 , 1]One Hot Encoding'i ise ÅŸu Ã¶rnekle aÃ§Ä±klayabilirim: Elimizde bir veriseti var ve verisetinde yaÅŸ isimli bir feature'Ä±mÄ±z bu. Bu feature'Ä± binning kullanarak binary veri gruplarÄ±na binary vector ile grupladÄ±ÄŸÄ±mÄ±zÄ± dÃ¼ÅŸÃ¼nÃ¼n. Bu gruplamalarda yeni feature'Ä±mÄ±zÄ±n binary vector deÄŸerleri yalnÄ±zca 1 adet 1 deÄŸeri iÃ§erebilir Ã§Ã¼nkÃ¼ bir kiÅŸi aynÄ± anda iki yaÅŸ grubuna giremez.One Hot Encoding Ã–rneÄŸi (Tek bir kategori seti iÃ§in Ã¶rneÄŸin yaÅŸ aralÄ±klarÄ±): [0, 0, 0, 1]Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 12 people like this.Like ReportReply",
    "->  teÅŸekkÃ¼r ederim.",
    " "
]
},
{
"question_isim": "->  uploaded 1 photo",
"quest": "Merhaba, bu soruda [binned longitude x binned latitude] ve [binned roomsperPerson] ÅŸeklinde iki feature kullanmak doÄŸru cevaptan daha mÄ± kullanÄ±ÅŸlÄ± olurdu yoksa daha kullanÄ±ÅŸsÄ±z mÄ±?",
"comment": [
    "",
    "-> Merhaba,[binned longitude x binned latitude] ve [binned roomsPerPerson] kullanmak daha kullanÄ±ÅŸsÄ±z olurdu. Ã‡Ã¼nkÃ¼ sizin istediÄŸiniz ÅŸey longitude, latitude ve roomsPerPerson deÄŸerlerinin her biri iÃ§in ihtimali featurelaÅŸtÄ±rÄ±p modelnize sokmak Ã§Ã¼nkÃ¼ hesaplanacak weight deÄŸerleri her ihtimal iÃ§in farklÄ± olacak. Ã–rneÄŸin sizin verdiÄŸiniz Ã¶rnek iÃ§in ([binned longitude x binned latitude] ve [binned roomsPerPerson]):Latitude x Longitude roomsPerPerson37.79 ve 76.51 3Bu durumda latitude x longitude iÃ§n ayrÄ± bir weight deÄŸeri, roomsPerPerson deÄŸeri iÃ§in ayrÄ± bir weight deÄŸeri hesaplanacaktÄ±r. Ama [binned longitude x binned latitude x binned roomsperPerson] kullanÄ±rsanÄ±z durum aÅŸaÄŸÄ±daki gibi olur:Latitude x Longitude x roomsPerPerson37.79 v3 76.51 ve 3Yani bu ihtimal iÃ§in tek bir weight deÄŸeri olur modelinizin hesaplayacaÄŸÄ± bu weight deÄŸeri diÄŸer ihtimale gÃ¶re daha tutarlÄ± olacaktÄ±r Ã§Ã¼nkÃ¼ bu ihtimal iÃ§in tek bir weight deÄŸeri varken aynÄ± ihtimale karÅŸÄ±lÄ±k gelen [binned longitude x binned latitude] ve [binned roomsperPerson] ihtimalinde 2 weight hesaplancaktÄ±r. (Bir tanesi [binned longitude x binned latitude] iÃ§in, diÄŸeri [binned roomsperPerson] iÃ§in.)Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 3 people like this.Like ReportReply",
    "->  bin etmesek ne olur, neden bin ettik.",
    "->  Fethi nin soyledigi gibi iki weights degeri hesaplanacaktir. Daha kullanisli olur mu sorusunun cevabi hayir daha kullanisli olmaz.Cunku daha fazla weights demek daha fazla hesaplama demektir,.Bu da daha uzun training sureci ve yuksek computational cost demektir..",
    "-> ->  yan.",
    "-> ->  ->  yani daha Ã§aba gerektiren ÅŸeyler olsada yinede doÄŸru bir yÃ¶ntem midir? KullanÄ±ÅŸlÄ± olmasa bile?.",
    "->  -> Merhaba, hayÄ±r deÄŸildir Ã§Ã¼nkÃ¼ bu durumda daha fazla weight sayÄ±mÄ±z olacak ve modelimizin karmaÅŸÄ±klÄ±ÄŸÄ± daha da artacak, bu da modelimizi overfitting olmaya daha da yaklaÅŸtÄ±racaktÄ±r. Burada bu argÃ¼manÄ± sunmamÄ±n sebebi bu 3 feature'Ä±n ayrÄ± ayrÄ± korelasyonu ile oluÅŸacak yeni sentetik verinin korelasyonu arasÄ±nda performans farkÄ± vardÄ±r. Bu yÃ¼zden siz bu 3 feature'I Ã§arpÄ±p tek bir sentetik feature elde edip buna baÄŸlÄ± olarak tek bir weight deÄŸeri elde edebilliyorken 3 tame farklÄ± feature kullanmanÄ±z hem performans aÃ§Ä±sÄ±ndan modelin training sÃ¼resi ve costunu uzatacaktÄ±r hem de tahminleriniz label ile bu featurelar arasÄ±ndaki korelasyonun daha az olmasÄ± sebebiyle daha da az performanslÄ± oluÅŸacaktÄ±r.Ä°yi Ã§alÄ±ÅŸmalar..",
    " "
]
},
{
"question_isim": "->  uploaded 1 photo",
"quest": "One-Hot Encoding kÄ±smÄ±nÄ± anladÄ±m fakat burada anlatÄ±lan Sparse Representation kÄ±smÄ±nda 0 olan verilerin alÄ±nmamasÄ±nÄ± nasÄ±l saÄŸlayacaÄŸÄ±z ve verisetinde bu iÅŸlem nasÄ±l bir etkiyle gÃ¶zÃ¼kecek ? Veri setine tablo ÅŸeklinde baktÄ±ÄŸÄ±mÄ±zda da 0 yerine boÅŸluklar ya da \"Nan\" vb. ÅŸeyler mi gÃ¶receÄŸiz. Daha Ã¶nce sorulduysa gÃ¶rmedim kusura bakmayÄ±n  iyi gÃ¼nler",
"comment": [
    "",
    "-> Merhaba arkadaÅŸlar,Sparse representation kÄ±saca ÅŸu demek oluyor. One hot encoding bildiÄŸiniz Ã¼zere elimizdeki veriyi bir sÃ¶zlÃ¼ÄŸe gÃ¶re indeksleme iÅŸlemi ÅŸeklinde dÃ¼ÅŸÃ¼nebilirsiniz.Burada nasÄ±l oluyordu mesela \"Ben bugÃ¼n Ã§alÄ±ÅŸÄ±yorum\" cÃ¼mlesi iÃ§in \"Ben\" kelimesini kodlamam iÃ§in (SÃ¶zlÃ¼ÄŸÃ¼mÃ¼zÃ¼n boyutu -kelime hacmi- 42000 kelime olduÄŸunu varsayarsak). Sadece \"Ben\" kelimesini gÃ¶sterim iÃ§inSÃ¶zlÃ¼k boyutunda bir tane dizi tanÄ±mlamam lazÄ±m ve bu dizininde sadece \"Ben\" kelimesine karÅŸÄ±lÄ±k gelen indeks deÄŸerinin 1 diÄŸerlerinin 0 olduÄŸu bir dizi oluÅŸturmuÅŸ olacaÄŸÄ±z.DiÄŸer 2 kelime iÃ§inde aynÄ± iÅŸlemi yaptÄ±ÄŸÄ±mÄ±zÄ± dÃ¼ÅŸÃ¼rsek. Dikkat ettiÄŸiniz Ã¼zere her bir kelime iÃ§in sÃ¶zlÃ¼k boyutu kadar diziler oluÅŸturuyoruz ve bu dizilerin bÃ¼yÃ¼k bir kÄ±smÄ± 0, boÅŸ, null veya ne derseniz artÄ±k.BÃ¶yle matrixlere sparse matrix denir. Bu hem hafÄ±z hemde iÅŸletim aÃ§Ä±sÄ±ndan zaman alacaÄŸÄ±ndan bu matriksleri daha az hafÄ±za alanÄ± kaplayan matriksler olara gÃ¶sterebiliriz.Yine aynÄ± cÃ¼mle Ã¼zerinden gidecek olursak Ben sÃ¶zlÃ¼ÄŸÃ¼n 140. bugÃ¼n 885. ve Ã§alÄ±ÅŸÄ±yorum 1987. kelimeleri olduÄŸunu dÃ¼ÅŸÃ¼nelim.O zaman bu cÃ¼mleyi kÄ±saca [140, 885, 1987] ÅŸeklinde tanÄ±mlayabiliriz. Bu ÅŸekilde 42000 x 3 byte yerine sadece 3 byte hafÄ±za alanÄ± ile aynÄ± gÃ¶sterimi saÄŸlamÄ±ÅŸ olduk.Ek olarak burada bir aÃ§Ä±klamayÄ± faydalÄ± gÃ¶rÃ¼yorum. Bu yeni indeksler her ne kadar sayÄ± olsalarda aralarÄ±nda bÃ¼yÃ¼klÃ¼k kÃ¼Ã§Ã¼klÃ¼k vb. matematiksel ifadelerin kullanÄ±lmamasÄ± gerekir.Ã‡Ã¼nkÃ¼ bunlar pointer deÄŸerleridir. Kategorik verileridir. Her ne kadar sayÄ± olsalarda sayÄ±sal veriler deÄŸildirler.1 month ago 11 people like this.Like ReportReply",
    "->  ->  TeÅŸekkÃ¼r ederim.",
    "->  ->  Buradan yola Ã§Ä±karsak her durumda one hot encoding kullanmak yerine sparse representation kullanmak Ã§ok daha mantÄ±klÄ±dÄ±r diyebilir miyiz? DoÄŸru mu anladÄ±m teyit etmek istedim..",
    "->  ->  Benim anladÄ±ÄŸÄ±m kadarÄ±yla veri kÃ¼mesi aÅŸÄ±rÄ± bÃ¼yÃ¼k deÄŸilse One-Hot Encoding yeterli olarak gÃ¶rÃ¼lÃ¼yor ama veri kÃ¼mesi bÃ¼yÃ¼k ise Sparse Representation yapÄ±yoruz ki hafÄ±za alanÄ±ndan tasarruf edebilelim..",
    "-> ->  ->  One hot encoding yerine sparse kullanabilirsiniz.Bunun bir sakÄ±ncasÄ± yok genel olarak kullanÄ±m ÅŸÃ¶yle oluyor diyebiliriz.Encoding iÅŸlemi yapÄ±lacak olan Ã¶zellik bir Ã§ok deÄŸer alÄ±yorsa bunun bu Ã¶zelliÄŸi sparse representation olarak kullanmak daha mantÄ±klÄ± oluyor.Bir Ã¶rnek ile kÄ±saca aÃ§Ä±klayacak olursak 2 Ã¶zelliÄŸimiz olsun bunlar il ve sokak. Ä°llerde de sadece istanbul Ankara ve Ä°zmir geÃ§tiÄŸini dÃ¼ÅŸÃ¼nelim.Sokak isimleri ile bu 3 ÅŸehirin sokak isimleri olacaÄŸÄ±ndan bunu ÅŸehir Ã¶zelliÄŸi iÃ§in one-hot encoding yaparken ÅŸehir isimleri iÃ§in sparse daha uygun olabilmektedir.Sparse'Ä±n bir dezavantajÄ± ÅŸu oluyor ilgili indeksin neye referans ettiÄŸini bir yerde saklamanÄ±z gerekiyor. Ama one-hot encoding iÃ§in yeni Ã¶zellikler (feature'lar) oluÅŸturduÄŸunuz iÃ§in verinize baÅŸka bir look-up table benzeri bir ÅŸeye ihtiyaÃ§Ä±nÄ±z yok.1 month ago 2 people like this.Like ReportReply",
    "->  ->  anladÄ±m teÅŸekkÃ¼rler.",
    "->  ->  Merhabalar. Tekrar yaparken bu konu hakkÄ±nda size bir ÅŸey danÄ±ÅŸmak istedim. Ã–nceki yorumlarda Ã¶rneÄŸin ÅŸehir kÃ¼mesini one-hot yaptÄ±ÄŸÄ±mÄ±zda her ÅŸehir ismi bir feature oluyor ve bunu,is_istanbul is_bursa is_antalya1 0 0ÅŸeklinde gÃ¶steriyoruz. Tablodan dÃ¼ÅŸÃ¼nÃ¼rsek sparse vektÃ¶re Ã§evirince sizindediÄŸinize gÃ¶re yalnÄ±zca Ä°stanbulun indeksi tutuluyor. Peki bu Ã¼stte verdiÄŸim Ã¶rnekteki ÅŸekilde tabloya gÃ¶rsel olarak etki ediyor mu? Yoksa sparse olayÄ± sadece arka planda verinin tutulma ÅŸekliyle mi ilgili?.",
    "->  ->  Merhaba aÃ§Ä±klama iÃ§in teÅŸekkÃ¼rler fakat son kÄ±sÄ±mdaki ifadenizi anlayamadÄ±m --\" Bu yeni indeksler her ne kadar sayÄ± olsalarda aralarÄ±nda bÃ¼yÃ¼klÃ¼k kÃ¼Ã§Ã¼klÃ¼k vb. matematiksel ifadelerin kullanÄ±lmamasÄ± gerekir. Her ne kadar sayÄ± olsalarda sayÄ±sal veriler deÄŸildirler.\"-- biraz daha aÃ§Ä±klayabilirmisiniz bu sayÄ±larÄ±n indexleri arasÄ±nda bÃ¼yÃ¼klÃ¼k kÃ¼Ã§Ã¼klÃ¼k iliÅŸkisi kurmayacaksak bilgisayara nasÄ±l o indexte bulunduklarÄ±nÄ± anlatÄ±cak yani bu indexte bulunan veri aynÄ± zamanda baÅŸka bir featurun 1532. indexi ile korelasyon halinde oldugunu biliyoruz ve bu iliÅŸkiyi kaybetmemeleri iÃ§in index numaralarÄ±nÄ± kullanmamÄ±z gerekirse ne yapmamÄ±z gerekir ?.",
    "->  Merhabalar -> ,Bir Ã¶rnek ile aÃ§Ä±klayacak olursam ÅŸÃ¶yle sÃ¶ylÃ¼yebiliriz. Ã–rneÄŸin Meslek adÄ±nda bir Ã¶zelliÄŸimiz olsun. Ve bu bilgi karakter olarak tutuluyor. (MÃ¼hendis, Doktor, Ã–ÄŸretmen, Avukat vb.)Bu bilgileri sparse encoding ÅŸeklinde kodladÄ±ÄŸÄ±mÄ±zda MÃ¼hendis iÃ§in 1, Doktor iÃ§in 2, Ã–ÄŸretmen iÃ§in 3 ve Avukat iÃ§in de 4 numaralÄ± indeksler ile ifade etmiÅŸ olduÄŸumuzu dÃ¼ÅŸÃ¼nelim.Burada ( 4 > 1) Avukat MÃ¼hendis'ten bÃ¼yÃ¼k deÄŸildir. Elimizdeki deÄŸerler nÃ¼merik ama bunlar arasÄ±nda matematiksel iÅŸlemler yapÄ±lmamalÄ±..",
    " "
]
},
{
"question_isim": "-> uploaded 1 photo",
"quest": "Sparse gÃ¶steriminde, one hot encoding yaptÄ±ktan sonra oluÅŸan ve Ã§oÄŸunluÄŸu 0'larla dolu vektÃ¶rÃ¼ kullanÄ±rken, sadece dolu kÄ±sÄ±mlarÄ±nÄ± ele alan bir representation'dan bahsedilmiÅŸ. Bu gÃ¶sterimde (saÄŸdaki tabloda yani) dolu olan kutunun indexi bulunan sÃ¼tunu feature sÃ¼tununa mÄ± ekliyoruz? EÄŸer Ã¶yle yapÄ±yorsak modelimizi kÃ¶tÃ¼ etkilemez mi? Bu kÄ±smÄ± tam anlamadÄ±m. Åimdiden teÅŸekkÃ¼r ederim",
"comment": [
    "",
    "-> BurasÄ± benim de kafamÄ± karÄ±ÅŸtÄ±rdÄ±. Åu ÅŸekilde yorumladÄ±m; Sparse representation 0 harici deÄŸerleri indisleriyle birlikte tutuyor, bunu da vektÃ¶r Ã§arpÄ±mÄ± vb. iÅŸlemlerde hÄ±z kazanmak iÃ§in yapÄ±yor (boÅŸuna 0 olan elemanlar ile Ã§arpma yapmamak iÃ§in) Ancak bunu feature olarak kullanmak istediÄŸimizde tekrardan \"dense\" haline Ã§evrilmesi gerekiyor. Bkz: https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensortf.sparse.SparseTensor Â |Â  TensorFlow Core v2.1.0www.tensorflow.orghttps://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor.",
    "-> -> Feature matrisindeki sÃ¼tun sayÄ±mÄ±z deÄŸiÅŸmiyor ve elimizdeki sparse tablosu featurelardan ayrÄ±ca bulunan bir bilgi, onu sadece iÅŸlem yaparken kolaylÄ±k olsun diye kullanÄ±yoruz . DoÄŸru anlamÄ±ÅŸ mÄ±yÄ±m?.",
    "-> -> Evet, en azÄ±ndan ben bu ÅŸekilde anladÄ±m. Mentor arkadaÅŸlarÄ±mÄ±z da yorumlarsa daha net bilgi edinmiÅŸ oluruz..",
    "-> -> TamamdÄ±r teÅŸekkÃ¼r ederim.",
    "->  Merhabalar aynÄ± soru olduÄŸundan ÅŸurada cevaplamaya Ã§alÄ±ÅŸtÄ±m.http://community.globalaihub.com/community/status/918-918-1587034561/#comment.4209.4144.4144.",
    "-> ->  AÃ§Ä±klayÄ±cÄ± olmuÅŸ teÅŸekkÃ¼rler.",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba,  Feature Crosses Programming Exercise kÄ±smÄ±nda aÅŸaÄŸÄ±daki parametrenin iÅŸlevini anlayamadÄ±m;  --------------------------------------- # Create a feature cross of latitude and longitude. latitude_x_longitude = tf.feature_column.crossed_column([latitude, longitude], hash_bucket_size=100) ---------------------------------------  Burada \"hash_bucket_size\" parametresi tam olarak neyi ifade ediyor ve deÄŸeri neye gÃ¶re belirleniyor?  TeÅŸekkÃ¼rler ÅŸimdiden.",
"comment": [
    "",
    "->  Merhaba,Feature Crossing yaptÄ±ÄŸnÄ±z anda ortaya Ã§Ä±kacak yeni binary vector'daki eleman sayÄ±sÄ±nÄ± temsil etmektedir. Ã–rneÄŸin elinizde resimdeki gibi bir feature crossing output'u olsun. Burada binary vector listesindeki(bu listedeki binary vectorlerin her biri yeni bir feature deÄŸeridir Ã§Ã¼nkÃ¼ biz iki feature'Ä± Ã§arptÄ±ÄŸÄ±mÄ±zda yeni featurelar elde ederiz.) her bir binary vector hash bucket, her bir hash bucket iÃ§indeki eleman sayÄ±sÄ± hash_bucket_size olur. Peki bu deÄŸeri az verirsek ne olur?EÄŸer hash_bucket_size'Ä± 100 deÄŸil de 10 verseydik kategorilenmiÅŸ verilerimizin Ã§arpÄ±m sonuÃ§ verktÃ¶rÃ¼nÃ¼n daha kÃ¼Ã§Ã¼k bir binary vector'de toplanmasÄ±nÄ± zorlayacaktÄ±k. Bu da birbiri ile alakasÄ±z kategorilerin aynÄ± alanda maplenmesine yol aÃ§abilirdi. Bu yÃ¼zden de modelimiz bu iki alakasÄ±z veriyi aynÄ± kategoriden sayacaktÄ±.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 5 people like this.Like ReportReply",
    "->  ->  CevabÄ±nÄ±z iÃ§in Ã§ok teÅŸekkÃ¼rler. Peki bu deÄŸerin parametre olarak kullanÄ±cÄ± tarafÄ±ndan girilmesinin spesifik bir sebebi var mÄ±? Yani tf.feature_column.crossed_column() fonksiyonuna latitude ve longtitude feature'larÄ±nÄ± verdiÄŸimizde bu \"hash_bucket_size\" deÄŸeri kullanÄ±cÄ±ya bÄ±rakÄ±lmadan da hesaplanabilirdi diye dÃ¼ÅŸÃ¼nÃ¼yorum. Tekrardan teÅŸekkÃ¼rler..",
    "->  ->  Merhaba,AnladÄ±ÄŸÄ±m kadarÄ±yla feature crossing verdiÄŸimiz orjinal featurelarÄ± alÄ±p onlarÄ± Ã§arpar ve berlirlediÄŸimiz hash_bucket_size kadar bucketlar iÃ§ine bu Ã§arpÄ±lan deÄŸerleri yerleÅŸtirir.hash_bucket_size deÄŸerini vermemiz, bÃ¼tÃ¼n ihtimal dahilinde kalan indis sayÄ±sÄ±nÄ± (featurelar Ã§arpÄ±ldÄ±ktan sonra) bilmeden Ã¶nce, modelimizi kayÄ±p verme riski olsa dahi oluÅŸturmamÄ±za yaramaktadÄ±r. Kaynak: https://stackoverflow.com/a/45219489/6139104Ä°yi Ã§alÄ±ÅŸmalar.",
    "what TensorFlow hash_bucket_size mattersstackoverflow.comI am creating a DNNclassifier with sparse columns. The training data looks like this, samples col1 col2 price label eg1 [[0,1,0,0,0,2,0,1,0,3,...] [....",
    "->  ->  TeÅŸekkÃ¼rler..",
    "->  10 buckets for latitude.10 buckets for longitude. OlduÄŸu iÃ§in hash_bucket_size=100 oluyor. YanlÄ±ÅŸÄ±m varsa dÃ¼zeltirseniz sevinirim.1 month ago 4 people like this.Like ReportReply",
    "->  ->  DoÄŸru, 10x10 feature deÄŸeri size 100 feature deÄŸeri verir yani feature crossing yaptÄ±ÄŸÄ±nÄ±zda 100 elemanlÄ± yeni bir binary vector elde edersiniz. Benim resimde verdiÄŸim Ã¶rnek longitude ve latitufe deÄŸerleri iÃ§in deÄŸil, sadece bucket'Ä± gÃ¶sterebilmek adÄ±na baÅŸka bir Ã¶rnekti. AÃ§Ä±klamanÄ±z iÃ§in teÅŸekkÃ¼rler, iyi Ã§alÄ±ÅŸmalar.1 month ago 2 people like this.Like ReportReply",
    "->  ->  Ben teÅŸekkÃ¼r ederim. Ä°yi Ã§alÄ±ÅŸmalar dilerim..",
    "->  ->  CevabÄ±nÄ±z iÃ§in teÅŸekkÃ¼rler..",
    " "
]
},
{
"question_isim": "->  uploaded 1 photo",
"quest": "Merhabalar, log ve min fonksiyonlarÄ± tam olarak ne iÅŸlev yaptÄ±ÄŸÄ± iÃ§in grafikler deÄŸiÅŸti ve neden 1.kodda( total_room/population+1) yani neden +1 dedik, 2.kodda  (total_room/population, 4) dedik ,4 Ã¼n iÅŸlevi nedir. TeÅŸekkÃ¼r ederim.",
"comment": [
    "",
    "->  Merhabalar,Log fonksiyonu verisetindeki her roomsPerPerson verisinin logaritmasÄ±nÄ± alÄ±yor. LogaritmasÄ± alÄ±nan deÄŸerler kÃ¼Ã§Ã¼lÃ¼yor ve kÃ¼Ã§Ã¼len bu yeni deÄŸerlerle yeni bir grafik oluÅŸturulduÄŸunda bile hala outlier yani diÄŸer verilerden Ã§ok uzakta verilerin olduÄŸu gÃ¶rÃ¼nÃ¼yor. Bunun nedeni ise roomsPerPerson feature deÄŸerleri normalde 3-4-5 gibi deÄŸerler iken bizim outlier deÄŸerimiz 50 ve 5 ile 50'nin logaritmasÄ± alÄ±nsa bile aralarÄ±nda yine bir aÃ§Ä±klÄ±k olacaktÄ±r.Bizim istediÄŸimiz verisetimizdeki bu outlier sorununu gidermek. Bunun iÃ§in ise yapabileceÄŸimiz ÅŸey roomsPerPerson iÃ§in kendimiz bir maksimum deÄŸer belirlemek (Ã¶rneÄŸin 4 belirlemiÅŸ olalÄ±m) ve o maksimum deÄŸerden bÃ¼yÃ¼k her deÄŸeri (Ã¶rneÄŸin outlier deÄŸerimiz 50) belirlediÄŸimiz maksimum deÄŸere eÅŸitleyelim.min fonksiyonu ise totalRooms/population iÅŸlemini yapÄ±yor ama bu deÄŸer 4'ten bÃ¼yÃ¼k ise 4 deÄŸerini alÄ±yor.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 2 people like this.Like ReportReply",
    "-> ->  ama sonuÃ§ta 4 deÄŸeri normal deÄŸerlerden yÃ¼ksek deÄŸil mi yinede.. YANÄ°, daÄŸÄ±lÄ±mdan uzakta... Burada onun seÃ§ilmesinin nedeni nedir?.",
    "->  -> ->  'nÄ±n paylaÅŸtÄ±ÄŸÄ± resme bakarsanÄ±z burada deÄŸer daÄŸÄ±lÄ±mlarÄ±nÄ±n 4'Ã¼ de kapsadÄ±ÄŸÄ±nÄ± ve 4'Ã¼n outlier deÄŸer olmadÄ±ÄŸÄ±nÄ± gÃ¶rebilirsiniz. Siz sanÄ±rÄ±m logaritma alÄ±ndÄ±ktan sonraki grafik iÃ§in konuÅŸuyorsunuz. Burada logaritma alÄ±p bu iÅŸin iÃ§inde Ã§Ä±kacaÄŸÄ±nÄ±zÄ± dÃ¼ÅŸÃ¼nebilirsiniz ama bu ÅŸekilde de outlier sorununu Ã§Ã¶zemediniz, o yÃ¼zden logaritma alma yaklaÅŸÄ±mÄ±na girmeden cap veya clip yÃ¶ntemini kullanabilirsiniz denmiÅŸ. 4 seÃ§ilmesinin belli bir nedeni yok, bu deÄŸerin ne olacaÄŸÄ± tamamen size kalmÄ±ÅŸ 5 de alabilirdik 3 de 6 da..",
    "->  aykÄ±rÄ±lÄ± deÄŸerleri onlemek adÄ±na 4 den bÃ¼yÃ¼k deÄŸerler alÄ±rsa bu deÄŸerler 4 olarak sabitleniyor diye anladÄ±m ben..",
    "-> +1 denmesinin sebebi \"log\" fonksiyonunun 0 deÄŸeri iÃ§in tanÄ±msÄ±z olmasÄ±ndan kaynaklanÄ±yor. (totalRooms/population) = 0 olmasÄ± durumunda roomsPerPerson hesaplanabilmesi iÃ§in +1 deÄŸeri eklenmiÅŸ, +1 yerine +0.00001 de eklenebilirdi.1 month ago 2 people like this.Like ReportReply",
    "->  -> Merhaba, bu durum iÃ§in +0.00001 deÄŸeri eklenmesi muhtemelen doÄŸru olmazdÄ± Ã§Ã¼nkÃ¼ log fonksiyonunda 0-1 arasÄ± deÄŸerler negatif deÄŸerler vereceÄŸinden tablomuz gerÃ§ekten uzaklaÅŸmÄ±ÅŸ olurdu diye dÃ¼ÅŸÃ¼nÃ¼yorum..",
    "-> ->  Evet +1 bu Ã¶rnek iÃ§in en doÄŸrusu. Ä°lgili feature'Ä±n negatif deÄŸer almasÄ± bir anlam ifade etmiyor. (0,+] aralÄ±ÄŸÄ±nda normalize olmasÄ± dediÄŸiniz gibi daha uygun..",
    " "
]
},
{
"question_isim": "->  uploaded 1 photo",
"quest": "Ã–ncelikle merhabalar, representation-qualities of good features kÄ±smÄ±nda bu ifadeyi tam olarak anlayamadÄ±m. Bu kÄ±sÄ±m ile ilgili bir aÃ§Ä±klama yapabilir misiniz? TeÅŸekkÃ¼r ederim.",
"comment": [
    "",
    "->  Merhaba,Az Ã¶nce bu kÄ±sÄ±mlarÄ± http://community.globalaihub.com/community/status/190-190-1586982868/#comment.4163.4048.4048 linkindeki yorumumda aÃ§Ä±klamaya Ã§alÄ±ÅŸtÄ±m ğŸ™‚ AklÄ±nÄ±za bir ÅŸey takÄ±lÄ±rsa tekrardan cevaplayabilirim.Ä°yi Ã§alÄ±ÅŸmalar..",
    "->  ->  gayet anlaÅŸÄ±labilir bir yorum olmuÅŸ, aÃ§Ä±klamanÄ±z iÃ§in teÅŸekkÃ¼r ediyorum ğŸ™‚.",
    " "
]
},
{
"question_isim": "->  uploaded 1 photo",
"quest": "Merhaba,  Resimdeki kÄ±smÄ± genel olarak anlayamadÄ±m.Burada tam olarak ne demek istiyor acaba?  TeÅŸekkÃ¼rler:)",
"comment": [
    "",
    "-> Merhaba,Bu kÄ±sÄ±mda demek istediÄŸini resimedki Ã¶rnek Ã¼zerinden anlatayÄ±m.Elinizde bir verisetin var ve verisetinde quality_rating isimli bir feature var. Bu feature'Ä±n deÄŸerinini girilmediÄŸi veri Ã¶rnekleriniz olabilir. Siz burada ÅŸÃ¶yle bir yaklaÅŸÄ±mda bulunabilirsiniz:EÄŸer quality_rating isimli feature'Ä±nÄ±zÄ±n verisi girilmemiÅŸ ise siz el ile -1 atayabilirsiniz ve -1 olan quality_rating feature'Ä±nÄ±n aslÄ±nda verisi girilmemiÅŸtir diyebilirsiniz. Ama bu yanlÄ±ÅŸtÄ±r Ã§Ã¼nkÃ¼ siz -1 koyarak quality_rating feature'nÄ±n varsayÄ±lan aralÄ±ÄŸÄ± olan 0-1 arasÄ±ndaki deÄŸerlerden farklÄ± bri deÄŸere girdiniz. Bu aynÄ± zamanda modelinizin Ã¶ÄŸrenme sÄ±rasÄ±nda da performansÄ± dÃ¼ÅŸÃ¼recek ve hatalÄ± tahminlere yol aÃ§acaktÄ±r. Bunun Ã¶nÃ¼ne ÅŸÃ¶yle geÃ§ebilirsiniz:Bool tipinde (0 veya 1 alan) bir feature oluÅŸturursunuz ve bu feature deÄŸeriniz sizin quality_rating feature'Ä±nÄ±zÄ±n deÄŸerinin girilip girilmediÄŸi bilgisini tutar. quality_rating girilmiÅŸse yeni bool feature'Ä±nÄ±za 1, girilmemiÅŸse 0 verdiÄŸinizi varsayalÄ±m. Peki iÅŸimiz bitti mi? HayÄ±r ama Ã§ok az kaldÄ± :)EÄŸer sizin quality_rating deÄŸeriniz discrete bir deÄŸer ise yani alabileceÄŸi deÄŸerler sÄ±nÄ±rlÄ±ysa: feature deÄŸerinin kayÄ±p olduÄŸunu belli eden bir deÄŸer ekleyin (Ã¶rneÄŸin elinizde sadece 0,1 deÄŸerleri var ise 2 deÄŸerini ekleyip bu 2'nin sadece girilmemiÅŸ deÄŸerler iÃ§in kullanÄ±ldÄ±ÄŸÄ±nÄ± belirtebilrisiniz. resimdeki Ã¶rnekte quality_rating continuos bir deÄŸer olduÄŸu iÃ§in bu yÃ¶ntem orada iÅŸe yaramaz.).EÄŸer sizin quality_rating deÄŸeriniz continuous bir deÄŸer ise: bu kayÄ±p deÄŸerlerin modeli etkilememesi iÃ§in quality_rating feature datalarÄ±nÄ±n ortalama deÄŸerlerini girilmemiÅŸ kÄ±sÄ±mlara yazÄ±n.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 13 people like this.Like ReportReply",
    "->  ->  feature deÄŸerlerimizin continuous veya discrete olmasÄ±, problemimizin classification veya regression olduÄŸunu belirlemiyor diye biliyorum, yazdÄ±ÄŸÄ±nÄ±zdan Ã¶yle anlaÅŸÄ±lÄ±yor ya da ben mi yanlÄ±ÅŸ anladÄ±m ? Ya da siz quality_rating'i bizim tahmin etmek istediÄŸimiz deÄŸer olarak aldÄ±nÄ±z.1 month ago 3 people like this.Like ReportReply",
    "->  ->  Merhaba, anlÄ±k kafa karÄ±ÅŸÄ±klÄ±ÄŸÄ±yla quality_rating'i label olarak almÄ±ÅŸÄ±m. DÃ¼zeltme iÃ§in teÅŸekkÃ¼rler ğŸ™‚1 month ago 3 people like this.Like ReportReply",
    "->  ->  is_quality_rating_defined bool feature yarattÄ±ÄŸÄ±mÄ±z yeterli deÄŸil mi? Continuous deÄŸerlerde ortalama ile deÄŸiÅŸtirmeye gerek yok diye dÃ¼ÅŸÃ¼nÃ¼yorum. Bu feature'i iÅŸlerken oluÅŸturduÄŸumuz bool feature bakarak bu boÅŸ deÄŸerlere goz ardi edebiliriz. Neyi etkiler bu eÄŸer deÄŸiÅŸtirmezsek?.",
    "->  ->  BildiÄŸim kadarÄ±yla belli featurelarÄ± gÃ¶z ardÄ± etme diye bir ÅŸey yok, sadece o feature'Ä±n mensup olduÄŸu veri Ã¶rneÄŸini gÃ¶z ardÄ± edebilirsiniz ama ya iki feature'Ä±nÄ±z var ise ve biri boÅŸ biri doluysa o zaman bu veri Ã¶rneÄŸini gÃ¶z ardÄ± etmekten sÃ¶z edemeyiz. Bu yÃ¼zden de bu veri Ã¶rneÄŸini alabilmek ama alÄ±rken de boÅŸ olan feature deÄŸerinin feature ortalamasÄ±na etki etmemesi iÃ§in ortalamayÄ± feature deÄŸeri olarak verebiliriz..",
    "->  ->  Genel tekrar yaparken aklÄ±ma bir ÅŸey takÄ±ldÄ± sormak istedim. Continuous ise ortalama alÄ±yoruz. Discrete ise o deÄŸerin yazÄ±lmadÄ±ÄŸÄ±nÄ± belli eden bir sÄ±nÄ±f oluÅŸturuyoruz. is_quality_rating diye ekstra Ã¶zellik aÃ§manÄ±n gerekliliÄŸi nedir? Buradan modelin quality belirlenenlere daha yÃ¼ksek bir aÄŸÄ±rlÄ±k verdiÄŸi mi anlaÅŸÄ±lmalÄ±?.",
    "->  ->  Merhaba,https://medium.com/@ftfethi/makine-%C3%B6%C4%9Frenmesinde-ham-veri-den-%C3%B6znitelik-%C3%A7%C4%B1karmak-8a6e234ada46 linkindeki yazÄ±mÄ±n 3.maddesinde bu konuya detaylÄ± deÄŸinmeye Ã§alÄ±ÅŸtÄ±m. EÄŸer aklÄ±nÄ±za takÄ±lan bir ÅŸey olursa sormaktan Ã§ekinmeyin.Ä°yi Ã§alÄ±ÅŸmalar.",
    "Makine Ã–ÄŸrenmesiâ€™nde Ham Veriâ€™den Ã–znitelik Ã‡Ä±karmakmedium.comMerhabalar,Â  UmarÄ±m hepiniz evinizde saÄŸlÄ±klÄ±, mutlu ve verimli gÃ¼nler geÃ§iriyorsunuzdur. Yeni bir yazÄ±mla karÅŸÄ±nÄ±zda olmanÄ±n vermiÅŸâ€¦.",
    "->  ->  TeÅŸekkÃ¼r ederim okuyacaÄŸÄ±m..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba,  Representation kÄ±smÄ±nda kategorik deÄŸerler iÃ§in one-hot-encoding kullanÄ±ldÄ±ÄŸÄ±nÄ± anlatÄ±yor.Bu kullanÄ±mda feature iÃ§in tek bir aÄŸÄ±rlÄ±k var deÄŸil mi ?Bu aÄŸÄ±rlÄ±k bu binary vector ile Ã§arpÄ±lÄ±nca mesela [0,0,5.0] yada [5,0,0,0] oluyor ikisi iÃ§inde 5 deÄŸerimi toplanacak?  Birde seyrek temsilden bahsediliyor.Bunu nasÄ±l kullanacaÄŸÄ±mÄ±zÄ± anlamadÄ±m.Her bir kategorik deÄŸer iÃ§in sayÄ±sal deÄŸer atÄ±caz fakat her biri iÃ§in farklÄ± aÄŸÄ±rlÄ±klar elde edicez olarak anladÄ±m ,ama peki nasÄ±l her biri iÃ§in farklÄ± aÄŸÄ±rlÄ±k elde edilcek?  TeÅŸekkÃ¼rler",
"comment": [
    "",
    "-> Merhaba Buse,One-Hot-Encoding yaptÄ±ÄŸÄ±nda bahsettiÄŸin vektÃ¶rdeki her bir deÄŸer ayrÄ± bir feature oluyor ve farklÄ± weight deÄŸerleri alÄ±yorlar. Ã–rneÄŸin elindeki datasette ÅŸehir adlarÄ±nÄ±n olduÄŸu bir feature var ve iÃ§erisinde [\"Ä°stanbul\", \"Ankara\", \"Ä°zmir\", \"Bursa\"] kategorik deÄŸerleri var. One-Hot-Encoding yaptÄ±ÄŸÄ±n zaman bu deÄŸerler datasete kolon olarak eklenirler. [\"Ä°stanbul\", \"Ankara\", \"Ä°zmir\", \"Bursa\"] kolon adlarÄ± olmak Ã¼zere eÄŸer satÄ±rda bu deÄŸerler geÃ§iyorsa 1, geÃ§miyorsa 0 olur. Mesela ilgili satÄ±rda \"Ankara\" var ise [0,1,0,0] olur. Bu deÄŸerleri feature olarak eklediÄŸimiz iÃ§in her birinin weight deÄŸeri farklÄ± olacaktÄ±r, Ã§Ã¼nkÃ¼ normal ÅŸartlarda her bir ÅŸehir adÄ±nÄ±n sÄ±nÄ±flandÄ±rma sonucuna etkisi farklÄ± Ã§Ä±kmalÄ±dÄ±r.Seyrek temsil olarak bahsettiÄŸin yani sparse represantation iÃ§in ise yukarÄ±da verdiÄŸim Ã¶rneÄŸe ek olarak tÃ¼m dÃ¼nya ÅŸehirlerini kullandÄ±ÄŸÄ±mÄ±zÄ± dÃ¼ÅŸÃ¼nelim. DÃ¼nya Ã¼zerinde yaklaÅŸÄ±k 2.5 milyon ÅŸehir var ve her biri iÃ§in bir kolon oluÅŸturup sadece ismi geÃ§en ÅŸehri 1 ile iÅŸaretleyip diÄŸerlerini 0 yapmak pek mantÄ±klÄ± deÄŸil.Bu gibi durumlarda kullanÄ±lÄ±yor ve sadece 1 olan yani ilgili satÄ±rda geÃ§en kategorik deÄŸerler gÃ¶steriliyor..",
    "->  ->  Sparse representationÄ±n ne olduÄŸunu tam olarak anlayamadÄ±m sadece kelime sayÄ±sÄ± milyonlarÄ± bulduÄŸunda one hot encodinging yetersiz kaldÄ±ÄŸÄ± durumlarda kullanÄ±lÄ±yor diye anladÄ±m sparse repin kullanÄ±mÄ± aklÄ±mda pek canlanmadÄ±. Ä°nternettede baya karmaÅŸÄ±k formÃ¼ller var yanlÄ±ÅŸ anlamadÄ±ysam sparse rep. konusu sÃ¶zlÃ¼ olarak anlatmaya pek mÃ¼sait deÄŸil?.",
    "->  ->  Seyrek temsil iÃ§in verdiÄŸiniz Ã¶rnekten gidecek olursak sadece Ankara ÅŸehir kolonunda 1 olan bir Ã¶rnek iÃ§in sadece \"Ankara\" feature'Ä± mÄ± tutuluyor? Geri kalan kolonlara 0 deÄŸerleri feature engineering adÄ±mlarÄ±nda mÄ± ekleniyor?.",
    "->  ->  Seyrek gÃ¶sterimi (Sparse representation) ÅŸu ÅŸekilde aÃ§Ä±klamaya Ã§alÄ±ÅŸayÄ±m. Seyrek gÃ¶sterim veri setinde sadece sÄ±fÄ±r olmayan Ã¶zelliklerin (feature) gÃ¶sterildiÄŸi Ã¶zellikle bÃ¼yÃ¼k (big data) veri setlerinde kullanÄ±lan bir gÃ¶sterim ÅŸeklidir. GÃ¶rsel ile aÃ§Ä±klamaya Ã§alÄ±ÅŸtÄ±m.1 month ago 3 people like this.Like ReportReply",
    "->  ->  TeÅŸekkÃ¼rler.Peki sparse representation 'da 1000 kategorik deÄŸer varsa 1000 feature eklemiyo muyum yani?Bu kÄ±smÄ± gene anlayamadÄ±m..",
    "->  ->  Ama her Ã¶rnek iÃ§in O olmayan deÄŸer deÄŸiÅŸecek.Mesela ÅŸehir bir Ã¶rnekte Ankara,diÄŸerinde Ä°zmir?Gene hepsi iÃ§in feature olmasÄ± lazÄ±m yoksa her example iÃ§in aynÄ± feature mÄ± olacak yani?.",
    "-> ->  evet yine 1000 feature ekleniyor ancak sparse matrix olarak ekleniyorlar. Tensorflow Ã¼zerinde Ã§alÄ±ÅŸÄ±rken bunun ile ilgili metodlar var.BildiÄŸin gibi bir yazÄ±lÄ±m dilinde(Python iÃ§in konuÅŸalÄ±m) variable iÃ§ine matris tanÄ±mlarsan (Numpy ile) onun uzunluÄŸu kadar hafÄ±zada yer kaplayacaktÄ±r. EÄŸer elimizde bahsettiÄŸimiz Ã¶lÃ§Ã¼de bÃ¼yÃ¼k bir matris var ise memory Ã¼zerine yazÄ±lamaz Ã§Ã¼nkÃ¼ matris iÃ§erisindeki 0'lar da yer kaplar. Bu noktada sparse matrixler kullanÄ±lÄ±r, bu matrisler farklÄ± mapping teknikleri ile 0 olan verileri boÅŸ olarak alÄ±r, sadece deÄŸer iÃ§eren veriler matris iÃ§erisinde depolanÄ±r. DolayÄ±sÄ±yla memory problemi oluÅŸmaz. Sparse matrixleri kullanmak iÃ§in Python'da Scipy kÃ¼tÃ¼phanesini kullanabilirsin.AÅŸaÄŸÄ±da bu konu ile ilgili yazÄ±larÄ± bulabilirsin ancak Machine Learning iÃ§in ÅŸimdilik bu konularÄ±n detaylarÄ±nÄ± bilmek zorunda deÄŸilsin, merak ettiÄŸin iÃ§in paylaÅŸÄ±yorum :)FarklÄ± Sparse Matrix tÃ¼rleri:https://matteding.github.io/2019/04/25/sparse-matrices/Ä°leri okuma iÃ§in:https://dziganto.github.io/Sparse-Matrices-For-Efficient-Machine-Learning/Sparse Matrices Â· Matt Edingmatteding.github.iohttps://matteding.github.io/2019/04/25/sparse-matrices/1 month ago 2 people like this.Like ReportReply",
    "-> One hot encoding yaptÄ±ÄŸÄ±mÄ±zda bir nitelikten, nitelikte bulunan dÃ¼zey sayÄ±sÄ± kadar yeni nitelik elde ederiz. Ã–rneÄŸin ÅŸehir niteliÄŸimizde Ä°stanbul,Ankara ve Ä°zmir dÃ¼zeyleri olsun. Åehir niteliÄŸine one-hot encoding yaptÄ±ÄŸÄ±mÄ±zda is_Ä°stanbul, is_Ankara , is_Ä°zmir ÅŸeklinde yeni nitelikler elde ederiz.Ã–rnek olarak ÅŸÃ¶yle bir verimiz olsunbuyukluk (m2), ÅŸehir, oda_sayisi, fiyat135 , Ä°zmir, 3 , 270000buna one-hot encoding uyguladÄ±ÄŸÄ±mÄ±zda verimizdeki nitelikler ve deÄŸerleribuyukluk (m2), is_Ä°stanbul, is_Ankara, is_Ä°zmir, oda_sayisi, fiyat135 , 0, 0 , 1, 3, 270000e dÃ¶nÃ¼ÅŸÃ¼r. ArtÄ±k modele girecek veri gÃ¶sterimi son elde ettiÄŸimiz gÃ¶sterim. Yani her bir nitelik iÃ§in ayrÄ± bir aÄŸÄ±rlÄ±ÄŸa sahip olacaÄŸÄ±z. DolayÄ±sÄ±yla is_Ä°stanbul, is_Ankara ve is_Ä°zmir niteliklerinin aÄŸÄ±rlÄ±klarÄ± birbirinden farklÄ± olacak1 month ago 2 people like this.Like ReportReply",
    "->  Fatih Bey'in Ã¶rneÄŸinden devam ederek anlatayÄ±m, farkettiyseniz burada sayÄ± ile Ã¶lÃ§Ã¼lemeyen Ã¶zelliÄŸimiz \"ÅŸehir bilgisi\". One hot encoding ile ÅŸehir Ã§eÅŸidi kadar yeni Ã¶zelliÄŸi (yani sÃ¼tunu) tablomuza eklediÄŸimizi dÃ¼ÅŸÃ¼nÃ¼n, yani her bir ÅŸehir ismi iÃ§in tabloya bir sÃ¼tun daha ekliyoruz, bunlar Ä°stanbul, Ankara ve Ä°zmir iÃ§in birer yeni sÃ¼tun oluyor Ã¶rnekte. Bizim gÃ¶zlemimizdeki (yani satÄ±rÄ±mÄ±zdaki) ev hangi ÅŸehirde ise o sÃ¼tunumuz 1, diÄŸerleri 0 oluyor. Bu ÅŸekilde gÃ¶zlemimizin o Ã¶zelliÄŸini kodlamÄ±ÅŸ oluyoruz. Ben en basit haliyle bu ÅŸekilde kullanÄ±yorum. UmarÄ±m anlatabilmiÅŸimdir.1 month ago 3 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "ArkadaÅŸlar merhaba. Ben \"Feature Crosses\" bÃ¶lÃ¼mÃ¼nÃ¼ etkinliklere raÄŸmen genel olarak anlayamadÄ±m. Ä°nternet Ã¼zerinde faydalÄ± bir site veya video ÅŸeklinde bir kaynak bulamadÄ±m. Bu konuyla ilgili bir site ya da herhangi bir kaynak bilgisi olan var mÄ±? Ä°yi Ã§alÄ±ÅŸmalar ğŸ™‚",
"comment": [
    "",
    "->  Merhaba,http://community.globalaihub.com/community/status/774-774-1586937745/#comment.4123.4009.4009 linkinde Feature Cross'u genel hatlarÄ±yla kabaca anlatmaya Ã§alÄ±ÅŸtÄ±m. EÄŸer bu kÄ±sÄ±mda sorularÄ±nÄ±z eksik gÃ¶rdÃ¼ÄŸÃ¼nÃ¼z veya anamadÄ±ÄŸÄ±nÄ±z yer olursa bu post altÄ±ndan daha aÃ§Ä±klamalÄ± halini yazmaya Ã§alÄ±ÅŸabilirim. AyrÄ±ca Andrew Ng'nin Coursera'daki Machine Learning kursununda da bunun aÃ§Ä±klamasÄ± mevcut, o kursu da Ã¶nerebilirim.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 3 people like this.Like ReportReply",
    "->  Ã‡ok teÅŸekkÃ¼r ederim..",
    "->  Ufak bir sorum daha olacak : Feature Crosses bÃ¶lÃ¼mÃ¼nÃ¼n Playground Exercise kÄ±smÄ±ndaki Task 1'de learning rate'den bahsedilmiÅŸ, orada \"non-linear\" model'de learning rate'in yakÄ±nsama deÄŸerine etkili olmadÄ±ÄŸÄ± mÄ± anlatÄ±lmaya Ã§alÄ±ÅŸÄ±lmÄ±ÅŸ?.",
    "->  ->  Merhaba,-> 'nÃ¼n de dediÄŸi gibi lineer modelleme bu verisetini efektif bir ÅŸekilde modelleyemiyor. Learning rate deÄŸerini deÄŸiÅŸtirmemiz lossumuzu yine azaltacaktÄ±r yani etkileyecektir ama en kadar azaltÄ±rsa azaltsÄ±n loss halen kabul edilemez dÃ¼zeyde yÃ¼ksek bir deÄŸere yakÄ±nsar, optimum deÄŸere yakÄ±nsayamaz. Yani learning rate yakÄ±nsamamÄ±zÄ± etkiler ama yeterli dÃ¼zeyde etkilemez.Ä°yi Ã§alÄ±ÅŸmalar..",
    "->  Merhaba Nil HanÄ±m, bahsettiÄŸiniz egzersizin \"Task 1\" bÃ¶lÃ¼mÃ¼nde linear modeli verilen ÅŸekliyle Ã§alÄ±ÅŸtÄ±rÄ±lmasÄ± istenmiÅŸ. VerildiÄŸi ÅŸekliyle de \"feature\" olarak sadece x1 ve x2 var yani feature cross olmadan verilen data seti linear olarak modelleyebilir miyiz'in cevabÄ±nÄ± sorgulamamÄ±z isteniyor. Learning rate loss'u azaltsa da verilen data setten linear bir model Ã§Ä±karmamÄ±z sÃ¶z konusu deÄŸil anladÄ±ÄŸÄ±m kadarÄ±yla.1 month ago 2 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "->  uploaded 1 photo",
"quest": "Merhaba, Representation: Cleaning Data bÃ¶lÃ¼mÃ¼ndeki, Scaling feature values baÅŸlÄ±ÄŸÄ±ndaki maddeleri ve floating-point teriminin ne olduÄŸunu anlayamadÄ±m, yardÄ±mlarÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederim.",
"comment": [
    "",
    "-> Merhaba,1- Siz bir feature alanÄ±nÄ± scale ettiÄŸinizde gradient descent algoritmasÄ±, feature deÄŸeri daha da kÃ¼Ã§Ã¼ldÃ¼ÄŸÃ¼nden dolayÄ± daha hÄ±zlÄ± optimum deÄŸere yakÄ±nsar.2-Scale etmek NaN tuzaÄŸÄ±nÄ± engellemenize yarayacaktÄ±r. NaN tuzaÄŸÄ± kavramÄ± ÅŸudur, EÄŸer sizin verisetinizde NaN (gerÃ§ek hayatta sayÄ±lar sonsuzdur ama bilgisayar donanÄ±mÄ±nÄ±n kÄ±sÄ±tladÄ±ÄŸÄ± bir sayÄ± sÄ±nÄ±rÄ± varÄ±dr. Bunu aÅŸmasÄ± durumunda NaN olacaktÄ±r. Peki nasÄ±l aÅŸabilir? BÃ¼yÃ¼k sayÄ±larla matematik iÅŸlemleri yaparsa bu sayÄ± NaN olabilir. O bÃ¼yÃ¼k sayÄ±yÄ± kÃ¼Ã§Ã¼ltmek ve belli bir range'e sokmak iÃ§in scale yapÄ±labilir.) bir veri var ise modeldeki diÄŸer sayÄ±larÄ±mÄ±zda eninde sonunda NaN olacaktÄ±r.3-Scale etmeniz modelinizin her bir feature'Ä±nÄ±z iÃ§in ilgili weight deÄŸerlerini Ã¶ÄŸrenmesi konusunda yardÄ±mcÄ± olacaktÄ±r Ã§Ã¼nkÃ¼ scale edilmemiÅŸ geniÅŸ aralÄ±ÄŸa sahip verilerde model weighr deÄŸerini Ã¶ÄŸrenmek iÃ§in daha Ã§ok kaynak ve zaman harcayacaktÄ±r.Floating point kavramÄ± aslÄ±nda reel sayÄ±larÄ±n bilgisayar alanÄ±ndaki adÄ±dÄ±r. Bu kavrama reel deÄŸil de floating-point denmesinin sebebi ise sayÄ± iÃ§erisindeki ondalÄ±k noktasÄ±nÄ±n kayabilme Ã¶zelliÄŸinden dolayÄ±dÄ±r. GerÃ§ek dÃ¼nyada sayÄ±lar sonsuza kadar giderken, bilgisayar ortamÄ±nda bilgisayar donanÄ±mÄ±nÄ±n getirdiÄŸi sÄ±nÄ±rlamalardan dolayÄ± bÃ¼tÃ¼n sayÄ±larÄ±n gÃ¶sterilmesi mÃ¼mkÃ¼n deÄŸildir. Bununla birlikte gerÃ§ekte sonsuza kadar giden birtakÄ±m deÄŸerler bilgisayar ortamÄ±nda ortamÄ±n kapasitesine baÄŸlÄ± olarak yaklaÅŸÄ±k deÄŸerlerle temsil edilirler. Bu sÄ±nÄ±rlamalarÄ±n etkisini en aza indiren, sayÄ±larÄ±n maksimum miktarda ve gerÃ§eÄŸe en yakÄ±n ÅŸekilde temsilini saÄŸlayan sisteme \"Kayan-NoktalÄ± SayÄ±lar\" sistemi denir. Kaynak ve daha fazlasÄ± iÃ§in: https://tr.wikipedia.org/wiki/Kayan_nokta adresini inceleyebilirsiniz.Ä°yi Ã§alÄ±ÅŸmalar.Kayan nokta - Vikipeditr.wikipedia.orghttps://tr.wikipedia.org/wiki/Kayan_nokta1 month ago 5 people like this.Like ReportReply",
    "->  ->  AÃ§Ä±klamanÄ±z iÃ§in teÅŸekkÃ¼r ediyorum ğŸ™‚.",
    "->  ->  peki scale iÅŸlemini nasÄ±l yapÄ±yoruz yani tam olarak neyi scale ettiÄŸimizi ve neye gÃ¶re sÄ±nÄ±rlarÄ± belirlediÄŸimiz anlayamadÄ±m.",
    "->  ->  Feature olarak kullanacaÄŸÄ±mÄ±z veri aralÄ±klarÄ±na bakÄ±yoruz. Zaten tek bir feature'Ä±mÄ±z var ise scale etmemiz gerekmiyor, birden fazla feature'Ä±mÄ±z var ise deÄŸer aralÄ±klarÄ±nÄ± karÅŸÄ±laÅŸtÄ±rabiliriz. Ã–rneÄŸin ev metrekaresi ve oda sayÄ±sÄ± featurelarÄ± deÄŸer aralÄ±ÄŸÄ± olarak aynÄ± dÃ¼zlemde olmayacaktÄ±r. (ev metrekaresi 50-300 arasÄ± skalada diyelim, oda sayÄ±sÄ± ise en fazla 10 olsun diyelim.) Bu durumda gradient descent fonksiyonumuzun daha hÄ±zlÄ± Ã§alÄ±ÅŸmasÄ± iÃ§in bu iki feature'Ä± benzer deÄŸer aralÄ±klarÄ±na sokmamÄ±z performansÄ± arttÄ±racaktÄ±r. Benzer dememin sebebi Ã¶rneÄŸin ev metrekaresi feature'Ä±nÄ± scale edip 50-300 aralÄ±ÄŸÄ±ndan -3Ã–zellik Ã–lÃ§ekleme ve NormalleÅŸtirme (Feature Scaling andÂ Normalization)1 month ago 3 people like this.Like ReportReply",
    "->  ->  TeÅŸekkÃ¼r ediyorum Ã§ok gÃ¼zel aÃ§Ä±klÄ±yorsunuz ????galiba yarÄ±sÄ± silinmiÅŸ yazÄ±nÄ±n.",
    "->  ->  Merhaba, yorumunuz iÃ§in teÅŸekkÃ¼r ederim ğŸ™‚ evet edit diyince yazÄ±nÄ±n tamamÄ± geliyor ama save diyince yarÄ±sÄ± gidiyor teknik bir problem var sanÄ±rÄ±m ğŸ™‚ Sizin iÃ§in ÅŸÃ¶yle bir ÅŸey yapabilirim ama, edit dediÄŸimde Ã§Ä±kan yazÄ±nÄ±n tamamÄ±nÄ± ekran gÃ¶rÃ¼ntÃ¼sÃ¼ alÄ±p atÄ±yorum. GÃ¶zlerinizden ÅŸimdiden Ã¶zÃ¼r diliyorum, iyi Ã§alÄ±ÅŸmalar diliyorum ğŸ™‚.",
    "->  ->  olur mu Ã¶yle ÅŸey ğŸ™‚ saolun kafamdaki soru iÅŸaretlerini giderdiÄŸiniz iÃ§in, kolay gelsin..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar. Regularization bÃ¶lÃ¼mÃ¼nÃ¼n son kÄ±smÄ±nda check your understanding 2. sorusunda sÄ±kÄ±ntÄ± yaÅŸadÄ±m. Cevap olarak 3 . ÅŸÄ±kkÄ± seÃ§tim verilen bir feature iÃ§inde noise olduÄŸu iÃ§in. Anlatabilecek birisi varsa Ã§ok sevinirim.",
"comment": [
    "",
    "->  Merhaba Mehmet,Regularization ile kastedilen modelin karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± azaltmaktÄ±r. Burada bahsedilen L2 ve daha sonra karÅŸÄ±laÅŸacaÄŸÄ±n L1 regularization ile modeldeki weight deÄŸerleri mÃ¼mkÃ¼n olduÄŸunca azaltÄ±lÄ±r. L2 regularization formÃ¼lÃ¼ gereÄŸi en yÃ¼ksek weight deÄŸerini hÄ±zlÄ±, dÃ¼ÅŸÃ¼k weight deÄŸerini ise yavaÅŸ ÅŸekilde 0'a yaklaÅŸtÄ±rÄ±r ancak tam olarak 0'a eÅŸitlemez. Ä°leride gÃ¶receÄŸin L1 regularization ise bazÄ± weightleri 0 yaparak model kompleksliÄŸini azaltÄ±r.\"One feature will have a large weight; the other will have a weight of almost 0.0.\" seÃ§tiÄŸin ÅŸÄ±kta bir feature'Ä±n yÃ¼ksek weight deÄŸerine sahip olacaÄŸÄ± diÄŸerinin ise 0'a yakÄ±nsayacaÄŸÄ±nÄ± sÃ¶ylÃ¼yor. Ancak L2 regularization yukarÄ±da da aÃ§Ä±kladÄ±ÄŸÄ±m gibi yÃ¼ksek weight deÄŸerini daha hÄ±zlÄ± bir ÅŸekilde azaltÄ±r ve modelde yÃ¼ksek weight deÄŸeri kalmaz Ã§Ã¼nkÃ¼ yÃ¼ksek weight deÄŸeri modelin karmaÅŸÄ±klÄ±ÄŸÄ±na en Ã§ok katkÄ± yapandÄ±r.1 month ago 7 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Herkese merhaba. Crossing One-Hot Vectors kÄ±smÄ±nÄ± tam oturtamadÄ±m yardÄ±mcÄ± olursanÄ±z sevinirim ğŸ™‚",
"comment": [
    "",
    "-> Merhaba,Ã–ncelikle Feature Cross yapmamÄ±zÄ±n sebebi modelimizin verileri tek bir lineer Ã§izgiyle ayÄ±ramamasÄ±dÄ±r. Bu yÃ¶ntemle yeni bir feature elde edip bu yeni feature modelimizin eÄŸitim sÄ±rasÄ±nda verileri daha etkili ayÄ±rÄ±p daha etkili bir hipotez fonksiyonu elde etmesinde yardÄ±mcÄ± oluyor. Ã–rneÄŸin elinizde \"dil\" ve \"Ã¼lke\" kategorik featurelarÄ± olsun.Ã–rneÄŸin dil feature deÄŸerleri: \"TÃ¼rkÃ§e, Ä°ngilizce, Japonca\"Ãœlke deÄŸerleri de: \"TÃ¼rkiye, Ä°spanya, Kanada\" olsun.Bu iki kategorik veriyi One Hot Encoding kullanarak binary vector'e Ã§evirdiniz ki modelimiz numerik veri Ã¼zerinde Ã§alÄ±ÅŸabilsin.EÄŸer siz bu iki feature'Ä± yani iki binary vector deÄŸerini Ã§arparsanÄ±z elinizde 9 elemanlÄ± bir binary vector olur. Bu binary vector deÄŸerlerinden her biri bir ihtimali temsil eder. Ã–rneÄŸin:[TÃ¼rkÃ§e ve TÃ¼rkiye,TÃ¼rkÃ§e ve Ä°spanya,TÃ¼rkÃ§e ve Kanada, Ä°ngilizce ve TÃ¼rkÃ§e,.......] gibi.Siz ilgili ihtimalin olduÄŸu indeksteki deÄŸere 1 koyduÄŸunuz anda artÄ±k o eÄŸitim Ã¶rneÄŸi iÃ§in o deÄŸer geÃ§erlidir. Ã–rneÄŸin [1,0,0,0,0,0,0,0,0] yaptÄ±ÄŸÄ±nÄ±zda artÄ±k TÃ¼rkÃ§e ve TÃ¼rkiye deÄŸerini o eÄŸitim Ã¶rneÄŸi iÃ§in deÄŸer belirlemiÅŸ olursunuz. Buradaki amaÃ§ featurelarÄ±n tek tek tahmine katkÄ±sÄ±ndan daha Ã§ok katkÄ± saÄŸlamalarÄ±nÄ± saÄŸlayabilmek. Ã–rneÄŸin dil ve Ã¼lke featurelarÄ± kend baÅŸlarÄ±na feature olarak katkÄ± saÄŸlarlar ama iki feature'Ä± Ã§arpÄ±p elde ettiÄŸimiz yeni feature tahminde daha Ã§ok katkÄ± saÄŸlayacaktÄ±r.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 19 people like this.Like ReportReply",
    "->  ->  DoÄŸru anlÄ±yor muyum? Dil Ã¼lke Ã¶rneÄŸi ile modelimizin verileri lineer olarak ayÄ±ramadÄ±ÄŸÄ± durumda, featurelar Ã§arpÄ±ldÄ± ve yeni bir Ã§Ä±ktÄ± elde ettik(binary vektÃ¶r). DaÄŸÄ±nÄ±k halde olan verileri daha dÃ¼zgÃ¼n bir hale getirip tekrar bir doÄŸru ile ayÄ±rÄ±p ayÄ±ramadÄ±ÄŸÄ±mÄ±za bakÄ±yoruz bu ÅŸekilde. Peki bu yeni feature'Ä±mÄ±z mÄ± oldu yani diÄŸer featurelarla birlikte nasÄ±l deÄŸerlendiriyoruz bu durumu?.",
    "->  ->  Evet, bu Ã§arpÄ±lan feature sizin yeni feature'Ä±nÄ±z oldu. x3 feature'Ä± olduÄŸunu dÃ¼ÅŸÃ¼nelim. x3=x1 (x) x2 olsun. Yani x1 ve x2 feature'Ä±mÄ±zÄ±n Ã§arpÄ±mÄ± ile x3 sentetik feature'Ä±mÄ±zÄ± elde edelim. Bu durumda y=w0+w1x1+w2x2 olan hipotez fonksiyonumuz artÄ±k y=w0+w1x1+w2x2+w3x3 olacak ve bu hipoetizimin doÄŸru olarak gÃ¶sterimi de bize verileri daha tutarlÄ± ayÄ±rmÄ±ÅŸ olacak. https://developers.google.com/machine-learning/crash-course/feature-crosses/playground-exercises playground'Ä±nda w1 ve w2 aÄŸÄ±rlÄ±klarÄ±mÄ±zÄ± 0, w3'Ã¼mÃ¼zÃ¼ 1 olarak aldÄ±ÄŸÄ±mÄ±zda aslÄ±nda yeni oluÅŸturduÄŸumuz feature'Ä±n tek baÅŸÄ±na gÃ¼zel bir veri ayÄ±rmasÄ± yaptÄ±ÄŸÄ±nÄ± gÃ¶rebiliyoruz. Bu da yeni oluÅŸturduÄŸumuz feature x3'Ã¼n, x1 ve x2 featurelarÄ±ndan daha efektif Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶steriyor.",
    "Feature Crosses: Playground Exercises Â |Â  Machine Learning Crash Coursedevelopers.google.comhttps://developers.google.com/machine-learning/crash-course/feature-crosses/playground-exercises1 month ago 10 people like this.Like ReportReply",
    "->  ->  teÅŸekkÃ¼r ettim, Ã§ok iyi aÃ§Ä±klÄ±yorsun..",
    "->  ->  teÅŸekkÃ¼r ederim ğŸ™‚.",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Herkese merhabalar. Feature crosses bolumundeki en son sorulan soruda (Check your understanding kisminda) neden one feature crossu diger featurelarinin binned halini alarak olusturduk. Binned hali olmadan alsak nasil bir sonuc dogurur? Binning konusunun uygulamasi kafamda tam oturmadi acikcasi. Bu konuda yardimci olursaniz cok sevinirim. Tesekkurler.",
"comment": [
    "",
    "->  Merhaba, bir ÅŸehirdeki boylam derecemiz 30 olsun ve kiÅŸi baÅŸÄ±na dÃ¼ÅŸen oda sayÄ±sÄ± da 1 olsun. DiÄŸer ÅŸehirde de boylam derecesi 20 ve kiÅŸi baÅŸÄ±na dÃ¼ÅŸen oda sayÄ±sÄ± yine 1. Åimdi bunlarÄ± binning yapmadan feature crossing yaparsak, derece ne kadar yÃ¼ksekse biz ona daha Ã§ok deÄŸer biÃ§miÅŸ oluyoruz. Binning yaptÄ±ÄŸÄ±mÄ±zda, sadece ÅŸehrin bulunduÄŸu boylamÄ± 1, diÄŸerlerini 0 ÅŸeklinde ifade ettiÄŸimiz iÃ§in, boylamÄ±n derecesine gÃ¶re karar vermemiÅŸ oluyoruz.1 month ago 3 people like this.Like ReportReply",
    "->  ->  Ben de rooms per person Ã¶zelliÄŸinin neden bin yapÄ±ldÄ±ÄŸÄ±nÄ± anlamadÄ±m. Enlem ve boylam da gerekliliÄŸini anlatÄ±yor. Rooms per person diÄŸer iki Ã¶zelliÄŸe gÃ¶re daha stabil ve gÃ¼venilir. Bu kÄ±smÄ±nda 50 gibi bir outlier deÄŸer vardÄ± onun etkisini kÄ±rmak iÃ§in mi yine bin yapmamÄ±z gerekti ?.",
    "->  ->  SanÄ±rÄ±m o outlier deÄŸerlerini bu iÅŸleme gelmeden temizlemiÅŸ oluyoruz. DediÄŸiniz gibi rooms per person bin iÅŸlemi diÄŸerleri kadar net gÃ¶rÃ¼lemiyor. Bin yapÄ±lmayÄ±p normal deÄŸerleri ile kullanÄ±lsaydÄ±, roomsperperson = 1 ve roomsperperson = 2 deÄŸerleri iÃ§in; 2 olan deÄŸere 2 kat Ã¶nem vermiÅŸ oluyoruz ve ister istemez w deÄŸerine mÃ¼dahele etmiÅŸ oluyoruz. Belki de fiyat olarak aralarÄ±nda net olarak 2 kat fark yok. Onu modelin vereceÄŸi aÄŸÄ±rlÄ±klar ve hesaplayacaÄŸÄ± hata ile kendisi tespit etmesini istiyoruz. AÄŸÄ±rlÄ±ÄŸa mÃ¼dahale etmemiz bizi doÄŸruluktan uzaklaÅŸtÄ±rabilir diye dÃ¼ÅŸÃ¼nÃ¼yorum.1 month ago 3 people like this.Like ReportReply",
    "->  ->  teÅŸekkÃ¼rler benim iÃ§in faydalÄ± oldu aÃ§Ä±klama ğŸ™‚.",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Herkese Merhaba, umarÄ±m dolu dolu bir machine learning crash course haftasÄ± geÃ§irirsiniz. Ben tam olarak Representation kÄ±smÄ±ndaki \"Account for upstream instability\" kÄ±smÄ±nÄ± anlamadÄ±m. YardÄ±mcÄ± olursanÄ±z sevinirim.iyi akÅŸamlar.",
"comment": [
    "",
    "->  Merhaba,Burada demek istediÄŸi feature'Ä±nÄ±zÄ±n deÄŸeri zaman iÃ§erisinde deÄŸiÅŸiklik gÃ¶stermemelidir yani Stationary durumda olmalÄ±dÄ±r. Ã–rneÄŸin siz her ÅŸehirdeki oy oranÄ±na bakacaksÄ±nÄ±z ve her ÅŸehir iÃ§n o ÅŸehri tanÄ±mlayacak bir belirleyici feature'a ihtiyacÄ±nÄ±z var. Bu feature ismine sehir_id dediniz ve 1234567 deÄŸerini atadÄ±nÄ±z. Bu deÄŸer ilerleyen zamanlar deÄŸiÅŸkenlik gÃ¶sterme potansiyeline sahip. Ã–rneÄŸin verisetinize yeni ÅŸehir eklendiÄŸinde veya Ã§Ä±kartÄ±ldÄ±ÄŸÄ±nda. Bunu yerine sehir_id feature deÄŸerinizi \"tr/istanbul\" yaparsanÄ±z bu deÄŸerin deÄŸiÅŸmeyeceÄŸi neredeyse kesindir (biri kalkÄ±p da ÅŸehrin adÄ±nÄ± deÄŸiÅŸtirmezse).Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 6 people like this.Like ReportReply",
    "->  ->  anladÄ±m teÅŸekkÃ¼rler. iyi Ã§alÄ±ÅŸmalar..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar Herkese!  UmarÄ±m programdaki 2. haftanÄ±z da verimli geÃ§iyordur ???? Pazar gÃ¼nÃ¼ gerÃ§ekleÅŸtirdiÄŸimiz mini quizin soru ve aÃ§Ä±klamalÄ± cevaplarÄ±na aÅŸaÄŸÄ±daki linkten eriÅŸebilirsiniz.  ????http://community.globalaihub.com/mlcc_week1-qas/  Bu soru ve cevaplarda katkÄ±sÄ± olan tÃ¼m mentorlarÄ±mÄ±za da tekrar teÅŸekkÃ¼r ederiz ????  Keyifli haftalar âœ¨",
"comment": [
    "",
    "->  Size ve mentorlarÄ±mÄ±za Ã§ok teÅŸekkÃ¼rler AslÄ± HanÄ±m, herkese keyifli haftalar ve iyi Ã§alÄ±ÅŸmalar dilerim ğŸ™‚1 month ago 2 people like this.Like ReportReply",
    "->  Merhabalar, sorulardan 2 si ile ilgili kafamÄ± kafamÄ± kurcalayan ÅŸeyler var. MÃ¼saadenizle buradan sormak istiyorum. 1. Si 1. soruyla ilgili. O kadar aÃ§Ä±klamaya raÄŸmen validation set in gerekliliÄŸi kafamda oturmuÅŸ deÄŸil. Ã‡Ã¼nkÃ¼ biz test verisini zaten elimizdeki veriyi en iyi temsil edecek ÅŸekilde seÃ§miyor muyduk? Bu yÃ¼zden test verisine overfit olmasÄ± beni Ã§ok rahatsÄ±z etmiyor. Belki de tecrÃ¼beyle ortaya Ã§Ä±kan bir sonuÃ§tur benim yeterli tecrÃ¼bem yok kusuruma bakmayÄ±n ğŸ™‚ 2. si 8. Soru ile ilgili. BazÄ± Ã¶zellikleri (Feature) kaldÄ±rmak Ã¶ÄŸrenmeyi olumsuz etkiler gibi geldi bana belki de ayÄ±rd edici veriler vardÄ± orada. Ne gibi durumlarda Ã¶zellik kaldÄ±rmak overfitting i engeller tecrÃ¼be etmiÅŸ olan varsa Ã¶rnek verebilirse sevinirim. TeÅŸekkÃ¼r ederim ğŸ™‚.",
    "-> ->  Test verilerine overfit olduÄŸunda elde ettiÄŸin sonuÃ§(accuracy) Ã§ok iyi gibi gÃ¶rÃ¼nebilir ama hiÃ§ karÅŸÄ±laÅŸmadÄ±ÄŸÄ± veriler(gerÃ§ek hayat verileri) Ã¼zerinde kÃ¶tÃ¼ performans gÃ¶sterecektir. Ã–rnek veriyorum, yarÄ±n sÄ±navÄ±mÄ±z var ve sÃ¼rekli hocanÄ±n derste iÅŸlediÄŸi Ã¶rnekleri sabaha kadar sular seller gibi ezberledik(overfitting). SÄ±nava girdik(daha Ã¶nce karÅŸÄ±laÅŸmadÄ±ÄŸÄ±mÄ±z veriler) ve gÃ¶rdÃ¼k ki hoca soruyu ters Ã§evirmiÅŸ, suya daldÄ±rmÄ±ÅŸ vs. Ã‡uvalladÄ±k. Oysa ki farklÄ± kaynaklardan farklÄ± Ã¶rnekler Ã¼zerinde de Ã§alÄ±ÅŸanlar(training with more data), Ã¶nemsiz konularÄ± Ã§alÅŸmayÄ±p kafasÄ±nÄ± bunlarla doldurmayanlar(feature removing), yeteri kadar Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼p uykusunu alanlar(early stopping), Ã¶rneklerin farklÄ± Ã§Ã¶zÃ¼m yÃ¶ntemlerini de araÅŸtÄ±rÄ±p Ã¶ÄŸrenmesini bunlarla harmanlayanlar(ensembling), Ã§alÄ±ÅŸmaya baÅŸlamadan Ã¶nemli konulara yÃ¼ksek Ã¶nemsiz konulara dÃ¼ÅŸÃ¼k puan verip vaktini konunun puanÄ±na gÃ¶re harcayanlar (regularization) daha Ã¶nce karÅŸÄ±laÅŸmadÄ±ÄŸÄ± sorular karÅŸÄ±sÄ±nda daha baÅŸarÄ±lÄ± sonuÃ§lar aldÄ±. DiÄŸer sorunuzda ise 4. soruyu Ã¶rnek alalÄ±m, ev fiyatlarÄ±nÄ± tahmin edebilen bir algoritma yazÄ±yoruz diyelim, Ã¶nceki ev sahibinin cinsiyetinin fiyat ile alakasÄ± olmadÄ±ÄŸÄ± iÃ§in bu Ã¶zelliÄŸi (feature) kaldÄ±rÄ±rsak (bkz:feature selection) hem zaman ve paradan tasarruf edip hem de modeli kompleks olmaktan biraz uzaklaÅŸtÄ±rdÄ±ÄŸÄ±mÄ±z iÃ§in overfittingden de uzaklaÅŸmÄ±ÅŸ olacaÄŸÄ±z. 1 taÅŸla 2 kuÅŸ vurmuÅŸ olacaÄŸÄ±z. Ã–rnekleme biraz zorlama oldu, umarÄ±m faydasÄ± olmuÅŸtur.1 month ago 6 people like this.Like ReportReply",
    "->  ->  Ã‡ok gÃ¼zel aÃ§Ä±klamÄ±ÅŸsÄ±nÄ±z, her ÅŸey daha net oturdu teÅŸekkÃ¼r ederim ğŸ™‚.",
    "->  Ä°lk haftaki sÄ±nava katÄ±lanlarÄ±n ortalama puanÄ± belli mi acaba?.",
    "->  ->  SÄ±nav ortalamasÄ±, 63 ğŸ™‚.",
    "->  Ã–ncelikle sÄ±nav ve sÄ±nav cevaplarÄ± iÃ§in teÅŸekkÃ¼r ederiz. Ama benim kafamda da takÄ±lan sorular var. Ã–ncelikle birinci soru \"validation sets increase model's performance on the fit\", bu cevap da doÄŸru deÄŸil mi? SonuÃ§ olarak ben validationÄ±mÄ± arttÄ±rÄ±rsam test veri setine girmeden Ã¶nce model daha iyi olacak ve daha sonra da teste soktuÄŸumda da daha iyi bir sonuÃ§ almaz mÄ±yÄ±m? Åimdi overfit olur diye dÃ¼ÅŸÃ¼nÃ¼yorum o yÃ¼zden testim kÃ¶tÃ¼ gelir ama test verimiyileÅŸtirir. bunu da geÃ§iyorum overfit olmasÄ±nÄ± engellemek iÃ§in verisetini arttÄ±rmak gerek o yÃ¼zden overfit olmasÄ±nÄ± da engellemiÅŸ oluyorum. Yani validation setinin artmasÄ± modelimin iyi olmasÄ±nÄ± etkilemez mi? 8. soru da ise removing feature overfit olmasÄ±nÄ± nasÄ±l etkiler modeli oluÅŸtururken train sÄ±rasÄ±nda arada Ã§ekmek mi burada ki kasÄ±t yoksa tamamen baÅŸtan featurelarÄ± Ã§Ä±karmak mÄ±? Åimdiden Ã§ok teÅŸekkÃ¼r ederim cevaplar iÃ§in ğŸ™‚1 month ago 2 people like this.Like ReportReply",
    "-> ->  Validation set modellerimizin performansÄ±nÄ± \"Ã¶lÃ§tÃ¼ÄŸÃ¼mÃ¼z\" settir. Yani validation seti arttÄ±rmak performansÄ± daha iyi Ã¶lÃ§memizi saÄŸlar, model performansÄ±nÄ± arttÄ±rmaz. Ã–rneÄŸin modelimiz gerÃ§ekte %10 hatalÄ± Ã§alÄ±ÅŸÄ±yor diyelim. Validation setimiz kÃ¼Ã§Ã¼k, %5~15 aralÄ±ÄŸÄ±nda hatalÄ± olduÄŸumuzu bulduk, validation setimizi arttÄ±rdÄ±k daha iyi Ã¶lÃ§Ã¼m yapabiliyoruz artÄ±k %9~11 aralÄ±ÄŸÄ±nda bir hata ile Ã§alÄ±ÅŸÄ±yor olduÄŸunu buluyoruz gibi dÃ¼ÅŸÃ¼nebiliriz. Ama hatamÄ±z hep %10 yani validationÄ±n artmasÄ±yla model performansÄ± ne arttÄ± ne de azaldÄ±. Neden? Ã‡Ã¼nkÃ¼ modelimizi sadece train set ile eÄŸitiyoruz. Validation ve test sete hiÃ§bir ÅŸekilde mÃ¼dahale etmiyoruz. 8. soruyla ilgili yukarÄ±da bir cevap yazdÄ±m onu okuyabilirsiniz. Genelde bir proje Ã¼zerinde Ã§alÄ±ÅŸÄ±yorsak, modelleme aÅŸamasÄ±na geÃ§meden Ã¶nce verimizi gÃ¼zelce bir inceler, iÃ§inde neler varmÄ±ÅŸ, hangi Ã¶zelliklere sahipmiÅŸ vb. fikirler edinmeye Ã§alÄ±ÅŸÄ±rÄ±z (Exploratory Data Analysis EDA), daha sonra feature engineering yaparak hedefimize yaklaÅŸmaya Ã§alÄ±ÅŸÄ±rÄ±z yani en baÅŸtan gereksiz featurelarÄ± Ã§Ä±karÄ±p elde ettiÄŸimiz bu yeni veri seti ile devam etmek genellikle bizim iÃ§in en karlÄ±sÄ± olur..",
    "->  ->  teÅŸekkÃ¼r ederim aÃ§Ä±klamalarÄ±nÄ±zdan dolayÄ± Tamer Bey..",
    "->  UÃ§arMerhabalar, ben de birinci soruda takÄ±ldÄ±m. Cross validation, modelin 'generalization'Ä± iyi yapÄ±p yapmadÄ±ÄŸÄ±nÄ± test etmek iÃ§in kullanÄ±lan bir yÃ¶ntem. Yani model veri daÄŸÄ±lÄ±mÄ±nÄ± iyi bir ÅŸekilde generalize etmeli ki hiÃ§ gÃ¶rmediÄŸi test verisinde baÅŸarÄ±lÄ± tahminler yapabilsin. Generalization'Ä±n iyi yapÄ±lmasÄ± iÃ§in de model, ne underfit ne de overfit olmamalÄ±, tabiri caizse fitfit olmalÄ±. Ä°lk defa eÄŸitime baÅŸladÄ±ÄŸÄ±mÄ±zda oluÅŸturulan model 99% (diyelim ki 1% doÄŸru weight'lerin gelmesi olasÄ±lÄ±ÄŸÄ±) underfit (high bias) durumuyla baÅŸlayacak. Weightleri validation setinde aldÄ±ÄŸÄ±mÄ±z hatalara gÃ¶re gÃ¼ncelleyerek/iyileÅŸtirerek, underfit durumundan fitfit durumuna getirmeye Ã§alÄ±ÅŸÄ±yoruz. Test setini hiÃ§ eÄŸitime katmadÄ±ÄŸÄ±mÄ±z ve validation set ile eÄŸitim setini sÃ¼rekli deÄŸiÅŸtirdiÄŸimiz (k-fold CV) iÃ§in de overfitting'den kurtulmuÅŸ oluyoruz. Yani hem underfitting'i hem de overfitting'i Ã¶nlemiÅŸ olmuyor muyuz? YukarÄ±da bu konuyla ilgili Ã¶ÄŸrendiklerimi yazdÄ±m. Bir bilgi yanlÄ±ÅŸlÄ±ÄŸÄ± varsa beni aydÄ±nlatabilir misiniz?.",
    "-> 4. Soruda kullanÄ±lmasÄ± gereksiz bir Ã¶zellik Ã¶rneÄŸi verilmiÅŸ fakat ters aÃ§Ä±dan bakarsak araba ilanlarÄ±nda doktordan, bayandan gibi Ã¶zellikler vurgulanmakta ve alÄ±cÄ±da gÃ¼ven oluÅŸturabilmektedir benzer bir bakÄ±ÅŸ aÃ§Ä±sÄ±yla 2 metre boyunda 1 karÄ±ÅŸ sakallÄ±, kÃ¶tÃ¼ imajlÄ± bir uyruktan veya benzer bir mantÄ±kla genel kanÄ±ya gÃ¶re kadÄ±nlardan daha az gÃ¼ven duyulan bir erkeÄŸin \"oldukÃ§a subjektif bir bakÄ±ÅŸ aÃ§Ä±sÄ±yla \" evin eski sahibi olmasÄ±ndansa bir kadÄ±nÄ±n eski ev sahibi olmasÄ± ve ben bunu biliyorsam etkili olabilir bu Ã¶zelliÄŸi kullanmak baÅŸarÄ±yÄ± artÄ±rabilirmi ? bu yaklaÅŸÄ±m yanlÄ±ÅŸmÄ±dÄ±r ?.",
    "->  -> bu varsayÄ±mÄ± geÃ§erli saysak bile diÄŸer parametreler iÃ§inde oldukÃ§a zayÄ±f kalacaktÄ±r. Modele bunun feature olarak tanÄ±mladÄ±ÄŸÄ±nÄ±zda da, sonuca etkilemeyecek kadar dÃ¼ÅŸÃ¼k bir aÄŸÄ±rlÄ±k verecektir benim tahminim. Bu dediÄŸiniz parametrenin ne kadar etkili olduÄŸunu anlamak iÃ§in deneme yapmanÄ±z gerekiyor diye dÃ¼ÅŸÃ¼nÃ¼yorum. Ã–rnek olarak aynÄ± boyutta bÃ¼yÃ¼klÃ¼kte aynÄ± mahalledeki evlerin fiyatlarÄ± birbirine yakÄ±n iken ev sahibinin cinsiyeti de feature olarak eklendiÄŸinde sonuÃ§lar deÄŸiÅŸiyorsa model ona gÃ¶re gÃ¼ncellenebilir..",
    "->  -> Eski ev sahibi kadÄ±n diye bir eve daha fazla veya az para Ã¶der misin?.",
    "->  TeÅŸekkÃ¼rler,bilgilendirme iÃ§in. Quizlerdeki notlar sertifika almayÄ± etkileyecek mi? Son quiz mi belirleyecek yoksa?.",
    "->  ->  AsÄ±l Ã¶nemli olan 10 MayÄ±s'taki final sÄ±navÄ± ğŸ˜‰.",
    "-> ->  1. quiz baÄŸlantÄ±sÄ± bana ulaÅŸmadÄ± AslÄ± hanÄ±m. 2. quiz baÄŸlantÄ±sÄ±nÄ±n ulaÅŸÄ±p ulaÅŸmayacaÄŸÄ± konusunda emin olamÄ±yorum. Acaba kontrol edebilir misiniz ?.",
    "->  -> Bir ÅŸekilde mail eline ulaÅŸmayan arkadailar iÃ§in ana sayfada ilgili link i post olarak da paylaÅŸmÄ±ÅŸtÄ±m sizlerle, top kÄ±sma da pin lemiÅŸtim, gÃ¶zÃ¼nÃ¼zden kaÃ§tÄ± sanÄ±rÄ±m. Pazar gÃ¼nÃ¼ yine aynÄ± ÅŸekilde ilgili linki direkt post olarak paylaÅŸÄ±p, en Ã¼ste pin leyeceÄŸim, oradan direkt sorulara ulaÅŸabilirsiniz.1 month ago 2 people like this.Like ReportReply",
    "-> ->  tamamdÄ±r, teÅŸekkÃ¼r ederim..",
    "-> ->  merhaba, konum deÄŸiÅŸikliÄŸi dolayÄ±sÄ±yla internet problemim olduÄŸu iÃ§in kursa yeni baÅŸlayacaÄŸÄ±m. GeÃ§en hafta sÄ±nav yapmÄ±ÅŸsÄ±nÄ±z ve yarÄ±nda yapacaksÄ±nÄ±z bunlara katÄ±lamamÄ±ÅŸ olacaÄŸÄ±m. Yol haritasÄ±ndaki 1. haftadan itibaren size yetiÅŸebilir miyim? KatÄ±lamadÄ±ÄŸÄ±m 2 sÄ±nav bir sorun teÅŸkil eder mi? TeÅŸekkÃ¼r ederim..",
    "->  ->  Hocam sÄ±nav sistemi geÃ§en haftaki gibi google form Ã¼zerinden mi olacak?.",
    "->  ->  Evet aynÄ± formatta ilerleyeceÄŸiz ğŸ˜‰.",
    "->  -> Haftaya 3 haftalÄ±k konu Ã§alÄ±ÅŸmak durumunda kalacaksÄ±nÄ±z, ancak Ã§ok sÄ±kÄ± Ã§alÄ±ÅŸÄ±rsanÄ±z yetiÅŸebilirsiniz. Ara sÄ±navlara katÄ±lamama durumunuzu 3. haftaki performansÄ±nÄ±za gÃ¶re deÄŸerlendrebiliriz ğŸ˜‰.",
    "-> \"Validation sets help us check if the model overfits or underfits.\" Bu statement neden doÄŸru deÄŸil acaba? Modelin dÃ¼zgÃ¼n Ã§alÄ±ÅŸmasÄ± iÃ§in overfit ve underfit arasÄ±ndaki dengeyi bulmaya Ã§alÄ±ÅŸmÄ±yor muyuz? TeÅŸekkÃ¼rler ğŸ™‚.",
    "->  -> Merhaba,Validation set modelimizin overfit veya underfit olmamÄ±zÄ± kontrol etmede bize yardÄ±mcÄ± olmaz. Validation set'imiz modelimizin overfit olmamasÄ± iÃ§in training setin iÃ§inden seÃ§ilir ve hipotez fonksiyonumuz gerekli iÅŸlemleri geÃ§irip optimum weight deÄŸerlerini bulduÄŸunda son kez test fonksiyonu ile test edilir.Ä°yi Ã§alÄ±ÅŸmalar ğŸ™‚.",
    "->  -> zaten validation setinin amacÄ± ÅŸuydu; test setimiz kÃ¶tÃ¼ sonuÃ§lar verdikÃ§e modeli iyileÅŸtirmeye Ã§alÄ±ÅŸarak modelin overfit olmaya yaklaÅŸmasÄ± mÃ¼mkÃ¼ndÃ¼. Test seti Ã¼zerinde hiÃ§ uygulama yapmadan bu iyileÅŸtirmeleri validation set Ã¼zerinde yapÄ±yoruz ki yanÄ±ltÄ±cÄ± sonuÃ§larÄ± almayalÄ±m. Bu aÅŸamada deÄŸerlendirme validation seti devreye giriyor. Validation set modelini iyileÅŸtirmek iÃ§in ipuÃ§larÄ± veriyor. Test seti hiÃ§ kullanmadan validation set Ã¼zerinde Ã§ok iyi sonuÃ§lar almaya Ã§alÄ±ÅŸÄ±rken bile overfit olmak mÃ¼mkÃ¼n..",
    "->  Merhaba, bu hafta sinav yok mu?.",
    "->  ->  http://community.globalaihub.com/wp-content/uploads/2020/04/MLCC-Yol-HaritasÄ±_642020.pdfProgramda her hafta pazar gÃ¼nleri deÄŸerlendirme testi olacaÄŸÄ± yazÄ±yor. Bu hafta da bÃ¼yÃ¼k ihtimalle olur..",
    "->  ->  Cok tesekkur ederim..",
    "->  ->  Rica ederim..",
    "->  GerÃ§ekten cevaplar Ã§ok aÃ§Ä±klayÄ±cÄ± olmuÅŸ. DoÄŸru yaptÄ±ÄŸÄ±m sorularÄ±n aÃ§Ä±klamalarÄ±nÄ± bile tekrar tekrar okudum. Ã‡ok teÅŸekkÃ¼r ederim ğŸ™‚.",
    " "
]
},
{
"question_isim": "->  uploaded 1 photo",
"quest": "Merhaba ArkadaÅŸlar,  Representation: Feature Engineering bÃ¶lÃ¼mÃ¼nde kategorik deÄŸerlerimize sayÄ±sal deÄŸerler tanÄ±mlayÄ±p doÄŸrudan modelimize dahil ettiÄŸimizde sorunlu olabilecek bazÄ± kÄ±sÄ±tlamalar olduÄŸundan bahsedilmiÅŸ. Buna istinaden eklediÄŸim iki maddeyi tam olarak anlayamadÄ±m. YardÄ±mcÄ± olursanÄ±z Ã§ok sevinirim. TeÅŸekkÃ¼rler",
"comment": [
    "",
    "-> Merhaba,1.Ã–rneÄŸin sizin sokak featureÄ±nÄ±z var ve string deÄŸerinde yani kategorik bir veri. Siz dediniz ki ben her bir sokak ismi iÃ§in bir index kullanacaÄŸÄ±m yani ilk sokak iÃ§in 0, ikinci sokak iÃ§in 1 diye bÃ¶yle gidecek. 10 sokaÄŸÄ±nÄ±z var ise son indexi 9 olur bu durumda. Burada ilk maddede diyor ki gÃ¼zel index kullandÄ±n ama Ã¶rneÄŸin siz o feature deÄŸeri iÃ§in ilgili weight'i 6 buldunuz bu sefer durum ÅŸÃ¶yle olacak 1.eÄŸitim Ã¶rneÄŸi iÃ§in 6x0 2. eÄŸitim Ã¶rneÄŸi iÃ§in 6x1......... 10.eÄŸitim Ã¶rneÄŸi iÃ§in 6x9 (lineer regresyon formÃ¼lÃ¼ndeki w (x) x kÄ±smÄ±ndan). Burada sizin her sokak iÃ§in bir weight deÄŸeri Ã¶ÄŸrenmeniz gerektiÄŸinden bahsediyor Ã§Ã¼nkÃ¼ sokaklarÄ±n hepsinin labelÄ±mÄ±za farklÄ± bir etkisi olur ama siz az Ã¶nceki ÅŸekilde yaparsanÄ±z bÃ¼tÃ¼n sokaklar iÃ§in aynÄ± weight bulmuÅŸ olur ve sokaklarÄ±n labela etkisini gÃ¶zlemleyemezsiniz. Buradaki indeksleme yÃ¶ntemi her katgorik deÄŸeri bir int deÄŸere maplemekti. One Hot Encoding veya Multi-Hot Encoding kullanÄ±rsak bÃ¼tÃ¼n bu ihtimalleri featurelara ayÄ±rÄ±rÄ±z ve bu featurelardan her birinin deÄŸeri binary bir vector olur.2.YukarÄ±da sokak isimleri labelÄ±mÄ±z tek bir sokak ismi alyÄ±yormuÅŸ gibi dÃ¼ÅŸÃ¼ndÃ¼k ve ona gÃ¶re indeksledik. Bazen sokak featureÄ±mÄ±z string tipinde iki tane sokak ismi alabilir.(Ã–rneÄŸin evimiz iki sokaÄŸÄ±n kÃ¶ÅŸesindeyse.) EÄŸer siz yukarÄ±daki gibi bunlar iÃ§in de indeks kullanÄ±rsanÄ±z bu veriyi encode edemeyeceÄŸimizden bahsediyor.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 7 people like this.Like ReportReply",
    "->  Ã‡ok teÅŸekkÃ¼rler ->  ÅŸimdi daha iyi anladÄ±m. Ä°yi Ã§alÄ±ÅŸmalar.",
    " "
]
},
{
"question_isim": "->  uploaded 1 photo",
"quest": "Merhaba, Tensorflow'u pip ile yÃ¼klemek istediÄŸimde bÃ¶yle bir hata alÄ±yorum. Ã‡ok yanlÄ±ÅŸ bir ÅŸey mi deniyorum? Numpy ve Pandas'Ä± bu ÅŸekilde yÃ¼klemiÅŸtim. Pip sÃ¼rÃ¼mÃ¼m gÃ¼nceldir.  YardÄ±mcÄ± olabilir misiniz? TeÅŸekkÃ¼rler,",
"comment": [
    "",
    "->  sanÄ±rÄ±m versiyon sÃ¶ylemenizi istiyor.pip install tensorflow==2.0.0.",
    "-> eÄŸer versiyon tanÄ±mÄ± sorunu Ã§Ã¶zmez ise bunlara bakabilirsiniz python versionunuz nedir acaba? python 3.5 veya 3.7 versiyonlu olmasÄ± gerekiyor. Åurada bir aÃ§Ä±klamasÄ± var. (https://www.tensorflow.org/install) ayrÄ±ca eÄŸer bu versiyonlarÄ± kullanÄ±yorsanÄ±z \"pip3 install tensorflow\" olarak da bir dener misiniz? Bir de python2 kullanmayÄ± tercih ediyorsanÄ±z (https://www.tensorflow.org/install/pip) ÅŸu link'te olduÄŸu gibi tensorflow versiyonunu seÃ§meniz gerekiyor. AyrÄ±ca ÅŸu siteden python3 indirebilirsiniz (https://www.python.org/downloads/windows)1 month ago 1 person likes thisLike Reply Edit",
    "->  TeÅŸekkÃ¼r derim Python 3.8.2 kullanÄ±yordum o yÃ¼zden olmadÄ± sanÄ±rÄ±m. Åimdi 3.7.7 indirdim ve pip ile versiyon belirtmeden yÃ¼kleme yapabildim.Ã‡ok teÅŸekkÃ¼r derim,.",
    "->  Anaconda kullanmak yeni baÅŸlayanlar iÃ§in en iyisi. Kendisi paketler arasÄ±nda uyumluluklarÄ± hallediyor ve gereklilikleri kuruyor..",
    " "
]
},
{
"question_isim": "->  uploaded 3 photos",
"quest": "Merhaba arkadaÅŸlar,  GeÃ§en haftanÄ±n konusu ile ilgili bir yerde takÄ±ldÄ±m. TecrÃ¼besi olanlar yardÄ±mcÄ± olabilir mi?  Elimdeki bir veri setine eÄŸitim gerÃ§ekleÅŸtiriyorum ancak bir tÃ¼rlÃ¼ loss deÄŸerinde sÃ¼rekli azalmayÄ± yakalayamadÄ±m(converged olmuyor). AÅŸaÄŸÄ±da denediklerimden 3 Ã¶rnek gÃ¶rseli paylaÅŸÄ±yorum. Ã‡ok daha fazla denemem oldu. GeÃ§tiÄŸimiz haftadan nasÄ±l yapmam gerektiÄŸini tam anlayamadÄ±ÄŸÄ±mÄ± fark ettim. Ã–ÄŸrenme oranÄ±nÄ± dÃ¼ÅŸÃ¼rdÃ¼m, epoch sayÄ±sÄ±nÄ± artÄ±rdÄ±m ve batch size Ä± azalttÄ±m. Grafik hep tÄ±rtÄ±klÄ± ÅŸekilde Ã§Ä±kÄ±yor. Bunlardan kurtulmak iÃ§in anladÄ±ÄŸÄ±m kadarÄ±yla kesin geÃ§erli bir yol yok. Parametre ayarlamalarÄ±nÄ± yaparken bildiÄŸiniz dikkat edilmesi gereken baÅŸka noktalar nelerdir?   TeÅŸekkÃ¼rler.",
"comment": [
    "",
    "->  Batch-size'Ä± dÃ¼ÅŸÃ¼rmek osilasyon yapmasÄ±na yol aÃ§abilir. Stochastic gradient descent yani batch-size=1 aldÄ±ÄŸÄ±nÄ±zda daha fazla osilasyon yapacaÄŸÄ±nÄ± tahmini ediyorum. 128-256 gibi sayÄ±lar denediniz mi ?.",
    "->  ->  MantÄ±klÄ± geldi dediÄŸiniz. Batch size bÃ¼yÃ¼dÃ¼kÃ§e daha az tahmin gerÃ§ekleÅŸtirecek. Ama yine de olmuyor..",
    "->  ->  SÃ¼rekli azalmasÄ±ndan ziyade, hatanÄ±n dÃ¼ÅŸÃ¼k olmasÄ± daha Ã¶nemli deÄŸil mi ? Hata miktarÄ± yeterince dÃ¼ÅŸÃ¼k gibi geldi bana. AzalÄ±p artmasÄ±ndan Ã§ok, en son ulaÅŸtÄ±ÄŸÄ± noktada ne kadar az hata deÄŸerine ulaÅŸtÄ±ÄŸÄ± daha Ã¶nemli diye biliyorum. Pratik konusunda daha tecrÃ¼beli arkadaÅŸlar belki daha iyi yanÄ±tlayabilir, her zaman teorik bilgi ile pratik baÄŸdaÅŸmÄ±yor. Belki sizin istediÄŸiniz gibi daha iyi bir sonuÃ§ elde edilebilir ğŸ™‚.",
    "->  ->  Åurada sÃ¼rekli azalmalÄ± diyor ama.",
    "->  ->  Bence orada demek istediÄŸi genel olarak azalan bir grafiÄŸe sahip olmasÄ±, sizin grafik iÃ§in konuÅŸacak olursak 0.04 e gelip sonra 0.08 e tekrar atlÄ±yorsa o zaman sorun var demektir. Ama 0.0310 dan 0.312 ye Ã§Ä±karsa, bunda bir sorun yok diye dÃ¼ÅŸÃ¼nÃ¼yorum. Sizin Ã§izdirdiÄŸiniz grafiÄŸin Ã¶lÃ§eÄŸi de bÃ¶yle gÃ¶zÃ¼kmesine sebep oluyor. HatayÄ± 0-100 arasÄ± Ã§izdirirseniz bÃ¼yÃ¼k ihtimal bu titreÅŸimler hiÃ§ gÃ¶zÃ¼kmeyecektir. Siz baÅŸka kaynaklarda gÃ¶rdÃ¼ÄŸÃ¼nÃ¼z sÃ¼rekli azalan grafikleri Ã¶lÃ§eÄŸi 0 - 0.10 aralÄ±ÄŸÄ±na dÃ¼ÅŸÃ¼rÃ¼p incelerseniz bÃ¼yÃ¼k ihtimal onlarda da bu tarz dalgalanmalar olacaktÄ±r..",
    "->  ->  steadily kelimesini sÃ¼rekli olarak deÄŸil de yavaÅŸ yavaÅŸ ve dÃ¼zenli bir ÅŸekilde olarak Ã§evirebilirsin..",
    "->  Modelinizin eÄŸitiminde herhangi bir sorun gÃ¶rÃ¼nmÃ¼yor. Bu kadarcÄ±k sizin deyiminizle tÄ±rtÄ±klÄ± olmasÄ± Ã§ok normal. Epoch sayÄ±sÄ± arttÄ±kÃ§a azalma gerÃ§ekleÅŸmiÅŸ ancak belli bir yerden sonra adÄ±mlar arasÄ± fark o kadar az ki grafikte net bir ÅŸekilde belli olmuyor. Bu azalÄ±ÅŸÄ± net bir ÅŸekilde gÃ¶rmek istersen Ã¶zellikle 0.04 deÄŸerinden dÃ¼ÅŸÃ¼k deÄŸerler iÃ§in y ekseninde ki noktalara Ã§ok yakÄ±ndan bakabilirsin (yanlÄ±ÅŸ hatÄ±rlamÄ±yorsam matplotlib'de ticker fonksiyonu ile yapabilirsin )..",
    "->  Evet bence de bazen daha kÃ¶tÃ¼ sonuÃ§lara izin vermesi gerekir ki lokal minimumlardan kurtulabilsin. Ã–rnekteki grafik sÃ¼rekli azalan ÅŸeklinde olunca sormak istedim. TeÅŸekkÃ¼rler cevaplar iÃ§in. Biraz araÅŸtÄ±rÄ±nca ÅŸu linke denk geldim. Ã‡ok faydalÄ± oldu sizinle de paylaÅŸayÄ±m: https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/1 month ago 4 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba.Representation kÄ±smÄ±nda verileri one hot encoding yÃ¶ntemi ile kullanÄ±yoruz fakat weight Ã¶zelliÄŸini nasÄ±l kullanacaÄŸÄ±mÄ±zÄ± anlayamadÄ±m.",
"comment": [
    "",
    "->  One hot encoding kullandÄ±ÄŸÄ±mÄ±zda Ã¶rnekte verilen evin bulunduÄŸu sokak deÄŸeri 1 oluyor, kalan sokaklar 0 oluyor. [0 0 0 1 0 0] ÅŸeklinde bir vektÃ¶r oluÅŸmuÅŸ oluyor (boyutlarÄ± rasgele yazdÄ±m). Ve weight deÄŸerimizle Ã§arparken sadece tahmin etmek istediÄŸimiz evin bulunduÄŸu sokak hesaba katÄ±lmÄ±ÅŸ oluyor. 0 olan diÄŸer sokaklarÄ± deÄŸerlendirmeye katmamÄ±ÅŸ oluyoruz (w * 0 = 0 olacaÄŸÄ±ndan). UmarÄ±m soruyu doÄŸru anladÄ±m ğŸ™‚1 month ago 3 people like this.Like ReportReply",
    "->  ->  evet doÄŸru anlamÄ±ÅŸsÄ±nÄ±z :). fakat bu deÄŸerleri sayÄ±sal olarak nasÄ±l kullanÄ±yoruz ?.",
    "->  ->  evin fiyatÄ± Ã¶rneÄŸi iÃ§in linear regression kullandÄ±ÄŸÄ±mÄ±zda, y' = w1*x1 + w2*x2 + .... + wn * xn + b ÅŸeklinde bir formulÃ¼mÃ¼z vardÄ± (n = feature sayÄ±sÄ±). Bizim sokak ismi feature'Ä±mÄ±z x2 olsun. (x2 * w2) -> sadece istediÄŸimiz sokak iÃ§in sayÄ±sal bir deÄŸer Ã¼retecektir. w2 deÄŸerimiz 5 ise oradan elde ettiÄŸimiz deÄŸer yukarÄ±da yazdÄ±ÄŸÄ±m formÃ¼lde sadece o sokak iÃ§in katkÄ± saÄŸlayÄ±p modelin o sokaÄŸÄ±n ev fiyatÄ±nÄ± tahmin ederken ne kadar etkili olduÄŸunu anlamasÄ±nÄ± saÄŸlayacaktÄ±r. weight deÄŸerleri ilk olarak 0 veya random olarak belirleniyor. model training kÄ±smÄ±nda evin gerÃ§ek fiyatÄ±nÄ± gÃ¶rÃ¼p hatayÄ± hesaplÄ±yor. weight deÄŸerlerini hatanÄ±n azalmasÄ± iÃ§in gradient descent kullanarak gÃ¼ncelliyor. Biz belirlemiyoruz weight deÄŸerlerini. Son kÄ±sÄ±mlarÄ± bÃ¼tÃ¼nlÃ¼k oluÅŸturmasÄ± aÃ§Ä±sÄ±ndan yazdÄ±m, diÄŸer arkadaÅŸlar okurken daha faydalÄ± olabilir.1 month ago 4 people like this.Like ReportReply",
    "-> ->  GÃ¼zel aÃ§Ä±klama teÅŸekkÃ¼rler. Ã‡ok ufak bir ekleme yapayÄ±m. EÄŸer bir ev 2 sokaÄŸÄ±n kesiÅŸiminde (2 sokaÄŸÄ±n kesiÅŸtiÄŸi kÃ¶ÅŸede) bulunuyor ise vektÃ¶rÃ¼mÃ¼zde bahsi geÃ§en 2 sokaÄŸÄ±n deÄŸeri de 1 oluyor. VektÃ¶r de Ã¶rneÄŸin [ 0 0 0 0 1 0 1 0 0] gibi bir ÅŸey oluyor. Ana regresyon denklemimizde de 2 farklÄ± katsayÄ±nÄ±n etkisini dikkate alÄ±yoruz.1 month ago 4 people like this.Like ReportReply",
    "->  ->  teÅŸekkÃ¼r ederim gayet iyi aÃ§Ä±klamÄ±ÅŸsÄ±nÄ±z ğŸ™‚.",
    "->  Merhaba, benim anladÄ±ÄŸÄ±m kadarÄ±yla; one-hot encoding yÃ¶ntemi sayÄ±sal olmayan raw data larÄ± feature a Ã§evirip eÄŸitimde Ã¶ÄŸrenilen weight ile Ã§arpabilmek iÃ§in kullanÄ±lan bir yÃ¶ntem. Yani aslÄ±nda Ã¶nce verileri feature a Ã§evirip ki bunu yaparken one-hot encoding yÃ¶ntemi de kullanÄ±lÄ±yor sonra eÄŸitim esnasÄ±nda weight leri buluyoruz. UmarÄ±m bende doÄŸru anlamÄ±ÅŸÄ±mdÄ±r..",
    "->  Ã‡alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z kÄ±sÄ±mda anlatÄ±lan, model weightlerinin anlamlÄ± olmasÄ± iÃ§in neden kategorik deÄŸiÅŸkenlerde one-hot encoding yÃ¶ntemini kullanmamÄ±z gerektiÄŸi. Bu anlayÄ±ÅŸla o kÄ±sma tekrar bakarsanÄ±z net bir ÅŸekilde anlayacaÄŸÄ±nÄ±zÄ± dÃ¼ÅŸÃ¼nÃ¼yorum..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar herkese, keyifli ve verimli haftalar ???????? Ben sparse representation Ä± tam olarak anlamadÄ±m. Ã‡ok fazla farklÄ± deÄŸer olan kategorik featurelarda multi-hot encoding yaparsak Ã§ok bÃ¼yÃ¼k bir vektÃ¶rde Ã§oÄŸu 0, birkaÃ§ elemanÄ± 1 olan bir gÃ¶sterimin pek doÄŸru olmayacaÄŸÄ±nÄ±, bunun iÃ§in sparse representation yapÄ±labileceÄŸi sÃ¶yleniyor. Bunun iÃ§in vocabularydeki her deÄŸeri indexliyor ve 1 milyon eleman tutmak yerine deÄŸeri 0 dan farklÄ± elemanlarÄ±n deÄŸerlerini ve bu elemanlarÄ±n index ini tutuyor.  Benim anlamadÄ±ÄŸÄ±m index bilgisini training iÅŸleminde nasÄ±l uyguluyor? Index iÃ§in de ayrÄ± bir weight mi kullanÄ±lÄ±yor?  TeÅŸekkÃ¼rler ????",
"comment": [
    "",
    "->  Merhabalar,DoÄŸru anlamÄ±ÅŸsÄ±nÄ±z. Yeniden bir indexleme yapÄ±lmÄ±yor. Sadece elimizde tutacaÄŸÄ±mÄ±z datalarÄ± indexleri ile birlikte alÄ±nÄ±yor. Ancak index bilgisi benzersiz olmasÄ± sebebi ile ML iÃ§in kullanÄ±lamamaktadÄ±r. EÄŸitime katkÄ± saÄŸlamamasÄ± sebebiyle veriden eÄŸitim aÅŸamasÄ±na gelmeden Ã§Ä±kartÄ±lÄ±r diye biliyorum.Ä°yi Ã§alÄ±ÅŸmalar. ğŸ™‚1 month ago 3 people like this.Like ReportReply",
    "->  Bu gÃ¶sterimin teorik temeli seyrek matrisler (sparse matrices ). https://en.wikipedia.org/wiki/Sparse_matrix linkinden ekstra inceleme yapabilirsiniz.",
    "Sparse matrix - Wikipediaen.wikipedia.orghttps://en.wikipedia.org/wiki/Sparse_matrix.",
    "->  TeÅŸekkÃ¼rler ğŸ™‚ ->  -> .",
    " "
]
},
{
"question_isim": "->",
"quest": "Merhaba,  \"There's a Goldilocks learning rate for every regression problem. \" Goldilocks ile learning rate baglantisini, Goldilocks learning rate kavramini biraz acabilir misiniz?",
"comment": [
    "",
    "->  Merhaba,Goldilocks kavramÄ± ve learning rate'in rolÃ¼ http://community.globalaihub.com/community/status/1043-1043-1586253928/ postunun altÄ±nda aÃ§Ä±klanmÄ±ÅŸtÄ±. Oradan bulabilirsiniz.Ä°yi Ã§alÄ±ÅŸmalar dilerim.1 month ago 2 people like this.Like ReportReply",
    "-> gozden kacirmisim, tesekkurler..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "The Future of AI Survey isimli 1 dakikalÄ±k anketimize katÄ±labilirsiniz. Sorularla ilgili yorumlarÄ±nÄ±zÄ± da merak ediyorum :)  <a class=\"ps-media-link\" href=\"https://docs.google.com/forms/d/e/1FAIpQLSekZsmKXYN2MmP9B57Z7os2JEc1phbOK0WYn15InNwSCnh-pg/viewform\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">https://docs.google.com/forms/d/e/1FAIpQLSekZsmKXYN2MmP9B57Z7os2JEc1phbOK0WYn15InNwSCnh-pg/viewform</a>",
"comment": [
    "",
    "->  Bu sorular bana Isaac Asimov kitaplarÄ±nÄ± hatÄ±rlattÄ±. Ä°leride Yapay ZekalarÄ±n en az insanlar kadar Ã¶nem kazanacaklarÄ± kendi kararlarÄ±nÄ± verecekleri hatta bilinÃ§ ve vicdan gibi hissel fonksiyonellik kazanacaklarÄ± bence mÃ¼mkÃ¼n olacaktÄ±r. Bununla ilgili Detroit Become Human isimli bir oyun vardÄ±. Bu oyun yapay zeka konusuna kesinlikle farklÄ± bir bakÄ±ÅŸ aÃ§Ä±sÄ± sunuyor..",
    "->  1- Dikkatli olmak koÅŸuluyla yapay zeka Ã§aÄŸÄ±nÄ±n olumlu yanlarÄ±nÄ±n daha aÄŸÄ±r bastÄ±ÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum. 2-Tercihim her Ã¼lkeye eÅŸit bir daÄŸÄ±lÄ±m. Ancak birkaÃ§ Ã¼lke Ã§ok daha ileri durumda. Yapay zekanÄ±n (uygun kullanÄ±mÄ±yla) getirisi Ã¼stel olduÄŸundan geride olsak da bir umut var. Ãœlke olarak sÃ¼rekli geliÅŸmekte olan Ã¼lkeler sÄ±nÄ±fÄ±ndan Ã§Ä±kmak istiyorsak yapay zeka yatÄ±rÄ±mÄ± ilk sÄ±ralarda olmalÄ±. Belki de ilk. 3- Beklentim yapay zekalarÄ±n bizim yaÅŸam kalitemizi arttÄ±rmak iÃ§in hizmetimizde kalmasÄ±. Ama diÄŸer iki vizyon da oldukÃ§a muhtemel gÃ¶rÃ¼nÃ¼yor..",
    "-> olumlu ve olumsuz yÃ¶nleri aslÄ±nda nasÄ±l kullanÄ±caÄŸÄ±mÄ±zla alakalÄ± kiÅŸisel haklarÄ± koruduÄŸumuz sÃ¼rece bende olumlu yÃ¶nlerinin daha fazla olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yorum ,Ã¼lke olarak siz deÄŸerli topluluklar sayesinde umarÄ±m bizlerde yapay zekaya yÃ¶n veren Ã¼lkelerden biri oluruz,herkese iyi Ã§alÄ±ÅŸmalar...",
    "->  Bu anket; bana, Ã§ok sevdiÄŸim bilimkurgu tÃ¼rÃ¼ndeki kitaplarÄ± anÄ±msattÄ±. Tek bir ulusun yapay zeka konusunda liderlik etmesini istemem. Her Ã¼lkenin eÅŸit olduÄŸu durum daha mantÄ±klÄ± gÃ¶rÃ¼nse de ben 2.soruda diÄŸer seÃ§eneÄŸini seÃ§tim. Yapay zeka konusunda bireylerin tek baÅŸÄ±na hareket edip bir milletin veya kurumun (teknoloji ÅŸirketi) mensubu olmadan yapay zeka Ã§atÄ±sÄ± altÄ±nda toplanacaklarÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum. Yapay zekanÄ±n insanlarÄ± geÃ§eceÄŸini, ama sosyal bir varlÄ±k olarak insan gibi olamayacaklarÄ±nÄ±, bildiÄŸimiz anlamda canlÄ± olmasalar bile onlarÄ± gerÃ§ek bir varlÄ±k olarak tanÄ±mladÄ±ÄŸÄ±mÄ± belirtmek istiyorum. Etik, toplum bilimi vb. birbirine baÄŸlÄ± deÄŸerleri de iÅŸin iÃ§ine katarsak bayaÄŸÄ± tartÄ±ÅŸmalÄ± bir konu olan yapay zekanÄ±n getireceÄŸi ÅŸeyleri yaÅŸayarak gÃ¶receÄŸiz. ????.",
    "->  Yapay zeka konusuna ben TÃ¼rkiye nin liderlik etmesini isterim buradak bulunma amacÄ±mÄ±zda bunu gerÃ§ekleÅŸtirmeye Ã§alÄ±ÅŸma azmimiz deÄŸil mi ki?.",
    "->  Sosyalist bir bakÄ±ÅŸ aÃ§Ä±sÄ±yla deÄŸerlendirirsek, AI gelecekte adil servet daÄŸÄ±lÄ±mÄ±na, devlet kontrollÃ¼ ekonomide eksiksiz bir planlama yetisine ve imkanlarÄ±n eÅŸit kullanÄ±mÄ±na imkan saÄŸlayabilir. Yapay zekanÄ±n gelecekte bir veya birkaÃ§ devletin kontrolÃ¼nde olmasÄ±ndansa, daÄŸÄ±nÄ±k merkezli bir gÃ¼Ã§ olmasÄ±, onun insanlÄ±ÄŸa olan faydasÄ±nÄ± artÄ±rÄ±r. Ä°nternetin bu sÄ±nÄ±rlÄ± daÄŸÄ±lÄ±mÄ± bile insanlara onlarca fÄ±rsat ve eÅŸitlik tanÄ±yÄ±p, onlarÄ± bir nebze Ã¶zgÃ¼rleÅŸtirdiyse, Ã§ok merkezli bir yapay zekanÄ±n insanlara, onun kullanÄ±m alternatiflerini gÃ¶rmeleri aÃ§Ä±sÄ±ndan daha yararlÄ± olacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum.1 month ago 6 people like this.Like ReportReply",
    "->  Fuat hocam yardÄ±ma ihtiyacÄ±m var mailim hacklendi mobil Ã¼zerinden mail adresini ve ÅŸifreyi deÄŸiÅŸtirdim log in olduÄŸum iÃ§in mobilden sÄ±kÄ±ntÄ±sÄ±z buraya girebiliyorum fakat pc Ã¼zerinden global ai community giriÅŸ yapamÄ±yorum yeni Ã¼yeliÄŸe yÃ¶nlendiriyor beni machine learning ve turkish ai gruplarÄ±na da giremeyeceÄŸim yeni Ã¼yelikte parola sÄ±fÄ±rlama linkide atmÄ±yor yeni maile lÃ¼tfen yardÄ±mcÄ± olun bana.",
    "->  ->  Ã–mer Bey merhaba, mail adresinizi iletebilir misiniz, ilgili arkadaÅŸa yÃ¶nlendireyim sizi, durumu Ã§Ã¶zelim..",
    "->  -> mail adresim twitter @cepnii_ buradan ulaÅŸamazsanÄ±z tw adresi yedek kalsÄ±n ne olur ne olmaz Ã§ok sevindim msjÄ±nÄ±zÄ± gÃ¶rÃ¼nce.",
    "->  En iyi seÃ§enek uzmanlardan oluÅŸan ve \"ulusÃ¼stÃ¼\" Ã§Ä±karlarÄ± gÃ¶zeten bir topluluk tarafÄ±ndan yÃ¶netilmesi olmaz mÄ±ydÄ±?AyrÄ±ca ilgisiz olabilir ama bir sorum var. Sizce singularity kaÃ§Ä±nÄ±lmaz mÄ±?.",
    "->  ->  Bence de oraya doÄŸru gidiyoruz..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba. Binning ile feature'Ä± belirli sÄ±nÄ±rlara bÃ¶lÃ¼p, bu sÄ±nÄ±r sayÄ±sÄ± kadar yeni feature elde edip, bu featurelarÄ± da binary vectorler ile mi ifade ediyoruz?",
"comment": [
    "",
    "-> Merhaba,Bunu basit bir Ã¶rnekle anlatabilirim. Ã–rneÄŸin sizin elinizde yaÅŸlarÄ± farklÄ± 10 tane insan olsun. Bu insanlarÄ±n yaÅŸlarÄ± numerik veridir ve siz binningde bunu kategorik veriye Ã§evirirsiniz ki feature ile label arasÄ±nda lineer bir baÄŸÄ±ntÄ± oluÅŸabilsin. Ã–rneÄŸin bu insanlarÄ±n yaÅŸlarÄ±na gÃ¶re diyabet olup olmadÄ±klarÄ±nÄ± tahmin etmek istiyorsunuz bunun iÃ§in ise elinizde her yaÅŸ grubu iÃ§in belli diyabet risk deÄŸerleri var Ã¶rmeÄŸin 50-60 arasÄ± riskli siyabet 40-50 arasÄ± az riskli diyabet gibi. Burada yapmanÄ±z gereken ÅŸey bu yaÅŸlarÄ± kategorik veriye Ã§evirmek. Bunun iÃ§in Elinizde 10 tane insan var ise bu insanlarÄ±n yaÅŸ aralÄ±klarÄ±nÄ± bulup bunlarÄ± kategorik veriye Ã§evirirsiniz (Ã¶rneÄŸin 19 yaÅŸ iÃ§in 10lar, 28 yaÅŸ iÃ§in 20ler.... gibi) Burada sÄ±nÄ±r sayÄ±sÄ± kadar yani bÃ¶ldÃ¼ÄŸÃ¼mÃ¼z kategorik veri sayÄ±sÄ± kadar feature'Ä±mÄ±z oldu. Bu featurelar binary vectorler ile ifade edilir Ã¶rneÄŸin 10lar feature'Ä±mÄ±zÄ±n value'sÄ± binary vectordÃ¼r ve karÅŸÄ±lÄ±ÄŸÄ± sÄ±rasÄ±yla [10lar,20ÅŸer,30lar,40lar,50ler,60lar,70ler,80ler,90lar] olacaktÄ±r. EÄŸer biz 19 yaÅŸÄ±ndaki bir insanÄ± bu binary vectÃ¶r ile ifade edeceksek [1,0,0,0,0,0,0,0,0] olarak yapmalÄ±yÄ±z ki bu insanÄ±n hangi kategoride olduÄŸunu belli edebilelim. (10- yaÅŸ arasÄ±nda). UmarÄ±m aÃ§Ä±klayÄ±cÄ± olmuÅŸtur eÄŸer olmamÄ±ÅŸsa ekstra olarak ÅŸu linki de inceleyebilirsiniz: https://www.youtube.com/watch?v=iv_ec0EfXcE&t=204s . EksiÄŸim veya hatam varsa dÃ¼zeltilmelere aÃ§Ä±ÄŸÄ±m ğŸ™‚Machine Learning Tutorial 10 - Binning Datawww.youtube.comBest Machine Learning book: https://amzn.to/2MilWH0 (Fundamentals Of Machine Learning for Predictive Data Analytics). Machine Learning and Predictive Analyti...1 month ago 8 people like this.Like ReportReply",
    "-> ->  NiÃ§in yaÅŸ gruplarÄ±nÄ± 10-19, 20-29 vs. gibi gruplara ayÄ±rÄ±yoruz. Ã–rneÄŸin; 10-14, 15-19, 20-24 vs. gibi ayÄ±rsak ne olurdu. Buna sezgisel mi karar veriyoruz?.",
    "->  -> Merhaba, buna sezgisel karar verebilirsiniz. Ã–rneÄŸin yeni bir hastalÄ±k tipi beÅŸerli yaÅŸ gruplarÄ± iÃ§in deÄŸiiklik gÃ¶steriyorsa bunun iÃ§in yaÅŸlarÄ± beÅŸerli gruplara ayÄ±rabilirsiniz..",
    "-> ->  O halde bir soru daha sorayÄ±m. EÄŸer bu aralÄ±klarÄ±mÄ±zÄ±n sabit olduÄŸunu (yani asimetri var) dÃ¼ÅŸÃ¼nmÃ¼yorsak yani 10-19, 20-29 gibi gruplar yapÄ±yorken belli bir yaÅŸtan sonra (Ã–rneÄŸin 60 yaÅŸÄ±ndan sonra gruplarÄ± 60-64, 65-69 ÅŸeklinde yapmamÄ±z gerekiyor olsun) bu gruplarÄ±n daralmasÄ± gerektiÄŸini dÃ¼ÅŸÃ¼nÃ¼yorsak nasÄ±l bir yol izlemeliyiz..",
    "->  -> Merhaba, https://medium.com/hacktive-devs/feature-engineering-in-machine-learning-part-1-a3904769cd93 linkinde 3 ÅŸekilde binning yapabileceÄŸimizden bahsediyor. Benim yukarÄ±da bahsettiÄŸim binning Ã§eÅŸidi Fixed-Width Binning Ã§eÅŸididir. Yani binning aralÄ±klalarÄ± arasÄ±nda sabit bir katsayÄ± vardÄ±r. Sizin dediÄŸiniz yÃ¶ntem de gerÃ§ekleÅŸtirilebilir buna Binning By Instinct(Ä°Ã§gÃ¼dÃ¼yle binning) denir. Burada bin range aralÄ±klarÄ±nÄ± siz belirliyorsunuz. Toparlamam gerekirse, dediÄŸiniz yÃ¶ntem iÃ§in Binning By Instinct kullanabilirsiniz.",
    "Feature Engineering in Machine Learning (Part 1)medium.comHandling Simple Numeric Data with Binning.",
    "-> buraya ek olarak bir ÅŸey sormak isterim, Ã§ok saÃ§ma olabilir ama kusura bakmayÄ±n lÃ¼tfen, peki bunlarÄ± bir sokakta yaÅŸayan, yaÅŸ aralÄ±klarÄ±nÄ±, diyabet durumlarÄ±nÄ±(az riskli, Ã§ok riskli, risksiz) ve yaÅŸadÄ±klarÄ± yerleri(latitude cinsinden) barÄ±ndÄ±ran bir raw values olarak dÃ¼ÅŸÃ¼nÃ¼rsek, yaÅŸ aralÄ±klarÄ±nÄ± ve yaÅŸadÄ±klarÄ± yerleri binning ile diyabet olma durumlarÄ±nÄ± ise on-hot-encodingle kategorileÅŸtirip hepsi iÃ§in yeni feature'lar (binary vectorler) elde ederek, bu sayede train modeli daha iyi tahmin verileri Ã§Ä±karsÄ±n diye mi eÄŸitiyoruz? Yoksa bunlar tamamen bu Ã¶rnekten farklÄ±, ayrÄ± ayrÄ± konular mÄ±?1 month ago Like Reply Edit",
    "-> -> Makine Ã¶ÄŸrenme algoritmalarÄ± doÄŸrudan kategorik veriler Ã¼zerinde Ã§alÄ±ÅŸmamaktadÄ±r bu yÃ¼zden verilerimizin sayÄ±sal verilere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi gerekmektedir.Ã–ncelikle binning feature ile numerik verimizi kategorik karÅŸÄ±lÄ±klarÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yoruz. Binning kullanarak yaÅŸlarÄ±mÄ±zÄ± 10-20,40-50 gibi kategorilere ayÄ±rÄ±yoruz ki amacÄ±mÄ±z verideki gÃ¼rÃ¼ltÃ¼yÃ¼ ve non-linearity durumunu azaltÄ±p modelimizin generalization oranÄ±nÄ± arttÄ±rmak. YaÅŸ iÃ§in konuÅŸursak ÅŸu an elimizde 10-20,21-30.. kategorilerine karÅŸÄ±lÄ±k gelen booelan featurelarÄ± oldu. Yani bir kiÅŸi 18 yaÅŸÄ±nda ise 10-20 yaÅŸ aralÄ±ÄŸÄ± feature'Ä± 1, diÄŸerleri 0'dÄ±r. Bir eÄŸitim Ã¶rneÄŸi iÃ§in bu yaÅŸ kategorilerinden aynÄ± anda ikisi de 1 olamaz. Ã–rneÄŸin bir kiÅŸi hem 27 hem de 37 yaÅŸÄ±nda olamaz. Bu yÃ¼zden bu One Hot Encoding olarak geÃ§er.YaÅŸadÄ±klarÄ± yer iÃ§in de tahminime gÃ¶re bu deÄŸerleri de binning ile kategorik verilere sokup labelÄ±mÄ±zÄ± bu kategorileÅŸmiÅŸ veriler Ã¼zerinden yapmamÄ±z, yani regression problemimizi classification problemine Ã§evirmemiz gerekiyor.Diyabet olma durumunu ise evet One Hot Encoding ile kategorileÅŸtirip bunu da numerik gÃ¶sterime sÄ±ÄŸdÄ±rabilmek iÃ§in binary vector elde ederiz ve tÃ¼m bu iÅŸlemlerimizin amacÄ± kategorik verileri numerik veriye sokmak ve generalization'Ä± yani veri tahminini arttÄ±rmaktÄ±r. GÃ¶zden kaÃ§Ä±rdÄ±ÄŸÄ±m veya eksik noktam varsa dÃ¼zeltmekten eklemekten Ã§ekinmeyin ğŸ™‚ Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 4 people like this.Like ReportReply",
    "-> ->  Ã§ok teÅŸekkÃ¼r ederim1 month ago 1 person likes thisLike Reply Edit",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar, Validation and Test sets kÄ±smÄ±nda, loss eÄŸrileri arasÄ±ndaki farkÄ± azaltmak iÃ§in, veri setini shuffle etmemiz gerektiÄŸi anlatÄ±lmÄ±ÅŸtÄ±(longtitude a gÃ¶re azalan indekslendiÄŸi iÃ§in, split ederken train ve validasyon setinin iÃ§eriÄŸi benzer olmuyor, bundan dolayÄ± shuffle etmemiz gerekiyor), shuffle ettikten sonra da eÄŸrilerin birbirine yakÄ±n konumlandÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼yoruz. Ancak, shuffle edilmemiÅŸ kÄ±sÄ±mda validation_split i 0.4 e Ã§ekerek de aradaki farkÄ± azaltabiliyoruz. Bu tamamen elimizdeki veri setine gÃ¶re gerÃ§ekleÅŸen rastlantÄ±sal bir durum mudur? Ä°ki yÃ¶ntemin birbirinden farkÄ± nedir teknik olarak? validasyona ayÄ±rdÄ±ÄŸÄ±mÄ±z veri miktarÄ±nÄ±n yÃ¼zdesini artÄ±rmak genel olarak tercih edilmemesi gereken bir yol mudur? TeÅŸekkÃ¼r ederim ÅŸimdiden yorumlar iÃ§in.",
"comment": [
    "",
    "-> Merhaba,Shuffle edilmemiÅŸ veride calidation boyutunu deÄŸitirerek loss eÄŸrilerini birbirine yakÄ±nlaÅŸtÄ±rabiliyoruz. Ä°lk durumda train loss 70, validation loss 90 olsun, validation setin boyutunu arttÄ±rdÄ±kÃ§a, train'in loss deÄŸeri artacak, validation'un azalacak yani 80 civarlarÄ±nda bu iki eÄŸri yaklaÅŸÄ±k olarak birbirlerinin aynÄ±sÄ± olacak. Ki bu durum loss da azalma yapmamakta aksine artÄ±ÅŸa sebep olmakta. Bu yÃ¼zden validation seti optimum boyutta tutarak, train seti olabildiÄŸince bÃ¼yÃ¼k tutmayÄ± amaÃ§lÄ±yoruz.SÄ±ralÄ± veri setinden rastgele Ã¶rnek Ã§ekmiÅŸ olsak bile sÄ±ralÄ± veri Ã§ekmiÅŸ oluruz. Bu durumda da Ã§ekmiÅŸ olduÄŸumuz Ã¶rnek ile train setimizi saÄŸlÄ±klÄ± bir ÅŸekilde ifade edemeyiz.(Train ve Test setleri aynÄ± daÄŸÄ±lÄ±mdan seÃ§ilmeli - Generalization Assumption 3). Bu sebeple veri setimizi karÄ±ÅŸtÄ±rÄ±yor sonrasÄ±nda Ã¶rneklem Ã§ekiyoruz. BÃ¶ylece verimizi genelleyebileceÄŸimiz bir Ã¶rnek Ã§ekebilme ihtimalimiz sÄ±ralÄ± veride olduÄŸundan daha fazla olacaktÄ±r.Loss EÄŸrilerinin grafiÄŸini inceleyerek bahsettiÄŸim durumlarÄ± gÃ¶zlemleyebilirsiniz.Ä°yi Ã§alÄ±ÅŸmalar..",
    "->  Validation ve train datasetleri icin shuffle = True dedigimizde randomization saglar ve modelin ezberlemesinin onune gecilmesine yardim eder.Tabiki ezberlemeyi yani overfitting i sadece shuffle = True diyerek engelleyemeyiz ve overfitting ortaya ciktiginda validation loss ile test loss arasindaki fark buyuk egriler uzak olur.Validation ve test loss egrilerini birbirine yaklastirmak demek validation sirasinda modelimizi check ederken aldigimiz iyi sonuclari(umarim iyi sonuclardir) test sirasinda da elde etmek, parallel sonuclara sahip olmak demektir.Yani bir anlamda overfittingi onlemek demektir.Iyi generalization demektir.Bunu yapmanin yolu validation setini buyutmek train setini kucultmek filan degildir..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba arkadaÅŸlar,  Ã–ncelikle umarÄ±m herkesin sÄ±navÄ± verimli olmuÅŸtur, yeni hafta iÃ§in de ÅŸimdiden iyi Ã§alÄ±ÅŸmalar :)  Correlation matrix Ã¼zerine biraz dÃ¼ÅŸÃ¼ndÃ¼m de, output ile yÃ¼ksek corr. deÄŸerine sahip olanlar Ã§ok Ã¶nemli onlarÄ± kesinlikle traininge dahil etmeliyiz ama hem output hem de diÄŸer featureâ€™lar ile 0a yakÄ±n corr deÄŸerine sahip olan bir featureâ€™Ä± traininge dahil etmeye gerÃ§ekten gerek var mÄ± sorusu kafamÄ± kurcaladÄ±.  Ama sonuÃ§ta corr matrix bize aralarÄ±ndaki bÃ¼tÃ¼n iliÅŸkiyi vermiyordu sadece artÄ±ÅŸ-azalÄ±ÅŸ iliÅŸkisi ile ilgili bir bilgi alÄ±yorduk bu da featureâ€™lar arasÄ±ndaki farklÄ± bir iliÅŸkinin outputu etkileme ihtimalinin bu matrix ile keÅŸfedilememe olasÄ±lÄ±ÄŸÄ±nÄ± ortaya Ã§Ä±kartÄ±yordu.  Bunu bir Ã¶rnekle aÃ§Ä±klamam gerekirse mesela a b c featurelarÄ±mÄ±z ve y output olsun, (a-b)+câ€™nin outputa eÅŸit olmasÄ± gibi bir durumda aâ€¦ <a class=\"ps-stream-post-more ps-js-content-excerpt-toggle\" href=\"#\">Read more</a></div><div class=\"ps-js-content-full\" style=\"\">Merhaba arkadaÅŸlar,  Ã–ncelikle umarÄ±m herkesin sÄ±navÄ± verimli olmuÅŸtur, yeni hafta iÃ§in de ÅŸimdiden iyi Ã§alÄ±ÅŸmalar :)  Correlation matrix Ã¼zerine biraz dÃ¼ÅŸÃ¼ndÃ¼m de, output ile yÃ¼ksek corr. deÄŸerine sahip olanlar Ã§ok Ã¶nemli onlarÄ± kesinlikle traininge dahil etmeliyiz ama hem output hem de diÄŸer featureâ€™lar ile 0a yakÄ±n corr deÄŸerine sahip olan bir featureâ€™Ä± traininge dahil etmeye gerÃ§ekten gerek var mÄ± sorusu kafamÄ± kurcaladÄ±.  Ama sonuÃ§ta corr matrix bize aralarÄ±ndaki bÃ¼tÃ¼n iliÅŸkiyi vermiyordu sadece artÄ±ÅŸ-azalÄ±ÅŸ iliÅŸkisi ile ilgili bir bilgi alÄ±yorduk bu da featureâ€™lar arasÄ±ndaki farklÄ± bir iliÅŸkinin outputu etkileme ihtimalinin bu matrix ile keÅŸfedilememe olasÄ±lÄ±ÄŸÄ±nÄ± ortaya Ã§Ä±kartÄ±yordu.  Bunu bir Ã¶rnekle aÃ§Ä±klamam gerekirse mesela a b c featurelarÄ±mÄ±z ve y output olsun, (a-b)+câ€™nin outputa eÅŸit olmasÄ± gibi bir durumda a ya da bâ€™nin bÃ¼tÃ¼n corr deÄŸerleri 0 olsa bile kendi aralarÄ±ndaki farkÄ±n outputa etkisi olduÄŸunu gÃ¶rebiliyoruz, yani corr matrix bir iÅŸimize yaramÄ±yor. Peki bu gibi durumlarda hangi featureâ€™larÄ±n elenmesi hangilerinin traininge dahil edilmesine nasÄ±l karar vermeliyiz?  Zaman ayÄ±rdÄ±ÄŸÄ±nÄ±z iÃ§in Ã§ok teÅŸekkÃ¼r ederim.</div></div>",
"comment": [
    "",
    "-> Overfit'i engellemenin yollarÄ±ndan birisi \"removing useless/irrelevant features\". Ä°lgisiz Ã¶zelliklerin modelde kullanÄ±lmasÄ± modelin verimini dÃ¼ÅŸÃ¼rebilir. Bu feature'lar ya veri setinden dÃ¼ÅŸÃ¼rÃ¼lÃ¼yor ya da daha iliÅŸkili olabilecek hale dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor.google crash course'da california housing data'yla Ã§alÄ±ÅŸÄ±rken toplam oda sayÄ±sÄ±nÄ± nÃ¼fusa bÃ¶lerek \"kiÅŸi baÅŸÄ±na dÃ¼ÅŸen oda sayÄ±sÄ±\" feature'Ä±nÄ± oluÅŸturduÄŸumuzda bunu yaptÄ±k. EÄŸer modeli tek yerine Ã§ok sayÄ±da Ã¶zellik kullanarak eÄŸitiyor olsaydÄ±k, \"evin kapÄ±sÄ±nÄ±n rengi\"(mesela) gibi bir kolonu model dÄ±ÅŸÄ±nda bÄ±rakmamÄ±z gerekirdi.DolayÄ±sÄ±yla, yanlÄ±ÅŸ yorumlamÄ±yorsam, bu Ã¼zerine Ã§alÄ±ÅŸÄ±lan alanÄ± iyi bilmemizi gerektiriyor. Ã‡Ã¼nkÃ¼, belki de kapÄ±nÄ±n rengi bu bÃ¶lge iÃ§in zenginlik/lÃ¼ks belirtisidir:Ã–r.Afrika'da birkaÃ§ sene Ã¶nce yoksul hanelere yapÄ±lacak yardÄ±mlarÄ±n doÄŸru kiÅŸilere ulaÅŸmasÄ±nÄ± saÄŸlamak iÃ§in bir derin Ã¶ÄŸrenme Ã§alÄ±ÅŸmasÄ± yapÄ±ldÄ±. Uydu fotoÄŸraflarÄ± yorumlanarak yardÄ±ma talip bÃ¶lgedeki evlerin ne kadarÄ±nÄ±n metal Ã§atÄ±lara sahip olduÄŸu ayÄ±rt edildi. BÃ¶ylece bu bÃ¶lgenin diÄŸer bÃ¶lgelere kÄ±yasla ne kadar fakir/zengin olduÄŸu ayÄ±rt edildi.https://www.liebertpub.com/doi/pdf/10.1089/big.2014.0061https://www.liebertpub.com/doi/pdf/10.1089/big.2014.0061www.liebertpub.comhttps://www.liebertpub.com/doi/pdf/10.1089/big.2014.00611 month ago 3 people like this.Like ReportReply",
    "->  Soruya detaylÄ± bir yanÄ±t veremeyeceÄŸim fakat ufak bir ekleme yapayÄ±m; feature'lar arasÄ±ndaki correlation Ã§ok yÃ¼ksekse bunun tahminimiz Ã¼zerinde ekstra bilgi taÅŸÄ±madÄ±ÄŸÄ±nÄ± ve bu feature'larÄ±n elenmesi gerektiÄŸini biliyorum. Mesela bir feature diÄŸerinin 2 katÄ± ise, correlation deÄŸeri 1 olur ve bir tanesini silmek verimlilik aÃ§Ä±sÄ±ndan faydalÄ± oluyor.1 month ago 2 people like this.Like ReportReply",
    "->  ->  Bence de corr deÄŸeri 1 ise o feature'lardan birini silmek gayet mantÄ±klÄ± bir karar olur sadece ufak bir ekleme yapmak istiyorum, anladÄ±ÄŸÄ±m kadarÄ±yla corr deÄŸeri bize artÄ±ÅŸ/azalÄ±ÅŸ katsayÄ±sÄ±nÄ± deÄŸil, olasÄ±lÄ±ÄŸÄ±nÄ± veriyor.(verdiÄŸiniz Ã¶rnekte bu yanlÄ±ÅŸ anlaÅŸÄ±lmalara yol aÃ§abilir diye eklemek istedim).",
    "->  Merhabalar,Bu konu ile alakalÄ± yakÄ±n bir geÃ§miÅŸte araÅŸtÄ±rma yapmak fÄ±rsatÄ±m oldu. KarÅŸÄ±laÅŸtÄ±ÄŸÄ±m yÃ¶ntemlerin bÃ¼yÃ¼k Ã§oÄŸunluÄŸu deneyerek buna karar vermekte. DiÄŸer kÄ±smÄ± ise modelde kimin kalacaÄŸÄ±na istatistiksel testler yaparak karar verip sonrasÄ±nda elde ettikleri modelleri deneyerek etkinlikliklerini Ã¶lÃ§mekte.Sorunuza cevap verecek olursam: Deneyerek karar verebilirsiniz..",
    "->  Herkese cevaplarÄ± iÃ§in Ã§ok teÅŸekkÃ¼r ederim, ÅŸu ana kadar yapÄ±lan yorumlardan elde ettiÄŸim Ã§Ä±karÄ±mlar; Ã¼zerine Ã§alÄ±ÅŸÄ±lan alana gÃ¶re bilgi sahibi olmak gerekebiliyor ya da deneyerek Ã¶nemli/Ã¶nemsiz feature'larÄ± tespit etmek. Ben aynÄ± zamanda ÅŸunu da merak ediyordum acaba bunlarÄ± tespit etmek iÃ§in belirli algoritma veya matematiksel yaklaÅŸÄ±mlar var mÄ±?.",
    "->  ->  Istatistiki yaklasimlar var.kisa cevap: Sormus oldugun sorunun temeli Multiple Regression Analysis. Bu isimle google'laya bilirsin ya da talep edersen sana link gonderebilirim.Konuya ne kadar hakimsin bilemiyorum ama oncelikle sunu vurgu yapmak gerekiyor, verdigin ornek ve uyguladigin correlation matrix multiple regression konusunun ogeleri, yani coklu aciklayici degisken ile bir bagimli degiskenin tahmini. Cok degiskenli regresyonlarda regresyonun tahmin gucu ana konudur. Bunun da olcutu R-Squared denen bir parametre. Yalniz regresyona her buldugun degiskeni atma sansin yok ne yazik ki; kurgulanmasinda kistaslar bulunuyor. Ornegin aciklayici degiskenler arasinda dogrusal bir iliski bulunmamali (collinearity). Bu tarz degiskenlerden sadece birini denkleme katabilirsin ya da degiskenleri arindirdiktan sonra kullanabilirsin..",
    "->  ->  Multiple Regression Analysis ile ilgili daha detaylÄ± araÅŸtÄ±rma yapacaÄŸÄ±m. R-squared parametresi yukarÄ±da anlattÄ±ÄŸÄ±nÄ±za gÃ¶re RMSE ile aynÄ± gÃ¶revi gÃ¶rÃ¼yor yani tahmin gÃ¼cÃ¼nÃ¼ anlamamÄ±za yarÄ±yor, bir farkÄ± var mÄ±dÄ±r acaba soruyorum Ã§Ã¼nkÃ¼ eÄŸer pek bir farkÄ± yoksa Ã¼zerinde durmanÄ±zÄ±n ve RMSE yerine onu kullanmanÄ±zÄ±n sebebini tam anlayamadÄ±m, teÅŸekkÃ¼rler..",
    "->  ->  Fark var. RMSE mevcut durumu acikliyor. Verilen degerlere bagli olarak su kadar ya da bu kadar basarili demek icin var. R-squared dagilimin aciklayicilik gucu var. Yani (dagilimda bir degisiklik olmadigi surece) modelin yeni verileri de ne kadar aciklayabildigini ifade etmek icin kullaniliyor. Su soylediklerim birbirinin aynisi ya da ayni seyin laciverti gibi geliyor kulaga belki ama degil. Ikisi de modelin gucuyle mi alakali, evet. Ayni seyler mi veya ayni amaca mi hizmet ediyorlar, hayir. Yazilim gecmisinden geldigini varsayarak, su soylediklerimi icsellestirebilmek sanirim istatistik ile biraz hasir nesir olmayi gerektiriyor, onu da sana ben veremiyor olabilirim. Suraya iki link birakayim, benim anlattiklarimdan daha faydali olurlar sanirim.RMSE: https://www.statisticshowto.com/rmse/R-squared: https://www.statisticshowto.com/probability-and-statistics/coefficient-of-determination-r-squared/",
    "RMSE: Root Mean Square Errorwww.statisticshowto.comShareTweetLinkedInEmail Regression Analysis > RMSE: Root Mean Square Error What is Root Mean Square Error (RMSE)? Root Mean Square Error (RMSE) is the standard deviation of the residuals (prediction errors). Residuals are a measure of how far from the regressionâ€¦.",
    "->  https://scikit-learn.org/stable/modules/feature_selection.html1.13. Feature selection â€” scikit-learn 0.22.2 documentationscikit-learn.orghttps://scikit-learn.org/stable/modules/feature_selection.html.",
    "->  Charles Wheelan'Ä±n Ã§Ä±plak istatistik kitabÄ±nda bu gibi durumlar iÃ§in Regresyon Analizini(diÄŸer tÃ¼m deÄŸiÅŸkenlerin aynÄ± ÅŸartlar altÄ±nda sabit tutularak, elimizdeki deÄŸiÅŸkenin(feature) etkisini Ã¶lÃ§meyi) Ã¶neriyordu. Ä°yice araÅŸtÄ±rmak gerekiyor sonuÃ§ olarak \"etkisi olabilir de olmayabilir de\" diye bir sonuca varÄ±yorsunuz ğŸ™‚ Yine domain hakkÄ±nda bilgi sahibi birisine danÄ±ÅŸmak da hÄ±zlÄ± bir Ã§Ã¶zÃ¼m olabilir diye Ã¶neriyordu..",
    "->  ->  teÅŸekkÃ¼rler, denemek ya da domain hakkÄ±nda bilgi gerekliliÄŸi sorunun popÃ¼ler cevaplarÄ± ğŸ™‚.",
    "-> 1 month ago 4 people like this.Like ReportReply",
    "->  ->  Yani elimizde birden fazla sayÄ±da ve farklÄ± modeller iÃ§in farklÄ± optimal feature selection algoritmalarÄ± var gibi gÃ¶rÃ¼nÃ¼yor. MÃ¼sait bir zamanÄ±mda tabloda adÄ± geÃ§en algoritmalara bi gÃ¶z atÄ±cam, teÅŸekkÃ¼r ederim..",
    "->  ->  Evet dogru.Rica ederim..",
    "->  Merhaba, Ã§oklu regresyon analizinde yeni bir baÄŸÄ±msÄ±z deÄŸiÅŸken(Ã¶zellik) modele dahil olursa R^2 ya aynÄ± kalÄ±r ya da artar. Ancak bu modelimizin daha iyi aÃ§Ä±klama oranÄ±na sahip olduÄŸu anlamÄ±na gelmez. AÃ§Ä±klayÄ±cÄ±lÄ±ÄŸÄ±n artÄ±p artmadÄ±ÄŸÄ±na bakmak iÃ§in R^2 adjusted deÄŸerine bakmamÄ±z gerekir. R^2 adjusted modele yeni bir Ã¶zellik eklendiÄŸinde modeldeki parametre sayÄ±sÄ±nÄ± ve Ã¶rneklem sayÄ±sÄ±nÄ± dikkate alarak RÂ² Ã¼zerinde ayarlama yapar. Modele yeni parametre ekledikÃ§e RÂ² deÄŸeri yÃ¼kselir ancak modelin karmaÅŸÄ±klÄ±ÄŸÄ±nÄ±n azaltÄ±lmasÄ± iÃ§in modelin en az deÄŸiÅŸken ile aÃ§Ä±klanmasÄ± beklenir. Bu nedenle modele yeni deÄŸiÅŸkenler eklendiÄŸinde gereksiz eklenen deÄŸiÅŸkenleri cezalandÄ±ran R_adjÂ² kullanÄ±lmasÄ± gereklidir. Åurada daha detaylÄ± gÃ¶stermeye Ã§alÄ±ÅŸmÄ±ÅŸtÄ±m: https://medium.com/@cerden/kategorik-veriler-ile-%C3%A7oklu-regresyon-analizi-minitab-uygulamas%C4%B1-e30f74a9b73d",
    "Kategorik Veriler ile Ã‡oklu Regresyon Analizi: Minitab UygulamasÄ±medium.comBu yazÄ±da kategorik verilerden oluÅŸan bir verisetinde Ã§oklu regresyon uygulamasÄ± Minitab Ã¼zerinde gerÃ§ekleÅŸtirilmiÅŸtir.1 month ago 2 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "-> ->",
"quest": "Selamlar, Bu soruyu yanlÄ±ÅŸ yaptÄ±m aÃ§Ä±klamasÄ± mevcut mu, teÅŸekkÃ¼rler.  Which of the following is prevent overfitting ? 1 - Cross-validation 2- Training with more data 3- Removing features 4- Ensembling",
"comment": [
    "",
    "->  https://elitedatascience.com/overfitting-in-machine-learningBu adreste oldukÃ§a iyi aÃ§Ä±klanmÄ±ÅŸ.1 month ago 3 people like this.Like ReportReply",
    "-> Merhabalar,Overfit durumuna dÃ¼ÅŸmemek iÃ§in alÄ±nabilecek Ã¶nlemleri sorulmuÅŸ, 4 maddede bu Ã¶nlemler arasÄ±nda mevcut.Her birini kÄ±saca aÃ§Ä±klamaya Ã§alÄ±ÅŸacaÄŸÄ±m.1. Cross Validation: Veri setini k tane parÃ§aya ayÄ±rarak eÄŸitimi yapar, bu k parÃ§adan 1 parÃ§ayÄ± test iÃ§in kullanÄ±r, bu parÃ§a her seferinde bir Ã¶nceki iterasyondan farklÄ± olur, bu yÃ¼zden modelimiz sÃ¼rekli yeni test seti ile test edilmiÅŸ olur.2. Training with more data: Ã–rnek sayÄ±mÄ±zÄ± artÄ±rmak verimizdeki target ile feature arasÄ±nda ki iliÅŸkiyi daha rahat anlamamÄ±zÄ± saÄŸlamayabilmekte.3. Removin Features: Feature setimizden alakasÄ±z featur'larÄ± Ã§Ä±kartarak target-feature iliÅŸkisini daha net bir hale getirebilmekteyiz.4. Ensembling : Birbirinden ayrÄ± modelleri bir arada kullanmamÄ±za olanak saÄŸlayan ML metodudur. BÃ¶ylece modelimiz daha karmaÅŸÄ±k yapÄ±lÄ± Ã¶rnekler ile overfit olmadan Ã§alÄ±ÅŸabilir.KÄ±saca Ã¶zetlemeye Ã§alÄ±ÅŸtÄ±m daha ayrÄ±ntÄ±lÄ± bir ÅŸekilde : https://elitedatascience.com/overfitting-in-machine-learningadresinden inceleyebilirsin.Ä°yi akÅŸamlar.1 month ago 3 people like this.Like ReportReply",
    "->  ->  hocam ÅŸu soruma bakar mÄ±sÄ±nÄ±z rica etsem bir kaÃ§ saat Ã¶nce post attÄ±m. ben de bu 4 adet ÅŸeyi seÃ§tim ama yanlÄ±ÅŸ cevap dedi.http://community.globalaihub.com/community/status/1468-1468-1586718659/https://www.quora.com/Can-early-stopping-of-machine-learning-algorithms-lead-to-overfitting-of-validation-data.",
    "->  ->  Ä°lk olarak VermiÅŸ olduÄŸunuz link Ã§alÄ±ÅŸmamakta.Edit: Bahsi geÃ§en soruda .Early stopping, .Regularization seÃ§enekleri de bulunmaktaydÄ±. Bunlarda overfit'i Ã¶nlemek iÃ§in alÄ±nabilecek Ã¶nlemler arasÄ±nda bulunmaktalar. Yani O soru iÃ§in hepsi doÄŸru olmalÄ±ydÄ±. Sadece bu postta bahsi geÃ§miÅŸ olan 4 yÃ¶ntem deÄŸil..",
    "->  ->  profilime tÄ±klar mÄ±sÄ±nÄ±z orada gÃ¶zÃ¼kÃ¼yor hocam.",
    "->  ->  Maalesef gÃ¶rebildiÄŸim bir post yok profilinizde ğŸ™.",
    "->  ->  sorum ÅŸuydu hocam:Overfit i Ã¶nlemek iÃ§in eÄŸitimin erken durdurulmasÄ± doÄŸru kabul edilmiÅŸ fakat internette ÅŸÃ¶yle bir yazÄ±ya rastladÄ±m. Ä°ki bilgi Ã§eliÅŸir gibi geldi..",
    "-> .",
    "-> .",
    "->  ->  GÃ¶rdÃ¼m ÅŸimdi, Renklendirerek paylaÅŸmÄ±ÅŸ olduÄŸun cevabÄ± eÄŸer yanlÄ±ÅŸ anlamadÄ±ysam sadece ilk paragrafÄ±nda soru ile alakalÄ± renklendirdiÄŸin kÄ±sÄ±m var cevabÄ±n kalanÄ±nÄ±n daha Ã§ok veri kalitesi train- test verisinin dengesi (generalization) Ã¼zerine olduÄŸunu gÃ¶rÃ¼yorum. Yani bu yazÄ± ile bu yÃ¶ntemler kesinlikle yanlÄ±ÅŸtÄ±r diyemeyiz. DevamÄ±nda bulunan 2. cevabÄ± okursan eÄŸer durumu daha iyi anlayacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum.Edit: Burada bahsi geÃ§en yÃ¶ntemlerin yanlÄ±ÅŸ kullanÄ±mÄ± halinde de yine overfit gibi bir durumla ya da daha farklÄ± problemlerle karÅŸÄ±laÅŸabiliriz. AlÄ±nabilecek Ã¶nlemler olarak kabul edilmiÅŸ yÃ¶ntem olmalarÄ± bu yÃ¶ntemleri kullanmamÄ±z halinde \"oldu tamam ben artÄ±k overfit problemini aÅŸtÄ±m\" diyerek arkamÄ±za yaslanabileceÄŸiz anlamÄ±na gelmiyor tabi ğŸ™‚Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 2 people like this.Like ReportReply",
    "->  ->  teÅŸekkÃ¼rnederim hocam ğŸ™‚.",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Bu konuda Ã§ok kafa karÄ±ÅŸÄ±klÄ±ÄŸÄ± var o yÃ¼zden buraya bir post yazayÄ±m dedim. Veriye validation set eklemezsek ne olur'la baksak Ã§ok daha iyi olacak.  Siz bir model geliÅŸtiriyorsunuz, training ve test seti ayÄ±rdÄ±nÄ±z, 100 Ã¶rnekten 80'i training 20'si test. Ev fiyatlarÄ±nÄ± tahminlemeye Ã§alÄ±ÅŸÄ±yorsunuz. Bir regresyon modeli train ettiniz, sonra iÃ§ine test verisinden 4 odalÄ± ve iki banyolu bir ev koydunuz o da size bu evin fiyatÄ±nÄ±n 100 bin lira olmasÄ± gerektiÄŸini sÃ¶yledi, ama gerÃ§ekte o ev (test verisindeki ev fiyatÄ± kolonu) 120 bin lira, buna gÃ¶re hatanÄ±za baktÄ±nÄ±z, parametrelerinizi deÄŸiÅŸtirip yeniden train ettiniz. Zamanla kendinizi bu test verisinden aldÄ±ÄŸÄ±nÄ±z hatalara gÃ¶re adapte ediyorsunuz, yani test verisine overfit ediyorsunuz. Farkettiyseniz test verisiyle hem parametreleri deÄŸiÅŸtiriyoruz hem de test ediyoruz, bu yanlÄ±ÅŸ, bu yÃ¼zden validation set ekliyoruz, hataya bakÄ±p parametre deÄŸiÅŸtirme iÅŸlemini validationâ€¦ <a class=\"ps-stream-post-more ps-js-content-excerpt-toggle\" href=\"#\">Read more</a></div><div class=\"ps-js-content-full\" style=\"\">Bu konuda Ã§ok kafa karÄ±ÅŸÄ±klÄ±ÄŸÄ± var o yÃ¼zden buraya bir post yazayÄ±m dedim. Veriye validation set eklemezsek ne olur'la baksak Ã§ok daha iyi olacak.  Siz bir model geliÅŸtiriyorsunuz, training ve test seti ayÄ±rdÄ±nÄ±z, 100 Ã¶rnekten 80'i training 20'si test. Ev fiyatlarÄ±nÄ± tahminlemeye Ã§alÄ±ÅŸÄ±yorsunuz. Bir regresyon modeli train ettiniz, sonra iÃ§ine test verisinden 4 odalÄ± ve iki banyolu bir ev koydunuz o da size bu evin fiyatÄ±nÄ±n 100 bin lira olmasÄ± gerektiÄŸini sÃ¶yledi, ama gerÃ§ekte o ev (test verisindeki ev fiyatÄ± kolonu) 120 bin lira, buna gÃ¶re hatanÄ±za baktÄ±nÄ±z, parametrelerinizi deÄŸiÅŸtirip yeniden train ettiniz. Zamanla kendinizi bu test verisinden aldÄ±ÄŸÄ±nÄ±z hatalara gÃ¶re adapte ediyorsunuz, yani test verisine overfit ediyorsunuz. Farkettiyseniz test verisiyle hem parametreleri deÄŸiÅŸtiriyoruz hem de test ediyoruz, bu yanlÄ±ÅŸ, bu yÃ¼zden validation set ekliyoruz, hataya bakÄ±p parametre deÄŸiÅŸtirme iÅŸlemini validation set'te yapÄ±yoruz, ardÄ±ndan yeni Ã§Ä±kan modeli test verisiyle test ediyoruz, bÃ¶ylece modelin gerÃ§ekten iyi bir performans sergileyip sergilemediÄŸini gÃ¶rebiliyoruz.</div></div>",
"comment": [
    "",
    "->  Merve Hanim, diger post altinda da sormaya calismistim ama sorumu yeterince izah edemedim sanirim. Benim anladigim;\"burada train edilmis model icin test datasini bir sekilde modelin tekrar guncellemesi icin kullanildigini soyluyorsunuz. Bu durum, kullandigimiz takdirde validation verisi icin de gecerli.\"Demek ki bir \"update rule\" kullanimi var. Bu \"update rule\" nasil yapilandiriliyor (matematiksel olarak)?Bana bununla ilgili bir aciklama ya da kaynak gostermeniz mumkun mu acaba? Benim bildigim tek update rule backpropagation ve bu sizin soylediginiz test verisine \"tune\" olma probleminin onune gecmek adina validation verisi kullanildigi kurs programinda da bahsediliyor lakin ben bunun nasil oldugunu henuz kavrayabilmis degili..",
    "->  Son bir ekleme daha yapabilir miyim;parametreler dedikleriniz \"agirliklar ve bias'lar\" mi yoksa \"learning rate, batch size, epochs\" mu?.",
    "->  ->  tabiki de \"learning rate, batch size, epochs\" ... ÅŸunu demek istemiÅŸ anladÄ±ÄŸÄ±m kadarÄ±yla bu parametreleri sÃ¼rekli deÄŸiÅŸtirip iyiye yÃ¶nelmek isterken test verisini overfitting yapÄ±yorsunuz yani networku ezberletmiÅŸ oluyorsunuz bunu validation verisi ile test verisini doÄŸrulatarak modeli eÄŸitmenin daha doÄŸru olduÄŸunu sÃ¶ylemiÅŸ..",
    "->  Evrim bence guzel soru sordun cunku anlam karmasasi yasiyoruz gercekten parametreler konusunda. zaman zaman dinlerken.Gradients denileni weights and biases olarak algiliyorum.Leraning rate, epoch, batch_size ise hyper parametrelerdir.Ancak konusmacilar weights ve biases icin parametreler ifadesini kullanabiliyor..",
    "->  ->  weight ve bias parametrelerine siz mÃ¼dehale etmiyorsunuz model katmanÄ±ndaki optimizasyon algoritmasÄ±(Ã–rneÄŸin: Stochastic Gradient Descent, Adam...) bu gÃ¼ncellemeyi yapar, deÄŸiÅŸtirir. YanlÄ±ÅŸsam biri beni dÃ¼zeltsin..",
    "->  ->  Eger dediginiz gibi ise sunu aciklarmisiniz: diyelim ki model = vgg16(pretrained) ve for param in model.features.parameters()...param.requires_grad= False dersem ben neyi freeze etmis oluyorum?.",
    "->  ->  Benim kafami karistiran terminoloji oldu. Sayet parametreden kastimiz sizin dediginiz gibi \"learning rate, batch size, epochs\" ise benim sorularim anlamsizlasiyor, cunku guncelleme metodu gerektiren seyler \"weights and biases\".Ilaveten Senay'a katilmak durumundayim, benim terminoloji bilgim su sekilde:hyperparamaters: \"learning rate, batch size, epochs\"parameters: \"weights and biases\"1 month ago 2 people like this.Like ReportReply",
    "->  ->  Ibrahim weights ve biases lere tabiki biz mudahale etmiyoruz biz sadece weightsleri optimizer.step() function kullanarak update ediyoruz.Bu konuda hemfikiriz..",
    "->  ->  Eywallah gÃ¼ncelleme gerektiren yerler weight ve bias ... diyelim ki siz modeli eÄŸitiniz sonuÃ§lar kÃ¶tÃ¼ loss azaltÄ±p accuracy deÄŸerini arttÄ±rmak iÃ§in ne yapmanÄ±z gerekecek learning rate, batch size ve epoch deÄŸerlerini hatta optimizer da deÄŸiÅŸtirerek en iyi sonucu bulmaya Ã§alÄ±ÅŸacaksÄ±nÄ±z bu denemeleri yaparken test veriniz overfitting olabilir.Bu yÃ¼zden veriyi 3 e ayÄ±rÄ±p validation set ve test seti kÄ±yaslamak gerekecek.",
    "-> -> :Ã–ncelikle terminoloji ile alakalÄ± sizinle aynÄ± fikirdeyim eÄŸer daha burada hata yapÄ±yorsak aydÄ±nlatÄ±lÄ±rsa Ã§ok iyi olur.hyperparamaters: \"learning rate, batch size, epochs\"parameters: \"weights and biases\"Bu soruda; \"The regressor might overfit to test set if we don't use validation sets. \"KafanÄ±za takÄ±lanÄ±n bu olduÄŸunu sÃ¶ylemiÅŸsiniz;Evet hatirliyorum. Benim sormaya calistigim, validation verisi kullanmak overfitting'i nasil onluyor? Nasil bir mekanik (bir gunceleme kurali ya da metodu) kullanilarak overfitting onleniliyor?Ve yanlÄ±ÅŸ anlamadÄ±ysam net olarak sormak istediÄŸiniz validation set iÅŸlemi iÃ§in farklÄ± bir matematiksel iÅŸlem olup olmadÄ±ÄŸÄ±.Benim anladÄ±ÄŸÄ±m validation set ile test set arasÄ±nda setlerin kendi Ã§alÄ±ÅŸma mantÄ±ÄŸÄ±nda hiÃ§bir fark yok, yani ikisinde de amaÃ§ aslÄ±nda test etmek. Ancak validation sette test ettikten sonra parametreleri gÃ¼ncelliyoruz(weights ve bias). AsÄ±l Test setinde ise sadece bu ayarlarÄ±n nasÄ±l sonuÃ§ verdiÄŸine bakÄ±yoruz. (parametreler Ã¶nceden validation sette ayarlandÄ±). EÄŸer bunu validation sette yapmayÄ±p test sette yaparsak test set hem parametreleri ayarlamak iÃ§in modele kendinden veri verecek, model bu verileri Ã¶ÄŸrenecek, sonra tekrar test setinde bu veriler test iÃ§in kullanÄ±lÄ±p \"overfitting\" olacak. Overfitting olacaksada validation sette olsun ki nasÄ±l olsa test sette modelin hiÃ§ gÃ¶rmediÄŸi verilerle modeli son kez test edeceÄŸiz. Ä°ÅŸlemler sonunda Training loss ve Test loss deÄŸerlerine bakarak modelin tahmin gÃ¼cÃ¼nÃ¼ anlÄ±yoruz.Test setteki parametre ayarlama matematiksel iÅŸlemlerini Validation sette yaptÄ±k.DoÄŸru anlamadÄ±ysam yÃ¼zÃ¼me vurun ğŸ™‚.",
    "-> ->  ilk basta sizin anlattiginiz gibi algiladim; yani validation veya test set uzerinden \"weights and biases\" icin bir update rule uyguluyoruz. Yalniz Ibrahim Ayaz kavram sorumun uzerine beni duzeltti. Bu durumda, yukurida da belirttigim uzere, benim sormaya calistigim sorular anlamsizlasiyor, cunku ben \"weights and biases\" icin bir guncelleme yaptigimizi saniyordum. Oysaki validation veya test seti \"learning rate, batch size, epochs\" uzerinde degisiklik yapmak icin kullanmaktan bahsediyormusuz. Bunlar bir \"update rule\"a bagli olmayan bizim elimizle girip degistirdigimiz degerler. Dolayisiyla validation set'in butun amaci bizim *training* sonuclarina bakarak kendimizce degisiklikler yapip modeli guclendirme amacimiza hizmet ediyor. Ki bu elimizle yaptigimiz degisiklikler de neticede bir cesit *tuning* olmasi sebebiyle test set uzerinde yapilirsa modelin genellenebilirligini zedeleyen bir unsura donusuyor, cunku model genel bir veri gurubu yerine test set verilerine duyarli hale geliyor, o yuzden de bunu validation set diye ayirdigimiz bir veri gurubu uzerinde yapmak daha mantikli.Kisa yorum: validation veya test set'in \"weights and biases\" ile dogrudan bir iliskisi yok. Amaci bizim gozlem (deneme-yanilma) yoluyla modelin gucune katki vermemize olanak tanimasi.Benim icin faydali bir tartisma oldu. Validation set'in islevi konusunda muglak fikirlerim vardi ve kavram tam olarak zihnimde yer etmemisti. Simdi tam olarak oturdu. Katki veren herkese tesekkur ederim.1 month ago 3 people like this.Like ReportReply",
    "-> Merhabalar,->  Ã–ncelikle paylaÅŸÄ±mÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederim. Ancak bazÄ± noktalarda eksikleriniz bulunmakta.Ã–rneÄŸimiz Ev FiyatlarÄ±nÄ±n Tahmin Edilmesi (Regresyon Problemi), Hedef: Evin FiyatÄ±, Feature(DeÄŸiÅŸken): Oda SayÄ±sÄ± . Ã–rnek BÃ¼yÃ¼klÃ¼ÄŸÃ¼ 100, Train/Test bÃ¼yÃ¼klÃ¼ÄŸÃ¼: 80/20 <- Sizin Ã¶rneÄŸiniz Ã¼zerinden aÃ§Ä±klamaya Ã§alÄ±ÅŸacaÄŸÄ±m.EÄŸitime baÅŸladÄ±ktan itibaren, her bir iterasyon sonunda bir Regresyon modeli tahmin edilir(Ã¶rneÄŸin: ev_fiyatÄ± = 45.000(bias) + 1250(weight) * oda_sayÄ±sÄ±). Bu model Test Setinin TamamÄ± ile(AyrÄ±lmÄ±ÅŸ olan 20 Ã¶rneÄŸin hepsi ile ) test edilir, Ã§Ä±kan sonuca gÃ¶re katsayÄ±lar(weight(1250), bias(45.000)), belirlemiÅŸ olduÄŸumuz learning rate'ye gÃ¶re gÃ¼ncellenir(Batch Size verinin nasÄ±l parÃ§alanÄ±p iÅŸleneceÄŸini(batch_size'nin bÃ¼yÃ¼klÃ¼ÄŸÃ¼ iterasyon sayÄ±sÄ±nÄ± belirler.), Epoch ise verinin bir bÃ¼tÃ¼n olarak kaÃ§ defa eÄŸitime tabii tutulacaÄŸÄ±nÄ± belirtir.). Sonraki iterasyon ile devam edilir. Belirlenen epoch sayÄ±sÄ±na ulaÅŸÄ±lÄ±ncaya kadar bu iÅŸlem bÃ¶yle devam eder. Ancak burada Test Set Ã¼zerine modelimizi overfit etmiÅŸ olmuyoruz. Modelimizin overfit olma olasÄ±lÄ±ÄŸÄ± var. BÃ¶yle bir durumu sadece test set ile Ã§alÄ±ÅŸarak gÃ¶zlemlememiz mÃ¼mkÃ¼n olamamakta. Bu yÃ¼zden 3. bir set oluÅŸturuyoruz: validation set olarak. BÃ¶ylece eÄŸitim boyunca bÃ¼tÃ¼n testleri validation set Ã¼zerinden yapacak ve eÄŸitim bittikten sonra test setimiz ile 2. defa modelimizi test edecek ve eÄŸitim sonuÃ§larÄ± ile tutarlÄ±lÄ±ÄŸÄ±nÄ± gÃ¶zlemleyebileceÄŸiz. EÄŸer eÄŸitim oranlarÄ± en son yapmÄ±ÅŸ olduÄŸumuz test oranlarÄ±ndan Ã§ok bÃ¼yÃ¼k ise eÄŸitim sÄ±rasÄ±nda overfit olmuÅŸ diyebiliriz, ve buna gÃ¶re modelimizi tekrar gÃ¶zden geÃ§irmek suretiyle gerekli deÄŸiÅŸiklikleri yapabiliriz.->  DediÄŸiniz gibi validation seti bÃ¼tÃ¼n eÄŸitim boyunca kullandÄ±ÄŸÄ±mÄ±z iÃ§in modelimiz validation set'e de overfit olabilmekte ancak en son Test Set'imizle yapmÄ±ÅŸ olduÄŸumuz deneme ile bu durumu tespit edebilmekteyiz.Ä°yi geceler, iyi Ã§alÄ±ÅŸmalar..",
    "->  ->  Bilgilendirmeniz iÃ§in teÅŸekkÃ¼r ederim. Ben de bu alana yeni baÅŸlayan biri olarak bir dÃ¼ÅŸÃ¼ncemi belirtmek istiyorum. YazÄ±larda ifade edilen terimler bazen olaylarÄ± kafamda farklÄ± ÅŸekillendirmeme sebep olabiliyor. Bundan dolayÄ± bu terimler kullanÄ±lÄ±rken daha hassas olunursa anlam karmaÅŸÄ±klÄ±ÄŸÄ±nÄ±n Ã¶nÃ¼ne geÃ§ileceÄŸini dÃ¼ÅŸÃ¼nmekteyim.Terminolojiyi takip etmek isteyenler iÃ§in;https://developers.google.com/machine-learning/glossary",
    "Machine Learning Glossary Â |Â  Google Developersdevelopers.google.comCompilation of key machine-learning and TensorFlow terms, with beginner-friendly definitions..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba arkadaÅŸlar ????  Hepinize teÅŸekkÃ¼r ederiz ???? BeklediÄŸimizden de fazla kiÅŸi sÄ±nava katÄ±lÄ±m gÃ¶sterdi, sÃ¼persiniz ???? Bu quizlerle amacÄ±mÄ±z; kendinize samimi olmanÄ±z, kendi geliÅŸiminizi gÃ¶zlemlemenizdi, bunu da layÄ±kÄ±yla yaptÄ±ÄŸÄ±nÄ±za inanÄ±yoruz ???? YarÄ±n cevaplarÄ± aÃ§Ä±klamalÄ± olarak paylaÅŸacaÄŸÄ±z, aklÄ±nÄ±za takÄ±lan kÄ±sÄ±mlar olursa oradan sorabilirsiniz. 2. haftanÄ±n konularÄ± iÃ§in ÅŸimdiden iyi Ã§alÄ±ÅŸmalar, iyi haftalar dilerim ????âœ¨",
"comment": [
    "",
    "->  AsÄ±l biz teÅŸekkÃ¼r ederiz, emeklerinize saÄŸlÄ±k ???? Ä°yi haftalar ????.",
    "->  Her ÅŸey iÃ§in teÅŸekkÃ¼rler..",
    "->  TeÅŸekkÃ¼rler, bekliyor olacaÄŸÄ±z.",
    "->  TeÅŸekkÃ¼rler..",
    "->  ÃœzÃ¼mcÃ¼ TeÅŸekkÃ¼rler,bazÄ± sorularÄ±n cevaplarÄ± cidden Ã¶nemli ğŸ™‚.",
    "->  HerÅŸey iÃ§in teÅŸekkÃ¼rler ????.",
    "-> Ã§ok teÅŸekkÃ¼rler..",
    "->  teÅŸekkÃ¼rler.",
    "->  Ä°lginiz iÃ§in teÅŸekkÃ¼rler..",
    "->  Elinize saÄŸlÄ±k, iyi Ã§alÄ±ÅŸmalar.",
    "->  Ã‡ok teÅŸekkÃ¼rler,iyi haftalar..",
    "->  EmeÄŸiniz ve ilginiz iÃ§in Ã§ok teÅŸekkÃ¼rler..",
    "->  Emeklerine ve Ã§abalarÄ±nÄ±za saÄŸlÄ±k.",
    "->  Ä°lginiz iÃ§in Ã§ok teÅŸekkÃ¼rler..",
    "->  Elinize saÄŸlÄ±k, Ã§ok teÅŸekkÃ¼rler..",
    "->  emeÄŸinize saÄŸlÄ±k, Ã§ok teÅŸekkÃ¼rler.",
    "->  TeÅŸekkÃ¼rler,kolay gelsin..",
    "->  Merhaba ->  hocam emeÄŸi geÃ§en herkese Ã§ok teÅŸekkÃ¼rler. EÄŸitimimizi tamamladÄ±ktan sonra Ã¶ÄŸrendiÄŸimiz bilgilerin pekiÅŸtirilmesi, daha iyi anlaÅŸÄ±lmasÄ± ve yorum yapmamÄ±zÄ± saÄŸlamasÄ± adÄ±na sÄ±nav Ã§ok yararlÄ±ydÄ±. SÄ±navÄ±n Ã§Ã¶zÃ¼mlerini bizimle paylaÅŸacak mÄ±sÄ±nÄ±z? Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 2 people like this.Like ReportReply",
    "->  ->  Biz teÅŸekkÃ¼r ederiz ğŸ™‚ Evet dÃ¼n paylaÅŸacaktÄ±m aslÄ±nda ama yetiÅŸmedi, bugÃ¼n paylaÅŸmÄ±ÅŸ olurum ğŸ˜‰.",
    " "
]
},
{
"question_isim": "-> ",
"quest": "SorularÄ±n hepsini doÄŸru yaptÄ±ÄŸÄ±mÄ± belirterek kendimce nasÄ±l yaptÄ±ÄŸÄ±mÄ± tek tek anlatacaÄŸÄ±m. YararlÄ± olmasÄ±nÄ± umuyorum ve yorumlarÄ±nÄ±zÄ± bekliyorum. YazÄ±m hatalarÄ± olabilir hÄ±zlÄ±ca yazdÄ±m kusuruma bakmayÄ±n. Hepsini yorum olarak paylaÅŸacaÄŸÄ±m.",
"comment": [
    "",
    "->  Q1: Soruda validation setini kullanma sebebimizi soruyordu.1.1: Regressor ifadesi bana regresyon modelini Ã§aÄŸrÄ±ÅŸtÄ±rdÄ±.Train setinde eÄŸittiÄŸimiz verilerdeki hiperparametreleri test setine gÃ¶re yaparsak model test setindeki verileri verdiÄŸimizde iyi sonuÃ§ verip bizi yanÄ±ltabilir.Bu sebeple validation ile parametre ayarlayÄ±p test setiyle overfitting'in oluÅŸup oluÅŸmadÄ±ÄŸÄ±nÄ± kontrol ediyoruz. 2 aÅŸamalÄ± deÄŸerlendirmeden sonra bunlarÄ±n loss deÄŸerleri birbirine Ã§ok yakÄ±n ise overfitting oluÅŸmadÄ±ÄŸÄ±na kanaat getiriyoruz.DolayÄ±sÄ±yla validation set kullanmaz isek \"test setine\" overfit olabilir.1.2: Validation setin modelin fit performansÄ±nÄ±na etkisi yoktur. Sadece test setine overfitting olmasÄ±nÄ± Ã¶nlemek iÃ§in ara aÅŸama.1.3: Modelin overfit veya underfit olmasÄ±nÄ± kontrol eden ÅŸey test setidir. Validation set sadece test setine olan overfiti denetler.1 month ago 2 people like this.Like ReportReply",
    "->  Q2: 6 resmin eÅŸleÅŸtirilmesini istiyordu.1.resimde overfit durumu gÃ¶rÃ¼yoruz. DolayÄ±sÄ±yla train setin kaybÄ± dÃ¼ÅŸÃ¼k, test setinin kaybÄ± yÃ¼ksek olmalÄ±.Bu nedenle B ÅŸeklindeki son duruma baktÄ±ÄŸÄ±mÄ±zda test setin kaybÄ± train sete gÃ¶re oldukÃ§a fazla.2.resimde optimal modeli gÃ¶rÃ¼yoruz. Ne 1 gibi Ã§ok karmaÅŸÄ±k bir model ne de 3 gibi Ã§ok basit.DolayÄ±sÄ±yla eÄŸitim performansÄ± iyi olmalÄ±, test performansÄ±da ona yakÄ±n olmalÄ±.3.resimde ise model Ã§ok basit. Verilere Ã§ok iyi uymuyor. DolayÄ±sÄ± ile eÄŸitim performansÄ± dÃ¼ÅŸÃ¼k olmalÄ±.Bu nedenle eÄŸitim performansÄ± diÄŸerlerinden daha dÃ¼ÅŸÃ¼k olan A ÅŸekliyle eÅŸleÅŸir. SonuÃ§: 1-B/2-C/3-A.",
    "->  Q3: Modelin kaÃ§ kez gÃ¼ncelleneceÄŸini soruyordu.250 Ã¶rneÄŸimiz var. 80/20 oranÄ±nda parÃ§alarsak train set 200 Ã¶rneÄŸe sahip oluyor. Batch size ise 32.200'e tam bÃ¶lÃ¼nmÃ¼yor. 200 iÃ§inde 6 tane batch var ve bunlarÄ± Ã§Ä±karÄ±nda 8 Ã¶rnek kalÄ±yor. DolayÄ±sÄ± ile bunlarÄ±n 7 iterasyon olacaÄŸÄ±nÄ± sÃ¶yleyebiliriz.Buradaki dÃ¼ÅŸÃ¼ncem kÃ¼sÃ¼rat olamayacaÄŸÄ± yÃ¶nÃ¼nde Ã§Ã¼nkÃ¼ iterasyon tam sayÄ±lardan olmalÄ± yarÄ±m iterasyon gibi bir ÅŸey mantÄ±ksÄ±z olacaktÄ±r.Batch 32 olduÄŸundan kafa karÄ±ÅŸtÄ±rabilir ama ben o yeterince veri yoksa elindeki veriler kadar yapacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum.DolayÄ±sÄ±yla cevaba 7*1000(epoch sayÄ±sÄ±) = 7000 dedim.1 month ago 2 people like this.Like ReportReply",
    "->  ->  Bu sorunun net olmadÄ±ÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum. Batch size 32 iken 8 Ã¶rnek ile train etmek ne kadar doÄŸrudur? Mevcut algoritmalar nasÄ±l davranÄ±yor bilmiyorum, bu konuda bilgisi olan varsa aÃ§Ä±klayabilirse Ã§ok iyi olur.Ben de 200 / 32 = 6.25 Ã§Ä±kÄ±yor ve batch size Ä±mÄ±z 32 i olduÄŸu iÃ§in 8 sample ile train edilmeyeceÄŸini dÃ¼ÅŸÃ¼ndÃ¼m ve 1 epoch da 6 iterasyon olur, 1000 epoch iÃ§in 1000*6 = 6000 iterasyon gerekir diye dÃ¼ÅŸÃ¼ndÃ¼m. TamsayÄ± Ã§Ä±kan bir deÄŸer sorulsaydÄ± daha aÃ§Ä±k ve net bir soru olurdu sanÄ±rÄ±m.1 month ago 4 people like this.Like ReportReply",
    "->  ->  Batch 32 diye 32 Ã¶rneÄŸe ihtiyacÄ±mÄ±z olmamasÄ± daha mantÄ±ksÄ±z deÄŸil mi? ÅÃ¶yle dÃ¼ÅŸÃ¼nÃ¼n batchte amacÄ±mÄ±z verileri parÃ§alamak biz diyoruz ki aynÄ± anda en fazla 100 veri iÅŸleyebiliriz. 8 veri gelmesi sizce mantÄ±ksÄ±z mÄ± olur? BÃ¶yle dÃ¼ÅŸÃ¼nmekte fayda var..",
    "->  ->  AyrÄ±ca ÅŸunu belirtmeyi unutmuÅŸum 8 Ã¶rneÄŸi dÄ±ÅŸarÄ±da bÄ±raktÄ±ÄŸÄ±nÄ±zda tÃ¼m verisetini eÄŸitimden geÃ§irmemiÅŸ oluyorsunuz. DolayÄ±sÄ±yla bununla da Ã§eliÅŸiyor dediÄŸiniz yÃ¶ntem..",
    "-> ->  elimizdeki veri sayÄ±sÄ± batch size'a gÃ¶re bÃ¶lÃ¼ndÃ¼kten sonra batch size'dan daha az sayÄ±da kalan veriler ne kadar olursa olsun son iterasyon olarak training'e katÄ±lÄ±yor. bu neden bu Ã¶rnek iÃ§in 6 iterasyon 32 veri ile, 7. iterasyon ise kalan 8 veri ile gerÃ§ekleÅŸiyor. tam sayÄ± Ã§Ä±kmamasÄ± aslÄ±nda sorunun ufak bir trick'i olmuÅŸ.1 month ago 4 people like this.Like ReportReply",
    "-> -> ->  Merhaba, yorumlar iÃ§in teÅŸekkÃ¼rler. Ben 8 Ã¶rnek ile update etmenin problem olabileceÄŸini dÃ¼ÅŸÃ¼ndÃ¼m, Ã§Ã¼nkÃ¼ kalan 8 Ã¶rnekten 4 tanesi iki kÃ¼menin tam sÄ±nÄ±rÄ±nda kalan veya yanlÄ±ÅŸ tarafta olan Ã¶rnekler olursa az sayÄ±da Ã¶rnekten dolayÄ± dÃ¼zgÃ¼n bir update iÅŸlemi olmayabilir, bu yÃ¼zden batch size a bir limit koyuyoruz, 32 lik datayla daha genel bir update iÅŸlemi oluyor.8 Ã¶rneÄŸi bir epochda dahil etmemek Ã§ok bÃ¼yÃ¼k bir problem deÄŸil. Zaten siz datasetteki bÃ¼tÃ¼n datalarla Ã¶ÄŸrenme iÅŸlemi yapmÄ±yorsunuz. Training ve test set olarak ayrÄ±lmamÄ±ÅŸ tek bir dataset varsa yaklaÅŸÄ±k yÃ¼zde 80 ini training e, yÃ¼zde 20 sini teste ayÄ±rÄ±yorsunuz ve sadece training datasÄ± ile update yapÄ±yorsunuz.Genelde her epochda datalarÄ±mÄ±zÄ± random olarak seÃ§tiÄŸimiz iÃ§in bir epochda kalan 8 Ã¶rnek diÄŸer epochda kullanÄ±labilir, her epochda kalan 8 Ã¶rnek aynÄ± olmayacaktÄ±r.Bu yÃ¼zden son 8 Ã¶rneÄŸi almamanÄ±n, alÄ±nacaksa da o epochda kullanÄ±lan datalardan random 24 tane daha datayÄ± dahil etmenin daha uygun olacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum.MentorlarÄ±mÄ±zdan biri de konuyla ilgili aÃ§Ä±klama yaparsa sÃ¼per olur.Kolay gelsin...",
    "->  ->  Teknik olarak algoritma son kalan 8 Ã¶rneÄŸi yeni bir batch olarak deÄŸerlendirip 8 Ã¶rnekle gÃ¼ncelleme yapÄ±yor. Bu tip durumlarda dediÄŸiniz gibi yÃ¶ntemlere baÅŸvurulabilir mi ? Ä°sterseniz bu fazlalÄ±klarÄ± veri setinizden Ã§Ä±karabilirsiniz veya random 24 tane veride verisetinden ekleyebilirsiniz (Ezberci eÄŸitime karÅŸÄ±yÄ±z ğŸ™‚ ). Bunlar ek Ã§Ã¶zÃ¼mler olur. Soruda sorulmak istenen algoritmanÄ±n nasÄ±l davranacaÄŸÄ±. Ã‡Ã¶zÃ¼m Enes beyin ifade ettiÄŸi gibi. Ancak sizin de ifade ettiÄŸiniz gibi Ã§ok Ã§ok aÅŸÄ±rÄ± farklÄ±lÄ±klar yaratmayacaktÄ±r..",
    "->  Q4: Ev fiyatÄ± iÃ§in hangisinin iyi bir Ã¶zellik olmayacaÄŸÄ±nÄ± soruyordu.Ã–nceki sahibinin cinsiyeti iyi bir Ã¶zellik olamazdÄ±.1 month ago 2 people like this.Like ReportReply",
    "->  Q5: Soruda learning rate'i optimal seÃ§memekten dolayÄ± oluÅŸan problemlerden olmayanÄ± soruyordu.DolayÄ±sÄ±yla Ã¶ÄŸrendiklerimizi dÃ¼ÅŸÃ¼nÃ¼rsek kÃ¶tÃ¼ learning rate in 2 etkisi vardÄ±: hÄ±zlÄ± adÄ±m atÄ±p minimumu kaÃ§Ä±rma veya Ã§ok yavaÅŸ adÄ±m atÄ±p uzun sÃ¼rede minimuma ulaÅŸma. BaktÄ±ÄŸÄ±mÄ±zda 1.ÅŸÄ±k ve 2.ÅŸÄ±k bunlarÄ± saÄŸlÄ±yor.3.ÅŸÄ±kka baktÄ±ÄŸÄ±mÄ±zda ise kayÄ±p eÄŸrisinde minimuma gitmek yerine test yÃ¶ne hareket ettiÄŸi yazÄ±yor. Bunun sebebinin gradyan hesaplarken yapÄ±lan hata olduÄŸunu dÃ¼ÅŸÃ¼nerek bu cevabÄ± seÃ§tim.1 month ago 2 people like this.Like ReportReply",
    "->  Q6: Hangisinin lineer regresyon problemi olduÄŸunu soruyordu soruda.SÄ±nÄ±flandÄ±rma ile aralarÄ±ndaki temel fark ise regresyondaki output sayÄ±sal yani sÃ¼rekli bir deÄŸer, sÄ±nÄ±flandÄ±rma ise kategorik deÄŸerdir. DolayÄ±sÄ±yla (negatif-pozitif, kadÄ±n-erkek, yazar) sÄ±nÄ±flandÄ±rma problemi oluyor. SatÄ±ÅŸ tahmin etmek ise regresyon problemidir.1 month ago 2 people like this.Like ReportReply",
    "->  Q7: Korelasyon matrisi hakkÄ±nda doÄŸru olanÄ± soruyordu.Bu tensorflow colabÄ±nda geÃ§iyordu. Her Ã¶zelliÄŸin ham deÄŸerinin diÄŸerlerinin ham deÄŸeri ile iliÅŸkisini veren deÄŸerlerimiz vardÄ±.Bir de doÄŸru hatÄ±rladÄ±ÄŸÄ±mÄ± kesinleÅŸtirmek iÃ§in ÅŸÃ¶yle dÃ¼ÅŸÃ¼ndÃ¼m, Neden her Ã¶zellik Ã¶zellik deÄŸeri diÄŸerlerinin ham deÄŸeriyle iliÅŸkili olsun ki?1 month ago 2 people like this.Like ReportReply",
    "-> Q8: Hangilerinin overfittingi Ã¶nlediÄŸini soruyordu.1.deki cross-validation'a validation'Ä± Ã¶ÄŸrenmiÅŸtik ve bu da validation'un bir Ã§eÅŸidi gibi gÃ¶rÃ¼ndÃ¼ÄŸÃ¼nden dolayÄ± doÄŸru dedim.2.deki daha fazla veriyle eÄŸitim yapmanÄ±n veri miktarÄ± ne kadar uzun olursa overfit olmanÄ±n o kadar uzun sÃ¼receÄŸini dÃ¼ÅŸÃ¼ndÃ¼m. Overfittingi kafamda ezberleme olarak kodlamÄ±ÅŸtÄ±m. Bir yerdeki insan sayÄ±sÄ± artarsa onlarÄ±n hepsinin ismini ezberlemeniz daha uzun sÃ¼rer mantÄ±ÄŸÄ±yla.3.de Ã¶zellik Ã§Ä±karmaya doÄŸru dedim Ã§Ã¼nkÃ¼ aÄŸÄ±rlÄ±k eksilmesi modelimizin karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± azaltÄ±yor. Buna ÅŸÃ¶yle bir Ã¶rnek versem saÃ§ma olur mu bilemiyorum. Kalem verisetimiz olduÄŸunu dÃ¼ÅŸÃ¼nelim. KÄ±rmÄ±zÄ± kalem Ã¶rneÄŸi Ã§ok olduÄŸundan iyi tahmin ediyor ancak mavi kalem Ã¶rneÄŸi az o kadar iyi deÄŸil. Her boydan yeterince kalem olduÄŸundan dolayÄ± 100% tahmin etsin. Renk Ã¶zelliÄŸini Ã§Ä±karÄ±rsak boylara gÃ¶re tahminimiz yÃ¼ksek olduÄŸundan test setimizin doÄŸruluÄŸu artÄ±yor. Overfitting dÃ¼ÅŸÃ¼yor.4.de erken bitirme olayÄ± overfit olmadan Ã¶nce en iyi seviyede modelin eÄŸitimini bitirebileceÄŸimizi dÃ¼ÅŸÃ¼nÃ¼rsek doÄŸru geliyor.5.de regular kelimesinin dÃ¼zenli anlamÄ±na geldiÄŸini biliyordum ve bundan yola Ã§Ä±ktÄ±m. Verisetini eÄŸitim iÃ§in dÃ¼zenleÅŸtireceÄŸini dÃ¼ÅŸÃ¼nerek overfittingi azaltabileceÄŸini dÃ¼ÅŸÃ¼ndÃ¼m ama buna pek gerek kalmadÄ±.1,2,3 ve 4 Ã¼n olduÄŸu tek ÅŸÄ±k vardÄ± o da son ÅŸÄ±k olan hepsiydi.1 month ago 2 people like this.Like ReportReply",
    "->  ->  Overfitting Ã¶nleme ile ilgili kursun hangi bÃ¶lÃ¼mÃ¼nde anlatÄ±yor? Ben bunlara bakmamÄ±ÅŸÄ±m.",
    "->  ->  Validation set kÄ±smÄ±nda anlatÄ±lÄ±yor..",
    "->  Q9: Uyumu test etmek iÃ§in test metadolojisi uygulanÄ±rken hangisi gereksizdir diye soruyordu.1.ÅŸÄ±kta olan Ã¶rneklerin setten baÄŸÄ±msÄ±z ve aynÄ± ÅŸekilde Ã§ekilmesi kesinlikle lazÄ±m.2.ÅŸÄ±kta olan daÄŸÄ±lÄ±mÄ±n deÄŸiÅŸmez olmasÄ± sonradan veri eklenmemesi gerekiyor. Ã‡Ã¼nkÃ¼ Ã¶rneÄŸin kedi kÃ¶pek sÄ±nÄ±flayan bir modelimiz var. Bunu eÄŸitirken kÃ¶pek sayÄ±sÄ± azsa yani kÃ¶peÄŸi tahmin etmesini geliÅŸtirmek iÃ§in yeterince Ã¶rnek yoksa ve biz sonradan abartÄ±rsak 10.000 kÃ¶pek verisi eklersem tahmin oranÄ± Ã§ok dÃ¼ÅŸer.3.ÅŸÄ±kta Ã¶rnekleri seÃ§erken rastgele seÃ§memiz gerektiÄŸinden bahsediyor ve kesinlikle doÄŸru.4.ÅŸÄ±kta model test seti Ã¼zerinde eÄŸitilmelidir diyor ve bu kesinlikle yanlÄ±ÅŸ. Model train seti Ã¼zerinde eÄŸitilir. Test seti Ã¼zerinde deÄŸerlendirilir.DolayÄ±sÄ±yla cevabÄ± 4.ÅŸÄ±k iÅŸaretledim.1 month ago 2 people like this.Like ReportReply",
    "->  Q10: Nispeten diÄŸerlerine gÃ¶re kolaydÄ±.Elbette atlamalarÄ±n sebebi Ã¶ÄŸrenme oranÄ±nÄ±n yÃ¼ksek olmasÄ±..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Ä°yi akÅŸamlar arkadaÅŸlar ğŸ™‚  Ã–ncelikle sÄ±nav sorularÄ±ndan bir tanesini sormak istiyorum. Belki Ã§ok basittir ama anlayamadÄ±m. \"The regressor might overfit to test set if we don't use validation sets. \" buradaki ifadeyi aÃ§Ä±klarmÄ±sÄ±nÄ±z?",
"comment": [
    "",
    "->  Bu soruyu ben yazdÄ±m. EÄŸer ekstra bir validation set kullanmazsak regressor overfit eder test setine demek. Bunun hangi kÄ±smÄ±nÄ± anlamadÄ±ÄŸÄ±nÄ±zÄ± sÃ¶ylerseniz aÃ§Ä±klayabilirim..",
    "->  ->  Devam niteliginde bir sorum olacak. Validation set'in islevi konusunda yerine oturtamadigim bir durum var. Yanlissam duzeltin;agirliklarin guncellenmesi icin sadece training verisinden gelen ciktinin label verisi ile karsilastirmasindan yararlaniliyor. Bu durumda validation verisi sadece gorsel bir karsilastirma yapmak icin var. O zaman overfit'i onleme processini nasil gerceklestiriyor? tam olarak yaptigi sey nedir?.",
    "->  Merve Hanim ifadenzide hata oldugunu dusunuyorum. Oncelikle regressor un test setine overfit etme ifadesine dogru diyemeyiz..Test sirasinda overfitting probleminin ortaya cikabilecegini soyleyebilirsiniz.Ancak bu problem de validation kullanilmadigi icin ortaya cikmaz..",
    "->  ->  bununla ilgili bir post yazdÄ±m..",
    "->  ->  overfit olayÄ± olunca illa ekstra validation set eklememize gerek yokki baÅŸka yollarla da overfitting Ã¶nlenebilir , bide benim eÄŸitimden de anladÄ±ÄŸÄ±m validation set testten once modeli anlamak iÃ§in kullanÄ±lÄ±yor..",
    "->  ->  overfitting'i regularisation'la engelliyoruz, validation seti eklemek ve ayrÄ± bir test seti kullanmak bizim overfit edip etmediÄŸimize bakmamÄ±zÄ± saÄŸlÄ±yor..",
    "->  Overfitting oneleme nasil olur sorusunun cevabi sinavin iceriginde mevcuttu hatirlarsaniz;Cross-validation, early stopping, train with more data, remove features ,regularization, dropout..",
    "->  ->  Overfitting nasil onlenir sorusunun cevabi sinav sorularindan biriydi.Hatirlarsaniz, cross-validation, remove features, train with more data, regularization, early stopping, dropout...",
    "->  ->  hmm simdi anladÄ±m ğŸ˜€ teÅŸekkÃ¼r ederÄ±m oturmamÄ±ÅŸ bu konu bende ğŸ™‚.",
    "->  ->  Evet hatirliyorum. Benim sormaya calistigim, validation verisi kullanmak overfitting'i nasil onluyor? Nasil bir mekanik (bir gunceleme kurali ya da metodu) kullanilarak overfitting onleniliyor?.",
    "->  ->  Overfitting engelleme ile ilgili kÄ±sÄ±mlar eÄŸitim serisi iÃ§inde nerede acaba? GÃ¶zden kaÃ§Ä±rdÄ±m sanÄ±rÄ±m..",
    "->  RegresÃ¶r regresyon yapan modele dendiÄŸini dÃ¼ÅŸÃ¼ndÃ¼m ben yaparken. EÄŸitimde de gÃ¶rdÃ¼k ki validation kullanma amacÄ±mÄ±z test setine overfitting oluÅŸmamasÄ±. DolayÄ±sÄ±yla kullanmaz isek test setine overfit oluÅŸabilir..",
    "->  AklÄ±mda check ve evaluate kavramlarÄ± kaldÄ±ÄŸÄ±ndan ben soruyu yanlÄ±ÅŸ cevapladÄ±m..",
    "->  Validation kullanmazsan test sirasinda overfitting problemi ortaya cikar diye bir kural yok.Ortaya cikabilir.Validatin kullanmamizin sebebi modelimizi check edip karar vermek, teste hazir olup olmadigina..",
    "->  ->  DÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼mÃ¼ aktaramamÄ±ÅŸÄ±m kesinlikle Ã¶yle oluÅŸmamasÄ± iÃ§in bir Ã¶nlem validation..",
    "->  Aslinda daha onemlisi su: Validation set kullanmadigin icin overfitting problemi ortaya cikmiyor, validation set kullanmak, test surecinden once modeli degerlendirmeni saglar.Dolayisiyla Merve Hanim ifadenizin dogrulugundan supheliyim..",
    "->  ->  might diyor orada zaten.",
    "->  ->  might diyor ama eger validation kullanmazsak diyor.Yanlis hatirlamiyorsam bu dogru yanitti.Ve test sirasinda ortaya cikabilecek olan overfiiting probleminin validation set kullanmamaya baglanmasina dogru diyemeyiz.1 month ago 2 people like this.Like ReportReply",
    "->  Bununla ilgili bir post yazdÄ±m..",
    "-> Soruda herhangi bir hata gÃ¶rmedim, ancak burada yazÄ±lanlar biraz fazla terimsel olduÄŸu iÃ§in konunun anlaÅŸÄ±lmasÄ±nÄ± engelliyor olabilir.Herhalde ÅŸunu biraz aÃ§mak bu meselenin anlaÅŸÄ±lmasÄ±nÄ± kolaylaÅŸtÄ±rabilir:Ä°ki parÃ§alÄ± veriyle(train+test) Ã§alÄ±ÅŸÄ±rken Ã¼rettiÄŸimiz modelin ne kadar baÅŸarÄ±lÄ± olduÄŸunu gÃ¶rmek iÃ§in model Ã¼zerinde deÄŸiÅŸiklikler yapÄ±yoruz. yaptÄ±ÄŸÄ±mÄ±z her deÄŸiÅŸiklik modelin \"kullandÄ±ÄŸÄ±mÄ±z test seti iÃ§in\" dÃ¼zenlenmesine sebep oluyor. Yani bir sÃ¼re sonra bu sisteme overfit olmaya baÅŸlayabilir. Bu da gerÃ§ek datayla Ã§alÄ±ÅŸmaya baÅŸladÄ±ÄŸÄ±mÄ±zda hata miktarÄ±nÄ±n Ã¶ngÃ¶remediÄŸimiz ÅŸekilde artmasÄ±na sebep olabilir.Bunu engellemek (yani tarafsÄ±zlÄ±ÄŸÄ±mÄ±zÄ± korumak) adÄ±na yapabileceÄŸimiz bir ÅŸey araya bir validation set ekleyip (train+validation+test) modeli validation set Ã¼zerinde elde ettiÄŸimiz sonuÃ§lara bakarak dÃ¼zeltmek. Modelle iÅŸimiz bittikten sonra performansÄ±nÄ± test sete bakarak belirleriz. BÃ¶ylece tarafsÄ±zlÄ±ÄŸÄ±mÄ±zÄ± daha iyi korumuÅŸ, Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z veriye overfit olma riskini de azaltmÄ±ÅŸ oluruz.1 month ago 3 people like this.Like ReportReply",
    "->  ->  ÅÃ¶yle bir Ã¶rnek daha net anlaÅŸÄ±lmasÄ±nÄ± saÄŸlayabilir belki. BoksÃ¶r olduÄŸumuzu dÃ¼ÅŸÃ¼nelim. GÃ¼Ã§lÃ¼ biriyle (test) turnuva maÃ§Ä±na Ã§Ä±kacaÄŸÄ±z. Antrenman yapÄ±p (train) direkt adamÄ±n karÅŸÄ±sÄ±na Ã§Ä±kmak yerine Ã¶ncesinde orta seviye biriyle (validation) maÃ§ yapÄ±p gÃ¼cÃ¼mÃ¼zÃ¼ test ediyoruz. Bu karÅŸÄ±laÅŸmaya gÃ¶re daha iyi hazÄ±rlanÄ±p turnuvadaki maÃ§Ä±mÄ±za (test) gidiyoruz. Orta seviye adama gÃ¶re Ã§alÄ±ÅŸmaya Ã§ok fazla odaklanÄ±rsak (overfitting) turnuvada Ã§ok fena dayak yiyebiliriz ğŸ™‚1 month ago 5 people like this.Like ReportReply",
    "->  ->  Harika! Bu Ã¶rneÄŸe bir dÃ¼zeltme; rakip boksÃ¶rlerin ne kadar gÃ¼Ã§lÃ¼ olduÄŸunu bilmiyor olmalÄ±yÄ±z. Aksi takdirde tarafsÄ±zlÄ±ÄŸÄ±mÄ±zÄ± kaybetmiÅŸ ve gene overfit riskiyle karÅŸÄ±laÅŸmÄ±ÅŸ oluruz.1 month ago 2 people like this.Like ReportReply",
    "->  ->  DoÄŸrudur o zaman ikisinide bilmediÄŸimizi ama birbirlerinden farklÄ± olduklarÄ±nÄ± dÃ¼ÅŸÃ¼nebiliriz sanÄ±rÄ±m..",
    "->  Overfitting, training esnasinda cok iyi sonuclar alip, test/validation sirasinda poor sonuclarin olusmasidir.Modeliniz training sirasinda ogrenmekten ziyade ezberlemistir..Dolayisiyla modelinize ezberledigi training dataset disinda farkli bir dataseti verdiginizde sonuclar icacici olmamistir,Peki neden olmustur bu? Yani overfittingin sebebi nedir? Kucuk bir dataseti ile cok katmanli complex bir model kullanmissinizdir.Nasil onleriz? Dropout, regularization, remove features, cross-validation, early stopping, train with more data.(Bazi yontemlerin ayni anda kullanilmasi tavsiye olunmaz).",
    " "
]
},
{
"question_isim": "-> ",
"quest": "merhabalar sÄ±nav iÃ§in mail gelmedi bana bugun olmasÄ± gerekiyordu. Ne yapmam gerekiyor",
"comment": [
    "",
    "->  AslÄ± hanÄ±mÄ±n yorumuna bakÄ±nÄ±z. SÄ±nav sabah baÅŸladÄ± akÅŸam 22 de bitecek. Linki paylaÅŸÄ±ldÄ±..",
    "->  Sinav linki: https://forms.gle/NPqhfziPutqcdoK79https://forms.gle/NPqhfziPutqcdoK79forms.glehttps://forms.gle/NPqhfziPutqcdoK79.",
    "->  Ä°lk posta bakÄ±n. AslÄ± hanÄ±m linki paylaÅŸtÄ±. http://community.globalaihub.com/community/profile/aslii/1 month ago 2 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba,   Sinavdaki bir soruyla ilgili bir sorum vardi da kime sorabilirim acaba ? Hala girmemiÅŸ arkadaslar var iken yazmak doÄŸru gelmedi.",
"comment": [
    "",
    "-> Hocam sÄ±navÄ±n bitmesini beklerseniz daha mantÄ±klÄ± olur.HenÃ¼z sÄ±nav iÃ§in zaman var..",
    "Sadettin DurmuÅŸ TalipoÄŸlu Merhabalar, Bende sÄ±nav sorularÄ±nda bir sorudaki seÃ§eneÄŸe takÄ±ldÄ±m. Ã–zniteliÄŸi dÃ¼ÅŸÃ¼rmek baÅŸarÄ± oranÄ±nÄ± arttÄ±rmayabilir. Ã–znitelik seÃ§imi gibi iÅŸlemler yapÄ±ldÄ±ÄŸÄ± takdirde artabilir..",
    "->  Merhabalar, soru cevaplarÄ±nÄ± aÃ§Ä±klamalÄ± olarak paylaÅŸacaÄŸÄ±z, onun Ã¼zerinden sorularÄ±nÄ±zÄ± sorabilirsiniz yarÄ±n ğŸ˜‰.",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar,  Sisteme girmede yaÅŸayabileceÄŸiniz olasÄ± problemlere karÅŸÄ± sizlere bireysel mail atmayÄ± dÃ¼ÅŸÃ¼nmÃ¼ÅŸtÃ¼k, ki sabah bana ilettiÄŸiniz mail adreslerine tek tek mailleri gÃ¶nderdik. Kimi arkadaÅŸlar maili alÄ±p, yanÄ±tlarÄ±nÄ± gÃ¶nderebilmiÅŸ iken,  anlamadÄ±ÄŸÄ±m bir sebepten Ã¶tÃ¼rÃ¼ bazÄ±larÄ±mÄ±z alamamÄ±ÅŸ. Bu gibi durumlarda spam kutunuzu da kontrol etmenizi rica ederiz. KÄ±sacasÄ± ilgili  TEST LÄ°NKÄ° ???? ni burada da tekrar iletiyorum.  ????????https://forms.gle/NPqhfziPutqcdoK79",
"comment": [
    "",
    "-> ->  hanÄ±m, kontrollerimi yaptÄ±m ancak mail maalesef gelmemiÅŸ. Bilginize.1 month ago 4 people like this.Like ReportReply",
    "->  Merhaba, sÄ±navÄ± ilettiÄŸiniz link Ã¼zerinden mi Ã§Ã¶zeceÄŸiz? Codela linki olacak mÄ±? banada mail gelmdi.",
    "->  ->  Codela'yÄ± son anda karÅŸÄ±laÅŸtÄ±ÄŸÄ±mÄ±z bir durumdan Ã¶tÃ¼rÃ¼ bu hafta kullanamÄ±yoruz, bu link Ã¼zerinden ileteceksiniz.1 month ago 2 people like this.Like ReportReply",
    "->  ->  YolladÄ±ÄŸÄ±nÄ±z google forms linkinden Ã§Ã¶zeceÄŸiz sÄ±navÄ± herhalde. Zaman aralÄ±ÄŸÄ±mÄ±z yine aynÄ± mÄ±? Bir de linke girdikten sonra 45 dakika iÃ§inde yollamamÄ±z mÄ± gerekyor? Az Ã¶nce linke tÄ±kladÄ±m ama ÅŸu an sÄ±nava girmek istemiyorum..",
    "->  ->  bende o ÅŸekilde yaptÄ±m ama sÄ±navÄ± ÅŸimdi yapmayacaktÄ±m. NasÄ±l olucak umarÄ±m cevap verirler biran Ã¶nce..",
    "->  ->  ->  Saat 22:00'ye kadar girip tamamlayabilirsiniz..",
    "->  Merhaba, Banada mail henuz ulasmadi..",
    "->  ->  YukarÄ±da paylaÅŸtÄ±ÄŸÄ±m link ten direkt teste eriÅŸebilirsiniz..",
    "->  Kaplan ArkadaÅŸlar biraz sakin olalÄ±m bu link Ã¼zerinde sÃ¼re sÄ±nÄ±rÄ± vs. yok ben az Ã¶nce Ã§Ã¶zdÃ¼m. DilediÄŸiniz gibi yapÄ±n ancak kendi kendinize sÃ¼re tutmak iyi bir fikir olabilir..",
    "->  ->  Kaplan TeÅŸekkÃ¼rler, amacÄ±mÄ±z zaten kendinize dÃ¼rÃ¼st olmanÄ±z, birÅŸeyler katabilmeniz ğŸ˜‰.",
    "->  YukarÄ±daki link'ten sÄ±navÄ± tamamladÄ±m. BaÅŸka bir ÅŸey yapmaya gerek yok sanÄ±rÄ±m..",
    "->  ->  aynen ÅŸuan iÃ§in yok, teÅŸekkÃ¼r ederiz ğŸ™‚.",
    "-> Bu testi bu gece 22:00'e kadar yapip gondermemiz gerekiyor degil mi? Baska bir online testi de yapmamiz gerekiyor mu?.",
    "->  -> evet, sadece bunu yapacaksÄ±nÄ±z..",
    "-> ->  OK, tesekkurler..",
    "->  ->  3.sorunun cevabÄ±nda hata var sanÄ±rÄ±m. Kontrol edebilir misiniz?1 month ago 2 people like this.Like ReportReply",
    "->  ->  evet sehven yanlÄ±ÅŸ iÅŸlenmiÅŸ, sisteme gerekli dÃ¼zeltmeler yapÄ±ldÄ±..",
    "->  ->  hocam nerede yanlÄ±ÅŸlÄ±k olduÄŸunu aÃ§Ä±klayabilir misiniz acaba?.",
    "->  ->  DoÄŸru cevap ÅŸÄ±kkÄ± yanlÄ±ÅŸtÄ±..",
    "->  ->  SorularÄ±n cevaplarÄ±nÄ± aÃ§Ä±klamalÄ± olarak paylaÅŸacaÄŸÄ±z.1 month ago 2 people like this.Like ReportReply",
    "->  ->  teÅŸekkÃ¼r ediyorum..",
    "->  TeÅŸekkÃ¼rler mail gelmemiÅŸti ama bu linkten sÄ±nava katÄ±ldÄ±m. 2.soruyu iÅŸaretlemiÅŸ olmama raÄŸmen boÅŸ bÄ±rakÄ±lmÄ±ÅŸ kabul etti. 3. soruda ben mi yanlÄ±ÅŸ yaptÄ±m bilmiyorum ama kÃ¼sÃ¼ratlÄ± bir sayÄ± buldum.ÅÄ±klar arasÄ±nda hem Ã¼st hem de alt olarak yuvarlanmÄ±ÅŸ seÃ§enekler vardÄ±. Ben alt seÃ§eneÄŸi seÃ§tim ama doÄŸru cevap Ã¼st olanmÄ±ÅŸ.1 month ago 2 people like this.Like ReportReply",
    "->  bende katÄ±lÄ±yorum..",
    "->  ->  SorularÄ±n cevaplarÄ±nÄ± aÃ§Ä±klamalÄ± oalrak paylaÅŸacaÄŸÄ±z..",
    "->  ->  1 devirdeki mini-batch sayÄ±sÄ± kÃ¼sÃ¼ratlÄ± olamayacaÄŸÄ± iÃ§in bÃ¶yle bir ÅŸey ortaya Ã§Ä±kÄ±yor. Ä°lk baÅŸlangÄ±Ã§ta eklemek gerekiyor..",
    "->  KaÃ§ puanÄ±n altÄ±ndakiler baÅŸarÄ±sÄ±z sayÄ±lacak acaba?.",
    "->  ->  eÄŸer standart puanlama yapÄ±lÄ±rsa 60 puan altÄ± baÅŸarÄ±sÄ±z sayÄ±lÄ±r. Ama yetkili arkadaÅŸlar daha iyi bilir..",
    "->  ->  70 puan almÄ±ÅŸÄ±m da ondan sordum ğŸ˜€ Ä°nÅŸallah bir sonraki tura geÃ§ebilirim ğŸ™‚ ğŸ™‚.",
    "->  ->  Bu ara quizler kendinizi Ã¶lÃ§ebilmeniz adÄ±na, 60 ve yukarÄ±sÄ± ben konuyu temel olarak kavradÄ±m diye dÃ¼ÅŸÃ¼nebilir ama tabii hedef her zaman daha yÃ¼ksek olmalÄ± ğŸ˜‰.",
    "->  ->  TeÅŸekkÃ¼rler. Peki ara quizlerde dÃ¼ÅŸÃ¼k puan alanlar (60 ya da daha dÃ¼ÅŸÃ¼k) eÄŸitimle iliÅŸkisi kesilecek mi yoksa devam edilip kursu takip edip etmediÄŸine baÅŸka ÅŸekilde mi karar verilecek ? (HaftalÄ±k gÃ¶revleri yerine getirmeyenler eÄŸitimden atÄ±lacak denmiÅŸti.).",
    "->  Ant Ben buradan Ã§Ã¶zdÃ¼m bir sÄ±kÄ±ntÄ± olmaz umarÄ±m . Direkt puanÄ± da gÃ¶sterdi .1 month ago 2 people like this.Like ReportReply",
    "->  Merhaba, yukaridaki linkten ben de sorulari tamamladim ancak kafama takilan sorular var. Kafa karistirmamak adina sinav sÃ¼resinin tamamlanmasini bekliyorum sormak icin..",
    "->  ->  SorularÄ±n cevaplarÄ±nÄ± ayrÄ±ca paylaÅŸacaÄŸÄ±z aÃ§Ä±klamalÄ± olarak, onun Ã¼zerinden kafanÄ±za takÄ±lanlarÄ± sorabilirsiniz ğŸ™‚.",
    "->  Ben yaptÄ±ÄŸÄ±mda puan gÃ¶stermemiÅŸti ? Sabah yaptÄ±m..",
    "->  ->  check result kÄ±smÄ±na ilerlememiÅŸ oalbilirsiniz..",
    "->  ->  Ã–yle bir seÃ§enek yoktu, cevabÄ±nÄ±z gÃ¶nderilmiÅŸtir diye bir mesaj Ã§Ä±ktÄ± sadece. GÃ¼n sonunda ilk aÅŸamayÄ± geÃ§enler aÃ§Ä±klanacak mÄ±? TeÅŸekkÃ¼rler ğŸ™‚.",
    "->  ->  SonuÃ§larÄ± ulaÅŸmÄ±ÅŸ olanlarÄ± paylaÅŸabilmeniz mÃ¼mkÃ¼n mÃ¼dÃ¼r? Herkes puanÄ±nÄ± gÃ¶rÃ¼ntÃ¼leyip ben gÃ¶rÃ¼ntÃ¼leyemeyince formu gÃ¶nderebildiÄŸimden ÅŸÃ¼phe duymaya baÅŸladÄ±m ğŸ™.",
    "->  10 soru biraz az oldu sanki ğŸ™‚ keÅŸke daha Ã§ok soru olsaydÄ±.",
    "->  ->  Bu ilk tur, Ä±sÄ±nma turuydu ğŸ™‚ Ä°lerleyen haftalarda konularÄ±mÄ±z biraz daha artacak, o zaman soru sayÄ±mÄ±z da artacaktÄ±r ğŸ˜‰.",
    "->  Merhaba, form'a mail adresimi bu sabah girmiÅŸtim bana da spam ve mailbox'a dÃ¼ÅŸmedi. Link Ã¼zerinden tamamladÄ±m. TeÅŸekkÃ¼rler..",
    "->  Ben de Ã§Ã¶zdÃ¼m, emin olamadÄ±ÄŸÄ±m sorularÄ± yanlÄ±ÅŸ yapmÄ±ÅŸÄ±m. Ã–zeleÅŸtiri yaparsam Ã§alÄ±ÅŸmam ve tekrarlarÄ±m yetersizmiÅŸ. 3. soruda zorlandÄ±m. Validation ve test konularÄ±ndaki eksiklerimi gÃ¶rdÃ¼m. 50 puan aldÄ±m. Ama grafikleri iyi anlamÄ±ÅŸÄ±m. Galiba Ã¶ÄŸrendiÄŸimi dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼m konularda da kendi iÃ§imde Ã§eliÅŸkiye girdiÄŸimden cevaplarÄ±ma yansÄ±mÄ±ÅŸ. Ã‡ok teÅŸekkÃ¼r ederim hocalarÄ±ma ve grupta soru sorup cevaplayan arkadaÅŸlara ????????.",
    "->  ->  Sizlere yararlÄ± olabildiysek ne mutlu bize ???? Biz teÅŸekkÃ¼r ederiz ????1 month ago 2 people like this.Like ReportReply",
    "->  (:.",
    "->  AslÄ± HanÄ±m bazÄ± sorularda kafama takÄ±lan ÅŸeyler var. Sizler daha sonra sorular Ã¼zerinden aÃ§Ä±klama yapacak mÄ±sÄ±nÄ±z?.",
    "-> Merhaba, paylaÅŸtÄ±ÄŸÄ±nÄ±z dokÃ¼manÄ± geÃ§ gÃ¶rdÃ¼ÄŸÃ¼m iÃ§in mail adresimi yazamadÄ±m. Bu linkten sÄ±nava katÄ±ldÄ±m. Fakat timer gÃ¶rÃ¼nmedi. Bu bir sorun oluÅŸturur mu?.",
    "->  AslÄ± HanÄ±m merhabalar, sÄ±navÄ± birkaÃ§ dakika Ã¶nce tamamladÄ±m. SonuÃ§larÄ± kontrol ettiÄŸimde ilk sorunun iÅŸaretlenmemiÅŸ olduÄŸunu gÃ¶rdÃ¼m. Halbuki birkaÃ§ kez kontrol etmiÅŸtim tÃ¼m sorularÄ± ( zaten iÅŸaretlendikten sonra geri alma ÅŸansÄ±mÄ±z yokmuÅŸ ). Bu tarz baÅŸka ÅŸikayetler aldÄ±nÄ±z mÄ± acaba deÄŸerlendirme ile ilgili?.",
    "->  AynÄ±sÄ± bana 2.soruda oldu.Ben de kontrol etmiÅŸtim halbuki..",
    "->  Bende 70 aldÄ±m fakat 8. soru bir sonraki haftanÄ±n konusu gibi geldi bana.1 month ago 2 people like this.Like ReportReply",
    "->  ->  KatÄ±lÄ±yorum bu haftanÄ±n konularÄ±nda geÃ§meyen bir soru vardÄ±. Bu hafta hiÃ§ tanÄ±tÄ±lmamÄ±ÅŸtÄ± bazÄ± terimler de mevcuttu, yine de genel olarak baÅŸarÄ±lÄ± bir sÄ±navdÄ±..",
    "->  Nihayet sÄ±navÄ± Ã§Ã¶zdÃ¼m, ne yazÄ±k ki notum pek yeterli deÄŸil. ğŸ™‚ Fakat yeni ilgi alanÄ±ma giren bir konu olmasÄ±na raÄŸmen bir Ã§ok kavramÄ± Ã¶ÄŸrendiÄŸim iÃ§in mutluyum. Ä°lk elin gÃ¼nahÄ± olmaz diyerek takÄ±ldÄ±ÄŸÄ±m yerleri tekrar edip, gelecek haftaki sÄ±navda daha iyi bir not almayÄ± planlÄ±yorum. SÄ±nav iÃ§in teÅŸekkÃ¼r ederiz..",
    "->  Testi ÅŸimdi tamamladÄ±m. Ã‡ok dikkatsizlikler yapmÄ±ÅŸÄ±m hÄ±zlÄ± yapacaÄŸÄ±m diye ğŸ™‚ AnlamadÄ±ÄŸÄ±m yerleri tekrar etmem iÃ§in iyi bir sebep oldu benim iÃ§in. Drive dosyasÄ±na mailimi yeni yazdÄ±m bir sonraki sÄ±navlar mail gelir deÄŸil mi? TeÅŸekkÃ¼rler tekrardan ğŸ™‚.",
    "->  Merhabalar, ben de yukarÄ±daki linkten sÄ±navÄ± tamamladÄ±m. Herkese baÅŸarÄ±lar diliyorum.Benim 1. ve 2. sorularda Ã§eliÅŸkim Ã§ok oldu, 2'yi anladÄ±m ama 1'de birden fazla doÄŸru cevap varmÄ±ÅŸ gibi geldi bana.3. soruda da ayrÄ±ca bir hesap problemi yaÅŸadÄ±m sanÄ±rÄ±m, sorularÄ±n aÃ§Ä±klamalarÄ±nÄ± bekliyorum.Ä°yi gÃ¼nler. ğŸ™‚1 month ago 2 people like this.Like ReportReply",
    "-> ->  1.soru iÃ§in ben de aynÄ± ÅŸeyi dÃ¼ÅŸÃ¼nÃ¼yorum ğŸ™‚.",
    "->  -> ben de 1 de Ã§eliÅŸkiye dÃ¼ÅŸtÃ¼m1 month ago 2 people like this.Like ReportReply",
    "->  SÄ±navlardaki kÃ¶tÃ¼ performansÄ±m burada da bÄ±rakmadÄ± peÅŸimi ğŸ™‚ epoch sorusunun cevabÄ±nÄ± Ã¶zellikle paylaÅŸÄ±rsanÄ±z Ã§ok memnun olurum.1 month ago 2 people like this.Like ReportReply",
    "->  8. soruya emin olmadÄ±ÄŸÄ±m 1-2 Ã§Ã¶zÃ¼mden dolayÄ± doÄŸru cevabÄ± veremedim.Daha Ã¶nceden bu konulara aÅŸina idim. Ancak Validation Data'larÄ±nÄ±n neden ve nasÄ±l kullanÄ±ldÄ±ÄŸÄ±nÄ± bilmiyordum. Ä°lk hafta bu durumu Ã§Ã¶zdÃ¼m programdan Ã§ok memnunum emeklerinize saÄŸlÄ±k..",
    " ->  Quiz bana ÅŸunu gÃ¶sterdi daha dÃ¼zenli ve sÄ±k Ã§alÄ±ÅŸmam gerektiÄŸini sorular aÃ§Ä±klayÄ±cÄ± ve Ã¶ÄŸreticiydi emeÄŸinize saÄŸlÄ±k..",
    " ->  Merhaba, mail gelmemiÅŸti bana, atÄ±lan bu linkten az Ã¶nce tamamladÄ±m. Emin olmadÄ±ÄŸÄ±m sorularÄ± yanlÄ±ÅŸ yapmÄ±ÅŸÄ±m, 70 aldÄ±m. Daha iyi Ã§alÄ±ÅŸÄ±p daha iyi oturacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum. TeÅŸekkÃ¼rler her ÅŸey iÃ§in. ????.",
    "S->  ->  hanÄ±m linke giriÅŸ yaptÄ±m, google docs Ã¼zerinden bir form gÃ¶rÃ¼ndÃ¼, zamanlayÄ±cÄ± burada yok sanÄ±rÄ±m. Sadece kontrol amacÄ±yla linke giriÅŸ yapmÄ±ÅŸtÄ±m, sÄ±navÄ± daha sonra Ã§Ã¶zeceÄŸim..",
    "->  Selamlar, ben de sinavi tamamladim. Sinavi cozerken de takildigim soru yanlis sadece, iterasyon hesaplama sorusu. Quic herkes icin kapandiginda, cevaplarinizi duymak isterim. Cok tesekkurler!.",
    " ->  Merhabalar, sÄ±navÄ± tamamladÄ±m. YanlÄ±ÅŸ yaptÄ±ÄŸÄ±m sorularÄ±n Ã§Ã¶zÃ¼mlerini anladÄ±m. Bir sonraki haftaya devam edecek kiÅŸiler ne zaman belirlenir ya da o sistem kurs sonunda kursu tamamlamaya hak kazananlar iÃ§in mi yapÄ±lacak? SÄ±kÄ± Ã§alÄ±ÅŸmaya devam, teÅŸekkÃ¼rler bize bÃ¶yle bir fÄ±rsat sunduÄŸunuz iÃ§in..",
    "-> 7. soruda korelasyon matrisi ile ilgili soruda problem olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yorum. Ä°statistikteki tanÄ±mÄ±na gÃ¶re testin verdiÄŸi cevap doÄŸru bir cevap deÄŸil..",
    "->  -> Evet haklÄ±sÄ±nÄ±z, ben de hatalÄ± olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yorum..",
    "->  -> Biraz kelime oyunu var gibi o sebepten olabilir..",
    " ->  -> ufak bir kelime oyunu var orada, dikkatli okuyunca anlaÅŸÄ±lÄ±yor..",
    "->  Devam edebilirsem haftaya daha dikkatli olacaÄŸÄ±m. GÃ¼zel bir sÄ±navdÄ±. TeÅŸekkÃ¼rler..",
    " ->  SÄ±navÄ± 80 puan ile tamamladÄ±m. 1. ve 7. sorunun ÅŸÄ±klarÄ± biraz kafa karÄ±ÅŸtÄ±rÄ±cÄ± geldi aÃ§Ä±kÃ§asÄ± .SÄ±nav iÃ§in teÅŸekkÃ¼rler..",
    "-> Merhaba, bana sÄ±nav iÃ§in mail gelmedi. Bu posttaki link ile googleforms Ã¼zerinden testi Ã§Ã¶zdÃ¼m. Bir Ã¶nceki postta testin \"Codela\" Ã¼zerinden gerÃ§ekleÅŸeceÄŸini sÃ¶ylemiÅŸtiniz. AyrÄ±ca sÄ±nava tekrar tekrar girebiliyorum. Buradaki test harici baÅŸka bir sÄ±nav var mÄ±? SÄ±nav iÃ§in de teeÅŸekkÃ¼rler ğŸ™‚.",
    " -> 2'nci ve 6'ncÄ± sorularda kafa karÄ±ÅŸÄ±klÄ±ÄŸÄ± yaÅŸadÄ±m. Sorular temel kavramlarÄ± test edecek ÅŸekildeydi diye dÃ¼ÅŸÃ¼nÃ¼yorum ama Tensor Flow tarafÄ±ndan kod sorularÄ± da bekliyordum. Cevaplar iÃ§in beklemedeyim. TeÅŸekkÃ¼rler ğŸ™‚.",
    "-> Merhaba, biraz Ã¶nce tamamladÄ±m testi fakat sonucum hiÃ§ hoÅŸ deÄŸil ğŸ™ fazlasÄ±yla dikkatsizim. Fakat quiz gÃ¼zeldi. 7 ve 8. sorunun aÃ§Ä±klamasÄ±nÄ± merak ediyorum. TeÅŸekkÃ¼rler..",
    "->  SÄ±navdan Ã§ok iyi bir sonuÃ§ aldÄ±m ve eÄŸitimin bana ne kadar yararlÄ± olabildiÄŸini bugÃ¼n daha iyi Ã¶ÄŸrendim. EmeÄŸi geÃ§en herkese teÅŸekkÃ¼rler ğŸ™‚.",
    "->   GÃ¼zel bir sÄ±navdÄ±. YanlÄ±ÅŸ yaptÄ±ÄŸÄ±m sorularÄ± dÃ¼ÅŸÃ¼nÃ¼nce Ã§Ã¶zÃ¼mlerini anladÄ±m. EÄŸitimler gerÃ§ekten verimli oluyor. TeÅŸekkÃ¼rler bÃ¶yle bir organizasyon iÃ§in ğŸ™‚.",
    "->  Merhabalar. SÄ±navÄ± tamamladÄ±m ve 1. soruda soruda Ã§eliÅŸki yaÅŸadÄ±m. Herkese baÅŸarÄ±lar diliyorum. SÄ±nav iÃ§in teÅŸekkÃ¼rler. Ä°yi gÃ¼nler ğŸ™‚.",
    "-> SÄ±navda dÃ¼ÅŸÃ¼k puan alsam da sorularÄ±n cevaplarÄ±nÄ± gÃ¶rmek gÃ¼zel oldu. YanlÄ±ÅŸlarÄ±mÄ± gÃ¶rmÃ¼ÅŸ oldum.",
    "->  Merhaba,Dun bilgisayar basinda olamadigimdan eposta adresimi zamaninda iletemedim ve dogal olarak bu sabah sizden bir eposta almadim. Bu gonderinizinde verdiginiz adrese girip testi yaptim yalniz, bir seyler yanlis sanirim. Asagida testin 45 dk sureli oldugu yaziyor ancak ben boyle bir kisit tespit edemedim. Ayrica testi tekrar alma imkani da mumkun gorunuyor. Ilginizi rica edebilir miyim, belli ki bir seyleri yanlis yapiyorum.1 month ago 2 people like this.Like ReportReply",
    "->  Merhabalar. Quizi az Ã¶nce tamamladÄ±m ve 80 aldÄ±m. Benim iÃ§in iyi bir sonuÃ§ deÄŸil. TakÄ±ldÄ±ÄŸÄ±m ve quiz bitiminden sonra soracaÄŸÄ±m bazÄ± sorular var. Fakat eÄŸitimin ne kadar verimli olduÄŸunu sorularla bir kez daha gÃ¶rmÃ¼ÅŸ oldum. TeÅŸekkÃ¼rler ğŸ™‚.",
    "->  8. soru ilk haftanÄ±n konularÄ± arasÄ±nda mÄ±ydÄ± ben kaÃ§Ä±rmÄ±ÅŸÄ±m heralde. 3 ve 8 yanlÄ±ÅŸ, 3 de dikkatsizilik, 8 ide daha Ã¶nce gÃ¶rmedim kaÃ§Ä±rdÄ±m biyerde heralde..",
    "-> Merhaba,quizi simdi tamamladÄ±m gerÃ§ekten tÃ¼m haftanÄ±n verimini en ince detayÄ±na kadar Ã¶lÃ§en bir quiz olmuÅŸ sorular gayet baÅŸarÄ±lÄ±ydÄ± tam sorulmasÄ± gereken gÃ¼zel sorulardÄ± ,gruptaki sorular ve verilen cevaplar da Ã§ok iyi oluyor herkese teÅŸekkÃ¼rler.",
    "->  Testi ÅŸimdi tamamladÄ±m ve 80 aldÄ±m. gerÃ§ekten tÃ¼m haftayÄ± Ã¶lÃ§en gÃ¼zel bir kurs olmuÅŸ. Bir tanÄ±m sorusunda fazla geniÅŸ dÃ¼ÅŸÃ¼nmekte benim hatam oldu, kurstaki bilgileri gayet gÃ¼zel sonuÃ§lar alÄ±nÄ±yor. TeÅŸekkÃ¼rler..",
    "->  Hocam bu haftaki kÄ±smÄ± Ã§alÄ±ÅŸtÄ±m, ingilizce olduÄŸu iÃ§in Ã§evirmek baya yordu 40 aldÄ±m, olmadÄ± verim alamadÄ±m..",
    "->  ->  Ä°ngilizce iÃ§in takÄ±ldÄ±ÄŸÄ±nÄ±z yerde ki bende kullanÄ±yorum, Inline Ã§eviri kullanabilirsiniz Google eklentisi olan ImTranslator'Ã¼ Ã¶neririm..",
    "->  SÄ±nav Ã§ok gÃ¼zel hazÄ±rlanmÄ±ÅŸ, tebrik ederim. Sonucum beni Ã¼zdÃ¼ ama olsun durmak yok. HatalarÄ±mÄ± gÃ¶rmem iyi oldu..",
    "-> Ã‡ok iyisiniz ekip olarak, baÅŸarÄ±larÄ±nÄ±zÄ±n devamÄ±nÄ± diliyorum.Buradaki arkadaÅŸlarÄ±n da Ã¶ÄŸrenme hevesleri hiÃ§ geÃ§mesin, bitmesin. Bilim gÃ¼zel ÅŸey !1 month ago 1 person likes thisLike Reply Edit",
    "->  SÄ±nav sorularÄ± pekiÅŸtirmek iÃ§in Ã§ok yararlÄ± olmuÅŸ. Eksiklerimin de ne olduÄŸunu gÃ¶rmÃ¼ÅŸ oldum. TÃ¼m ekibe teÅŸekkÃ¼rler.1 month ago 2 people like this.Like ReportReply",
    "->  Ben de sÄ±navÄ±mÄ± tamamladÄ±m. YanlÄ±ÅŸ yaptÄ±ÄŸÄ±m konulara tekrar bakÄ±p pekiÅŸtirmek gerekiyor sanÄ±rÄ±m. Bu hafta baÅŸlangÄ±Ã§ iÃ§in verimli geÃ§ti diyebilirim..",
    "-> -> sÄ±nav faydalÄ± oldu bence daha iyi Ã§alÄ±ÅŸtÄ±k sadece bi sorunun cevabÄ± tatmin etmedi sÃ¼resi bitince konuÅŸabiliriz sanÄ±rÄ±m..",
    "->  -> -> sorularÄ±n cevaplarÄ±nÄ± paylaÅŸacaÄŸÄ±z, oradan belirtebilirsiniz ğŸ˜‰.",
    "->  Ã‡ok verimli bir haftaydÄ± hem mlcc Ã¼zerinden hemde textbooklar Ã¼zerinden sÃ¼reci ilerletiyorum.",
    "->  GÃ¼n iÃ§inde iÅŸlerim olduÄŸu iÃ§in sÄ±navÄ± yeni tamamladÄ±m 8. soruda gÃ¼zel bir mantÄ±k yÃ¼rÃ¼tÃ¼p hepsini baÅŸarÄ±yla Ã§Ã¶zdÃ¼m. BaÅŸlangÄ±Ã§ iÃ§in heves kÄ±rmayacak bir quizdi teÅŸekkÃ¼rler ğŸ™‚ SÃ¼re bitince sorularÄ±n kendimce Ã§Ã¶zÃ¼mÃ¼nÃ¼ paylaÅŸmak istiyorum herkesle..",
    "-> TeÅŸekkÃ¼rler az Ã¶nce bitirdim sorular gayet gÃ¼zeldi ????????????.",
    " ->  Ã–ÄŸrendiklerimizi yorumlayÄ±p aklÄ±mÄ±zda iyice yer etmesi iÃ§in gÃ¼zel bir quiz'di. EmeÄŸi geÃ§enlere teÅŸekkÃ¼r ederim..",
    "-> Teoriyi Ã§ok iyi kavramak gerekiyor, kursu takip ederken anladÄ±ÄŸÄ±mÄ± zannettiÄŸim konularda ikilemde kaldÄ±ÄŸÄ±mÄ± gÃ¶rdÃ¼m test sonucunda. EmeÄŸi geÃ§en herkese teÅŸekÃ¼r ederim:).",
    " ->  Ben de ÅŸimdi tamamladÄ±m testi.YetiÅŸtiremediÄŸim konularda yanlÄ±ÅŸlarÄ±m oldu,test ayÄ±rt ediciydi.Ã‡alÄ±ÅŸmaya devam etmem gerekiyor.TeÅŸekkÃ¼rler..",
    " ->  Eksiklerimi gÃ¶rmemde fazlasÄ±yla yardÄ±mÄ± oldu, teÅŸekkÃ¼rler..",
    "->  Ben linkten testi tamamladÄ±m fakat excel listesine adÄ±mÄ± ekleyemedim. sonraki haftada mail almak isterim. -> .",
    "->  DalgÄ±nlÄ±kla 2 soruyu yanlÄ±ÅŸ okumuÅŸum. Bu beni biraz Ã¼zdÃ¼ ama olsun quiz sorularÄ± gayet netti. TeÅŸekkÃ¼rler.",
    "->  Merhaba.DeÄŸerlendirme sorularÄ±nda sayÄ±sal sorularÄ±n cevaplarÄ±nÄ±n aÃ§Ä±klamasÄ± olur mu?BÃ¶yle bir ÅŸeyi dÃ¼ÅŸÃ¼nÃ¼r mÃ¼sÃ¼nÃ¼z?.",
    "->  ->  SorularÄ±n aÃ§Ä±klamalarÄ±nÄ± paylaÅŸacaÄŸÄ±z ğŸ˜‰1 month ago 2 people like this.Like ReportReply",
    "->  ->  TeÅŸekkÃ¼rler ????????.",
    "->  Merhaba ben maili gÃ¶rmedim, yarÄ±m saat Ã¶nce twitterda gÃ¶rdÃ¼m ne yapmalÄ±yÄ±m?.",
    "->  ->  saat 22:00'ye kadar vaktiniz var, hala girebilirsiniz ğŸ˜‰.",
    "->  SÄ±nav biraz garip olmus, herhangi bir hesapla sinava girip sinav sonunda cevaplari alarak asil hesapla sinav tekrar yapilabilir..",
    "->  ->  Buradaki asÄ±l olay kendinize samimi olmanÄ±z, ne kadar dÃ¼rÃ¼st yanÄ±tlarsanÄ±z o derece kendi geliÅŸiminizi gÃ¶rÃ¼p, kendinize daha da birÅŸeyler katabilirsiniz ğŸ˜‰.",
    "->  ->  haklisiniz ama sinavin sonunda odul olunca insanlar boyle dusunmeyebilir. ben yine de durumu belirteyim dedim..",
    "->  ->  AsÄ±l kendinizi gÃ¶stermeniz gereken kÄ±sÄ±m final sÄ±navÄ± ğŸ˜‰1 month ago 2 people like this.Like ReportReply",
    "->  ->  Benim Markov Chain Monte Carlo Deep Learning modeli nasil yapilir, onu ogrenmem lazim. Finalden korkmuyorum (:.",
    "->  BugÃ¼n linki gÃ¶rdÃ¼m ve gÃ¶rÃ¼r gÃ¶rmez sÄ±navÄ± yaptÄ±m. Sorun olur mu?.",
    " "
]
},
{
"question_isim": "-> ",
"quest": "BugÃ¼n sÄ±nav gÃ¼nÃ¼! BitirdiÄŸinize dair mesajlarÄ± okudukÃ§a Ã§ok mutlu oluyorum.  YazÄ±lan her mesajÄ± tek tek okuduÄŸumu bilmenizi isterim. EÄŸitimi bitirenlerden birebir yapacaÄŸÄ±mÄ±z mÃ¼lakatlarÄ± geÃ§enleri Yapay Zeka Yetenek ProgramÄ±mÄ±za dahil edeceÄŸiz.   Birlikte dirsek temasÄ± Ã§alÄ±ÅŸacaÄŸÄ±mÄ±z ve sÃ¼rekli iletiÅŸimde kalacaÄŸÄ±mÄ±z arkadaÅŸlarÄ± sabÄ±rsÄ±zlÄ±kla bekliyorum.",
"comment": [
    "",
    "-> Hocam verdiÄŸiniz emekler iÃ§in size ve ekibinize Ã§ok teÅŸekkÃ¼r ederim..Hep beraber bunlarÄ±n karÅŸÄ±lÄ±ÄŸÄ±nÄ± alacaÄŸÄ±z..",
    "->  Merhaba hocam, Yapay Zeka ve Makine Ã–ÄŸrenmesine ilgili bizlere bÃ¶ylesine bir fÄ±rsat sunduÄŸunuz iÃ§in size ve emeÄŸi geÃ§en herkese tek tek teÅŸekkÃ¼rlerimi ve ÅŸÃ¼kranlarÄ±mÄ± sunarÄ±m. Umuyorum ki bu eÅŸsiz fÄ±rsatÄ± en iyi ÅŸekilde deÄŸerlendireceÄŸiz. Ä°yi Ã§alÄ±ÅŸmalar ve kolaylÄ±klar dilerim.1 month ago 3 people like this.Like ReportReply",
    "->  Fuat Hocam gerÃ§ekten 1 hafta boyunca kendimize Ã§ok Ã¶nemli bilgiler kattÄ±k. Bu imkanÄ± bize verdiÄŸiniz iÃ§in Ã§ok teÅŸekkÃ¼rler. KonularÄ± derinlemesine Ã¶ÄŸrendikten sonra kodlarÄ± yazmak ve Ã§alÄ±ÅŸtÄ±rmak varsa sorunlarÄ± Ã§Ã¶zmek gerÃ§ekten Ã§ok daha Ã¶nemli, eÄŸitici ve eÄŸlenceli.1 month ago 3 people like this.Like ReportReply",
    "-> ->  bey, dÃ¼n gece ->  hanÄ±mÄ±n attÄ±ÄŸÄ± mail'i sabah gÃ¶rdÃ¼m. ve mail adresimi yaklaÅŸÄ±k 2 saat Ã¶nce google doc. daki listeye ekledim. Ancak henÃ¼z sÄ±nav adresi gelmedi. Daha Ã¶ncede belirttiÄŸim gibi sÄ±navdan ziyada Ã¶ÄŸrenmek Ã¶nemli. ancak tÃ¼m aÃ§Ä±klamarÄ±nÄ±z sÄ±navlarÄ± geÃ§en kursu bitirenlerle olduÄŸu iÃ§in adresime ve dÃ¼n gece yapÄ±lan aÃ§Ä±klamayÄ± gece gÃ¶ren tÃ¼m arkadaÅŸlara sÄ±nav adresini gÃ¶nderebilir misiniz ?1 month ago 3 people like this.Like ReportReply",
    "->  ->  Merhaba, Bende dÃ¼n sheete mail adresimi kaydetmeme raÄŸmen sÄ±nav linki alamamÄ±ÅŸ Ã¶ÄŸrenciler arasÄ±ndayÄ±m. SÄ±nav linki iÃ§in tekrar mail atma durumu olacak mÄ±?.",
    "->  ->  tabii tekrar iletebilirim.",
    "-> Bende eklememe raÄŸmen hala Linki alamadÄ±m aslÄ± hanÄ±m iyi Ã§alÄ±ÅŸmalar.",
    "->  ->  Merhaba, ben de dÃ¼n gece ben de mailimi google docsa girmeme ragmen sÄ±nav maili gelmedi, iletirseniz sevinirim, iyi gÃ¼nler..",
    "->  Merhabalar, ben de az Ã¶nce sÄ±navÄ± tamamladÄ±m ve cevaplarÄ±mÄ± kontrol edebildim. Emekleriniz iÃ§in teÅŸekkÃ¼r ederim. Hala sÄ±navÄ± yapacak arkadaÅŸlar olduÄŸu iÃ§in aklÄ±ma takÄ±lan bir soruyu burdan ÅŸu an sormamam gerektiÄŸini dÃ¼ÅŸÃ¼nÃ¼yorum. Acaba sÄ±nav sÃ¼resi bitince genel bir post Ã§Ä±kÄ±lÄ±r mÄ± bunun Ã¼zerine, sorularÄ±n aÃ§Ä±klamalarÄ±/cevaplarÄ±nÄ± iÃ§eren yoksa bireysel olarak post mu aÃ§malÄ±yÄ±z? Ä°yi pazarlar ğŸ™‚1 month ago 6 people like this.Like ReportReply",
    "->  Merhaba benim de sÄ±navÄ±m bitti. TeÅŸekkÃ¼rler ilginiz iÃ§in..",
    "->  Merhabalar, ÅŸimdi bitirdim sÄ±navÄ± ben de, dikkatsizliÄŸim sonucu bazÄ± hatalar yapmÄ±ÅŸÄ±m, Emekleriniz teÅŸekkÃ¼r ederim, EÄŸitimin sonunu baÅŸarÄ± ile bitireceÄŸimi Ã¼mit ederek sabÄ±rsÄ±zlÄ±kla beklemekteyim.Ä°yi gÃ¼nler, iyi pazarlar ğŸ™‚1 month ago 2 people like this.Like ReportReply",
    "->  Merhabalar, ben de sÄ±navÄ± bitirmiÅŸ bulunmaktayÄ±m. Herkese iyi gÃ¼nler dilerim.1 month ago 2 people like this.Like ReportReply",
    "->  Merhaba,SÄ±navÄ±mÄ± bitirmiÅŸ bulunmakla beraber iÃ§indeki sorular gerÃ§ekten Ã§ok gÃ¼zeldi. Eksiklerimi gÃ¶rmem ve kafamda bazÄ± mantÄ±klarÄ± oturtmamda daha da yardÄ±mcÄ± oldu. Herkese baÅŸarÄ±lar, iyi gÃ¼nler iyi haftasonlarÄ± ğŸ™‚1 month ago 2 people like this.Like ReportReply",
    "-> Merhaba, sÄ±navÄ± bitirdim. Soru 2 ve Soru 8'in cevaplarÄ± ile ilgili kafama takÄ±lan bazÄ± noktalar var. SÄ±nav devam ettiÄŸi iÃ§in buradan aÃ§Ä±k olarak yazmayacaÄŸÄ±m ancak bitiren arkadaÅŸlar ile Ã¶zelden bu konuyu tartÄ±ÅŸabiliriz. Herkese kolay gelsin ????.",
    "-> ->  ile konuyu irdeledik. AslÄ±nda aynÄ± cevabÄ± vermiÅŸiz ama sistem bana yanlÄ±ÅŸ derken OÄŸuzhan'a doÄŸru demiÅŸ.Ben sÄ±nava baÅŸladÄ±ÄŸÄ±mda sistemde bu sorunun cevabÄ± yanlÄ±ÅŸ kaydedilmiÅŸ, sonradan dÃ¼zeltildiÄŸi iÃ§in bÃ¶yle bir anomali olmuÅŸ diye dÃ¼ÅŸÃ¼nÃ¼yoruz..",
    "->  -> Evet doÄŸru cevabÄ± vermiÅŸiz ikimizde bende doÄŸru onda yanlÄ±ÅŸ gÃ¶rÃ¼nÃ¼yor, o erken Ã§Ã¶zdÃ¼ÄŸÃ¼ iÃ§in hata sonradan dÃ¼zeltildi sanÄ±rÄ±m..",
    "->  -> 2.soruda hata mÄ± var ?.",
    "-> ->  SÄ±navÄ± erken Ã§Ã¶zenler iÃ§in doÄŸru ÅŸÄ±k seÃ§iminde bir hata olmuÅŸ. Fuat bey bu durumun dikkate alÄ±narak not deÄŸerlendirmesi yapÄ±lacaÄŸÄ±nÄ± iletti. Soruyu doÄŸru yanÄ±tladÄ±ysanÄ±z ve form size yanlÄ±ÅŸ yaptÄ±ÄŸÄ±nÄ±zÄ± sÃ¶ylediyse, dikkate almayÄ±n..",
    "->  SÄ±nav gerÃ§ekten gÃ¼zeldi ancak correlation matrixin ne olduÄŸunu bilmeme raÄŸmen 7. soruyu yapamadÄ±m b ve c ÅŸÄ±klarÄ±nda anlatÄ±lmak istenen aÃ§Ä±k bir biÃ§imde anlatÄ±lamamÄ±ÅŸ bence, emeÄŸi geÃ§en herkese teÅŸekkÃ¼rler.1 month ago 2 people like this.Like ReportReply",
    "-> SÄ±navÄ± tamamladÄ±m, teÅŸekkÃ¼rler. BazÄ± arkadaÅŸlarÄ±n bahsettiÄŸi gibi, sÄ±nav sÃ¼resi dolduktan sonra soru ve cevaplarÄ±n irdelenmesi gibi bir tartÄ±ÅŸma yapÄ±labilirse gÃ¼zel olur diye dÃ¼ÅŸÃ¼nÃ¼yorum.1 month ago 3 people like this.Like ReportReply",
    " ->  Ä°yi gÃ¼nler benim de sÄ±navÄ±m bitti. 2. soruyu Ã§Ã¶zmÃ¼ÅŸtÃ¼m fakat ÅŸÄ±kka tÄ±klayamadÄ±m sanÄ±rÄ±m o soru boÅŸ kaldÄ± xd. Herkese baÅŸarÄ±lar..",
    "->  Sinav olmayi ozlemisim umarim 50 gecer nottur ğŸ˜€.",
    "->  Ã¼nlÃ¼ Merhabalar bir iki sorunun Ã§Ã¶zÃ¼mÃ¼nÃ¼ merak ediyorum, Ã§Ã¶zÃ¼mler olcak mÄ± ? ya da bilahare sorabilir miyiz?.",
    "->  ->  Ã¼nlÃ¼ CevaplarÄ± aÃ§Ä±klamalÄ± olarak paylaÅŸacaÄŸÄ±z, o paylaÅŸÄ±mÄ±n Ã¼zerinden kafanÄ±za takÄ±lanlarÄ± sorabilrisiniz ğŸ™‚.",
    "->  Uzun zamandÄ±r bÃ¶yle gÃ¼zel sÄ±nava girmeye hasret kalmÄ±ÅŸtÄ±k teÅŸÅŸekÃ¼rler.",
    "->  SÄ±navÄ± bitirdim. Sorular gerÃ§ekten bu haftanÄ±n gÃ¼zel bir deÄŸerlendirmesi niteliÄŸindeydi, teÅŸekkÃ¼rler..",
    " ->  ben de sÄ±navÄ± bitirdim. sorular sanki bu haftanÄ±n konularÄ±nÄ± Ã¶zetlemiÅŸti. bi iki soruda Ã§eliÅŸkide kaldÄ±m, eksiklerimi gÃ¶rmÃ¼ÅŸ oldum, ancak gerisi iyiydi. ikinci hafta konularÄ±na devam. emekleriniz iÃ§in teÅŸekkÃ¼rler..",
    "-> Ã–zeleÅŸtiri yaptÄ±ÄŸÄ±mda, daha dÃ¼zenli Ã§alÄ±ÅŸmam gerekiyor. Ã‡Ã¼nkÃ¼ sÄ±nav sonucuma gÃ¶re eksiklerim mevcut. Emekleriniz iÃ§in teÅŸekkÃ¼rler, ->  ve ->  ..",
    "->  SÄ±navÄ± bitirdim. DikkatsizliÄŸimden dolayÄ± bazÄ± hatalarÄ±m oldu. Bu sÄ±nav ile neyi anlayÄ±p neyi anlamadÄ±ÄŸÄ±mÄ± gÃ¶rmÃ¼ÅŸ oldum. Emekleriniz iÃ§in teÅŸekkÃ¼r ediyorum..",
    "-> merhaba sÄ±navÄ± bitirdim. Ã§ok dÃ¼ÅŸÃ¼k bir not almadÄ±ysam da kendi performansÄ±mÄ±n altÄ±nda olduÄŸunu dÃ¼ÅŸÃ¼nmekteyim ğŸ™‚ aÃ§Ä±klanÄ±lacak cevaplarÄ± heyecanla bekliyorum aklÄ±mda olan bir tane soru var ğŸ˜€ <3.",
    "-> SÄ±navÄ± tamamladÄ±m. Ã–ncelikle gÃ¼zel hazÄ±rlanmÄ±ÅŸ bir sÄ±nav olduÄŸunu sÃ¶yleyebilirim. Ä°lk haftanÄ±n konularÄ±nÄ± da yeterince kapsamÄ±ÅŸ bence. YalnÄ±z 8. soru bu hafta iÃ§erisinde bahsedilmemiÅŸ gibi geldi bana. Ya da ben gÃ¶zden kaÃ§Ä±rdÄ±m. BazÄ± sorularda arada kaldÄ±ÄŸÄ±m durumlar oldu. AÃ§Ä±klamalÄ± cevaplar yayÄ±mlanÄ±rsa eksiklerimizi daha iyi gÃ¶rebiliriz. Herkesin emeÄŸine saÄŸlÄ±k.1 month ago 2 people like this.Like ReportReply",
    "->  Ä°lk sÄ±navÄ±mÄ±n olduÄŸunu gÃ¶z Ã¶nÃ¼nde bulundurduÄŸumda puanÄ±m beni tatmin etti. Eksikliklerimi gÃ¶rme fÄ±rsatÄ±m oldu, emeÄŸiniz iÃ§in Ã§ok teÅŸekkÃ¼rler..",
    "->  Tamamen mantÄ±ÄŸÄ±n oturup oturmamasÄ± ile ilgili gÃ¶rÃ¼ndÃ¼ sÄ±nav. BazÄ± netleÅŸmeyen yerler vardÄ±, sonuÃ§ da 50 gÃ¶steriyor bunu. - Soru-cevaplar ilk haftada faydalÄ± oldu. AyrÄ±ca mentorlar da faydalÄ± linkler verdi. Acaba sabit baÅŸlÄ±klardan birinin iÃ§eriÄŸine haftalÄ±k konularla ilgili mentorlarÄ±n Ã¶nerdiÄŸi linklerin bir listesi olabilir mi? (Hyperparameters... Training, test, validation sets... vb baÅŸlÄ±klarla ilgili blog, video gibi).",
    "->  Hep birlikte bu topluluÄŸu daha iyi yerlere getireceÄŸimize inanÄ±yorum Ã§alÄ±ÅŸmalarÄ±nÄ±z Ã§ok gÃ¼zel ve taktir ediyorum. Bizim de katkÄ±mÄ±z olursa ilerleyen dÃ¶nemde ne mutlu bizlere..",
    " ->  GerÃ§ekten sÄ±nav o haftaki izlediÄŸimiz konular ile alakalÄ±, mantÄ±ÄŸÄ±nÄ± anlayÄ±p anlamadÄ±ÄŸÄ±mÄ±zÄ± Ã¶lÃ§Ã¼yordu. Ben Ã§ok memnun kaldÄ±m tekrardan teÅŸekkÃ¼rler. Hep birlikte daha iyiye..",
    "->  Merhaba, sÄ±navÄ± henÃ¼z bitirdim. Konulara hakim olduÄŸumu dÃ¼ÅŸÃ¼nÃ¼yordum ama hÄ±zlÄ±ca Ã§Ã¶zmeye Ã§alÄ±ÅŸÄ±nca Ã¼st Ã¼ste dikkatsizce hatalar yapmÄ±ÅŸÄ±m. AldÄ±ÄŸÄ±m sonuÃ§tan pek tatmin olmasam da en azÄ±ndan bu durum benim iÃ§in ders oldu diyebilirim. Ä°lginiz iÃ§in teÅŸekkÃ¼rler..",
    "->  Ã–ÄŸrenmeyi Ã¶lÃ§en gÃ¼zel bir sÄ±navdÄ± hazÄ±rlayanlara teÅŸekkÃ¼r ediyorum. HatalarÄ±mÄ± gÃ¶rdÃ¼m ve ÅŸimdi eksiklerimi kapatma zamanÄ±. Haftaya daha iyi olacaÄŸÄ±mÄ± umuyorum. Ä°lgi ve alakanÄ±z iÃ§in teÅŸekkÃ¼rler..",
    " ->  Her ÅŸey iÃ§in size ve ekibinize Ã§ok teÅŸekkÃ¼rler. ????.",
    "->  AÃ§Ä±kcasÄ± her ÅŸey gÃ¼zel gidiyor, herkes sÄ±nav bilincinde ve gÃ¼zel sorular soruyorlar. AÃ§Ä±kcasÄ± beklediÄŸimden daha iyi bi ortam oluÅŸtu. Bunun iÃ§in sizlere teÅŸekkÃ¼r ederim. ğŸ™‚.",
    "->  Ä°lk hafta oldukÃ§a verimli geÃ§ti, tekrardan size ve emeÄŸi geÃ§en herkese teÅŸekkÃ¼rler..",
    "->  SÄ±navÄ±mÄ± bitirdim. Bu sÄ±nav bana hatalarÄ±mÄ± ve eksikliklerimi gÃ¶rmemi saÄŸladÄ±. Eksiklerimi gÃ¶rerek hem bir sonra ki sÄ±nava daha iyi hazÄ±rlanacaÄŸÄ±ma hem de bilginin Ã¼zerine bilgi katarak kendime geliÅŸtirmeye Ã§alÄ±ÅŸacaÄŸÄ±m. Emekleriniz iÃ§in TeÅŸekkÃ¼rler.",
    "->  SÄ±navla bu hafta Ã§alÄ±ÅŸtÄ±ÄŸÄ±m videolarÄ± ne kadar kavradÄ±ÄŸÄ±mÄ± anladÄ±m.Bize sunduÄŸunuz program iÃ§in teÅŸekkÃ¼rler..",
    "->  Hocam sÄ±navÄ±m biraz kÃ¶tÃ¼ geÃ§ti moralim bozuldu ama eksikliklerimi de gÃ¶rdÃ¼m. Bir dahakine umuyorum ki daha iyi olacak. AyrÄ±ca bize bÃ¶yle bir fÄ±rsat verdiÄŸiniz iÃ§in ne kadar teÅŸekkÃ¼r etsek az. Sevgiler ????.",
    "->  Galiba bazÄ± konularda anladÄ±ÄŸÄ±mÄ± zannederken bu yaptÄ±ÄŸÄ±nÄ±z test sayesinde yeteri kadar anlamadÄ±ÄŸÄ±mÄ± gÃ¶rdÃ¼m ve gerÃ§ekten gÃ¼zel bir baÅŸlangÄ±Ã§ oldu iÅŸin ciddiyetini kavramak adÄ±na..",
    "->  GÃ¼zel sorulardÄ±! ğŸ™‚.",
    "-> Testi tamamladÄ±m. BazÄ± yanlÄ±ÅŸlarÄ±m oldu ama eksiklerimi gÃ¶rmÃ¼ÅŸ oldum. Ä°lk hafta gayet verimli geÃ§ti. Her ÅŸey iÃ§in teÅŸekkÃ¼rler:D.",
    "->  Ã‡ok teÅŸekkÃ¼ler hocam ğŸ™‚.",
    "->  Hocam merhaba, sÄ±navdaki bazÄ± sorular kurstaki anlatÄ±lanlarla Ã§Ã¶zÃ¼lemeyecek gibiydi bence. Ek bir kaynaÄŸa ihtiyacÄ±mÄ±z var mÄ±?1 month ago 8 people like this.Like ReportReply",
    "->  SÄ±navlarÄ±m bitti????tekrar etmemize gÃ¶zden kaÃ§Ä±rdÄ±klarÄ±mÄ±za tekrar bakmaya vesile oldu TeÅŸekkÃ¼r ederiz.",
    "->  Ben de morali bozulanlardanÄ±m. Ã–ÄŸrenirken bilgiyi daha fazla yorumlayarak devam etmek gerektiÄŸinin farkÄ±na vardÄ±m.",
    "-> Bende de sÄ±nav bittikten sonra ufak bir moral bozulmasÄ± oldu, kendimi toparladÄ±ÄŸÄ±mÄ± dÃ¼ÅŸÃ¼nÃ¼yorum. AslÄ±nda, gÃ¶zÃ¼mÃ¼zden kaÃ§an onca ÅŸey olduÄŸunu fark ettim. DÃ¼zeltmek iÃ§in elimden gelen gayreti gÃ¶stereceÄŸime inanÄ±yorum. Her ne kadar gÃ¶nlÃ¼m bu aldÄ±ÄŸÄ±m sonuca razÄ± gelmese de, sÃ¼reÃ§ hala devam ediyor. Herkese tekrar baÅŸarÄ±lar ve iyi Ã§alÄ±ÅŸmalar diliyorum..",
    "->  EmeÄŸi geÃ§en herkese teÅŸekkÃ¼r ederim. Kodsal sorular yerine iÅŸin temelini,mantÄ±ÄŸÄ±nÄ± Ã¶lÃ§meye dair sorular olmasÄ± Ã§ok iyi dÃ¼ÅŸÃ¼nÃ¼lmÃ¼ÅŸ..",
    "-> HaftalÄ±k ilerlememizin performansÄ±nÄ±n Ã¶lÃ§Ã¼lmesi adÄ±na nitelikli bir sÄ±nav olmuÅŸ. Testi tamamladÄ±m, bir haftalÄ±k artÄ± ve eksilerimi gÃ¶rmemi saÄŸladÄ±. EmeÄŸi geÃ§en herkese teÅŸekkÃ¼rler..",
    "->  Biraz heyecana geldi test. Hackathon'a katÄ±lmÄ±ÅŸtÄ±m. YarÄ±ÅŸmaya dalÄ±nca sÄ±nav gÃ¼nÃ¼ olduÄŸu tamamen kafamdan uÃ§muÅŸ. ÅÃ¼kÃ¼r ucundan yakaladÄ±m ama tamamen doÄŸru yapma hedefim vardÄ± o gerÃ§ekleÅŸemedi. Haftaya inÅŸallah ğŸ™‚.",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba arkadaÅŸlar, bugÃ¼nkÃ¼ sÄ±nav iÃ§in gÃ¶nderilecek link henÃ¼z mailime gelmedi. BaÅŸka mail gelmeyen arkadaÅŸlar var mÄ±?",
"comment": [
    "",
    "-> Mail gÃ¶nderildi.Mailinizi kayÄ±t etmeniz gerekiyordu.https://docs.google.com/spreadsheets/d/1IBfHARyiyb1btoA1ikraoZlFzBIIudLjyL_zjgaRrJs/edit#gid=0",
    "->  KaydetmiÅŸtim dÃ¼n. o yÃ¼zden sordum sorun mu var acaba diye:) Cevap iÃ§in teÅŸekkrÃ¼ler -> . PaylaÅŸtÄ±ÄŸÄ±n link Ã¼zerinden sÄ±navÄ± yapabilir miyim yoksa maile gelecek linki beklemem mi gerekiyor acaba?.",
    "-> Maili buraya kayÄ±t etmen gerekiyor.Burdan maillere toplu olarak gÃ¶nderliliyor.Bir sorun yaÅŸarsan adminlerle konuÅŸ hallederler.BaÅŸarÄ±lar..",
    "->  DÃ¼n bu sheete kaydetmiÅŸtim mailimi sanÄ±rÄ±m biraz daha beklemem gerkiyor. TeÅŸekkÃ¼r ederim bilgiler iÃ§in1 month ago 3 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Veri setinden veri setine deÄŸiÅŸtiÄŸini bilmekle beraber en iyi epoch, learning rate ve batch size kombinasyonu (iÅŸlem hÄ±zÄ±nÄ± da gÃ¶zeterek) learning rate ve batch size'Ä± mÃ¼mkÃ¼n mertebe dÃ¼ÅŸÃ¼k tutup epoch sayÄ±sÄ±nÄ± yÃ¼ksek tutmak mÄ±dÄ±r? Ã‡Ã¼nkÃ¼ anladÄ±ÄŸÄ±m kadarÄ±yla batch sayÄ±sÄ±nÄ± ne kadar kÃ¼Ã§Ã¼ltÃ¼rsek ana Ã¶rneklemimizi o denli kÃ¼Ã§Ã¼k parÃ§alara ayÄ±rÄ±yor ve her seferinde learning rate'i kullanarak aÄŸÄ±rlÄ±klarÄ± update ediyor. Bu durum da iÅŸimize gelmeli.  Epoch tarafÄ±ndan bakacak olursak da, 1 epoch sanÄ±yorum ki tÃ¼m mini batchlerimizin iÅŸlenmesi anlamÄ±na geliyor (Yani ana verideki Ã¶rneklem sayÄ±sÄ±/mini batchteki Ã¶rneklem sayÄ±sÄ± kadar iterasyon). Bu sayÄ±yÄ± ne kadar yÃ¼ksek tutarsak da defalarca kez veriyi iÅŸleriz ve sonucunda dÃ¼ÅŸÃ¼k bir MSE deÄŸerine ulaÅŸÄ±rÄ±z.  First Step with TF dersinin 'Linear Regression with a Real Dataset' egzersizinde learning rate'i dÃ¼ÅŸÃ¼rÃ¼rken epoch ve batchâ€¦ <a class=\"ps-stream-post-more ps-js-content-excerpt-toggle\" href=\"#\">Read more</a></div><div class=\"ps-js-content-full\" style=\"\">Veri setinden veri setine deÄŸiÅŸtiÄŸini bilmekle beraber en iyi epoch, learning rate ve batch size kombinasyonu (iÅŸlem hÄ±zÄ±nÄ± da gÃ¶zeterek) learning rate ve batch size'Ä± mÃ¼mkÃ¼n mertebe dÃ¼ÅŸÃ¼k tutup epoch sayÄ±sÄ±nÄ± yÃ¼ksek tutmak mÄ±dÄ±r? Ã‡Ã¼nkÃ¼ anladÄ±ÄŸÄ±m kadarÄ±yla batch sayÄ±sÄ±nÄ± ne kadar kÃ¼Ã§Ã¼ltÃ¼rsek ana Ã¶rneklemimizi o denli kÃ¼Ã§Ã¼k parÃ§alara ayÄ±rÄ±yor ve her seferinde learning rate'i kullanarak aÄŸÄ±rlÄ±klarÄ± update ediyor. Bu durum da iÅŸimize gelmeli.  Epoch tarafÄ±ndan bakacak olursak da, 1 epoch sanÄ±yorum ki tÃ¼m mini batchlerimizin iÅŸlenmesi anlamÄ±na geliyor (Yani ana verideki Ã¶rneklem sayÄ±sÄ±/mini batchteki Ã¶rneklem sayÄ±sÄ± kadar iterasyon). Bu sayÄ±yÄ± ne kadar yÃ¼ksek tutarsak da defalarca kez veriyi iÅŸleriz ve sonucunda dÃ¼ÅŸÃ¼k bir MSE deÄŸerine ulaÅŸÄ±rÄ±z.  First Step with TF dersinin 'Linear Regression with a Real Dataset' egzersizinde learning rate'i dÃ¼ÅŸÃ¼rÃ¼rken epoch ve batch size'Ä± bÃ¼yÃ¼tmenin Ã§oÄŸunlukla en iyi kombinasyon olduÄŸu yazÄ±yor ancak ben batch size kÄ±smÄ±na katÄ±lmÄ±yorum.</div></div>",
"comment": [
    "",
    "-> Merhaba,Batch size'Ä± Ã§ok kÃ¼Ã§Ã¼k bir deÄŸere ayarlamak kararsÄ±zlÄ±ÄŸa neden olabilir. Ã–ncelikle batch size'Ä± bÃ¼yÃ¼k bir deÄŸere ayarlayÄ±p azalmayÄ± gÃ¶rene kadar ufak ufak kÃ¼Ã§Ã¼ltmeniz daha iyi olacaktÄ±r. Batch size'Ä± bÃ¼yÃ¼k bir deÄŸer almamÄ±zdaki dezavantaj memoryde kaplayacaÄŸÄ± yer ve zaman karmaÅŸÄ±klÄ±ÄŸÄ±dÄ±r(complexity.) AvantajÄ± ise bÃ¼yÃ¼k bir batch size'da daha doÄŸru ve tutarlÄ± eÄŸimler elde edersiniz Ã§Ã¼nkÃ¼ daha bÃ¼yÃ¼k bir veri grubu (batch sayÄ±sÄ± kadar veri) iÃ§indeki kaybÄ±mÄ±zÄ± optimize ediyoruz. Yani batch size'Ä±nÄ±z dÃ¼ÅŸÃ¼kken daha sÄ±k gÃ¼ncelleme yapÄ±yor olsanÄ±z da bu sÄ±klÄ±k optimizasyonun daha iyi yapÄ±lacaÄŸÄ± anlamÄ±na gelmez. Bunu bir Ã§ok kÃ¶tÃ¼ gÃ¼ncelleme vs Ã§ok az iyi gÃ¼ncelleme olarak dÃ¼ÅŸÃ¼nebilirsiniz. En ekstrem Ã¶rnekte zaten batch_size training size'a eÅŸit olacak kadar bÃ¼yÃ¼ktÃ¼r. Kaynak olarak: https://forums.fast.ai/t/disadvantages-of-using-very-large-batch-size/29177/3 linkini verebilirim. Ä°yi Ã§alÄ±ÅŸmalar dilerim ğŸ™‚",
    "Disadvantages of using very large batch sizeforums.fast.aiI donâ€™t think itâ€™s as simple as that. Realize that in your stochastic gradient descent (SGD), the gradient of the loss function is computed over the entire batch. If you have a very small batch size, your gradient will really be all over the place and pretty random, because learning will be image by image.â€¦1 month ago 6 people like this.Like ReportReply",
    " "
]
},

{
"question_isim": "-> ",
"quest": "Tekrar merhabalar,  YarÄ±nki sÄ±nava katÄ±lmak isteyen arkadaÅŸlar aÅŸaÄŸÄ±da paylaÅŸtÄ±ÄŸÄ±m dokumana gÃ¼ncel mail adreslerini yazabilir mi? Sabah maillerinize ilgili linki gÃ¶ndermiÅŸ olacaÄŸÄ±m.  <a class=\"ps-media-link\" href=\"https://docs.google.com/spreadsheets/d/1IBfHARyiyb1btoA1ikraoZlFzBIIudLjyL_zjgaRrJs/edit?usp=sharing\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">https://docs.google.com/spreadsheets/d/1IBfHARyiyb1btoA1ikraoZlFzBIIudLjyL_zjgaRrJs/edit?usp=sharing</a>  TeÅŸekkÃ¼rler!",
"comment": [
    "",
    " ->  SÄ±nava tÃ¼m gÃ¼n boyunca eriÅŸebilir miyiz? YarÄ±n saat 23.59'a kadar gÃ¶nderme ÅŸansÄ±mÄ±z var mÄ± acaba? BazÄ±larÄ±mÄ±zÄ±n sÃ¼rekli internet internet baÄŸlantÄ±sÄ± yok, mesela benim..",
    "->   ->  AslÄ± hanÄ±m aÅŸaÄŸÄ±daki gÃ¶nderide belirtmiÅŸ: \" SÄ±nav belirli bir saat aralÄ±ÄŸÄ±nda olmayacak, sabah mail adreslerinize bir link gÃ¶ndereceÄŸim. YarÄ±n sabah 10 ile akÅŸam 10 arasÄ±nda istediÄŸiniz saatte girebilirsiniz. Linke girdiÄŸinizde 45 dk sÃ¼reniz ve timer olacak, sÃ¼re bittikten sonra tekrar sisteme girme ÅŸansÄ±nÄ±z olmayacaktÄ±r. \" Pinned postlarÄ± takip etsen gÃ¶rebilirsin dostum, iyi geceler.1 month ago 2 people like this.Like ReportReply",
    "->  Merhaba, sÄ±nav esnasÄ±nda ses ve/veya gÃ¶rÃ¼ntÃ¼ alÄ±nacak mÄ±? Bir kez giriÅŸ hakkÄ±mÄ±z olacaÄŸÄ±ndan bunu Ã¶nceden bilmem daha faydalÄ± olur diye dÃ¼ÅŸÃ¼nÃ¼yorum. TeÅŸekkÃ¼rler.",
    "->  ->  yok hayÄ±r, bÃ¶yle bir veri almÄ±yoruz ğŸ™‚.",
    " ->  merhabalar, dÃ¼n takip edemediÄŸim iÃ§in bu mesajÄ±nÄ±za cevap veremedim. dolayÄ±sÄ±yla mail adresini posta giremedim. ÅŸuan gÃ¼ncel mail adresini yazdÄ±ÄŸÄ±m taktirde sÄ±nav linkini alabilecek miyim? yoksa bir sonra ki paylaÅŸÄ±mÄ±nÄ±z altÄ±na mÄ± mailimi bÄ±rakayÄ±m..",
    "->  merhabalar, ben bu postu gÃ¶remedim:/ Kursu bitirdim, hala sÄ±nava katÄ±lma hakkÄ±m var mÄ±?.",
    "-> Merhaba, gdoc'a eposta adresimi suan (alfabetik sirayi izleyerek ilgili yere) girdim..",
    "->  Selamlar. Bu postu sÄ±navÄ± tamamladÄ±ktan sonra gÃ¶rdÃ¼m. Ä°smimi ekledim, sÄ±navÄ± tekrarlamama gerek var mÄ±?1 month ago 2 people like this.Like ReportReply",
    "->  ->  sÄ±navÄ± tamamladÄ±ysanÄ±z gerek yok, teÅŸekkÃ¼rler ğŸ™‚.",
    "->  ->  TeÅŸekkÃ¼r ederim..",
    " ->  Merhabalar, ben de maili alamamÄ±ÅŸtÄ±m dokÃ¼mana ekledim..",
    " -> Merhabalar, benim bilgilerim bulunmuyor dokumana ekledim..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar,  Validation and Test Sets Collab kÄ±smÄ±nda task2 de train ve validation setindeki verilere yeterince benzemiyor diyor ve head ile incelenmesini sÃ¶ylÃ¼yor.Tam olarak benzememeden kastÄ± ne ve de bu sette bunu nasÄ±l gÃ¶zlemleyip evet benzemiyor diyebilirim?  TeÅŸekkÃ¼rler:)",
"comment": [
    "",
    "->  dataframe ismi ile birlikte .head(1000) diyerek kullanÄ±rsan ilk 1000 veri geliyor Ã¶rneÄŸin. Burada verilerin hepsinin farklÄ± olduÄŸunu gÃ¶zlemliyoruz hepsi bu ğŸ™‚1 month ago 2 people like this.Like ReportReply",
    " -> Merhaba Buse,Ã‡Ã¶zÃ¼m kÄ±smÄ±na baktÄ±ÄŸÄ±nda, 0-4 ile 25-29 arasÄ±ndaki deÄŸerleri incelemeni sÃ¶ylÃ¼yor. Kodu yazÄ±p baktÄ±ÄŸÄ±mÄ±zda, bazÄ± farklÄ± ve aÅŸÄ±rÄ± deÄŸerler gÃ¶rebiliriz. Birisi 1000-7000 arasÄ± deÄŸiÅŸirken, diÄŸeri 700-2000 arasÄ± deÄŸiÅŸmekte.1 month ago 3 people like this.Like ReportReply",
    " -> Merhaba, sanÄ±rÄ±m \"validation seti train setine yeterince benzemiyor yani rastgele daÄŸÄ±lmamÄ±ÅŸ\" bunu keÅŸfetmemizi bekliyor Task 2. Longitude deÄŸerine bakarsak verinin sÄ±ralandÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼yoruz.1 month ago 3 people like this.Like ReportReply",
    "->  SanÄ±rÄ±m keÅŸfetmemizi istediÄŸi ÅŸey train setindeki verilerin longitude deÄŸerlerine gÃ¶re sÄ±ralÄ± olmasÄ±. Bu durum veri setini train ve validation olarak ayÄ±rÄ±rken, validation setinin sadece belirli bir aralÄ±ktaki longitude deÄŸerlerine iÃ§ermesine sebep oluyor. Bu durumun problem olmasÄ±nÄ±n asÄ±l sebebi de longitude deÄŸerinin median_house_value deÄŸerini etkilemesi olduÄŸunu sÃ¶ylÃ¼yor colab'deki aÃ§Ä±klama. Bu etkiyi yani feature'larÄ±n birbirleri arasÄ±ndaki iliÅŸkinin derecesini bir Ã¶nceki exercise'larda correlation matrix ile gÃ¶rebileceÄŸimizi Ã¶ÄŸrenmiÅŸtik fakat corr matrisine gÃ¶re aralarÄ±nda(median_house_value ve longitude) bir iliÅŸki olmamasÄ± gerekiyor. TeÄŸit etmek iÃ§in datayÄ± incelediÄŸimde de aralarÄ±nda bir iliÅŸki gÃ¶remiyorum. Bu durumun sebebini anlayamadÄ±m, birisi aydÄ±nlatabilirse sevinirim, ÅŸimdiden teÅŸekkÃ¼rler..",
    " "
]
},
{
"question_isim": "->",
"quest": "Son aÅŸamada (Validation Set)  Åimdi ilk Ã¶nce training set ile veri eÄŸitiliyor, ilk epoch sonunda test ediliyor deÄŸil mi? eÄŸer iyi bir tahmin yoksa, ikinci epoch'a geÃ§iyor sonra test set ile yine test ediliyor. Bu yÃ¼zden overfitting olmamasÄ± iÃ§in Validation Set kullanÄ±yoruz. Buraya kadar doÄŸru anlamÄ±ÅŸ mÄ±yÄ±m? Bir diÄŸer sorumda Training Set iÃ§inde Test Set verileri yok, ayrÄ± yani bu veriler, overfitting nasÄ±l oluyor? BurayÄ± tam anlayamadÄ±m. TeÅŸekkÃ¼rler:)",
"comment": [
    "",
    "->  Benim anladÄ±ÄŸÄ±m training setinden verilerimizi eÄŸittikten sonra her aÅŸamada test setteki veriler ile test edince modelimiz verileri ezberlemesi duruma overfitting oldu deniliyor. Modelimiz overfitting olduÄŸunda ise yeni bir veri eklediÄŸinde dÃ¼zgÃ¼n bir ÅŸekilde Ã§alÄ±ÅŸamÄ±yabiliyor. Bu yÃ¼zden bu durumu engelleyebilmek iÃ§in modelimizi eÄŸitirken validation seti kullanarak hyperparameterleri ayarlÄ±yoruz ve modelimizin hazÄ±r olduÄŸuna karar verdiÄŸimizde son aÅŸama olan test iÃ§in ayÄ±rdÄ±ÄŸÄ±mÄ±z test seti ile modelimizi test ediyoruz.1 month ago 3 people like this.Like ReportReply",
    "->  yani modelimizi overfitting olmamasÄ± iÃ§in validation seti kullanarak test ediyoruz en son aÅŸamada test seti kullanarak modelimizin iyi olup olmadÄ±ÄŸÄ±nÄ± belirliyoruz. UmarÄ±m daha Ã§ok kafanÄ± karÄ±ÅŸtÄ±rmamÄ±ÅŸÄ±mdÄ±r1 month ago 2 people like this.Like ReportReply",
    " ->  Merhaba, https://medium.com/data-science-tr/overfitting-underfitting-cross-validation-b47dfda0cf4e bu sitede overfitting durumu Ã§ok basit bir dille anlatÄ±lmÄ±ÅŸ belki faydasÄ± olabilir",
    "Makine Ã–ÄŸrenmesi Dersleri 8: Cross Validationmedium.comOverfitting (High Variance)1 month ago 5 people like this.Like ReportReply",
    "-> Ã‡ok teÅŸekkÃ¼r ederim cevaplarÄ±nÄ±z iÃ§in.",
    "->  ÅÃ¶yle ki eÄŸitim setinde test verileri bulunmuyor ama eÄŸitme iÅŸleminde hiperparametreleri kullanarak test setindeki verilerin doÄŸruluÄŸunu iyileÅŸtirmek iÃ§in kullandÄ±ÄŸÄ±mÄ±zdan dolayÄ± model sadece test verileri iÃ§in iyi deÄŸer vermiÅŸ oluyor. Yeni veri gelince patlÄ±yor..",
    "->  Verini Ã¼Ã§e bÃ¶lÃ¼yorsun, eÄŸitim, deÄŸerlendirme ve test. DeÄŸerlendirme de aslÄ±nda bir test seti. Verini batch'ler halinde eÄŸittin, her batch'te deÄŸerlendirme setindeki verilerle hata hesaplayÄ±p hiperparametrelerini gÃ¼ncelliyorsun. Yani bu her epoch sonu deÄŸil her batch sonu olan bir ÅŸey. Verini eÄŸittikten sonra hiperparametrelerini gÃ¼ncellediÄŸin deÄŸerlendirme setiyle kontrol edersen modelinin Ã§ok iyi bir performans sergilediÄŸini gÃ¶rÃ¼rsÃ¼n, ama aslÄ±nda modelin kendi hatasÄ±na baka baka deÄŸerlendirme setini ezberlemiÅŸtir, biz buna overfitting diyoruz, yani modelin Ã§ok iyi gibi gÃ¶zÃ¼kÃ¼yor da aslÄ±nda deÄŸil. O yÃ¼zden ikinci bir test seti kullanÄ±yoruz test etmek iÃ§in.1 month ago 9 people like this.Like ReportReply",
    "-> Cevaplar iÃ§in Ã§ok teÅŸekkÃ¼r ederim. Åimdi Ã§ok daha iyi anladÄ±mmm...",
    " "
]
},
{
"question_isim": " -> ",
"quest": "Merhaba. Benim bir sorum olacaktÄ±. Åimdi biz veri setini kÃ¼Ã§Ã¼k gruplara ayÄ±rarak Ã¶ÄŸrenme iÅŸlemini bu kÃ¼Ã§Ã¼k gruplar yani mini-batchler Ã¼zerinden devam ettiriyoruz. Peki bu mini-batchler Ã¼zerinden giderek bulduÄŸumuz cost function'Ä± ve bu cost'u minimize etmek iÃ§in kullandÄ±ÄŸÄ±mÄ±z gradient descent batchlere gÃ¶re deÄŸiÅŸiklik mi gÃ¶steriyor. Yani her bir batch iÃ§in ayrÄ± bir cost function mÄ± buluyoruz o kÄ±smÄ± tam anlamadÄ±m. AnlamadÄ±ÄŸÄ±m iÃ§in de karÄ±ÅŸtÄ±rmÄ±ÅŸ olabilirim ???? DÃ¼zeltilmeye aÃ§Ä±ÄŸÄ±m, vereceÄŸiniz cevaplar iÃ§in ÅŸimdiden teÅŸekkÃ¼r ediyorum. ????",
"comment": [
    "",
    "->  Merhaba, evet mini-batch iÃ§in belirlediÄŸimiz sayÄ±da Ã¶rneÄŸi kullanarak loss'u (yani gerÃ§ek sonuÃ§lardan ne kadar uzak olduÄŸumuzu) hesaplÄ±yoruz ve parametrelerimizi (W, b) mini-batch Ã¼zerinde bulduÄŸumuz loss'a gÃ¶re gÃ¼ncelliyoruz. SeÃ§tiÄŸimiz farklÄ± Ã¶rnekler, farklÄ± feature deÄŸerlerine sahip olduÄŸu iÃ§in, mini-batch'lerimizin loss'larÄ± da doÄŸal olarak farklÄ± olacaktÄ±r. UmarÄ±m doÄŸru anladÄ±m soruyu ğŸ˜€1 month ago 3 people like this.Like ReportReply",
    " ->  TeÅŸekkÃ¼rler Mert cevabÄ±n iÃ§in. Peki genel olarak modelden dÃ¶necek olan weight ve bias, mini-batchlerden hesaplanan weight ve biaslarÄ±n ortalamasÄ± olarak mÄ± olur? Yani nasÄ±l formÃ¼lize edilir? Bunun da yanÄ±tÄ±nÄ± verebilirsen Ã§ok iyi olur ğŸ™‚.",
    "-> Sorunu tam olarak anlamadÄ±m ama baÅŸtan itibaren kendimce mantÄ±ÄŸÄ±nÄ± aÃ§Ä±klamaya Ã§alÄ±ÅŸayÄ±m. Linear Regression Ã¼zerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±zÄ± dÃ¼ÅŸÃ¼nelim. Ä°lk olarak w ve b deÄŸerlerimizi 0'a eÅŸitliyoruz. y'(tahminimiz) = w.x + b gibi bir formÃ¼lle ifade ediliyor. X ise feature vektÃ¶rÃ¼mÃ¼z, yani ev fiyatÄ± tahmin etmek istiyorsak feature'larÄ±mÄ±z x = [oda sayÄ±sÄ±, metrekare, evin yaÅŸÄ±, vb.] , ardÄ±ndan bu y' deÄŸerimizi hesapladÄ±ÄŸÄ±mÄ±zda fotoÄŸrafta olduÄŸu gibi bir doÄŸru tahmin etmiÅŸ oluyoruz. DoÄŸrumuzun Ã¶rneklerimizin bulunduÄŸu noktalara gÃ¶re olan uzaklÄ±ÄŸÄ± loss deÄŸerimizi ifade ediyor. Ã–rneÄŸin mini-batch-size=5 iÃ§in kullandÄ±ÄŸÄ±mÄ±z Ã¶rneklerin rastgele Ã§ok lÃ¼ks evlerden denk geldiÄŸini dÃ¼ÅŸÃ¼nelim. Fakat ortalama olarak o mahalledeki evler, lÃ¼ks evler kadar pahalÄ± olmayacaÄŸÄ±ndan Ã§izgimiz noktalarÄ±mÄ±zla alakasÄ±z Ã§Ä±kacak ve loss yÃ¼ksek Ã§Ä±kacak. Sonraki 5 Ã¶rneÄŸimize geÃ§tiÄŸimizde ise ortalama fiyatlara sahip evler geldiÄŸini dÃ¼ÅŸÃ¼nelim. Bu sefer bu evler iÃ§in yaptÄ±ÄŸÄ±mÄ±z tahminler gerÃ§ek sonuÃ§larÄ±mÄ±za yakÄ±n olduÄŸundan Ã§izgiyi verilerimize daha uygun ÅŸekilde Ã§izebileceÄŸiz. Bu ÅŸekilde mini-batch'ler Ã¼zerinde iÅŸlem yaparak Ã§izgimizi, noktalardan en az uzak olacak ÅŸekilde Ã§izmeye Ã§alÄ±ÅŸÄ±yoruz. Bu kursta bahsedilmemiÅŸ terimler kullandÄ±ysam ve anlaÅŸÄ±lmadÄ±ysa Ã¼zgÃ¼nÃ¼m, aÃ§Ä±klamaya Ã§alÄ±ÅŸtÄ±m, umarÄ±m faydasÄ± olur :)1 month ago 6 people like this.Like ReportReply",
    "->  ->  AklÄ±ma cevabÄ±nÄ±zÄ± okuyunca bir soru geldi. Batch'in alacaÄŸÄ± veriler rastgele seÃ§iliyor dediÄŸiniz gibi. Bu rasgelelik seÃ§ilen Ã¶ÄŸenin bir daha seÃ§ilmemesi Ã¼zerine mi yoksa rastgele veri Ã§ektiÄŸimiz havuza her zaman veriseti iÃ§erisindeki tÃ¼m veriler dahil oluyor mu?.",
    "->  ->  Bizim ÅŸu ana kadar kursta ilerlediÄŸimiz kadarÄ±yla epoch kavramÄ±nÄ±n aÃ§Ä±klanÄ±ÅŸÄ± ve genel olarak bilinen yÃ¶ntem, seÃ§ilen Ã¶rneÄŸin tekrar seÃ§ilmemesi diye biliyorum. Fakat yapay sinir aÄŸlarÄ± uygulamalarÄ±nda seÃ§ilen Ã¶rneÄŸin tekrar havuza geri atÄ±lmasÄ± kullanÄ±lÄ±yormuÅŸ. With replacement - without replacement ÅŸeklinde geÃ§iyor. AttÄ±ÄŸÄ±m linkte bahsettiÄŸin durum ile alakalÄ± bir deÄŸerlendirme var.https://stats.stackexchange.com/questions/235844/should-training-samples-randomly-drawn-for-mini-batch-training-neural-nets-be-dr",
    "Should training samples randomly drawn for mini-batch training neural nets be drawn without replacement?stats.stackexchange.comWe define an epoch as having gone through the entirety of all available training samples, and the mini-batch size as the number of samples over which we average to find the updates to weights/biases1 month ago 2 people like this.Like ReportReply",
    "->  ->  AnladÄ±m teÅŸekkÃ¼r ederim..",
        ->  ->  Her mini-batch iÃ§in bir y' tahmin ediyoruz. yani Ã¶rneklere en az uzak olucak sekilde Ã§izgi Ã§iziyoruz. nihai Ã§izgiyi, nasÄ±l elde ediyoruz? elimizde bir Ã§ok y' olucak. mesela arasÄ±ndaki en iyisini mi alÄ±yoruz? yoksa bÃ¼tÃ¼n y' alÄ±p ortalamasÄ±nÄ± alarak en iyi tahmin edecek modeli mi elde ediyoruz? yada baÅŸka birÅŸey mi.",
    "->  ebubekir ceylan y' dediÄŸimiz ÅŸeyler tahmin ettiÄŸimiz deÄŸerler bunun modeli Ã§izmekle dolaylÄ± bir iliÅŸkisi var. Modelin doÄŸruluÄŸunu Ã¶lÃ§mek iÃ§in Cost Functiondan kayÄ±p deÄŸeri hesaplamamÄ±za yarÄ±yor. Bizim batchler sonunda elde ettiklerimiz bias ve weight deÄŸerleri. Ki bu da birden fazla olmuyor bir denklemdeki aÄŸÄ±rlÄ±klarÄ± deÄŸiÅŸtirerek kaybÄ± azaltmaya Ã§alÄ±ÅŸÄ±yoruz. Ama tek bir denklem var elimizde. Ortalama vs sÃ¶z konusu deÄŸil.1 month ago 2 people like this.Like ReportReply",
    "->  ebubekir ceylan Nihai Ã§izgi, en son elde ettiÄŸimiz weight ve bias deÄŸerlerini kullanarak Ã§izdiÄŸimiz Ã§izgi oluyor. Ã–nceki Ã§izgileri sadece hatamÄ±zÄ± hesaplayÄ±p w ve bias deÄŸerlerimizi gÃ¼ncellemek iÃ§in kullanÄ±yoruz. Zaten mini-batch sayÄ±sÄ± Ã§ok Ã§ok kÃ¼Ã§Ã¼k belirlemediysek, her adÄ±mÄ±mÄ±zda daha iyi bir Ã§izgi Ã§izmemiz yani daha az cost'a sahip olmamÄ±z beklenir..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Herkese merhaba, YarÄ±n sabah 9.30 da bu haftaki quiz ile ilgili detaylÄ± bilgileri vereceÄŸim.  Sabah 10:00'da baÅŸlayÄ±p akÅŸam 22:00'ye kadar vaktiniz olacak. SÄ±nava sadece 1 kere katÄ±lma hakkÄ±nÄ±z ve bir kere baÅŸladÄ±ktan sonra sistemden Ã§Ä±kÄ±p tekrar girme hakkÄ±nÄ±z olmayacak. 10 soruluk ingilizce bir test formatÄ±nda olacak. Åimdiden herkese baÅŸarÄ±lar, bol ÅŸans ????",
"comment": [
    "",
    "->  TeÅŸekkÃ¼rler bilgilendirme iÃ§in.Ä°nternet baÄŸlantÄ±sÄ±nda bir sorun olursa peki?.",
    "->  ->  sistemimizde bir takÄ±m Ã§alÄ±ÅŸmalar var buaralar, o sebeple ara ara takÄ±lmalar yaÅŸÄ±yoruz. En kÄ±sa zamanda normal akÄ±ÅŸÄ±na dÃ¶necek ???? AÅŸaÄŸÄ±da da belirttiÄŸim gibi farklÄ± bir platform Ã¼zerinden sÄ±navÄ± gerÃ§ekleÅŸtireceksiniz, ÅŸimdiden baÅŸarÄ±lar!.",
    "->  Merhaba, teÅŸekkÃ¼rler..",
    "->  Ã‡ok teÅŸekkÃ¼rler. BugÃ¼n ara ara bu platforma girdim fakat ya hata alÄ±yorum ya da donma oluyor. YarÄ±n da benzer bir sorun olursa diye yazmak istedim. SÄ±navÄ± baÄŸlantÄ± yÃ¶nlendirmesiyle yapacaksÄ±nÄ±z dimi?1 month ago 2 people like this.Like ReportReply",
    "->  ->  Merhaba aynÄ± sorun bende de var. 502 Bad Gateway veya Database connection hatasÄ± alÄ±yorum dÃ¼nden beri birkaÃ§ kez. UmarÄ±m sÄ±nav baÄŸlantÄ± yÃ¶nlendirmesi ile olur.1 month ago 2 people like this.Like ReportReply",
    "->  ->  sistemimizde bir takÄ±m Ã§alÄ±ÅŸmalar var buaralar, o sebeple ara ara takÄ±lmalar yaÅŸÄ±yoruz. En kÄ±sa zamanda normal akÄ±ÅŸÄ±na dÃ¶necek ğŸ™‚.",
    "->  ->  Merhaba bilgilendirme iÃ§in Ã§ok teÅŸekkÃ¼r ederim, iyi akÅŸamlar ve Ã§alÄ±ÅŸmalar dilerim ğŸ™‚.",
    "->  Tabii, sÄ±nav farklÄ± bir platform Ã¼zerinden gerÃ§ekleÅŸecek, ben ilgili yÃ¶nlendirmeyi yapacaÄŸÄ±m size yarÄ±n ğŸ˜‰1 month ago 4 people like this.Like ReportReply",
    "->  ->  Ã‡ok teÅŸekkÃ¼rler :)).",
    "-> Ã‡ok teÅŸekkÃ¼rler..",
    " -> Bilgilendirme iÃ§in teÅŸekkÃ¼rler..",
    "->  Tesekkurler..",
    "->  TeÅŸekkÃ¼rler.",
    " ->  TeÅŸekkÃ¼rler.",
    "-> TeÅŸekkÃ¼rler.",
    "-> TeÅŸekkÃ¼rler.",
    "-> TeÅŸekkÃ¼rler.",
    "-> Ã‡ok teÅŸekkÃ¼r ederim..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Validation Set kÄ±smÄ±nda oluÅŸan yeni iÅŸ akÄ±ÅŸÄ±nda validation ile en iyi modeli seÃ§in sonrasÄ±nda test setine gÃ¶re 2 kez kontrol edin diyor neden iki kez?Birde bu iÅŸ akÄ±ÅŸÄ±nÄ±n test setine daha az exposures oluÅŸturur derken ne demek istiyor anlayamadÄ±m?  TeÅŸekkÃ¼rler:)",
"comment": [
    "",
    " -> SanÄ±rÄ±m ingilizce olmasÄ±ndan Ã¶tÃ¼rÃ¼ farklÄ± anlaÅŸÄ±lÄ±yor ????Ben ÅŸÃ¶yle anlamÄ±ÅŸtÄ±m, burada bir validation set Ã¼zerinde en uygun yaklaÅŸÄ±mÄ± aldÄ±k. Bu bizim iÃ§in, Ã¶ÄŸrenim sonrasÄ±nda validation setâ€™e gÃ¶re en iyi sonuÃ§ veren yapÄ±. Bunu, test setinin Ã¼zerinde tekrar kontrol ederek, validation setâ€™e overfit olup olmadÄ±ÄŸÄ±nÄ± kontrol ediyoruz. Yani ilk check, validation set Ã¼zerinde, ikinci check ise test seti Ã¼zerinde. Double checkâ€™i bÃ¶yle anladÄ±m ben.1 month ago 3 people like this.Like ReportReply",
    " -> Exposure'dan kastÄ± da ÅŸÃ¶yle ki, Verimizi \"train-validation-test\" olarak bÃ¶lmek ile \"train-test\" ÅŸeklinde bÃ¶lmenin kÄ±yasÄ±nÄ± yapÄ±yor anladÄ±ÄŸÄ±m kadarÄ±yla. BÃ¶ylece, test Ã¼zerinde ustalaÅŸmayan yapÄ±nÄ±n doÄŸruluÄŸun, gÃ¶rseldeki yolla daha iyi gÃ¶rebiliyoruz..",
    "->  Merhaba,AnladÄ±ÄŸÄ±m kadarÄ±yla oradaki double check demesinin sebebi veriyi daha Ã¶nceden validation set ile kontrol etmemizdi yani oradaki double, test setini iki kez kontrol et demek deÄŸil ikinci kez test verisinde kontorle t demek. Az exposure kÄ±smÄ± iÃ§in validation set'i iÅŸin iÃ§ine sokmamÄ±zÄ±n amacÄ± ise, validation setin olmadÄ±ÄŸÄ± iÅŸ akÄ±ÅŸÄ±nda modeli optimize ÅŸekle ayarlamak iÃ§in model eÄŸitildikten sonra test setimizi deneyerek o anki optimumluk deÄŸerine gÃ¶re bu workflow dÃ¶ngÃ¼sÃ¼nÃ¼ sÃ¼rdÃ¼rÃ¼yordu. Validation set ise training set iÃ§inden seÃ§ileceÄŸi iÃ§in test ve train datasÄ±nÄ± ayÄ±rarak training sonrasÄ± test datasÄ±nÄ±n unseen data olarak kalmasÄ±nÄ± saÄŸlar. Yani test datasÄ±nÄ±n exposure'luÄŸu Ã¶nlenmiÅŸ olur.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 7 people like this.Like ReportReply",
    "->  OÄŸuzhan ve Fethi'nin dediÄŸi gibi validation datasÄ± ile yapÄ±lan teste ek olarak test datasÄ±yla da test edilmesi double check olmuÅŸ oluyor.Burada datamÄ±zÄ± Ã¼Ã§ farklÄ± parÃ§aya bÃ¶lmemizdeki amaÃ§ ÅŸu, train datasÄ± ile eÄŸittik ve validation datasÄ± hiperparametrelerimizi ayarladÄ±k ve en iyi modelimizi seÃ§tik. Peki bu ayarlamadan sonra ya modelimiz validation datasÄ±na overfit olduysa? Ä°ÅŸte burada test datasÄ± devreye giriyor ve bir kez daha modelimizi test etmiÅŸ oluyoruz.1 month ago 3 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": " -> uploaded 1 photo",
"quest": "Merhaba,   AnladÄ±ÄŸÄ±m kadarÄ±yla Epoch, learning rate ve batch kavramlarÄ±nÄ± gÃ¶stermeye Ã§alÄ±ÅŸtÄ±m. Sizden talebim, hatalarÄ±mÄ± dÃ¼zeltmeniz Ã§Ã¼nkÃ¼ sebebini bilmediÄŸim bir ÅŸekilde anlamakta zorlandÄ±ÄŸÄ±mÄ± dÃ¼ÅŸÃ¼nÃ¼yorum.  Veri setimizi, tÃ¼m veriyi tek seferde iÅŸlemek zorunda kalmasÄ±n diye batch'lere ayÄ±rÄ±yoruz. Burada veri setimiz 10, batch boyutumuz ise 2.   10 veriyi, 2'li parÃ§alara ayÄ±rdÄ±ÄŸÄ±mÄ±z iÃ§in, toplam 5 kez (her seferinde 2 veri olacak ÅŸekilde) veriyi alÄ±yor ve kendisini eÄŸitiyor. bu iÅŸlemi 5 kez yaptÄ±ktan sonra yani tÃ¼m seti parÃ§a parÃ§a aldÄ±k bÃ¶ylece bir epoch bitti. Bu epoch'un sonucunun, feature'u ve bias'Ä± ne kadar deÄŸiÅŸtireceÄŸi de bizim learning rate'imize baÄŸlÄ±.  0,5 veya 1'se bu sonuÃ§ fazla etkileyecekken, 0.001 gibi bir deÄŸerse etkisi Ã§ok az olacaktÄ±r.  Burada bir hata var mÄ±? Åimdiden teÅŸekkÃ¼r ederim.",
"comment": [
    "",
    "->  DoÄŸru anlamÄ±ÅŸsÄ±n. Her batch'ten sonra modelin weight'leri ve bias'larÄ± gÃ¼ncelleniyor, senin Ã¶rneÄŸine gÃ¶re her epoch'ta 5 kez gÃ¼ncelleme yapÄ±lÄ±yor, yani parametre gÃ¼ncellemesi her epoch sonunda yapÄ±lmÄ±yor, batch bitince yapÄ±lÄ±yor. Ama epoch sayÄ±sÄ±nÄ± istediÄŸin kadar belirleyebilirsin bunlardan baÄŸÄ±msÄ±z olarak. Senin modelin veri setine epoch sayÄ±sÄ± kadar defa maruz kalÄ±r. UmarÄ±m aÃ§Ä±klayabilmiÅŸimdir.1 month ago 18 people like this.Like ReportReply",
    " -> ->  Ã‡ok teÅŸekkÃ¼r ederim, gayet iyi aÃ§Ä±kladÄ±nÄ±z..",
    "->  ->  Epoch sayÄ±sÄ±nÄ±n Ã§ok fazla yaptÄ±ÄŸÄ±mÄ±zda overfitting oluÅŸmuyor mu acaba ?.",
    "->  ->  learning rate'in ve parametrelerin yeterince dÃ¼ÅŸÃ¼kse overfitting'e yol aÃ§maz, aynÄ± ÅŸekilde regularizasyonla da bunun Ã¶nÃ¼ne geÃ§ebilirsin, ama evet, mantÄ±ken overfitting'e mÃ¼sait bir yapÄ± varsa epoch sayÄ±sÄ±nÄ± arttÄ±rmak overfitting'i arttÄ±rÄ±r.1 month ago 3 people like this.Like ReportReply",
    "->  ->  TeÅŸekkÃ¼rler. Learning rate'in overfitting ile ilgili olduÄŸunu bilmiyordum. Ama nasÄ±l bir ilgisi var onu anlayamadÄ±m..",
    "->  ->  demeye Ã§alÄ±ÅŸtÄ±ÄŸÄ±m ÅŸey eÄŸer learning rateâ€™in ve parametrelerin dÃ¼ÅŸÃ¼kse overfitting olmasÄ± iÃ§in Ã§ok fazla epoch olmasÄ± gerek, yani Ã§ok kÃ¼Ã§Ã¼k adÄ±mlar atÄ±yorsun sonuÃ§ta gibi dÃ¼ÅŸÃ¼nebilirsin. dÃ¼ÅŸÃ¼k learning rate de overfittingâ€™e yol aÃ§abiliyor bazen, burada aÃ§Ä±klamasÄ± var learning rateâ€™ini probleme gÃ¶re nasÄ±l seÃ§men gerektiÄŸinin https://mlexplained.com/2018/01/29/learning-rate-tuning-in-deep-learning-a-practical-guide/.",
    "->  ->  Ä°nceliyorum teÅŸekkÃ¼r ederim..",
    "->  \"tÃ¼m veriyi tek seferde iÅŸlemek zorunda kalmasÄ±n diye\" yerine \"tek bir parametre gÃ¼ncellemesi(weight update(iteration)) iÃ§in bÃ¼tÃ¼n sample'larÄ±n Ã¼zerinden geÃ§mesini bekleyerek zaman kaybetmemek amacÄ±yla\" olarak gÃ¼ncelleyebiliriz sanÄ±rÄ±m.1 month ago 2 people like this.Like ReportReply",
    "->  First Steps with TF bÃ¶lÃ¼mÃ¼ndeki Linear Regression with Synthetic Data kÄ±smÄ±nÄ±n 5. gÃ¶revinde sorduÄŸun sorunun cevabÄ± var ->  kÄ±saca gÃ¼zel aÃ§Ä±klamÄ±ÅŸ..",
    "-> Batch (kÃ¼me) lere ayÄ±rmak istememizin nedenlerinden biri de dataset Ã§ok bÃ¼yÃ¼k olduÄŸunda tek seferde bu kadar datayÄ± tutarak iÅŸlem yapabilecek memory mizin olmayacaÄŸÄ±ndan dolayÄ±. AyrÄ±ca tek seferde ne kadar Ã§ok data olursa bu hesaplamalar matris Ã§arpÄ±mlarÄ±na dayalÄ± olduÄŸu iÃ§in matrisin satÄ±r sayÄ±sÄ± artmÄ±ÅŸ oluyor ve iÅŸlem sÃ¼resi de baya artÄ±yor.Bir tane data alÄ±p loss hesaplayarak parametreleri gÃ¼ncellerseniz hÄ±zlÄ± iÅŸlem yapÄ±yorsunuz fakat kÃ¼meden Ã§ok farklÄ± noktalar seÃ§erek updatelediÄŸiniz iÃ§in stabil olmayan bir Ã¶ÄŸrenme gerÃ§ekleÅŸiyor. Ã–rneÄŸin ders iÃ§eriklerinde Ã¶rnek verilen sick-healthy trees datasetinde healthy lerin iÃ§inde bir tane bulunan sick Ã¶rneÄŸi ile train ederken model parametreleri sapabilir. Bu yÃ¼zden daha fazla Ã¶rneÄŸi kapsayan bir gÃ¼ncelleme daha doÄŸru sonuÃ§ veriyor.Ã‡Ã¶zÃ¼m olarak da imkan verdiÄŸince yÃ¼ksek batch size ile baÅŸlayÄ±n, hÄ±zlanmak ve daha hÄ±zlÄ± train edebilmek adÄ±na yavaÅŸ yavaÅŸ batch size Ä± dÃ¼ÅŸÃ¼rÃ¼n, sonuÃ§lar bozulup loss zigzag Ã§izene kadar batch size Ä± azaltabilirsiniz Ã¶neriliyor.1 month ago 3 people like this.Like ReportReply",
    "->  Bu ayrÄ±mÄ± yapmakta Ã§ok zorlanÄ±yordum. Ã‡ok aÃ§Ä±k ve faydalÄ± bir anlatÄ±m olmuÅŸ. Destekleriniz iÃ§in Ã§ok teÅŸekkÃ¼rler.1 month ago 2 people like this.Like ReportReply",
    " -> ->  Rica ederim, ben de uzun uÄŸraÅŸlar sonucu da oturtabilmiÅŸtim, size faydasÄ± olduysa ne mutlu ğŸ™‚.",
    " "
]
},
{
"question_isim": "SENA KÃœÃ‡ÃœKERDOÄAN",
"quest": "Merhabalar, yarÄ±n ki sÄ±nav saati belli oldu mu?",
"comment": [
    "",
    " ->  Merhaba, 09.30-22.00 saatleri arasÄ±nda istediÄŸimiz zaman sÄ±navÄ± Ã§Ã¶zebileceÄŸiz.",
    " "
]
},
{
"question_isim": " ->  uploaded 1 photo",
"quest": "Merhaba,   Validation &amp; Test Sets Programming Exercise kÄ±smÄ±nda veri train ve validation olarak 2'ye ayrÄ±lÄ±yor. 3'e ayÄ±rÄ±p test seti kesinlikle train iÃ§inde kullanmamamÄ±z gerekiyor diye anlamÄ±ÅŸtÄ±m. Exercise'da en son problemleri Ã§Ã¶zdÃ¼kten sonra test set kullanÄ±lÄ±yor. Bu durum modeli baÅŸarÄ±lÄ± yorumlamamÄ±za sebep olmaz mÄ± ?   Birde bu exercise'da veriyi karÄ±ÅŸtÄ±rararak, yeni index atayarak sanÄ±rÄ±m problemi Ã§Ã¶zmeye Ã§alÄ±ÅŸÄ±yor. MantÄ±ÄŸÄ± anlayamadÄ±m. KÄ±saca bahsedebilirseniz Ã§ok sevinirim .   TeÅŸekkÃ¼rler ğŸ™‚",
"comment": [
    "",
    "-> Bu Ã¶rnekte yanlÄ±ÅŸ hatÄ±rlamÄ±yor isem,verilerimizi okuyup scale ederken zaten test verimizi ayÄ±rÄ±yorduk.Ancak anlatÄ±mda da bahsedildiÄŸi Ã¼zere,test verilerini modelin eÄŸitimi sÄ±rasÄ±nda validation iÃ§in bile kullanmamÄ±z modeli etkileyecektir.Bu yÃ¼zden,train setin iÃ§inden bir validation set ayÄ±rÄ±p eÄŸitimimizi Ã¶yle gerÃ§ekleÅŸtiriyoruz.Ve evet modelin tahmin yeteneÄŸini arttÄ±rÄ±r bu iÅŸlem.Ä°kinci sorunuza istinaden,train set iÃ§erisinden validation setlerini ayÄ±rÄ±rken 0.8-0.2 oranÄ±nÄ± kullanÄ±yoruz.Yani datanÄ±n ilk %80 lik kÄ±smÄ± (100 satÄ±r iÃ§inden ilk 80 satÄ±r gibi) train,%20 (son 20 satÄ±r gibi) validation iÃ§in kullanÄ±lÄ±yor.Ancak verilerimiz,ilk kolona gÃ¶re sÄ±ralÄ± olduÄŸu iÃ§in,modelimiz eÄŸitim aÅŸamasÄ±nda yeteri kadar farklÄ± Ã¶rnek gÃ¶remiyor.Bu yÃ¼zden,indexleri karÄ±ÅŸtÄ±rarak,yani veri setinin kÃ¼Ã§Ã¼kten bÃ¼yÃ¼ÄŸe olan sÄ±ralamasÄ± rastgele hale getirerek,elimizdeki veri Ã§eÅŸidini daha farklÄ± Ã¶rneklere kavuÅŸturuyoruz mantÄ±ÄŸÄ± bu.Kod yapÄ±sÄ± iÃ§in pandas dÃ¶kÃ¼mantasyonunu incelemenizi tavsiye ederim.Eksik veya yanlÄ±ÅŸ sÃ¶ylediÄŸim bir ÅŸey varsa dÃ¼zeltin lÃ¼tfen ğŸ™‚1 month ago 3 people like this.Like ReportReply",
    " ->  ->  Ã§ok teÅŸekkÃ¼rler bazÄ± kÄ±sÄ±mlarÄ± kaÃ§Ä±rmÄ±ÅŸÄ±m ğŸ™‚.",
    " ->  Merhaba,En baÅŸta internetten aldÄ±ÄŸÄ±mÄ±z 2 tane csv var. Bunlardan bir tanesi test iÃ§in. DiÄŸeri de training ve validation'Ä± barÄ±ndÄ±ran csv. Yani test verisi training-validation verisi iÃ§inde yer almÄ±yor.DiÄŸer sorunuza gelince de ÅŸÃ¶yle Ã¶rnek vereyim;- Elinizde bir veri var ve o veri bir sÃ¼tuna gÃ¶re sÄ±ralanmÄ±ÅŸ ve siz bÃ¶lmek istiyorsunuz. Peki bÃ¶ldÃ¼ÄŸÃ¼nÃ¼zde elmalar bir tarafta armutlar bir tarafta kalÄ±rsa ne olur? Sadece elmalara gÃ¶re eÄŸitmiÅŸ olursunuz modelinizi ve armut gÃ¶rÃ¼nce sapÄ±tÄ±r. Bu yÃ¼zden sÄ±ralama olmadan karÄ±ÅŸÄ±k bir ÅŸekilde bÃ¶lme yapÄ±lÄ±rsa daha anlamlÄ± bir daÄŸÄ±lÄ±m elde etme ÅŸansÄ± artar. UmarÄ±m yardÄ±mcÄ± olmuÅŸumdur..",
    " ->   ->  teÅŸekkÃ¼r ederim.",
    "-> Merhabalar,Ä°lk sorun iÃ§in, 3 sete ayÄ±rmamÄ±zÄ±n sebebi aslÄ±nda Ã¶zet olarak Validation Set: Check Your Intuition baÅŸlÄ±ÄŸÄ± altÄ±nda bulunmakta, kÄ±saca Ã¶zetleyecek olursam:test setimizi her iterasyonda modelin verimliliÄŸini test iÃ§in kullanmamÄ±z halinde modelimiz test setimizin iÃ§ermekte olduÄŸu ya da olabileceÄŸi kendine has durumlara adapte olmasÄ±na sebep olabilmekte.(modelin test sete aÅŸÄ±rÄ± uyumu/ overfitting).Bunun yerine bir valiadation set ile her eÄŸitim sonunda model etkinliÄŸini test edip, nihai modele karar verdikten sonra test seti ile test ederek, modelimizin etkinliÄŸini daha saÄŸlÄ±klÄ± bir ÅŸekilde gÃ¶zlemleyebiliriz. Bu ÅŸekilde modelimizin validation setimize aÅŸÄ±rÄ± uyum saÄŸlayÄ±p saÄŸlamadÄ±ÄŸÄ±nÄ± tespit edebilir ve devam eden aÅŸamalara daha saÄŸlÄ±klÄ± karar verebiliriz.Veriyi karÄ±ÅŸtÄ±rmasÄ±nÄ±n sebebi ise elimizde bulunan verinin longitude alanÄ±na gÃ¶re kÃ¼Ã§Ã¼kten bÃ¼yÃ¼ÄŸe sÄ±ralanmÄ±ÅŸ olmasÄ±, bu durum her ne kadar veriden rastgele seÃ§im yapsakta sÄ±ralÄ± veri seÃ§memize sebep olmakta ve sonuÃ§lara baktÄ±ÄŸÄ±mÄ±z zaman train ve validation loss deÄŸerleri arasÄ±nda ki farkÄ±n fazla olduÄŸunu gÃ¶rmekteyiz. Verinin sÄ±ralÄ± olmasÄ± yapÄ±lan ayrÄ±m sonucunda train ve validation setlerinin daÄŸÄ±lÄ±mlarÄ±nÄ±n birbirlerine yakÄ±n olmadÄ±ÄŸÄ±nÄ± gÃ¶stermekte. Bunu dÃ¼zeltebilmek iÃ§in sÄ±ralÄ± olan veriyi setini, karÄ±ÅŸtÄ±rmayÄ± Ã§Ã¶zÃ¼m yolu olarak Ã¶neriyor ve uygulayarak sonuÃ§larÄ± gÃ¶zlemliyor.Ä°yi Ã§alÄ±ÅŸmalar ...1 month ago 9 people like this.Like ReportReply",
    " ->  ->  Ã§ok teÅŸekkÃ¼r ederim.",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba,  Ben de ilk hafta kurslarÄ±nÄ± bitirdim. PAzar gÃ¼nÃ¼ sÄ±nav ne zaman ve nasÄ±l olacak bilgi verebilir misiniz? EÄŸer daha Ã¶nce paylaÅŸÄ±m yaptÄ±ysanÄ±z link gÃ¶nderebilirseniz Ã§ok memnun olurum.  Ä°lk haftanÄ±n verimli geÃ§tiÄŸini belirtmek isterim.",
"comment": [
    "",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba epoch batch size ve iteration kavramlarÄ±nÄ± kafamda pek oturtamadÄ±m bunlarÄ± biz neden kullanÄ±yoruz?",
"comment": [
    "",
    "->  iteration: yineleme demek ya TÃ¼rkÃ§esi ordan bakarsak olaya, modelin bir kere iÅŸlemesi (tabi diÄŸer deÄŸiÅŸkenlere gÃ¶re) 1 iteration oluyor anladÄ±ÄŸÄ±m kadarÄ±yla. Batch size ise kaÃ§ Ã¶rnekte bir iteration yani modeli baÅŸtan Ã§alÄ±ÅŸtÄ±racak onun sayÄ±sÄ±. Ã–rneÄŸin 12 Ã¶rnekli bir datasetinde batch size 6 ise burdaki 1 epoch ta 2 yineleme (iteration) olacak demektir. Bilmem anlatabildim mi? ğŸ™‚.",
    "-> Batch size: Bir kerede iÅŸlenen veri sayÄ±sÄ±.Iteration: TÃ¼m verileri iÅŸlemek iÃ§in gereken batch size sayÄ±sÄ±.Epoch: TÃ¼m verisetinin iyileÅŸtirme aÅŸamasÄ±ndan kaÃ§ kez geÃ§irileceÄŸi.Ä°terasyonlarÄ± oluÅŸturma yani batch size ayarlama sebebimiz tÃ¼m verilerin aynÄ± anda iÅŸlenmesinin maliyetli olmasÄ± ve daha uzun zaman almasÄ±. Ã‡ok fazla epoch olmasÄ± durumunda hem eÄŸitim sÃ¼resi Ã§ok uzuyoor hem de overfitting sorunu baÅŸ gÃ¶steriyor.AnladÄ±klarÄ±mÄ± kabaca bir senaryoya dÃ¶keyim. 10.000 verimiz var ve batch size 200, tÃ¼m bu verileri iÅŸlemek iÃ§in 50 iterasyona ihtiyacÄ±mÄ±z var. 1.epochun 1.iterasyonunda 200 veri geliyor modelimizin ilk parametrelerini oluÅŸturuyoruz. Ve cost functiona sokarak kaybÄ± hesaplÄ±yor. 2.iterasyonda ise bu kayÄ±p deÄŸerini azaltmak iÃ§in parametrelerde deÄŸiÅŸiklikler yapÄ±yor yeniden cost functiona sokarak kaybÄ± hesaplÄ±yor. 1.epoch sonunda tÃ¼m verileri iÅŸleyerek elde ettiÄŸimiz bir modele sahip oluyoruz. 2.epochta amaÃ§ yine tÃ¼m verileri iterasyonlara bÃ¶lerek yeniden iÅŸleyerek modeli daha da iyleÅŸtirmek..",
    "->  EÄŸitmenlerimizden senaryonun doÄŸruluÄŸu hakkÄ±nda onay almak gÃ¼zel olacaktÄ±r ğŸ™‚.",
    "->  1000 verimizin olduÄŸunu dÃ¼ÅŸÃ¼nelim. Modele vereceÄŸimiz her BÄ°R veri \"iterasyon\"dur.TÃ¼m iterasyonlar tamamlandÄ±ÄŸÄ±nda yani 1000 verimiz tamamen modele verilip, loss deÄŸerlerinin hesaplanmasÄ±, BÄ°R \"epoch\"tur.Batch-size ise bu loss deÄŸerlerimizin iÅŸleme alÄ±nÄ±p, aÄŸÄ±rlÄ±klarÄ±n gÃ¼ncellemesinin sÄ±klÄ±ÄŸÄ±nÄ± ifade eder.Yani Batch-size =100 yaparsak; her 100 iterasyonda (her 100 verinin iÅŸlenmesinde) modelin aÄŸÄ±rlÄ±klarÄ± gÃ¼ncellenecektir.1 month ago 3 people like this.Like ReportReply",
    "->  ->  SanÄ±rÄ±m iteration tam olarak bu deÄŸil. AnladÄ±ÄŸÄ±m kadarÄ±yla iteration parametre gÃ¼ncellemesi anlamÄ±na geliyor. Yani her weight update bir iteration'dÄ±r diyebiliriz. Bu durumda eÄŸer 1000 sample varsa eÄŸer SGD iÃ§in iteration sayÄ±mÄ±z bir epoch iÃ§in 1000 olacaktÄ±r ama mini-batch(batch-size=100) tercih edersek bu kez bir epoch iÃ§in iteration sayÄ±mÄ±z 10 olacaktÄ±r..",
    "->  ->  HaklÄ±sÄ±n. Yinelemenin tam tanÄ±mÄ±nÄ± ÅŸÃ¶ylede dÃ¼ÅŸÃ¼nebiliriz; \"Yineleme, bir epoch tamamlamak iÃ§in gereken batch sayÄ±sÄ±dÄ±r\". BÃ¶ylelikle 1 epoch yani toplamda 1000 veriyi 100'er veri iÃ§eren partilerle tamamlamak iÃ§in 10 yineleme yapmamÄ±z gerektiÄŸi ortaya Ã§Ä±kÄ±yor..",
    "->  ->  \"iterasyon\" dÃ¼zeltmesi iÃ§in teÅŸekkÃ¼rler. Ben de ÅŸunu dÃ¼zelteyim Ã¶rneÄŸinizde; SGD random seÃ§tiÄŸi bir Ã¶rnek Ã¼zerinden gÃ¼ncelleme yapar. Yani 1000 Ã¶rneÄŸimiz iÃ§in bir epochta 1 gÃ¼ncelleme olur, \"iterasyon\" sayÄ±mÄ±z da 1 oluyor haliyle. EÄŸer GD yapsaydÄ±k o zaman 1000 Ã¶rnek iÃ§in bir epochta 1000 gÃ¼ncelleme olacaÄŸÄ±ndan, \"iterasyon\" sayÄ±mÄ±z da 1000 olacaktÄ±r. KÄ±saca GD-SGD farkÄ±na deÄŸinmek istedim ????.",
    "->  teÅŸekkÃ¼rler.",
    "-> ArkadaÅŸlar merhaba,Burada kÃ¼Ã§Ã¼k bir karÄ±ÅŸÄ±klÄ±k sezdim, onun iÃ§in ek bir aÃ§Ä±klama yapmak istiyorum :)Ä°terasyon dediÄŸimiz ÅŸey iÅŸlem sayÄ±sÄ±dÄ±r, ML konularÄ±nda bu iÅŸlem weight update'dir. Yani modelimizde bulunan weight ve bias'Ä±n kaÃ§ kere gÃ¼ncellendiÄŸidir.Epoch, modelinizin tÃ¼m data ile kaÃ§ kere eÄŸitileceÄŸidir. EÄŸer elinizde 10.000 adet veriniz varsa, modeliniz bir epoch sonunda tÃ¼m datayÄ± gÃ¶rmÃ¼ÅŸ olur.Batch ise Ã§ok yÃ¼ksek sayÄ±da veriyi aynÄ± anda modele vermemek ve bu sayede oluÅŸabilecek memory sorunlarÄ±na Ã¶nlem olarak kullanÄ±lan, bir iterasyonda kullanacaÄŸÄ±nÄ±z veri miktarÄ±dÄ±r. Ã–rneÄŸin batch_size 1000 alÄ±nÄ±rsa, 10.000 adet verinin iÃ§inden 1000 adet veri alÄ±nÄ±r, 1 kez weight update yapÄ±lÄ±r, ardÄ±ndan diÄŸer veriler 1000er 1000er modele verilir ve her biri ile yine weight update yapÄ±lÄ±r. 10.000 verinin tamamÄ± verildiÄŸinde 1 epoch tamamlanmÄ±ÅŸ ve veriniz 10 kere gÃ¼ncellenmiÅŸ olur..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Validation test kÄ±smÄ±ndaki check your intuition bÃ¶lÃ¼mÃ¼nÃ¼ tam anlayamadÄ±m.ÅÃ¶yle anladÄ±m,modeli eÄŸitim setiyle eÄŸiticez bu eÄŸitim kÄ±smÄ±nda hiperparametreleri dÃ¼zenleyeceÄŸiz.En son test setiyle deÄŸerlendireceÄŸiz.Yani her iterasyonda eÄŸitim olur ama test en sonda olur.DoÄŸru mu anladÄ±m?",
"comment": [
    "",
    " ->  Benim anladÄ±ÄŸÄ±m kadarÄ±yla ÅŸÃ¶yle bir ÅŸeyden bahsediyor orada -ki cevapla da Ã¶rtÃ¼ÅŸÃ¼yor-- Bir training set ve bir test set var elimizde,- Her bir Ã§evrimde Ã¶nce train edip sonra test sete uyumuna bakÄ±yor,- Haliyle aslÄ±nda test setini de bir bakÄ±ma training set olarak kullanÄ±yor ve overfitting oluÅŸuyor.1 month ago 2 people like this.Like ReportReply",
    "->  Merhabalar, KÄ±saca Ã¶zetleyecek olursam, umarÄ±m yanlÄ±ÅŸ anlamamÄ±ÅŸÄ±mdÄ±r :)Ana baÅŸlÄ±ÄŸa gÃ¶re:Modelimizi her bir iterasyonda eÄŸitiyoruz ve her eÄŸitimin sonunda test setimiz ile Ã¶lÃ§Ã¼mlerimizi yapÄ±yoruz. Elde ettiÄŸimiz sonuÃ§lara gÃ¶re parametrelerimizde deÄŸiÅŸiklik yapÄ±p yapmayacaÄŸÄ±mÄ±za karar veriyoruz.Burada ki problemimiz: Her bir iterasyonda test setimizi bir Ã¶lÃ§Ã¼m seti olarak kullandÄ±ÄŸÄ±mÄ±z iÃ§in, modelimizin test setinde oluÅŸabilecek garipliklere uyum saÄŸlayarak bizi aldatabilecek sonuÃ§lar elde etmemize sebep olabilmekte.Bu sebepten Ã¶tÃ¼rÃ¼ de setimizi 3'e bÃ¶lerek bir de validation_set oluÅŸturuyoruz. BÃ¶ylece BÃ¼tÃ¼n eÄŸitim sonunda elde ettiÄŸimiz modelimizi test seti ile gÃ¶zlemleyerek modelimizin validation_set'imize aÅŸÄ±rÄ± uyum saÄŸlayÄ±p saÄŸlamadÄ±ÄŸÄ±nÄ± gÃ¶zlemleyebilmekteyiz.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 6 people like this.Like ReportReply",
    "->  eÄŸitim setiyle belirlediÄŸimiz en uygun parametreleri test setinde tahmin edeceÄŸiz diye biliyorum..",
    " -> Merhaba, benim anladÄ±ÄŸÄ±m kadarÄ±yla amaÃ§ overfitting'i azaltmak ve modelin kalitesini deÄŸerlendirmek. Bu nedenle Ã¶nce training setin bir kÄ±smÄ±nÄ± split ederek validation_set'i oluÅŸturuyor. EÄŸitim aÅŸamasÄ±ndan sonra sonuÃ§larÄ± deÄŸerlendirmek iÃ§in doÄŸrulama setini kullanÄ±yor, doÄŸrulama bittikten sonra test seti Ã¼zerinde test ediyor.1 month ago 2 people like this.Like ReportReply",
    "->  EÄŸitim verisetini eÄŸittiÄŸimizde model kendi baÅŸÄ±na overfitting oluÅŸtururken, test seti iÅŸin iÃ§ine girdiÄŸinde, test setinde kaybÄ± dÃ¼ÅŸÃ¼rmek iÃ§in yaptÄ±ÄŸÄ±mÄ±z mÃ¼dahaleler sonucunda overfitting oluÅŸuyor diye dÃ¼ÅŸÃ¼nÃ¼yorum. YanlÄ±ÅŸ mÄ± dÃ¼ÅŸÃ¼nÃ¼yorum acaba?.",
    "->  Merhaba, modelimiz eÄŸitilirken her bir Ã§evrimde test seti ile karÅŸÄ±laÅŸtÄ±rma yapÄ±lÄ±yor. Burdan Loss alÄ±nÄ±p model eÄŸitiliyor. Bu durumda test setindeki veriler eÄŸitimde kullanÄ±lmÄ±ÅŸ oluyor. Daha sonra test aÅŸamasÄ±nda bu deÄŸerler eÄŸitimde kullanÄ±ldÄ±ÄŸÄ±ndan dolayÄ± overfitting ihtimali artÄ±yor. Bu nedenle eÄŸitim verilerimizi eÄŸitim ve validation olarak ikiye bÃ¶lÃ¼yoruz. ArtÄ±k modelimiz eÄŸitilirken validasyon datalarÄ± ile karÅŸÄ±laÅŸtÄ±rma yapÄ±yor. BÃ¶ylece test aÅŸamasÄ±nda test datalarÄ±mÄ±z eÄŸitimde kullanÄ±lmadÄ±ÄŸÄ± iÃ§in daha Ã¶nce karÅŸÄ±laÅŸmadÄ±ÄŸÄ± datalarla modeli test etmiÅŸ oluyoruz. Hem overfitting azalÄ±yor hem de daha doÄŸru bir test yapmÄ±ÅŸ oluyoruz diye anladÄ±m ben. YanlÄ±ÅŸÄ±m varsa mentÃ¶r hocalarÄ±mÄ±z dÃ¼zeltsinler lÃ¼tfen. Ä°yi Ã§alÄ±ÅŸmalar dilerim.1 month ago 3 people like this.Like ReportReply",
    " ->  ->  Merhaba, buradan anladÄ±ÄŸÄ±m kadarÄ±yla ilk baÅŸta eÄŸitim setimizi eÄŸitim ve validation set olarak ayÄ±rÄ±yoruz. Modelimizi eÄŸitim seti ile eÄŸitip validation datalarÄ± ile karÅŸÄ±laÅŸtÄ±rma yapÄ±yoruz. Validation datalarÄ±mÄ±z ile karÅŸÄ±laÅŸtÄ±rma yaparken modelimizin daha doÄŸru Ã§alÄ±ÅŸmasÄ± iÃ§in parametrelerimizi en doÄŸru sonuca ulaÅŸana kadar tekrar tekrar deÄŸiÅŸtirip validation datalarÄ±mÄ±z ile test ediyoruz (Bu kÄ±sÄ±m doÄŸru mudur?). En sonunda da test datalarÄ±mÄ±zÄ± modelimizde kullanÄ±p karÅŸÄ±laÅŸtÄ±rma yapÄ±yoruz. Ã–zet olarak sormak istediÄŸim eÄŸitim setimizi bÃ¶ldÃ¼kten sonra modelimizi eÄŸitim setiyle eÄŸitip en uygun sonuca ulaÅŸana kadar parametreleri deÄŸiÅŸtirip tekrar tekrar validation datalarÄ±mÄ±z ile mi karÅŸÄ±laÅŸtÄ±rÄ±yorz? YanlÄ±ÅŸ anlamÄ±ÅŸ olabilirim dÃ¼zeltebilirseniz sevinirim. TeÅŸekkÃ¼r ederim..",
    "->   ->  ben de sizin gibi dÃ¼ÅŸÃ¼nÃ¼yorum. Ancak kursta Ã¶ÄŸrenciyim yanlÄ±ÅŸ bir bilgi verip kafa karÄ±ÅŸtÄ±rmak istemiyorum. AÅŸaÄŸÄ±da paylaÅŸtÄ±ÄŸÄ±m linkte validation set kÄ±smÄ±ndaki aÃ§Ä±klama ile de Ã¶rtÃ¼ÅŸÃ¼yor dediklerimiz. Ek olarak eÄŸer validation set olmasa bu iÅŸlemde test seti kullanÄ±lacak. BÃ¶ylece modelimiz test setindeki verilerle Ã§alÄ±ÅŸmÄ±ÅŸ olacak. Modeli en son test ettiÄŸimizde modelin daha Ã¶nce gÃ¶rmediÄŸi verilerle test etmemiz bize daha doÄŸru sonuÃ§lar verecektir. Bir yanlÄ±ÅŸlÄ±k varsa mentÃ¶r hocalarÄ±mÄ±z yardÄ±m etsinler lÃ¼tfen. Ä°yi Ã§alÄ±ÅŸmalar dilerim.https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7",
    "About Train, Validation and Test Sets in Machine Learningtowardsdatascience.comThis is aimed to be a short primer for anyone who needs to know the difference between the various dataset splits while training Machineâ€¦.",
    " ->  ->  TeÅŸekkÃ¼r ederim bilgiler iÃ§in. Ä°yi Ã§alÄ±ÅŸmalar..",
    "->  Modelimizi training data Ã¼zerinden eÄŸitirken test ile de modelin genelleme yeteneÄŸini ve ne kadar iyi Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± test ediyoruz. Ancak burada ÅŸundan bahsetmiÅŸ, peki train datasÄ± Ã¼zerinde eÄŸitim yaparken test sonuÃ§larÄ±na bakarak learning rate gibi parametreleri daha iyi bir model oluÅŸturmak iÃ§in deÄŸiÅŸtirebilir miyiz? Cevap olarak ise bu da test datasÄ±nda iyi bir sonuÃ§ alÄ±nabilir ama bu seferde seÃ§ilen test verilerine Ã¶zgÃ¼ bir modelleme olur ve genelleme yeteneÄŸi dÃ¼ÅŸÃ¼k olur..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba, Generalization kÄ±smÄ±nda ki ML Fine Print altÄ±nda anlatÄ±lanÄ± anlayamadÄ±m.Tam olarak ne demek istiyor acaba?  TeÅŸekkÃ¼rler",
"comment": [
    "",
    "-> Merhaba,Burada Generalization yani modelimizin daha Ã¶nce gÃ¶rÃ¼lmemiÅŸ bir veriyi tahmin etme yeteneÄŸine rehberlik ve etki eden 3 varsayÄ±mdan bahsetmiÅŸ:1.(Independently and Identically): Burada verilerinizi random olarak almanÄ±z gerektiÄŸinden bahsediyor. Ã–rneÄŸin elinizde insanlarÄ±n yaÅŸ, boy, kilo, cinsiyet ve Ã¼lke bilgilerini iÃ§eren bir veriseti var. Burada Ã¼lke sizin labelÄ±nÄ±z, diÄŸer alanlar ise featurelarÄ±nÄ±z olsun. EÄŸer verisetinizi eÄŸitime sokarken random olarak almazsanÄ±z eÄŸitim-test bÃ¶lme iÅŸleminde eÄŸitim verisinde sadece tek bir Ã¼lkeye ait veriler gelmiÅŸ olabilir. (Ã–rneÄŸin elinizde TR-US-FR Ã¼lkeleri olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼n. EÄŸitim setinde sadece TR verileri olursa modelimiz FR ve US verilerini tahmin etmekte efektif Ã§alÄ±ÅŸmayacaktÄ±r.)2. (Stationary): Burada da verilerimizin daÄŸÄ±tÄ±mÄ±nÄ±n sabit olduÄŸundan bahseder. Ã–rneÄŸin verisetinizde bir ÅŸemsiye ÅŸirketinin satÄ±ÅŸ listesi olsun. Åemsiye satÄ±ÅŸlarÄ± mevsimsel olarak farklÄ±lÄ±k gÃ¶stereceÄŸinden bu daÄŸÄ±tÄ±m sabitliÄŸini ihlal eder.3. Bu kÄ±smÄ± tam anlayamamakla birlikte anladÄ±ÄŸÄ±m kadarÄ±yla Ã¶rneklerimizi aynÄ± daÄŸÄ±tÄ±mÄ±n iÃ§indeki bÃ¶lÃ¼mlerden Ã§iziyoruz bunu nedeni test ve eÄŸitim verilerimizi birbirinden farklÄ± distributionlarda olursa test loss'umuzun fazla olacaÄŸÄ± yani tahminleri doÄŸru yapamayacaÄŸÄ±dÄ±r.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 10 people like this.Like ReportReply",
    "->  ->  3. KÄ±sÄ±m DaÄŸÄ±lÄ±mlarÄ±n aynÄ± olmasÄ±n bahsetmektedir. Ã‡Ã¼nkÃ¼ daÄŸÄ±lÄ±mÄ±n deÄŸiÅŸmesi ile verinin karakteristiÄŸi deÄŸiÅŸir, ve elinde iki farklÄ± veri seti olmuÅŸ olur. (Her daÄŸÄ±lÄ±mÄ±n kendisine has olan Ã§Ã¶zÃ¼m yÃ¶netim vardÄ±r.) Bu durumda biri ile eÄŸitim yaparak diÄŸeri ile test etmen saÄŸlÄ±klÄ± sonuÃ§lar vermeyecektir.1 month ago 4 people like this.Like ReportReply",
    "->  ->  AÃ§Ä±klama iÃ§in teÅŸekkÃ¼r ederim ğŸ™‚ Ä°yi Ã§alÄ±ÅŸmalar dilerim..",
    "-> ->  Stationary'den kastÄ±mÄ±z verinin ortalamasÄ±nÄ±n, varyansÄ±nÄ±n ve kovaryansÄ±nÄ±n sabit olmasÄ± deÄŸil midir?.",
    "->  -> Evet, ortalama, kovasyans ve varyans deÄŸerleri Stationary'de sabittir. Bu konu ile alakalÄ± http://people.duke.edu/~rnau/411diff.htm linkinde yazÄ±lmÄ±ÅŸ Ã§ok gÃ¼zel bir yazÄ± mevcut, okumanÄ±zÄ± tavsiye ederim ğŸ™‚.",
    "->  Ã‡ok teÅŸekkÃ¼rler ÅŸimdi daha iyi anladÄ±m:).",
    " "
]
},
{
"question_isim": "->",
"quest": "YarÄ±nki sÄ±nav zamanÄ± ve detaylar ile ilgili bir geliÅŸme var mÄ±?",
"comment": [
    "",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar. BazÄ± terimleri TÃ¼rkÃ§e nasÄ±l aÃ§Ä±klayacaÄŸÄ±mÄ± bulamÄ±yorum. Ã–rneÄŸin tuning ve fit ifadelerinin bu iÅŸin iÃ§inde Ã§alÄ±ÅŸanlar nasÄ±l TÃ¼rkÃ§eleÅŸtiriyor? Fit iÃ§in \"uydurma\" Tuning iÃ§in \"ayarlama\" ifadesini kullanmak anlamÄ±nÄ±n kaybolmasÄ±na yol aÃ§Ä±yormuÅŸ gibi geliyor. Mediumda yazÄ± yazmak gibi bir hedefim var. Ã–ÄŸrendiklerimi en iyi ÅŸekilde aÃ§Ä±klamak istiyorum.  Bir de \"offset\" tam olarak nedir?",
"comment": [
    "",
    "->  tuning final modeli oluyor fit etmek train verilerini eÄŸitmek oluyor diye biliyorum..",
    "->  Bence her ÅŸeyi TÃ¼rkÃ§e olarak yazmak zorunda deÄŸilsiniz. EÄŸer kelimeyi TÃ¼rkÃ§e yazdÄ±ÄŸÄ±nÄ±zda daha zor anlaÅŸÄ±lacaksa, TÃ¼rkÃ§e yazmaya Ã§alÄ±ÅŸmanÄ±n Ã§ok da bir anlamÄ± yok. BazÄ± kavramlar oturmuÅŸ ve sÃ¼rekli Ä°ngilizce karÅŸÄ±lÄ±klarÄ± karÅŸÄ±mÄ±za Ã§Ä±kÄ±yor. AyrÄ±ca bazÄ± kelimelerin de tam karÅŸÄ±lÄ±klarÄ± yok. Tabii bu konuda net bir doÄŸru yok, dilimize oturmasÄ± iÃ§in sÃ¼rekli TÃ¼rkÃ§e yazÄ±lmasÄ± daha iyi olur diyenler de olabilir. En azÄ±ndan 2020 yÄ±lÄ±nda tamamen TÃ¼rkÃ§e iÃ§erik yazmak zor olabilir ğŸ™‚ Belki 10 yÄ±l sonra dilimizde tam karÅŸÄ±lÄ±klarÄ± olur ve insanlar TÃ¼rkÃ§e olarak bu kavramlara aÅŸina olur.1 month ago 6 people like this.Like ReportReply",
    "->  ->  AnladÄ±m. O zaman olduÄŸu gibi kullanmak dediÄŸiniz gibi en mantÄ±klÄ±sÄ± olacaktÄ±r. TeÅŸekkÃ¼rler..",
    "->  https://github.com/deeplearningturkiye/turkce-yapay-zeka-terimleri/blob/master/ingilizce-turkce.mdBurayÄ± kullanabilirsin. Ethem AlpaydÄ±n Yapay Ã–ÄŸrenme kitabÄ±nda kullandÄ±ÄŸÄ± TÃ¼rkÃ§e karÅŸÄ±lÄ±klar oldukÃ§a deÄŸerli. TÃ¼rkÃ§e anlaÅŸabilmemiz bu kavramlarÄ± TÃ¼rkÃ§eleÅŸtirebilmenin her bilim dalÄ±nda olduÄŸu gibi Ã§ok Ã¶nemli olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yorum. Ian Goodfellow, Yoshua Bengio ve Aaron Courville'nin Deep Learning kitabÄ±nÄ±n BuzdaÄŸÄ± YayÄ±nevinden Ã§Ä±kan Ã§evirisinde Ã§eviri ekibinin kullandÄ±ÄŸÄ± terimleri de mutlaka kullanmalÄ±..",
    "->  ->  DediÄŸiniz kaynaÄŸa bakÄ±yorum kafama takÄ±lan bir ÅŸey olunca. Ama fit yerine \"uydurma\" kelimesini kullanmak biraz zorlama gibi durduÄŸu iÃ§in acaba kullanÄ±lÄ±yor mu diye Ã¶ÄŸrenmek istemiÅŸtim. TeÅŸekkÃ¼r ederim..",
    "->  Ben de TÃ¼rkÃ§e kullanmaya gayret eden biriyim. EÄŸer TÃ¼rkÃ§e karÅŸÄ±lÄ±k olarak tam ifade eden kelime yoksa Ä°ngilizce kullanmakta sakÄ±nca olmayacaktÄ±r. Bu durumu da yazÄ±nÄ±zÄ±n sonunda bir dipnot ÅŸeklinde belirtebilirsiniz yazarlar genelde Ã¶yle yapÄ±yor1 month ago 3 people like this.Like ReportReply",
    "->  ->  DediÄŸiniz gibi mini bir sÃ¶zlÃ¼k eklemeyi dÃ¼ÅŸÃ¼nÃ¼yorum yazdÄ±ÄŸÄ±mda. TeÅŸekkÃ¼r ederim..",
    "->  Fit kelimesinin karÅŸÄ±lÄ±ÄŸÄ± olarak uyarlama kullanÄ±labilir..",
    " "
]
},
{
"question_isim": " -> uploaded 1 photo",
"quest": "Merhaba, Scale iÅŸleminin tam olarak ne yaptÄ±ÄŸÄ±nÄ± anlayamadÄ±m. Biraz basit bir soru oldu galiba, Ã¶zÃ¼r dilerim.",
"comment": [
    "",
    "->  Scale iÅŸlemi genelde verileri yorumlamayÄ± kolaylaÅŸtÄ±rÄ±yor. Ã–rneÄŸin nÃ¼fusun yaÅŸa gÃ¶re daÄŸÄ±lÄ±m verilerimiz var. 25 yaÅŸ birey sayÄ±sÄ±nÄ± toplam sayÄ±ya bÃ¶lerek 0 ve 1 arasÄ±na yani olasÄ±lÄ±ksal yorumlanmasÄ± iÃ§in gerekli aralÄ±ÄŸa dÃ¼ÅŸÃ¼rmÃ¼ÅŸ oluyoruz. Ã–te yandan grafik Ã§izerken bazÄ± deÄŸerlerin 100000 lerde olduÄŸunu (Ã¶rneÄŸin ev fiyatÄ±) bazÄ±larÄ±nÄ±n ise 10 lardan daha kÃ¼Ã§Ã¼k olduÄŸunu (Ã¶rneÄŸin oda sayÄ±sÄ±) dÃ¼ÅŸÃ¼n. GÃ¶rselleÅŸirmek zor olacaktÄ±r. EÄŸitmenlerimizden gerekli dÃ¼zeltmeleri bekliyorum.1 month ago 3 people like this.Like ReportReply",
    "-> Andrew NG de bu ÅŸekilde aÃ§Ä±klÄ±yor. Ã–zetleyecek olursak convex ÅŸeklin daha dÃ¼zgÃ¼n oluÅŸmasÄ± iÃ§in scaling yapÄ±yoruz. Daha dÃ¼zgÃ¼n oluÅŸmasÄ± ise ÅŸekilde gÃ¶rÃ¼ldÃ¼ÄŸÃ¼ Ã¼zere daha az ve doÄŸru yÃ¶nden sapmayan adÄ±mlarla global minimuma ulaÅŸmamÄ±zÄ± saÄŸlar.1 month ago 2 people like this.Like ReportReply",
    " -> Yani anladÄ±ÄŸÄ±m kadarÄ±yla, kÄ±yasÄ±n daha doÄŸru yapÄ±labilmesi iÃ§in, deÄŸeri belirli bir sayÄ±yla Ã§arpÄ±yor veya bÃ¶lÃ¼yoruz. BÃ¶ylece gÃ¶rselleÅŸtirme olsun, bizim modelin gidiÅŸatÄ±nÄ± anlamamÄ±z olsun bu konularda yararlÄ± oluyor.1 month ago 2 people like this.Like ReportReply",
    "->   -> Aynen Ã¶yle..",
    " -> ->  Ã‡ok teÅŸekkÃ¼r ederim..",
    "->   -> evet Ã¶lÃ§eklendirme yapÄ±yoruz..",
    "->  Verilerimizi Ã¶lÃ§eklememiz featurelar arasÄ±ndaki uÃ§urumu azaltacaktÄ±r. Andrew Ng'den alÄ±nan -> 'Ä±n paylaÅŸatÄ±ÄŸÄ± grafiÄŸe bakarsanÄ±z elimizde ev boyutu ve evdeki lavabo sayÄ±sÄ± adlÄ± featurelarÄ±mÄ±z var. Bu featurelarÄ±n deÄŸer aralÄ±klarÄ± ev boyutu iÃ§in (0-2000), lavabo asyÄ±sÄ± iÃ§in (1-5). Bu deÄŸer aralÄ±klarÄ±nÄ±n Ã§ok farklÄ± olmasÄ± gradient descent fonksiyonumuzun yavaÅŸ Ã§alÄ±ÅŸmasÄ±na neden olacaktÄ±r Ã§Ã¼nkÃ¼ resimdeki soldaki garafiÄŸimizde optimum deÄŸer olan en iÃ§ deÄŸere yaklaÅŸmasÄ± uzun sÃ¼recektir. Bu problemi Ã§Ã¶zmek iÃ§in feature scaling yapabilirsiniz. Feature scaling aslÄ±nda tÃ¼m featurelarÄ±nÄ±zÄ±n belli bir deÄŸer aralÄ±ÄŸÄ±na alÄ±nmasÄ±dÄ±r. En optimum deÄŸer aralÄ±ÄŸÄ± diye bir ÅŸey yoktur ama olabilrdiÄŸinde birbrine yakÄ±n kÃ¼Ã§Ã¼k deÄŸerler arasÄ±na alÄ±nmaya Ã§alÄ±ÅŸÄ±labilir. Ã–rneÄŸin -1About Feature Scaling and Normalizationsebastianraschka.comSections1 month ago 5 people like this.Like ReportReply",
    "->  ArkadaÅŸlarÄ±n teknik olarak aÃ§Ä±klamasÄ±nÄ±n yanÄ±nda bana hitap eden kÄ±smÄ± ÅŸÃ¶yle. GÃ¶rselleÅŸtirme ve grafiklerde Ã§ok bÃ¼yÃ¼k rakamlar bu mantÄ±kla bin ya da milyon Ã¶lÃ§eÄŸinde gÃ¶sterilir ki veri okumasÄ± kolay olsun, gÃ¶rsel Ã§irkin gÃ¶zÃ¼kmesin. En basit haliyle model yazmaya baÅŸlamadan Ã¶nce define gibi komutlarla veriye genel bir bakÄ±ÅŸ aÃ§Ä±sÄ± ile baktÄ±ÄŸÄ±nÄ±zda, her bir feature milyon seviyesinde olursa okumasÄ± bakan kiÅŸiyi yoracaktÄ±r ve tek bir sayfaya sÄ±ÄŸmasÄ±nÄ± zorlaÅŸtÄ±racaktÄ±r. Veri Biliminde en Ã¶nemli ÅŸeylerden birisinin de kodunuzun okunabilir olmasÄ±. Ã‡alÄ±ÅŸmanÄ±za bakan diÄŸer insanlarÄ± dÃ¼ÅŸÃ¼nerek en sade ve yalÄ±n ÅŸekilde olmasÄ± Ã¶nemli. Bu nedenle tekniÄŸin de Ã¶tesinde bu sebeplerle Ã¶lÃ§eklendirme Ã¶nemli bence..",
    "->  Verileri aynÄ± dÃ¼nyaya indirgeme iÅŸlemidir. BÃ¶ylece modelimiz daha iyi ve hÄ±zlÄ± Ã¶ÄŸrenir. Yapay zeka da yÄ±ÄŸÄ±n normalizasyonu denilen iÅŸlem vardÄ±r. Veriler bir sonraki katamana gÃ¶nderilmeden Ã¶nce aÃ§Ä±k bir ÅŸekilde normalize edilir. Ã‡Ã¼nkÃ¼ sonraki katman, daha Ã¶nce bu katmana gÃ¶nderilen daÄŸÄ±lÄ±ma benzeyen bir veri yÄ±ÄŸÄ±nÄ± beklemektedir..",
    "->  Scale yani Ã¶lÃ§eklendirme iÅŸlemi biraz daha okunaklÄ± hale getirmek iÃ§in kullanÄ±lmÄ±ÅŸ. Yani 1000 e bÃ¶lÃ¼yor ev fiyatlarÄ±nÄ± daha okunaklÄ± bir deÄŸer ortaya Ã§Ä±kÄ±yor. \"/=\" ifadesi zaten pythonda aynÄ± deÄŸeri yani median_house_value deÄŸerlerini 1000 e bÃ¶l ve tekrar eÅŸitle anlamÄ±nda..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar, teorik olarak anladÄ±ÄŸÄ±mÄ± dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼m ÅŸeylerin Playground Exercise lar esnasÄ±nda yerine oturmadÄ±ÄŸÄ±nÄ± fark ediyorum. Ã–rneÄŸin Training and Test Sets: Playground Exercise kÄ±smÄ±nda taskleri yerine getirip, gÃ¶zlem yapsam da bazÄ± neden sonuÃ§ iliÅŸkilerini kuramÄ±yorum. Task 2 ve 3 teki  \"Is the delta between Test loss and Training loss lower or higher with this new Learning rate? What happens if you modify both Learning rate and batch size?\" ve \"Does altering the training data percentage change the optimal learning settings that you discovered in Task 2? If so, why?\" sorularÄ±nÄ±n cevaplayamadÄ±m.  YardÄ±mcÄ± olabilirseniz sevinirim ve aynÄ± zamanda kafamda daha iyi oturtabilmek adÄ±na gelebilecek tavsiyelere de aÃ§Ä±ÄŸÄ±m. TeÅŸekkÃ¼rler.",
"comment": [
    "",
    "-> Task 1â€™de modeli eÄŸittiÄŸimizde overfitting(test loss >> training loss) olduÄŸunu gÃ¶rÃ¼yoruz. Yani modelimiz eÄŸitim verilerine Ã§ok iyi uyuyor, ancak yeni bir veri geldiÄŸinde veriyi doÄŸru ÅŸekilde genelleÅŸtiremiyor.Task 2â€™de learning rateâ€™i azalttÄ±ÄŸÄ±mÄ±zda, test loss deÄŸerinin training loss deÄŸerine yaklaÅŸtÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼yoruz. Batch sizeâ€™Ä± arttÄ±rdÄ±ÄŸÄ±mÄ±zda, test loss deÄŸerinin traning loss deÄŸerinin birazcÄ±k altÄ±na dÃ¼ÅŸtÃ¼ÄŸÃ¼nÃ¼ gÃ¶rÃ¼yoruz. Peki bunu niye yapÄ±yoruz? AmaÃ§ burda perfect fittingâ€™i(test loss ~ training loss) yakalamak. Yani her iki deÄŸerin de kabaca aynÄ± veya birbirine yakÄ±n deÄŸerler olmasÄ±nÄ± istiyoruz. Task 3â€™te ise training data percentage oranÄ±nÄ± %10 olarak ayarladÄ±ÄŸÄ±mÄ±zda, verilerin %10â€™u training set iÃ§in, kalan %90â€™Ä± test set iÃ§in kullanÄ±lÄ±yor. Training setindeki veri yÃ¼zdesini bu kadar azaltmak veri noktalarÄ±nÄ±n sayÄ±sÄ±nÄ± bÃ¼yÃ¼k bir oranda azaltÄ±yor. Ã‡Ã¼nkÃ¼ eskiye gÃ¶re daha az veriyle eÄŸitim saÄŸlamÄ±ÅŸ oluyoruz. Learning rate ve batch sizeâ€™a yÃ¼ksek bir deÄŸer verdiÄŸimizde, eÄŸitim modelindeki dÃ¼zensiz atlamalarÄ± gÃ¶rÃ¼yoruz. Loss curve deki minimum pointe asla ulaÅŸamÄ±yor, tekrar tekrar Ã¼stÃ¼nden atlÄ±yor. Ä°yi bir model iÃ§in yeterli Ã¶lÃ§Ã¼deki bir training sete ihtiyacÄ±mÄ±z var. Ben Ã¶ÄŸrendiklerimle bu ÅŸekilde yorumladÄ±m, yanlÄ±ÅŸÄ±m varsa arkadaÅŸlar dÃ¼zeltirse sevinirim.1 month ago 8 people like this.Like ReportReply",
    "->  ->  SanÄ±rÄ±m Task1'de overfitting gerÃ§ekleÅŸmiyor aksine learning rate Ã§ok yÃ¼ksek olduÄŸu iÃ§in modelimiz training loss'u yeterince dÃ¼ÅŸÃ¼remiyor yani yeterince iyi Ã¶ÄŸrenemiyor ve bu da delta'nÄ±n (test loss - training loss) yÃ¼ksek olmasÄ±na sebep oluyor Ã§Ã¼nkÃ¼ iyi Ã¶ÄŸrenememesi sebebiyle yeni gelen test datasÄ±nda iyi tahmin gerÃ§ekleÅŸtiremiyor. Yani Ã§ok iyi Ã¶ÄŸrendiÄŸi(overfit) iÃ§in deÄŸil yeterince iyi Ã¶ÄŸrenemediÄŸi iÃ§in (test loss >> training loss).1 month ago 5 people like this.Like ReportReply",
    "->  ->  DÃ¼zelttiÄŸiniz iÃ§in teÅŸekkÃ¼r ederim, ben de doÄŸrusunu Ã¶ÄŸrenmiÅŸ oldum bÃ¶ylece..",
    "->  TeÅŸekkÃ¼r ederim ÅŸimdi daha iyi anladÄ±m.1 month ago 2 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "->  uploaded 1 photo",
"quest": "Merhabalar. Ã–ncelikle yardÄ±mlarÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederim. SorularÄ±mÄ± Ã§alÄ±ÅŸmam bittikten sonra teker teker sormak istedim. Gradient Descent optimizasyonunu Ã¶nceden tek seferde sÃ¼rekli yineleme yaparak optimum deÄŸerleri buluyor gibi dÃ¼ÅŸÃ¼nÃ¼yordum. Ama epoch kavramÄ± iÅŸin iÃ§ine girdi ve kafam biraz karÄ±ÅŸtÄ±. Tek veya birden fazla epoch arasÄ±nda ne fark var anlayamadÄ±m. Batch_size olarak verileri rastgele almadÄ±ÄŸÄ±mÄ±zÄ±, tÃ¼m veriseti aldÄ±ÄŸÄ±mÄ±zÄ± dÃ¼ÅŸÃ¼nÃ¼rsek sÃ¼rekli aynÄ± sonucu Ã¼retmez mi? Epochlarda ne oluyor ki deÄŸerlerimizi sÃ¼rekli optimize edebiliyoruz? Bir de diyelim ki her epochda ikiÅŸer iterasyonumuz var. Resimde gÃ¶rdÃ¼ÄŸÃ¼mÃ¼z ÅŸekilde 1. epochta 2 nokta ilerleyip ikincisinde kaldÄ±ÄŸÄ±mÄ±z noktadan devam etmiÅŸ mi oluyoruz? Epochlar arasÄ± geÃ§iÅŸlerde elimizde olanlarÄ± kafamda tam olarak  oturtamadÄ±m.",
"comment": [
    "",
    "->  Benim de burada oturtamadÄ±ÄŸÄ±m ÅŸeyler vardÄ±. Bu linkte tartÄ±ÅŸmÄ±ÅŸtÄ±k kafandaki soru iÅŸaretleri gidecektir. Ä°yi Ã§alÄ±ÅŸmalar dilerim. http://community.globalaihub.com/community/status/1377-1377-1586334163/?t=1586558632#comment.2492.2559.2585.26061 month ago 3 people like this.Like ReportReply",
    "->  ->  Hala gitmedi maalesef. Epoch artÄ±nca belirli bir seviyeye kadar maliyet azalÄ±yor konuÅŸmalardan sadece bunu Ã§Ä±karabiliyorum ki zaten eÄŸitimde bundan bahsediliyor oradan biliyorum ancak Ã¶ÄŸrenmek istediÄŸim tam olarak bu deÄŸil..",
    "->  ->  1 epoch'ta bÃ¼tÃ¼n weightler 1 kere gÃ¼ncelleniyor. 10 epoch yaparsan bÃ¼tÃ¼n hepsini 10 kere gÃ¼ncellemiÅŸ olursun. Yani daha fazla yakÄ±nsarsÄ±n..",
    "->  ->  Her epochun iÃ§inde aÄŸÄ±rlÄ±klar iterasyon baÅŸÄ±na gÃ¼ncelleniyor..",
    "-> ->  aÄŸÄ±rlÄ±k iterasyon baÅŸÄ±na gÃ¼ncelleniyor diye biliyorum hocam.",
    "->  Elinde 200 sayfalÄ±k bir kitap var diye dÃ¼ÅŸÃ¼n. AmacÄ±n bu kitapta yazÄ±lanlarÄ± Ã¶ÄŸrenmek. Bunun iÃ§in bir strateji belirledin kendine. Dedin ki ben bunu 5 sayfalÄ±k parÃ§alara ayÄ±rÄ±p her bir parÃ§ayÄ± Ã§alÄ±ÅŸtÄ±ktan sonra bir sonraki kÄ±sÄ±ma geÃ§eceÄŸim.Batch size dediÄŸimiz ÅŸey modelin parametrelerini gÃ¼ncellemeden Ã¶nce Ã¼zerinde Ã§alÄ±ÅŸÄ±lacak eÄŸitim verisi sayÄ±sÄ±. Yani kitap Ã¶rneÄŸinde bu sayÄ± 5. Modelin y = w.x + b olduÄŸunu kabul edelim.Ä°lk olarak w ve b parametrelerine rasgele deÄŸerler veriyoruz. Sen 5. sayfayÄ± okuduktan sonra w ve b parametrelerini gÃ¼ncelliyorsun. KitabÄ± bitirmen iÃ§in 200/5 = 40 adet batch'in mevcut. Yani model parametreleri 40 kere gÃ¼ncellendi ve kitabÄ± tamamladÄ±n. Epoch tÃ¼m kitabÄ±n tamamlanma sayÄ±sÄ±. Yani ÅŸu ana kadar 1 epoch tamamlanmÄ±ÅŸ oldu. KitabÄ± kaÃ§ kere okuyacaÄŸÄ±mÄ±z bize kalmÄ±ÅŸ. 100 kere okursak kitabÄ± 100 epoch'a ihtiyacÄ±mÄ±z var.1 month ago 7 people like this.Like ReportReply",
    "->  ->  Epochu tamamlayÄ±p 2. epocha geÃ§tiÄŸimde kitaptan 1.epochta Ã¶ÄŸrendiklerimi pekiÅŸtirerek devam ediyorum diyebilir miyiz? 2.Epocha geÃ§erken birinciden elde ettiÄŸimiz modele gÃ¶re loss belirleyip her epochta bunu tekrar mÄ± ediyoruz? Ve 2 nokta atlama olayÄ± hakkÄ±nda bir fikir verebilir misiniz acaba? Bu ÅŸuna mÄ± benziyor bir kitabÄ± bir gÃ¼n okuyup bitirmek yerine bugÃ¼n 2 kez yani iter 5er sayfa okuyup devamÄ±nÄ± ertesi gÃ¼n yani 2.epochta okumak?.",
    "->  ->  Birinci sorunun cevabÄ± evet. 2. Epocha geÃ§erken birinciden elde ettiÄŸimiz modele gÃ¶re loss belirleme ifadesi yerine ÅŸÃ¶yle diyelim: Loss fonksiyonu en baÅŸta tanÄ±mlanÄ±r. Ã–rneÄŸin regresyon problemi iÃ§in ortalama kare hata Ã§ok kullanÄ±lan bir loss fonksiyonudur. Bunu en baÅŸta belirlersin. DolayÄ±sÄ±yla her epoch'ta aynÄ± loss fonksiyonu kullanÄ±lÄ±r. Loss fonksiyonunun deÄŸerlerine gÃ¶re modelin parametreleri gÃ¼ncellenir. Bu gÃ¼ncelleme her bir batch_size tamamlandÄ±ÄŸÄ±nda gerÃ§ekleÅŸir. Kitap Ã¶rneÄŸinde senin ifadenle nokta atlama 5 sayfalÄ±k dilimi tamalayÄ±p diÄŸer 5 sayfaya geÃ§tiÄŸinde oluyor. 1 epoch kitabÄ± bir kere bitirmek demek..",
    "->  Kitap Ã¶rneÄŸinin doÄŸru bir Ã¶rnek olabilmesi iÃ§in tabii ki bilgilerin Ã¼st Ã¼ste giden bilgiler olmadÄ±ÄŸÄ±nÄ± da belirtmem lazÄ±m..",
    "->  peki epoch sayÄ±sÄ±nÄ± Ã§ok fazla artÄ±rÄ±nca ne olur? sanÄ±rÄ±m loss deÄŸeri artÄ±yor ama nedenini anlayamadÄ±m?.",
    "->  ->  Epoch sayÄ±sÄ±nÄ± Ã§ok fazla artÄ±rÄ±rsanÄ±z mutlak sÄ±fÄ±ra yakÄ±nsarsÄ±nÄ±z. EÄŸer loss deÄŸeriniz artÄ±yorsa learning_rate deÄŸerinizi Ã§ok bÃ¼yÃ¼k seÃ§miÅŸsinizdir. DolayÄ±sÄ±yla learning_rate deÄŸerinizi kÃ¼Ã§Ã¼ltmeniz gerektiÄŸini anlayabilirsiniz bÃ¶yle bir durumla karÅŸÄ±laÅŸÄ±rsanÄ±z.1 month ago 4 people like this.Like ReportReply",
    "->  Kurs iÃ§erisinde de ÅŸÃ¶yle bir ifade geÃ§iyordu: \"Epoch sayÄ±sÄ±nÄ± ve batch size arttÄ±rÄ±rken learning rate azaltmak genelde iyidir.\".",
    "->  ->  cevap icin tesekkur ederim, simdi daha iyi anladim..",
    "-> Merhabalar,http://community.globalaihub.com/community/status/190-190-1586531975/?t=1586595736#comment.2872.2860.2900.2877Burada makina Ã¶ÄŸreniminin rastgeleliÄŸi ile alakalÄ± bir paylaÅŸÄ±m olmuÅŸtu. Bu postu iÅŸaret etmemin sebebibu rastgelelik 1 epoch iÃ§in de geÃ§erli 100000 epoch iÃ§inde. Epoch kavramÄ±nÄ± basitÃ§e tanÄ±mlamak gerekirse: elinde bulunan veri seti'ni epoch olarak dÃ¼ÅŸÃ¼nebilirsin. batch_size ise elinde ki veri setini nasÄ±l alt kÃ¼melere ayÄ±racaÄŸÄ±na karar verdiÄŸin deÄŸer, iterasyon ise basitce veri setinini bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼n batch_size ye oranÄ±. Yani elinde bulunan verinin bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼ 1000 olduÄŸunu varsayalÄ±m, batch_size deÄŸerini de 100 bu durumda 10 kÃ¼me elde edebilirsin. Bu 10'da senin iterasyon boyutun oluyor.Ancak epoch, batch_size ve iteration_size Ã¼Ã§lÃ¼sÃ¼ rastgelelikle alakalÄ± kavramlar deÄŸiller. Bu kavramlarÄ± nasÄ±l deÄŸiÅŸtirirsen deÄŸiÅŸtir rastgelelik ortadan kalkmayacaktÄ±r. SonuÃ§larÄ±n her denemede farklÄ± olmasÄ±nÄ±n sebebi kullanÄ±lan yÃ¶ntemin \"Stochastic\" olmasÄ±.Stochastic Gradient Descent' in son cÃ¼mlesi: \"The term \"stochastic\" indicates that the one example comprising each batch is chosen at random.\" ÅŸeklindeydi. Mini-Batch SGD iÃ§in bu cÃ¼mleyi one example kÄ±smÄ±nÄ± batch_size olarak dÃ¼ÅŸÃ¼nebilirsin.Bir eÄŸitim sÃ¼resince bÃ¼tÃ¼n epoclar birbiri ile baÄŸlantÄ±lÄ± olarak iÅŸleyecektir. Yani bir epoch'un Ã§Ä±kÄ±ÅŸ deÄŸeri diÄŸer epoch iÃ§in giriÅŸ deÄŸeri olmaktadÄ±r. Bu ÅŸekilde optimal loss deÄŸerine ulaÅŸana kadar iÅŸlemlere devam edilmektedir.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 8 people like this.Like ReportReply",
    "->  ->  ->  Ã‡ok teÅŸekkÃ¼r ederim kafamdaki tÃ¼m sorulara cevap buldum sayenizde..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba, First Step with TF da yapÄ±lan araÅŸtÄ±rmayÄ± yaptÄ±ÄŸÄ±mda ÅŸÃ¶yle bir sonuÃ§ gÃ¶rdÃ¼m.  Batch Size deÄŸiÅŸtirdiÄŸimde bir farklÄ±lÄ±k gÃ¶remedim. Epoch sayÄ±sÄ±nÄ± arttÄ±rÄ±nca ve learnin rate arttÄ±rÄ±nca  rmse azalma oldu. Genelde hep bu ÅŸekilde mi sonuÃ§lanÄ±yor yoksa bu Ã¶rneÄŸe istisna bir ÅŸey miydi? Bu konuda yardÄ±mcÄ± olabilir misiniz?",
"comment": [
    "",
    "-> yapÄ±lan aÅŸamalarÄ± sonda Ã¶zetlemeye Ã§alÄ±ÅŸmÄ±ÅŸ.",
    "->  bu konuda ben de merak edip farklÄ± denemeler yaptÄ±m ama gÃ¶rdÃ¼ÄŸÃ¼m kadarÄ±yla yalnÄ±zca eÄŸitim hÄ±zÄ±na etki eden bir parametre gibi , ama tabiki kesin bir ÅŸey sÃ¶ylemem .. Daha deneyimli birinden Ã¶ÄŸrenmek daha saÄŸlÄ±klÄ± olur.",
    "-> Merhabalar. Ã–ncelikle Modellerde bir genelleme yapmak Ã§ok fazla sÃ¶z konusu deÄŸil. Hiper parametrelerin hangisinde nasÄ±l bir ayarlama yapacaÄŸÄ±nÄ±z, elinizdeki veri setine gÃ¶re deÄŸiÅŸiklik gÃ¶sterebiliyor. Ã–zellikle batch-size ayarlamalarÄ±, Ã§ok bÃ¼yÃ¼k boyutlarda veri setiniz olduÄŸunda size lazÄ±m olacaktÄ±r. KÃ¼Ã§Ã¼k tuttuÄŸunuzda Ã§ok fazla zaman alacak ve bu da size maliyet anlamÄ±na gelecektir. Gelelim learning rate durumuna. Learning rate iÃ§in de deÄŸer ayarlama Ã¶nemlidir. Ã‡ok kÃ¼Ã§Ã¼k tuttuÄŸunuzda modeliniz Ã¶ÄŸrenmesi iÃ§in Ã§ok fazla epoch gerekebilir hatta Ã¶ÄŸrenmeyebilir. Ã‡ok bÃ¼yÃ¼k tuttuÄŸunuzda da aradan kaÃ§Ä±rabileceÄŸiniz deÄŸerler olabilir bu da Ã¶ÄŸrenme grafiÄŸinizde dalgalanmalara sebep olabilir. Epoch deÄŸeri ise yine verisetine gÃ¶re deÄŸiÅŸebilir. Gereksiz Ã§ok uzun tutulan epoch sayÄ±sÄ± size zaman maliyetine sebep olacaktÄ±r. Hatta buna ek olarak bir sÃ¼re sonra loss deÄŸerinizin artmasÄ±na da sebep olabilir. TÃ¼m bunlardan, aslÄ±nda bir ÅŸÃ¶yle bir Ã§Ä±karÄ±m yapmak gerekiyor. Burada genelleme yapmayÄ±p, her bir parametrenin iÅŸlevinin ne olduÄŸunu kavramaya Ã§alÄ±ÅŸmak gerekiyor. Hepimize iyi kurslar diliyorum.1 month ago 7 people like this.Like ReportReply",
    "->  ->  teÅŸekkÃ¼r ederim Serkan Bey.",
    "->  Merhaba, bu konuyla alakalÄ± Linear Regression with Synthetic Data kÄ±smÄ±nÄ±n sonunda seÃ§enekler Summary of hyperparameter tuning kÄ±smÄ±nda Ã¶zetlenmiÅŸ durumda. Buradaki aslÄ±nda pÃ¼k nokta hyperparametre Ã¼zerindeki deÄŸiÅŸikliklerin ya da etkilerin grafikler Ã¼zerinden okunmasÄ±. Grafikler, hangi parametre Ã¼zerinde ihtiyaÃ§ ya da deÄŸiÅŸikliÄŸe gitmemiz konusunda ipuÃ§larÄ± veriyor..",
    " "
]
},
{
"question_isim": "-> uploaded 3 photos",
"quest": "1- Kodlama PratiÄŸi kÄ±smÄ±nda gerÃ§ek veriler bÃ¶lÃ¼mÃ¼nde (Regression with a Real Dataset ) en son TASK,  Ne yaptÄ±ysam, gerÃ§ek deÄŸerlere yakÄ±n bir tahmin Ã¼rettiremedim. Yapanlar var mÄ±?  2- Bias KavramÄ±nÄ±da tam kafamda oturtmuÅŸ deÄŸilim. Neden acaba? Bu tanÄ±m olarak anlÄ±yorum biasta eÄŸitime giriyor, yani aslÄ±nda bias mantÄ±ÄŸÄ±yla hatalarÄ± Ã¶ÄŸretmek ve onlardan kaÃ§Ä±nmak iÃ§in mi? binevi hatalardan ders Ã§Ä±kar mantÄ±ÄŸÄ±?  3- Birde epoach ile iterasyon arasÄ±ndaki fark nedir? mini batch deÄŸeri 30 olduÄŸunda 1. iterasyonda 30 kÃ¼meyi parÃ§a parÃ§a iÅŸliyor anlamÄ±nda mÄ±? Sonra 2. iterasyonu istersen yine 30 kere Ã¶ÄŸrenmeye devam ediyor.  4- GRAFÄ°KLÄ° ÅEKÄ°LDE, \"some fraction of the gradient's magnitude\" ile kastetiiÄŸi ÅŸey nedir? EklediÄŸi ÅŸeyi anlayamadÄ±m. Terimlere uzaÄŸÄ±z galiba baÄŸdaÅŸtÄ±ramadÄ±m.   Åimdiden Ã§ok teÅŸekkÃ¼r ederimâ€¦ <a class=\"ps-stream-post-more ps-js-content-excerpt-toggle\" href=\"#\">Read more</a></div><div class=\"ps-js-content-full\" style=\"\">1- Kodlama PratiÄŸi kÄ±smÄ±nda gerÃ§ek veriler bÃ¶lÃ¼mÃ¼nde (Regression with a Real Dataset ) en son TASK,  Ne yaptÄ±ysam, gerÃ§ek deÄŸerlere yakÄ±n bir tahmin Ã¼rettiremedim. Yapanlar var mÄ±?  2- Bias KavramÄ±nÄ±da tam kafamda oturtmuÅŸ deÄŸilim. Neden acaba? Bu tanÄ±m olarak anlÄ±yorum biasta eÄŸitime giriyor, yani aslÄ±nda bias mantÄ±ÄŸÄ±yla hatalarÄ± Ã¶ÄŸretmek ve onlardan kaÃ§Ä±nmak iÃ§in mi? binevi hatalardan ders Ã§Ä±kar mantÄ±ÄŸÄ±?  3- Birde epoach ile iterasyon arasÄ±ndaki fark nedir? mini batch deÄŸeri 30 olduÄŸunda 1. iterasyonda 30 kÃ¼meyi parÃ§a parÃ§a iÅŸliyor anlamÄ±nda mÄ±? Sonra 2. iterasyonu istersen yine 30 kere Ã¶ÄŸrenmeye devam ediyor.  4- GRAFÄ°KLÄ° ÅEKÄ°LDE, \"some fraction of the gradient's magnitude\" ile kastetiiÄŸi ÅŸey nedir? EklediÄŸi ÅŸeyi anlayamadÄ±m. Terimlere uzaÄŸÄ±z galiba baÄŸdaÅŸtÄ±ramadÄ±m.   Åimdiden Ã§ok teÅŸekkÃ¼r ederim cevaplarÄ±nÄ±z iÃ§in...</div></div>",
"comment": [
    "",
    " ->  2 - Bias Linear Regression da doÄŸrumuzun (modelimiz) y - ekseni Ã¼zerindeki konumunu ayarlamada yardÄ±mcÄ±dÄ±r. EÄŸer bias deÄŸeri vermezsek modelimiz originden geÃ§mek zorunda kalacaktÄ±r ve bu Ã§oÄŸu veri setinde muhtemelen kÃ¶tÃ¼ sonuÃ§lar elde etmemize neden olacak ve modelimize zarar verecektir. 3 -epoch - iteration - batch size arasÄ±ndaki baÄŸlantÄ± iÃ§in Ã¶rnek: 12 verilik veri setimizde batch size = 12 olsun, bu durumda bir epoch 1 iterasyon ile sonlanacak, bir de batch size = 6 iken deneyelim, bu durumda bir epoch 2 iterasyonda sonlanacaktÄ±r. 4 - belirlediÄŸimiz learning rate sayesinde bulduÄŸumuz sÄ±Ã§rama mesafesi ile eÄŸrimiz Ã¼zerinde sÄ±radaki konumumuzu belirliyoruz, eÄŸri Ã¼zerinde bu ÅŸekilde gezinerek modelimize vermemiz gereken optimum aÄŸÄ±rlÄ±k deÄŸerlerini arÄ±yoruz. Eksik veya yanlÄ±ÅŸ bir bilgi varsa lÃ¼tfen bilgilendirin. Ä°yi Ã§alÄ±ÅŸmalar..",
    "->  ->  Peki o zaman Epoch sayÄ±sÄ±nÄ± arttÄ±rdÄ±ÄŸÄ±mÄ±zda nasÄ±l oluyor? Yine bir Ã¶rnekle aÃ§Ä±klama imkanÄ±n olur mu rica etsem? Sonucunu biliyorum, mantÄ±ÄŸÄ±nÄ± anlamaya Ã§alÄ±ÅŸÄ±yorum ezber olmamasÄ± iÃ§in ğŸ™‚.",
    " ->  -> Batch_size'Ä± sabit tutarak, elimizdeki veri seti 10 epoch ile underfitting, 50 ile optimum , 100 ile overfitting modeller oluÅŸturabilir. Burada iterasyon sayÄ±sÄ± aynÄ± Ã§Ã¼nkÃ¼ batch deÄŸiÅŸmiyor. Overfitting ve underfitting konularÄ±nÄ± biraz daha araÅŸtÄ±rÄ±p, batch, epoch sayÄ±larÄ±nÄ± da Ã§ok yÃ¼ksek veya dÃ¼ÅŸÃ¼k deÄŸerler ile model Ã¼zerinde denediÄŸinde konunun netleÅŸeceÄŸini dÃ¼ÅŸÃ¼nÃ¼yorum..",
    "->  ->  Ã‡ok teÅŸekkÃ¼r ediyorum, tavsiyeni dikkate alacaÄŸÄ±m...",
    "->  1-predict_house_values fonksiyonunda hata olduÄŸunu baÅŸka bir postta yazmÄ±ÅŸlardÄ±. O yÃ¼zden print ettiÄŸiniz feature value, label value deÄŸerleri predicted value deÄŸerlerinin gerÃ§ek deÄŸerleri deÄŸil. Ben predict_house_values fonksiyonunda ÅŸu kÄ±smÄ± deÄŸiÅŸtirdim:print (\"%5.0f %6.0f %15.0f\" % (training_df[feature][10000+i],training_df[label][10000+i],predicted_values[i][0] ))Sonra sizin yazdÄ±ÄŸÄ±z deÄŸerler ile eÄŸittim modeli. Loss function zaten nerdeyse deÄŸiÅŸmiyor yani zaten olabilecek en iyi score bulmuÅŸsunuz gibi gÃ¶zÃ¼kÃ¼yor. Root_mean_square 83 civarÄ± ve sonuÃ§lar da ona uygun. Tek Ã¶zellik ile tahmin yapÄ±ldÄ±ÄŸÄ±nÄ± gÃ¶z Ã¶nÃ¼ne alÄ±nca Ã§ok iyi bir score beklemek doÄŸru deÄŸil zaten..",
    "-> ->  Ã‡ok teÅŸekkÃ¼r ederimm..",
    "->  4-\"some fraction of the gradient's magnitude\" dediÄŸi resimdeki kÄ±rmÄ±zÄ± ok. w parametresi gÃ¼ncellenirken w:=w-learning rate*(Loss fonksiyonunun w parametresine gÃ¶re kÄ±smi tÃ¼revi). \"Loss fonksiyonunun w parametresine gÃ¶re kÄ±smi tÃ¼revi\" kÄ±smÄ± gradyantÄ±n genliÄŸi oluyor. some kelimesini kullanmasÄ±nÄ±n nedeni learning rate faktÃ¶rÃ¼nden kaynaklÄ± olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yorum. Ã‡Ã¼nkÃ¼ parametreyi gÃ¼ncellerken genliÄŸi learning rate ile Ã§arptÄ±ÄŸÄ±n iÃ§in scale etmiÅŸ oluyorsun. kÄ±rmÄ±zÄ± ok learnin rate*magnitude oluyor yani. bu deÄŸer sonra w deÄŸerinin o anki olduÄŸu konumunun Ã¼zerine gradyanÄ±n negatif yÃ¶nÃ¼nde(loss functionun azalmasÄ± iÃ§in) ekleniyor ve yeni w deÄŸeri bulunuyor. Biraz karmaÅŸÄ±k oldu sanÄ±rÄ±m ama parametre gÃ¼ncelleme ile ilgili gÃ¶rsel ekledim daha aÃ§Ä±klayÄ±cÄ± olabilir.1 month ago 2 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "->  uploaded 1 photo",
"quest": "Merhabalar,  Linear Regression with a Real Dataset kÄ±smÄ±nda aklÄ±ma takÄ±lan bir kÄ±smÄ± sormak istiyorum. Batch deÄŸerleri n e baÄŸlÄ± olarak training_df 'in o aralÄ±ktaki deÄŸerlerinden oluÅŸuyorken ve bu deÄŸerleri  alÄ±p prediction iÅŸlemi gerÃ§ekleÅŸtiriliyorken aÅŸaÄŸÄ±da for iÃ§erisinde indexi direkt olarak i kabul etmiÅŸ.Burada olmasÄ± gereken 10000+i deÄŸil midir(Sadece training_df  iÃ§in )? Yoksa ben mi bir ÅŸeyleri kaÃ§Ä±rdÄ±m.",
"comment": [
    "",
    "->  Merhabalar,Evet dediÄŸiniz gibi olmalÄ±, tahmin iÃ§in kullandÄ±ÄŸÄ± deÄŸerler yerine veri setinin ilk deÄŸerlerini almÄ±ÅŸ. YazÄ±m sÄ±rasÄ±nda gÃ¶zden kaÃ§Ä±rÄ±lmÄ±ÅŸ olmalÄ±.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 4 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba benim sorum NumPy Ultraquick tutorial ile  alakalÄ±. \"np.random.random([6])\" bu kod satÄ±rÄ± bize 0'la 1 arasÄ±ndaki  random floating deÄŸerlerini buluyor.Peki -2 ile +2 arasÄ±ndaki floating deÄŸerlerini nasÄ±l bulacaÄŸÄ±z?",
"comment": [
    "",
    "->  0 ile 1 arasÄ±nda dÃ¶dÃ¼ÄŸÃ¼ iÃ§in (np.random.random() * 4) - 2 yapÄ±lacak. ÅÃ¶yle dÃ¼ÅŸÃ¼n en kÃ¼Ã§Ã¼k deÄŸer 0 olabilir ve bizim yazdÄ±ÄŸÄ±mÄ±z denklemde 0*4 - 2 = -2 oluyor . En bÃ¼yÃ¼k deÄŸer iÃ§in ise 1 olabilir, 1 ise 1*4 - 2 = 2 olabilir. Bu ÅŸekilde dÃ¼ÅŸÃ¼nmemiz gerekiyor. Bu denklemi nasÄ±l elde ediyoruz dersen hiÃ§ araÅŸtÄ±rmadÄ±m ama mantÄ±ÄŸÄ±m ÅŸu yÃ¶nde. en kÃ¼Ã§Ã¼k sÄ±fÄ±r gelceÄŸi iÃ§in aralÄ±ktaki en kÃ¼Ã§Ã¼k sayÄ±yÄ± + olarak yazmak ve istenilen fark ile Ã§arpmak. Ã‡arpmak dediÄŸim yukarÄ±da gÃ¶sterdiÄŸim ÅŸekilde tÃ¼m terimi deÄŸil..",
    "->  yada ÅŸu ÅŸekilde bir kÄ±sayolu var : np.random.randint(low = -2, high =2, size=(6)) -2 ve 2 arasÄ±nda 6 deÄŸer atar1 month ago 2 people like this.Like ReportReply",
    "->  ->  Ama bu sadece bize tam sayÄ±larÄ± veriyor, bize ondalÄ±klÄ± sayÄ±lar lazÄ±m..",
    "->  teÅŸekkÃ¼rler.",
    "->  np.random.uniform(low=-2, high=2)1 month ago 2 people like this.Like ReportReply",
    "->  import numpy as np4*np.random.random_sample((5,))-21 month ago 2 people like this.Like ReportReply",
    "->  ->  Bu konu aralÄ±k aritmetiÄŸi (interval arithmetic) ile alakalÄ±. BildiÄŸimiz aritmetik iÅŸlemler aralÄ±klar Ã¼zerinde de geÃ§erli. AslÄ±nda ÅŸÃ¶yle bir denklem kuruyoruz x.(0,1) + y = (-2,2) . Burada (0,1) 0 1 aralÄ±ÄŸÄ±nÄ± gÃ¶steriyor.Denklemin Ã§Ã¶zÃ¼mÃ¼x.0 + y = -2x.1 + y = 2den x =4 y=-2 olarak bulunuyor. DolayÄ±sÄ±yla (np.random.random() * 4) - 2 iÅŸlemi bize istediÄŸimiz aralÄ±ÄŸÄ± veriyor.1 month ago 6 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar,  Linear Regression with Synthetic Data Ã§alÄ±ÅŸma kodunda Task 2 'de epoch sayÄ±sÄ±nÄ± artÄ±rma yapÄ±lmasÄ± isteniyor.Ben 200 olarak yaptÄ±ÄŸÄ±mda her Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±mda farklÄ± grafikler elde ediyorum.Yani aynÄ± parametreler ile modeli eÄŸitirken her run edildiÄŸinde farklÄ± sonuÃ§ Ã§Ä±kabiliyor mu?O zaman bir model iÃ§in optimum value leri nasÄ±l saptayacaÄŸÄ±z?Epoch 200 iken model converge oladabiliyor,olmayadabiliyor.  TeÅŸekkÃ¼rler",
"comment": [
    "",
    "-> Merhaba,Makina Ã–ÄŸrenimi algoritmalarÄ± kararsÄ±z yapÄ±lar olmasÄ± sebebiyle her yeni baÅŸlangÄ±Ã§ta farklÄ± sonuÃ§lara ulaÅŸmaktadÄ±r. Bunun sebebi de rassallÄ±ktan(randomness) dolayÄ± olmaktadÄ±r. Yani algoritmamÄ±z her ne kadar aynÄ± data ile Ã§alÄ±ÅŸÄ±yor olsa bile datanÄ±n sÄ±ralamasÄ±ndaki deÄŸiÅŸim sonuÃ§larÄ± etkilemektedir. EÄŸer her seferinde aynÄ± sonuÃ§larÄ± almak istiyorsanÄ±z random seed deÄŸeri verebilirsiniz. Bu deÄŸer her seferinde aynÄ± deÄŸeri Ã¼retmek iÃ§in sabitlenmektedir. EÄŸer bu deÄŸere sabit bir sayÄ± tanÄ±mlamamÄ±ÅŸsak varsayÄ±lan olarak sistem zamanÄ±nÄ± kullanÄ±r. Bu yÃ¼zden her seferinde farklÄ± sonuÃ§lar elde etmemize sebep olmaktadÄ±r.import numpy as npnp.random.seed(42)tf.random.set_seed(42)YukarÄ±daki satÄ±rlarÄ± kodunuza eklerseniz her seferinde tutarlÄ± bir ÅŸekilde aynÄ± sonuÃ§larÄ± alabilirsiniz.42 olarak belirttiÄŸim deÄŸer keyfi olarak seÃ§ilebilir, sabit kaldÄ±ÄŸÄ± sÃ¼rece sonuÃ§lar deÄŸiÅŸmeyecektir.Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 7 people like this.Like ReportReply",
    "->  ->  Ã‡ok teÅŸekkÃ¼rler:).",
    "-> Merhaba,model.fit metodunu incelediÄŸimde model.fit metodunun shuffle isminde bir parametre aldÄ±ÄŸÄ±nÄ± ve bu parametre deÄŸerinin default olarak TRUE olduÄŸunu gÃ¶rdÃ¼m. Bu parametrenin aÃ§Ä±klamasÄ± ise :\"Shuffle the training data on each epoch\" yani her epochta eÄŸitim datasÄ±nÄ± karÄ±ÅŸtÄ±rÄ±r bu yÃ¼zden veriler karÄ±ÅŸtÄ±ÄŸÄ± iÃ§in her algoritma Ã§alÄ±ÅŸmasÄ±nda aynÄ± sonucu elde edemeyiz. AraÅŸtÄ±rdÄ±ÄŸÄ±m kadarÄ±yla Keras'Ä±n model.compile() metodu otomatik olarak bu shuffle deÄŸerini true yapmaktadÄ±r. (Kodu https://github.com/keras-team/keras/blob/7a39b6c62d43c25472b2c2476bd2a8983ae4f682/keras/engine/training.py#L1584 linkinden inceleyebilirsiniz.). Bu shuffle'Ä± False yapabilmek iÃ§in Ã¶nerilenler arasÄ±nda Keras'tan Ã¶nce numpy kÃ¼tÃ¼phanesini import etmek ve ederken de seed metodunu Ã§aÄŸÄ±rmak var. Yani;\"import numpy as npnp.random.seed(1337)from keras.models import Sequential\"tarzÄ±nda bir yaklaÅŸÄ±mda bulunmak. Buradaki seed metodu her Ã§aÄŸrÄ±ldÄ±ÄŸÄ±nda aynÄ± random sayÄ±larÄ± dÃ¶ner. Yine araÅŸtÄ±rdÄ±ÄŸÄ±ma gÃ¶re Keras'ta bu shuffle randomness'Ä± kullanabilmenin yolu numpy kÃ¼tÃ¼phanesindeki random.seed metodunu kullanmak. EksiÄŸim var ise eklemelere aÃ§Ä±ÄŸÄ±m ğŸ™‚ iyi Ã§alÄ±ÅŸmalar.",
    "keras-team/kerasgithub.comDeep Learning for humans. Contribute to keras-team/keras development by creating an account on GitHub.1 month ago 6 people like this.Like ReportReply",
    "->  ->  Merhaba,Her ne kadar shuffle parametresini False yapsak ve np.random.seed(1337), bir deÄŸere sabitlesek bile, tensorflow iÃ§in random seed'i set etmez isek yeterli olmamakta. (tf.random.set_seed(1337)) ile tutarlÄ±lÄ±k saÄŸlanmakta.Edit: Hatta sadece tf.random.set_seed(1337), model.fit() fonksiyonunun shuffle parametresinin True ya da False olmasÄ±na bakÄ±lmasÄ±zÄ±n tutarlÄ±lÄ±ÄŸÄ± saÄŸlamakta, ÅŸimdi test ederek sonuÃ§larÄ± inceledim.1 month ago 3 people like this.Like ReportReply",
    "->  ->  Merhaba,CevabÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederim. Evet, bu shuffle deÄŸerini model.compile metodunda kendisi eziyorYukarÄ±da verdiÄŸim bilgi kaynaklarÄ±nÄ± ÅŸÃ¶yle paylaÅŸabilirim. (https://github.com/keras-team/keras/issues/2479#issuecomment-213892402 - https://github.com/keras-team/keras/issues/2743#issuecomment-219777627). Burada numpy seed'inin randomness'Ä±n kalkmasÄ± iÃ§in yeterli olduÄŸundan bahsediliyor. EÄŸer bu bilgiler hatalÄ± veya eksikse ekleme ve bilgilendirme iÃ§in teÅŸekkÃ¼r ederim, iyi Ã§alÄ±ÅŸmalar dilerim.",
    "Each time I run the Keras, I get different result. Â· Issue #2743 Â· keras-team/kerasgithub.comEach time I run the Keras, I get inconsistent result. Is there any way that it converges to the same solution as we have 'random_state' in sklearn which helps us getting the same solution h...1 month ago 2 people like this.Like ReportReply",
    "->  ->  tensorflow'un da numpy random seed'i eziyor olmasÄ± ya da hiÃ§ gÃ¶rmÃ¼yor olmasÄ± muhtemel, bahsettiÄŸiniz kaynaÄŸÄ± ben de inceledim ancak test ettiÄŸim zaman tutarlÄ±lÄ±ÄŸÄ± saÄŸlamadÄ±ÄŸÄ±nÄ± farkettim. SonrasÄ±ndahttps://stackoverflow.com/questions/46119435/keras-lstm-why-different-results-with-same-model-same-weightsburada tensorflow iÃ§in de seeed deÄŸeri atandÄ±ÄŸÄ±nÄ± gÃ¶rdÃ¼m. DenediÄŸim zaman sorunsuz tutarlÄ±lÄ±k saÄŸlandÄ±.Kaynak iÃ§in teÅŸekkÃ¼rler. iyi Ã§alÄ±ÅŸmalar ğŸ™‚",
    "Keras LSTM - why different results with \"same\" model & same weights?stackoverflow.com(NOTE: Properly fixing the RNG state before each model creating as described in comment in comment practically fixed my problem, as within 3 decimals results are consistent, but they aren't exactly...1 month ago 5 people like this.Like ReportReply",
    "->  ->  KaynaÄŸÄ±nÄ±zÄ± inceledim, bilgilendirme ve ekleme iÃ§in tekrar teÅŸekkÃ¼rler iyi Ã§alÄ±ÅŸmalar ğŸ™‚1 month ago 2 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": " ->  uploaded 1 photo",
"quest": "Merhaba, iÅŸaretlediÄŸim kÄ±smÄ± anlamakta sorun yaÅŸÄ±yorum. \"smooth out noisy gradients\"  derken ne demeye Ã§alÄ±ÅŸÄ±yor ve Noisy Gradient kavramÄ± nedir?",
"comment": [
    "",
    "->  Merhaba,Noisy data verisetimizdeki anlamsÄ±z verilere denir. Bu anlamsÄ±z veriler tahminleri olumsuz etkiler. Ã–rneÄŸin modelimizi eÄŸitirken oda sayÄ±sÄ± 100 olan bir ev veri Ã¶rneÄŸi soktuÄŸumuzda Ã§Ä±kacak olan lineer grafiÄŸimiz (lineer olduÄŸunu varsayÄ±yorum) olmasÄ± gerekenden daha az performanslÄ± olacaktÄ±r Ã§Ã¼nkÃ¼ diÄŸer oda sayÄ±sÄ± deÄŸerleri muhtemelen 1-10 arasÄ±nda olacaktÄ±r. AnladÄ±ÄŸÄ±m kadarÄ±yla burada demek istediÄŸi redundancy i batch size arttÄ±ÄŸÄ±nda artan bir ÅŸey olarak tanÄ±mlamÄ±ÅŸ ve batch size'Ä±nÄ±z arttÄ±kÃ§a bu artÄ±ÅŸ noisy (gÃ¼rÃ¼ltÃ¼lÃ¼) iÃ§erikleri yumuÅŸatmak iÃ§in kullanÄ±ÅŸlÄ± olabilir demek istemiÅŸ. Noisy Gradient dediÄŸi anladÄ±ÄŸÄ±m kadarÄ±yla Noisy Data iÃ§in kullanÄ±lmÄ±ÅŸ. YanlÄ±ÅŸÄ±m var ise dÃ¼zeltilmesinden memnun olurum ğŸ™‚ Ä°yi Ã§alÄ±ÅŸmalar dilerim.1 month ago 7 people like this.Like ReportReply",
    " ->  ->  teÅŸekkÃ¼r ederim, anladÄ±m ÅŸimdi..",
    "->  Noisy gradient, resmin saÄŸÄ±ndaki gibi loss fonksiyonumuzun dengesiz ÅŸekilde deÄŸerler almasÄ±na deniyor. EÄŸer minibatch-size'Ä± Ã§ok dÃ¼ÅŸÃ¼k seÃ§ersek veya stochastic gradient descent kullanÄ±yorsak(zaten SGD'de batch-size=1 oluyordu) loss'u hesaplarken Ã§ok az Ã¶rnek kullandÄ±ÄŸÄ±mÄ±z iÃ§in; loss deÄŸeri bir iterasyonda birden yÃ¼kselip diÄŸer iterasyonda birden azalabilir. Ã‡Ã¼nkÃ¼ loss deÄŸerimizi Ã§ok az miktarda Ã¶rneÄŸi deÄŸerlendirip gÃ¼ncelliyoruz.1 month ago 7 people like this.Like ReportReply",
    " ->  ->  teÅŸekkÃ¼r ederim..",
    " "
]
},
{
"question_isim": "-> uploaded 1 photo",
"quest": "Merhaba,  First Step with TF kÄ±smÄ±ndaki programming exercises bÃ¶lÃ¼mÃ¼ndeki Ã¶rnekleri aÃ§mak Ã¼zre Colab uygulamasÄ±na girmek istedigimde aÅŸaÄŸÄ±daki \"failed to fetch \" mesajÄ±yla karÅŸÄ±laÅŸtÄ±m.YardÄ±mcÄ± olabilcek olan varmÄ± Ã¶rnek uygulamalara eriÅŸebilmem iÃ§in ? TeÅŸekkÃ¼rler",
"comment": [
    "",
    "->  Merhaba sizin internet eriÅŸiminiz yada Colab uygulamasÄ±ndaki serverlardaki bir sorundan olabilir. Bence bir sÃ¼re sonra tekrar deneyin aÃ§Ä±lacaktÄ±r..",
    "-> ->  Merhaba ,chromeda yine acÄ±lmadÄ± ama firefox kurdum onda sorunsuz acÄ±ldÄ± cok teÅŸekkÃ¼rler.",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Az Ã¶nce kursun haftalÄ±k kÄ±smÄ±nÄ± bitirdim ama aklÄ±ma takÄ±lan bir nokta var. Biz weightleri gradient descent ile ayarlarken ÅŸu ÅŸekil bir denklem kullanÄ±yoruz: w1 = w1 - (learning_rate)*(costun_w1e_gÃ¶re_tÃ¼revi) Bu denkleme gÃ¶re n tane featurimiz olsa hepsinde aynÄ± learning rati mi kullanÄ±caÄŸÄ±z. Learning rateye ayar Ã§ekerken bunu tek bir featureye gÃ¶re yapÄ±yorduk bu feature uyan learning rate bÃ¼tÃ¼n featurelara uyar mÄ± deriz yoksa learning rate iÃ§in bÃ¼tÃ¼n featurelara karÅŸÄ±lÄ±k gelen learning ratelerin olduÄŸu bir vektÃ¶r mÃ¼ oluÅŸturmamÄ±z gerekiyor? UmarÄ±m iyi anlatabilmiÅŸimdir.",
"comment": [
    "",
    "-> Merhaba. Learning rate gradient decent algoritmasÄ±nÄ±n bir hiperparametresidir(hiperparametreleri modeli kuran kiÅŸinin seÃ§ebileceÄŸi parametreler olarak dÃ¼ÅŸÃ¼nebilirsiniz. Ã¶rn: K-MEANS algoritmasÄ±ndaki k deÄŸeri, garadient decent de learning rate vb. Model parametreleri ise tahmin fonsiyonumuzdaki feature'larÄ±n katsayÄ±larÄ± bigi aslÄ±nda bulmaya Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z ÅŸeylerdir). Gradient decent ise direk tÃ¼rev alarak optimizasyon yÃ¶nteminin alternatifidir. feature ve sample sayÄ±sÄ±nÄ±n Ã§ok fazla olduÄŸu veri setlerinde direk tÃ¼rev alma yÃ¶ntemi Ã§ok uzun sÃ¼rdÃ¼ÄŸÃ¼ iÃ§in gradient decent kullanÄ±lÄ±r. Her iterasyonda optimum noktaya yaklaÅŸabilmek iÃ§in de learning rate belirleyerek ilerleriz. AsÄ±l sorunuzu en sonda cevaplayayÄ±m. Evet her aÄŸÄ±rlÄ±k iÃ§in tek bri tane learning rate belirleriz. AÄŸÄ±rlÄ±klarÄ±n farklÄ± olmalarÄ±nÄ±n bir Ã¶nemi yoktur. Ã‡Ã¼nkÃ¼ her iterasyonda formÃ¼lÃ¼n doÄŸasÄ± gereÄŸi hata fonksiyonun mininmum noktasÄ±na yaklaÅŸmaya devam ederiz. Tabi ki learning rate'i optimum noktayÄ± atlayacak kadar bÃ¼yÃ¼k seÃ§mediysek.1 month ago 4 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba, Validation Set kÄ±smÄ±ndaki pratikte \"test setini ve doÄŸrulama setini nasÄ±l bÃ¶ldÃ¼ÄŸÃ¼nÃ¼z Ã¶nemli deÄŸil \" diyor fakat Validation set ile test boyutu aynÄ± olmasÄ± gerekmez mi ? Ã–rneÄŸin valid set size % 20 ise test set' de %20 olmasÄ± gerekmez mi? SonuÃ§ta modele en Ã§ok girdi nereden veriliyorsa o tarafta Ã¶ÄŸrenme artmasÄ± sÃ¶z konusu olur.",
"comment": [
    "",
    "->  Merhaba,Validation Set'de aslÄ±nda bir test settir. DolayÄ±sÄ±yla Test Set'in karÅŸÄ±lamasÄ± beklenen iki ÅŸartÄ±;- Ä°statistiksel olarak anlamlÄ± sonuÃ§lar ifade edecek kadar bÃ¼yÃ¼k mÃ¼?- BÃ¼tÃ¼n seti(trainin data) temsil edebiliyor mu?karÅŸÄ±lamalÄ±. BÃ¼tÃ¼n bunlarÄ± saÄŸladÄ±ÄŸÄ± sÃ¼rece test ve validation setlerini nasÄ±l bÃ¶ldÃ¼ÄŸÃ¼mÃ¼zÃ¼n Ã¶nemi olmayacaktÄ±r.1 month ago 11 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar herkese, BugÃ¼n genel tekrar yaparken kafama birkaÃ§ soru takÄ±ldÄ± onlarÄ± sormak istedim.  1-) Uygulama kÄ±smÄ±nda \"epoch\" ve \"batch size\" parametrelerini arasÄ±ndaki iliÅŸkiyi tam kavrayamadÄ±m.  2-) Gene uygulama kÄ±smÄ±nÄ±nÄ± son kÄ±smÄ±nda \"correlation matrix\" den bahsedilmiÅŸ, bir takÄ±m deÄŸerler Ã¼zerinden (1.0,0.0 ve -1.0 gibi) yorum yapÄ±lÄ±yor. O deÄŸerlerden nasÄ±l bir yorum Ã§Ä±karabiliriz ? 3-) Son olarak da, \"Generalization\" kÄ±smÄ±nda diagramda \"Hidden truth\" diye bir kavram var sanÄ±rÄ±m bizim referansÄ±mÄ±z ama onun kaynaÄŸÄ± ne onu tam kavrayamadÄ±m. YardÄ±mcÄ± olursanÄ±z sevinirim.",
"comment": [
    "",
    "->  1- bir epoch veri setimizdeki tÃ¼m verileri iÅŸlememiz anlamÄ±na geliyor, batch-size ise gradient descent grafiÄŸini hatÄ±rlarsanÄ±z orda adÄ±m adÄ±m minimuma doÄŸru gitmeye Ã§alÄ±ÅŸÄ±rken veri setimizdeki kaÃ§ Ã¶rneÄŸi deÄŸerlendirerek loss hesaplayÄ±p parametreleri gÃ¼ncelleyeceÄŸimizi ifade ediyor. Mesela 1000 verimiz olsun, 100 batch-size ve 10 epoch belirleyelim. 1 epoch iÃ§in 10 iterasyon gerekiyor ( veri sayÄ±sÄ± / batch-size). Toplamda 10 epoch ise 10x10 = 100 iterasyon gerekiyor.2- correlation matrix ise feature'larÄ±mÄ±zÄ±n birbirleriyle ne kadar iliÅŸkili olduÄŸunu gÃ¶steriyor. 1 olmasÄ± birbirlerine tamamen baÄŸlÄ± olduklarÄ±nÄ± -1 olmasÄ± ise tamamen zÄ±t olduklarÄ±nÄ± gÃ¶steriyor. Mesela oda sayÄ±sÄ± ve evin metrekaresi sÃ¼tunlarÄ±mÄ±z olsun. BunlarÄ±n correlation deÄŸerlerinin 1'e yakÄ±n olmasÄ± beklenir. Fakat evin yaÅŸÄ± sÃ¼tunu ile evin deÄŸeri sÃ¼tunlarÄ±nÄ±n correlation deÄŸerlerinin -1'e yakÄ±n olmasÄ± beklenir. UmarÄ±m aÃ§Ä±klayabildim.1 month ago 6 people like this.Like ReportReply",
    "->  ->  teÅŸekkÃ¼rler sanÄ±rÄ±m daha iyi anladÄ±m verdiÄŸiniz Ã¶rneklerle..",
    "-> 1. soruna gÃ¼zel cevap verebileceÄŸimi dÃ¼ÅŸÃ¼nmÃ¼yorum.2. soru benim de aklÄ±ma takÄ±lmÄ±ÅŸtÄ±, internette biraz araÅŸtÄ±rma yaptÄ±ktan sonra bÃ¶yle bir gÃ¶rselle karÅŸÄ±laÅŸtÄ±m, (https://en.wikipedia.org/wiki/Correlation_and_dependence#/media/File:Correlation_examples2.svg) anlamama yardÄ±mcÄ± oldu. Correlation deÄŸerinin 0 olmasÄ± aralarÄ±nda lineer bir baÄŸÄ±ntÄ± olmadÄ±ÄŸÄ±nÄ± gÃ¶steriyor sanÄ±rÄ±m. Yani dÃ¼zenli olarak \"artarsa artar, azalÄ±rsa azalÄ±r\" gibi yorum yapamÄ±yoruz anlamÄ±na geliyor. (yanlÄ±ÅŸÄ±m varsa lÃ¼tfen dÃ¼zeltin)3. sorun iÃ§in ÅŸÃ¶yle bir ÅŸey diyebilirim, onun verdiÄŸi Ã¶rnekten devam edecek olursak, makine Ã¶ÄŸrenmesi modelimizi belirli bir veri setiyle besleyeceÄŸiz, bu kÄ±sÄ±tlÄ± bir veri seti olacak. Elimizdeki verilere %100 uyuyor olmasÄ± \"hidden truth\"tan gelecek yeni verilerle uyuÅŸmayabilir. GerÃ§ek hayat verilerinde mutlaka anomaliler olur. KullandÄ±ÄŸÄ±Ä±mÄ±z verileri de %100 doÄŸrulukla tahmin eden bir model de bu yÃ¼zden dÃ¼zgÃ¼n bir ÅŸekilde \"generalized\" tahminlerde bulunamaz. Ã‡Ã¼nkÃ¼ makinemizi beslediÄŸimiz veri setinde de anomaliler olacaktÄ±r. AsÄ±l amacÄ±mÄ±z elimizdeki veri setini %100 doÄŸrulukla tahmin etmek deÄŸil, \"hidden truth\"a olabildiÄŸince yakÄ±nsamaktÄ±r. KarÄ±ÅŸÄ±k oldu kusura bakma, umarÄ±m anlatabilmiÅŸimdir ğŸ™‚1 month ago 4 people like this.Like ReportReply",
    "->  ->  TeÅŸekkÃ¼r ederim yanÄ±tÄ±n iÃ§in fotoÄŸraf anlamamda yardÄ±mcÄ± oldu..",
    "->  ->  Rica ederim..",
    "-> epoch, batch ve batch size iÃ§in oldukÃ§a aÃ§Ä±klayÄ±cÄ± bir makale: https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/.",
    "-> 2. Sorunuz iÃ§in sunu sÃ¶yleyebilirim. Korelasyon katsayÄ±sÄ± iki deÄŸiÅŸken arasÄ±ndaki iliÅŸkinin yÃ¶nÃ¼ ve derecesi hakkÄ±mda bilgi verir. Regresyon analizinde model kurarken baÄŸÄ±msÄ±z deÄŸiÅŸkenlerinizin baÄŸÄ±mlÄ± deÄŸiÅŸkenimizle ilgili olan deÄŸiÅŸkenler olmasÄ± Ã¶nemlidir. Yapilan uygulamada oda sayÄ±sÄ± ve nÃ¼fus baÄŸÄ±mlÄ±.deÄŸiÅŸkenimiz olan medyan ev deÄŸeri ile modelleri Ã§ok basarili Ã§Ä±kmamÄ±ÅŸtÄ±r. EÄŸer model anlamlÄ±ligina ve parametre tahminlerine bakilsaydi bÃ¼yÃ¼k ihtimalle anlamsÄ±z Ã§Ä±karlardÄ±.DolayÄ±sÄ±yla uygulamada daha sonra baÄŸÄ±mlÄ± deÄŸiÅŸkenle acaba hangi deÄŸiÅŸkenler (yani features) arasÄ±nda yakÄ±n iliÅŸki vardÄ±r sorusuna bakmak iÃ§in korelasyon incelemesi yapÄ±ldÄ±. SonuÃ§ olarak baÄŸÄ±mlÄ± deÄŸiÅŸken ile yani medyan ev deÄŸeri ile medyan gelir arasÄ±nda pozitif yÃ¶nde 0.70 lik bir iliÅŸki bulduk. Bu deÄŸiÅŸkeni modelimizde kullanabiliriz anlamÄ±na geliyor. Ã‡Ã¼nkÃ¼ 0.70 yeterli bir korelasyon olarak deÄŸerlendirilebilir.Zaten regresyon analizinin Ã¶zÃ¼ de biraz koreasyonlarla ilgilidir. BaÄŸÄ±mlÄ± deÄŸiÅŸkenimizi etkilemeyecek deÄŸiÅŸkeni modele katmanÄ±n anlamÄ± olmaz dÃ¼ÅŸÃ¼ncesindeyim. Biraz uzun oldu ama umarÄ±m faydasÄ± olur..",
    " "
]
},
{
"question_isim": " -> ",
"quest": "Herkese merhaba. Benim kafamÄ± takÄ±lan bir soru vardÄ±. Learning rate, loss, cost function ve gradient arasÄ±nda nasÄ±l bir iliÅŸki var? Bu kavramlarÄ± tam olarak oturtmak istiyorum. CevaplarÄ±nÄ±z iÃ§in ÅŸimdiden teÅŸekkÃ¼r ederim ????",
"comment": [
    "",
    "-> Merhaba,Yapay Zeka'da modelimizi eÄŸitir ve ilerideki tahminlerimizi bu modeli kullanarak gerÃ§ekleÅŸtiririz. Elimizde bir modelimiz olsun. Bu model evin oda sayÄ±sÄ±na gÃ¶re evin fiyatÄ±nÄ± tahmin etmeye Ã§alÄ±ÅŸsÄ±n. Modelimizi eÄŸittikten sonra modelimize oda sayÄ±sÄ± vererek bir tahminde bulunmasÄ±nÄ± isteyelim. Oda sayÄ±sÄ±nÄ±n tekabÃ¼l ettiÄŸi gerÃ§ek fiyat deÄŸeri ile modelimizin tahmin ettiÄŸi deÄŸer arasÄ±ndaki fark \"loss\" olmaktadÄ±r.Cost function ise modelimizdeki tÃ¼m tahminlerin hata oranlarÄ±nÄ± bize ortalama olarak dÃ¶ndÃ¼rÃ¼r ve biz modelimizdeki toplam hata oranÄ±nÄ± bu fonksiyon sayesinde bulabiliriz. Bir nevi modelimizin doÄŸruluÄŸudur(accuracy).Gradient Descent AlgoritmasÄ± ise bahsettiÄŸimiz bu cost function'Ä± minimize etmek iÃ§in kullanÄ±lÄ±r. Bunu da cost function deÄŸerinin derivative'ini alÄ±p theta deÄŸerinden Ã§Ä±kararak yapar. http://community.globalaihub.com/community/status/1043-1043-1586253928/#comment.2355.2369.2369 bu linte gradient descent algoritmasÄ±nÄ± ve learning rate'i anlatmaya Ã§alÄ±ÅŸtÄ±m ama Learning Rate'den de kÄ±saca bahsetmem gerekirse, Gradient Descent fonksiyonu cost function'Ä±mÄ±zÄ± minize ederken minimum deÄŸere atacaÄŸÄ± adÄ±m bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼ simgeliyor. Learning deÄŸeri Ã§ok kÃ¼Ã§Ã¼k bir deÄŸer verilirse minimuma yaklaÅŸmasÄ±, kÃ¼Ã§Ã¼k adÄ±mlar atacaÄŸÄ± iÃ§in Ã§ok uzun sÃ¼recek, eÄŸer Ã§ok bÃ¼yÃ¼k verlirse de belki minimumu aÅŸacaÄŸÄ± iÃ§in de yanlÄ±ÅŸ Ã§alÄ±ÅŸacaktÄ±r. Bu bahsettiÄŸim aÃ§Ä±klamayla ilgili  -> 'in gÃ¼zel bir Ã¶rneÄŸi de ÅŸurada mevcut: http://community.globalaihub.com/community/status/664-664-1586282486/#comment.2420.2475.2475UmarÄ±m aÃ§Ä±klayÄ±cÄ± olmuÅŸtur. Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 9 people like this.Like ReportReply",
    "->  Ben de kÄ±sa aÃ§Ä±klamalarÄ±nÄ± yazacaÄŸÄ±m. Cost function dediÄŸimiz aslÄ±nda modelimizin girdi ve Ã§Ä±ktÄ±larÄ± arasÄ±ndaki iliÅŸkiyi tahmin etme aÃ§Ä±sÄ±ndan ne kadar hatalÄ± olduÄŸudur. Loss dediÄŸimiz kavram ele alÄ±nan bir girdiden Ã§Ä±kan tahmin ile bu girdinin gerÃ§ek Ã§Ä±ktÄ±sÄ±(etiketi) arasÄ±ndaki fark. Learning rate : Ã–ÄŸrenme aÅŸamasÄ±nda aÄŸÄ±rlÄ±klarÄ± gÃ¼ncellerken kullanacaÄŸÄ±mÄ±z katsayÄ±, kÄ±saca ne kadar Ã¶ÄŸreneceÄŸim sorusuna lr ile cevap verilebilir.1 month ago 6 people like this.Like ReportReply",
    " ->  Harika cevaplarÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederim. ???? Ã‡ok aÃ§Ä±klayÄ±cÄ± oldu...",
    "-> cost functionÄ± loss functionlarÄ±n toplamÄ± olarakta dÃ¼ÅŸÃ¼nebilirsin.",
    "->  Merhabalar, bahsettiÄŸin parametreleri maliyet (cost) fonksiyonu Ã¼zerinden anlatmaya Ã§alÄ±ÅŸtÄ±m.1 month ago 3 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "MENTORLUK PROGRAMI Ä°LK HAFTA DEÄERLENDÄ°RMESÄ°  GÃ¼naydÄ±n - Machine Learning Crash Course nasÄ±l nasÄ±l gidiyor? Kimler takip ediyor acaba? Ä°lk haftanÄ±n programÄ±nÄ± bitirenler kimler? Buraya yorum olarak yazabilirsiniz.   Bu arada sizlere gÃ¼zel bir haber vereyim: Bu kursu bitirenleri mÃ¼lakat yaparak Deep Learning TÃ¼rkiye'de yeni baÅŸlattÄ±ÄŸÄ±mÄ±z Yapay Zeka Yetenek ProgramÄ±'na dahil edeceÄŸiz. MÃ¼lakatÄ± geÃ§ebilmek iÃ§in gerÃ§ekten bu kursu bitirmeniz gerekiyor.",
"comment": [
    "Show 5 more comments",
    "->  GÃ¼naydÄ±n, benim de Ã§ok az kaldÄ± bugÃ¼n bitireceÄŸim bu haftayÄ± ğŸ™‚.",
    "->  Merhaba, ben hafta iÃ§i vakit bulamamÄ±ÅŸtÄ±m. Ancak bugÃ¼n bitirmeyi planlÄ±yorum diÄŸer arkadaÅŸlar gibi..",
    "->  BugÃ¼n iÃ§inde biter diye umut ediyorum..",
    "->  Merhabalar, bende bugÃ¼n bitireceÄŸim bu haftanÄ±n programÄ±nÄ±.",
    "->  Ben bitirdim tekrar yapÄ±yorum..",
    "->  Merhabalar ilk hafta programÄ±nÄ± bitirdim umarÄ±m gÃ¼n iÃ§inde tekrar yapacak vakit bulurum..",
    "-> Merhaba,bende bugÃ¼n bitiriyorum..",
    "-> Merhaba, 1 konum kaldÄ± bugÃ¼n bitireceÄŸim..",
    "->  merhabalar, bugÃ¼n bitiyor benim de:).",
    " ->  BugÃ¼n iÃ§inde bitmiÅŸ olur ğŸ™‚ Malum hafta iÃ§i yoÄŸun iÅŸ temposunda Ã§ok ilgilenemiyorum :/.",
    "->  Ã¼nlÃ¼ Merhabalar bugÃ¼n bitiyor benim de:).",
    " ->  Merhaba, bir konum kaldi ondan sonra genel bir tekrar yapacagim..",
    "->  Merhaba, bugÃ¼n tamamlayacaÄŸÄ±m bende...",
    " -> BugÃ¼n tamamlamayÄ± planlamaktayÄ±m ğŸ™‚.",
    "-> Hepsi bitti ancak pratik yapmaya ihtiyacÄ±m var zamanÄ±m olursa kaggleda bir notebook yazacaÄŸÄ±m..",
    "->  Ã‡ok az kaldÄ± bugÃ¼n bitecek.",
    "->  Merhaba, sÄ±nav yarÄ±n kaÃ§ta olacak? Belli bir saat aralÄ±ÄŸÄ±nda mÄ± Ã§Ã¶zmeliyiz?1 month ago 2 people like this.Like ReportReply",
    "-> Merhaba, bugÃ¼n iÃ§inde bitiyor bu haftaki programÄ±m..",
    " ->  Merhaba, bugÃ¼n genel tekrar yapacaÄŸÄ±m..",
    "->  Merhaba, Ã¼ni dersleri yÃ¼zÃ¼nden haftaiÃ§i Ã§alÄ±ÅŸma fÄ±rsatÄ± bulamadÄ±m. Ancak cuma ve cumartesi gÃ¼nÃ¼mÃ¼ Ã§alÄ±ÅŸmaya ayÄ±rdÄ±m. bugÃ¼n gÃ¼n iÃ§erisinde Ã§alÄ±ÅŸmam bitecek..",
    "->  Her ÅŸey harika gidiyor..",
    "->  Merhaba, ilk haftanÄ±n programÄ±nÄ± bitirdim. Tekrar yapÄ±yorum..",
    "->  Merhabalar, bende bu haftaki programÄ± tamamlamak Ã¼zereyim.",
    "->  Merhaba. Ä°lk hafta programÄ±nÄ± bugÃ¼n bitirdim. Genel olarak verimli geÃ§iyor..",
    "->  Merhabalar,bende ilk haftanÄ±n programÄ±nÄ± tamamladÄ±m,tekrarlarÄ±mÄ± yapacaÄŸÄ±m..",
    "->  Merhabalar, bende ilk haftanÄ±n programÄ±nÄ± bitirdim genel tekrar yapacaÄŸÄ±m..",
    "->  HaftalÄ±k yoÄŸunluÄŸumdan kaynaklÄ± bu haftaki gÃ¶revlere pek bakamamÄ±ÅŸtÄ±m, fakat bitireceÄŸim birkaÃ§ saat iÃ§inde.",
    "->  Bu akÅŸam itibariyle ilk haftayÄ± tamamlayacaÄŸÄ±m. Gayet verimli geÃ§iyor..",
    "->  Son egzersizi bu akÅŸam bitirmeyi planlÄ±yorum..",
    "->  Ä°lk haftanÄ±n programÄ±nÄ± bugÃ¼n bitirdim. Ã‡ok verimli geÃ§iyor..",
    "->  ProgramÄ±n 2.haftasÄ± bitti baya zevkli geÃ§iyor aÃ§Ä±klamalarÄ± ek olarak dÃ¶kÃ¼man olarak vermeleri bence iÅŸi daha da hÄ±zlandÄ±rmÄ±ÅŸ. SÄ±nav saati ne zaman belli oldu mu ?.",
    "->  Bu haftanÄ±n son konusundayÄ±m 1 saat iÃ§inde bitirim. Ã‡ok verimli geÃ§iyor sistem gayet gÃ¼zel , teÅŸekkÃ¼rler..",
    "->  Selam, Ben de ilk hafta programÄ±nÄ± bitirdim..",
    "->  Kurs Ã§ok ilgi Ã§ekici, takÄ±ldÄ±ÄŸÄ±m konularÄ± youtube vb. farklÄ± kaynaklardan da dinleyip pekiÅŸtiriyorum. Åu an ana gÃ¼ndem konularÄ±ndan kaÃ§mak ve kendimi geliÅŸtirmek iÃ§in Ã§ok deÄŸerli bir eÄŸitim oluyor. Bu akÅŸam itibariyle kalan eksiklerimi tamamlayÄ±p ilk haftayÄ± bitireceÄŸim..",
    "-> Ä°lk hafta programÄ±nÄ± bitirdim ben de..",
    "->  Merhaba ilk hafta bÃ¶lÃ¼mÃ¼nÃ¼ bitirdim. Google AI kÄ±smÄ±ndaki diger derslerle daha verimli geÃ§iyor ....",
    "->  Ä°lk haftayÄ± sonunda bitirebildim. Ã‡ok gÃ¼zel ilerliyor konular ile ilgili internetten Ã¶rnek toparlayarak pekiÅŸtirmeye Ã§alÄ±ÅŸÄ±yorum bu da biraz zaman alÄ±yor. Åimdilik baya verim aldÄ±ÄŸÄ±mÄ± dÃ¼ÅŸÃ¼nÃ¼yorum..",
    "->  Ne yazÄ±kki son bÃ¶lÃ¼me baÅŸlayamadÄ±m 2 gÃ¼ndÃ¼r pek Ã§alÄ±ÅŸma fÄ±rsatÄ±m olmuyor dedem hastahanede yatÄ±yor Ã§Ã¼nkÃ¼ ama en kÄ±sa zamanda toparlamaya Ã§alÄ±ÅŸacaÄŸÄ±m.",
    "-> Merhaba bende ilk hafta programÄ±nÄ± bitirdim . Her ÅŸey yolunda gidiyor ÅŸimdilik.",
    "->  Merhaba bende ilk hafta programÄ±nÄ± bitirdim..",
    "->  Merhaba ben de ilk haftanÄ±n programÄ±nÄ± bitirdim !!.",
    "->  Selamlar, ilk hafta programÄ± bitti. YarÄ±nki quiz iÃ§in heyecanlÄ±yÄ±z. ğŸ™‚.",
    "->  Ä°lk haftayÄ± bitirdik, son tekrarlarÄ± yaptÄ±k yarÄ±nÄ± bekliyoruz artÄ±k ğŸ™‚.",
    "->  Ä°lk hafta bitti ğŸ™‚.",
    "-> ..",
    "->  Ilk haftayi tamamladim.Tesekkurler..",
    "->  ilk hafta programÄ±nÄ± bitirdim ancak itiraf etmeliyim ki biraz zorlandÄ±m. crash course u ilk aÃ§tÄ±ÄŸÄ±mda terimlerin ne anlama geldiÄŸi hakkÄ±nda en ufak bir fikrim yoktu. Ä°ÅŸi tÃ¼rev nedir? Fonksiyon nedir? den alarak 1. haftanÄ±n sonuna kadar getirmek beni yorsa da Ã¶ÄŸrenmekten bÃ¼yÃ¼k keyif aldÄ±m. Kodlama pratiÄŸi kÄ±smÄ±ndan Ã§ekiniyorum yalnÄ±zca..",
    "->  Ä°lk haftayÄ± tamamladÄ±m. Fakat makine Ã¶ÄŸrenmesi Ã¼zerine Ã§ok daha fazla kod yazmam gerektiÄŸini farkettim..",
    "->  Bu haftayÄ± tamamladÄ±m. Verimli olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yorum. TeÅŸekkÃ¼rler..",
    "->  Ant Ä°lk haftayÄ± tamamladÄ±m . Bilgilerimi tazeledim biraz iyi oldu. Linear regression iÃ§in scikit-learn kullanmaya devam ederim gibi geliyo ..",
    "->  Ä°lk haftam benim de bitti. Baya kafa patlanmam gerekti. Bazen burada cevaplanmÄ±ÅŸ sorularÄ± bakarak kafama takÄ±lanlarÄ± Ã¶ÄŸrendim bazende hintli youtuberlarÄ± dinleyerek sorularÄ±ma cevap aradÄ±m. TÃ¼rkÃ§e kaynaÄŸÄ±n Ã§ok fazla olmamasÄ±ndan dolayÄ± bu eÄŸitime sizinle baÅŸladÄ±ÄŸÄ±ma ÅŸÃ¼krediyorum. YarÄ±n sÄ±navda gÃ¶rÃ¼ÅŸÃ¼rÃ¼z. UmarÄ±m yapay zeka yetenek programÄ±nda da gÃ¶rÃ¼ÅŸÃ¼rÃ¼z ğŸ™‚.",
    "->  Merhaba ilk haftamÄ± tamamladÄ±m. Benim iÃ§in sÃ¼reÃ§ Ã§ok iyi gidiyor, emekleriniz iÃ§in teÅŸekkÃ¼rler..",
    " ->  Merhabalar ilk haftalÄ±k bÃ¶lÃ¼mÃ¼ tamamladÄ±m. Ã‡ok gÃ¼zel ilerliyor kurs..",
    "->  Merhaba. Ä°lk haftalÄ±k bÃ¶lÃ¼mÃ¼ tamamladÄ±m. Benim iÃ§in oldukÃ§a verimli ilerliyor. ğŸ™‚.",
    "->  Merhaba, Ä°lk haftalÄ±k bÃ¶lÃ¼m tamamlandÄ± :)..",
    "->  Ä°lk haftayÄ± tamamladÄ±m. Son tekrarlarÄ±mÄ± yapÄ±yorum..",
    "-> Ä°lk haftalÄ±k bÃ¶lÃ¼mÃ¼ tamamladÄ±m yarÄ±nki quizden Ã¶nce son bir Ã¼stÃ¼nden geÃ§iyorum ..",
    "->  Bitti hocam, bende tekrarÄ±mÄ± yapÄ±yorum..",
    "->  Kurs oldukÃ§a verimli gidiyor. Ä°lk haftanÄ±n programÄ±nÄ± bitirdim..",
    "->  Merhaba, Ã§ok verimli geÃ§ti, ilk haftayÄ± bitirdim ben de. ğŸ™‚.",
    "-> Merhaba ben de takip ediyorum, ilk haftayi bitirmek uzereyim...",
    " ->  Ä°lk haftayÄ± tamamladÄ±m,quizden Ã¶nce son bir Ã¼stÃ¼nden geÃ§iyorum. Ã‡ok verimli bir program gerÃ§ekten teÅŸekkÃ¼rler.",
    " ->  Verimli, konu ayrÄ±mlarÄ±nÄ±n olabildiÄŸince sade ve Ã¶z anlatÄ±ldÄ±ÄŸÄ± bir kurs. Mentorluk edilmesi farklÄ± kiÅŸilerin sorularÄ±nÄ± ve cevaplarÄ±nÄ± gÃ¶rmek verimi katlÄ±yor. Ä°lk haftayÄ± tamamladÄ±m. Herkese TeÅŸekkÃ¼rler..",
    " ->  Bu hafta bitti ve kurs iÃ§eriÄŸi Ã§ok verimliydi teÅŸekkÃ¼rler..",
    "->  Merhabalar, ilk haftalÄ±k bÃ¶lÃ¼mÃ¼ tamamladÄ±m. EÄŸitim aÃ§Ä±klamalarÄ± gayet net olduÄŸundan verimli bir ÅŸekilde ilerlemekte ğŸ™‚ TeÅŸekkÃ¼rler. Herkese iyi Ã§alÄ±ÅŸmalar...",
    "->  Harika ilerliyor, her ÅŸey iÃ§in teÅŸekkÃ¼rler..",
    " ->  merhaba, ilk haftayÄ± tamamladÄ±m..",
    "->  ilk hafta programÄ± bitti, tekrarÄ± dÃ¶nÃ¼yorum ğŸ™‚.",
    "->  Ben nerdeyse 2 haftayÄ± tamamladÄ±m. Åu an kodlarla biraz daha pratiÄŸe ihtiyacÄ±m olduÄŸunu hissediyorum..",
    "->  SÄ±navÄ± Ã§Ã¶zmeden Ã¶nce tekrarlarÄ±mÄ±zÄ± yapÄ±yoruz hocam bitti ğŸ™‚.",
    "->  EÄŸitimin Ã§ok temelden baÅŸlamasÄ±, daha Ã¶nce atladÄ±ÄŸÄ±m detaylarÄ± da Ã¶ÄŸrenmemi saÄŸladÄ±. Åu anda her ÅŸey gÃ¼zel gidiyor. Her ÅŸey iÃ§in teÅŸekkÃ¼rler, eÄŸitime devam ğŸ™‚.",
    "->  Bu hafta sÄ±navlarÄ±mdan ve projelerimden dolayÄ± yeterli performansÄ± gÃ¶steremedim ama Ã¶nÃ¼mÃ¼zdeki Ã¶nÃ¼mÃ¼zdeki hafta itibariyle yoÄŸun bir ÅŸekilde Ã§alÄ±ÅŸÄ±p telafi edeceÄŸim..",
    "->  Ä°LK SINAVIMIZDAN Ã‡IKTIK ÅÃœKÃœR. HATALARI NOT ALDIM ÅÄ°MDÄ°DE ONLARI TAMAMLAMA YOLUNDA Ã‡LIÅACAÄIM %40 ORANINDA BÄ°R BAÅARI SAÄLADIM AMA BAKALIM 4. HAFTA SONUNDA BU BAÅARIYI % KAÃ‡A KADAR Ã‡IKARABÄ°LECEÄÄ°M.1 month ago 3 people like this.Like ReportReply",
    "->  Gayet gÃ¼zel gidiyor , sÄ±nav sayesinde eksiklerimizi gÃ¶rdÃ¼k. Tam gaz devam, teÅŸekkÃ¼r ederiz ğŸ™‚.",
    "->  oldukca faydali, emek verenlere cok tesekkurler,4 weeks ago Like ReportReply",
    "-> Åu an itibariyle kursu tamamladÄ±m, yol gÃ¶stericiliÄŸiniz iÃ§in teÅŸekkÃ¼rler.Onun haricinde muhtemelen bu ekibe dahil olmasaydÄ±m kendimi zorlayÄ±p bitiremezdim ve bu kurs da daha Ã¶nce alÄ±p baÅŸlayÄ±p yarÄ±da bÄ±raktÄ±ÄŸÄ±m kurslar gibi olurdu.Bu ekibin diÄŸer bir faydasÄ± da -itiraf etmem gerekir ki-; kursta dinlediklerim okuduklarÄ±ma kÄ±yasla buradan sorulan sorulardan ve verilen cevaplardan daha Ã§ok ÅŸey Ã¶ÄŸrendim. Sorulan sorular sayesinde bazen gÃ¶zden kaÃ§Ä±rdÄ±ÄŸÄ±m, bazen de anlamadÄ±ÄŸÄ±mÄ±n farkÄ±na varmadÄ±ÄŸÄ±m yerleri fark ettim. Tabii ki hala eksiklerim var ama gerek sÄ±navlar gerekse burada yanÄ±tlanan sorular bu eksikleri kapatmak iÃ§in zaten.ÃœnlÃ¼ bir iÅŸ adamÄ±nÄ±n da dediÄŸi gibi baÅŸarmak istiyorsan yapman gereken 3 ÅŸey var; Ã‡ALIÅMAK, Ã‡ALIÅMAK, Ã‡ALIÅMAK.BÃ¶yle veda konuÅŸmasÄ± gibi oldu ama umarÄ±m yola devam birlikte devam edebiliriz.Bu vesileyle hem size ( ->  ), hem AslÄ± HanÄ±m'a ( ->  ), hem bu ekibin kurulmasÄ±nda destek olan diÄŸer yetkililere, hem sorularÄ±mÄ±zÄ± cevaplayan mentorlarÄ±mÄ±za, hem de sorular sorarak gÃ¶zden kaÃ§Ä±rdÄ±klarÄ±mÄ±zÄ± fark etmemizi saÄŸlayan tÃ¼m ekibe tekrar teÅŸekkÃ¼r ederim.Edit: YazÄ±m hatasÄ± dÃ¼zenlemesi.3 weeks ago 5 people like this.Like ReportReply",
    "-> -> Program iÃ§in teÅŸekkÃ¼rler, herkese baÅŸarÄ±lar.3 weeks ago Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Ä°yi akÅŸamlar  Benim Validation Set kÄ±smÄ±nda kafama tam oturtamadÄ±ÄŸÄ±m ÅŸeyler var. Uygulama: <a class=\"ps-media-link\" href=\"https://colab.research.google.com/github/google/eng-edu/blob/master/ml/cc/exercises/validation_and_test_sets.ipynb?utm_source=mlcc&amp;utm_campaign=colab-external&amp;utm_medium=referral&amp;utm_content=validation_tf2-colab&amp;hl=tr\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">https://colab.research.google.com/github/google/eng-edu/blob/master/ml/cc/exercises/validation_and_test_sets.ipynb?utm_source=mlcc&amp;utm_campaign=colab-external&amp;utm_medium=referral&amp;utm_content=validation_tf2-colab&amp;hl=tr</a>  1)Bu uygulama kÄ±smÄ±nda neden en baÅŸta label valuelarÄ±mÄ±zÄ±  scale ediyoruz? 2)AnladÄ±ÄŸÄ±m kadarÄ±yla yapmamÄ±z gereken ÅŸey test setimizi tamamen bir kenara koymak ve model tamamen hazÄ±r olmadan kullanmamalÄ±yÄ±z. Valudation setimiz de bizim modelimizin parametrelerini daha uygun bir ÅŸekilde dÃ¼zeltmemiz iÃ§in erken test yapmamÄ±zÄ± saÄŸlÄ±yor.Fakat  neden train seti bÃ¶lmeden lossu indirgeyip testte test edip yeterli accuracy ye ulaÅŸamayÄ±nca dÃ¶nÃ¼p parametreleri deÄŸiÅŸtirmek yerine validation sete bÃ¶lÃ¼yoruz?  Onu aÃ§Ä±kcasÄ± tam anlayamadÄ±m. Not: Ã–nceden K-Fold crossâ€¦ <a class=\"ps-stream-post-more ps-js-content-excerpt-toggle\" href=\"#\">Read more</a></div><div class=\"ps-js-content-full\" style=\"\">Ä°yi akÅŸamlar  Benim Validation Set kÄ±smÄ±nda kafama tam oturtamadÄ±ÄŸÄ±m ÅŸeyler var. Uygulama: <a class=\"ps-media-link\" href=\"https://colab.research.google.com/github/google/eng-edu/blob/master/ml/cc/exercises/validation_and_test_sets.ipynb?utm_source=mlcc&amp;utm_campaign=colab-external&amp;utm_medium=referral&amp;utm_content=validation_tf2-colab&amp;hl=tr\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">https://colab.research.google.com/github/google/eng-edu/blob/master/ml/cc/exercises/validation_and_test_sets.ipynb?utm_source=mlcc&amp;utm_campaign=colab-external&amp;utm_medium=referral&amp;utm_content=validation_tf2-colab&amp;hl=tr</a>  1)Bu uygulama kÄ±smÄ±nda neden en baÅŸta label valuelarÄ±mÄ±zÄ±  scale ediyoruz? 2)AnladÄ±ÄŸÄ±m kadarÄ±yla yapmamÄ±z gereken ÅŸey test setimizi tamamen bir kenara koymak ve model tamamen hazÄ±r olmadan kullanmamalÄ±yÄ±z. Valudation setimiz de bizim modelimizin parametrelerini daha uygun bir ÅŸekilde dÃ¼zeltmemiz iÃ§in erken test yapmamÄ±zÄ± saÄŸlÄ±yor.Fakat  neden train seti bÃ¶lmeden lossu indirgeyip testte test edip yeterli accuracy ye ulaÅŸamayÄ±nca dÃ¶nÃ¼p parametreleri deÄŸiÅŸtirmek yerine validation sete bÃ¶lÃ¼yoruz?  Onu aÃ§Ä±kcasÄ± tam anlayamadÄ±m. Not: Ã–nceden K-Fold cross validation'Ä± incelemiÅŸtim oradaki kullanÄ±mÄ± gÃ¼zeldi ama onun dÄ±ÅŸÄ±nda nasÄ±l kullanÄ±lacaÄŸÄ±nÄ± aÃ§Ä±kcasÄ± pek anlayamadÄ±m.  Åimdiden herkese teÅŸekkÃ¼r ederim.</div></div>",
"comment": [
    "",
    " ->  BilgiÄŸim kadarÄ±yla scaling veya normalizing iÅŸlemleri, verileri daha iyi ve kolay eÄŸitmemizi saÄŸlÄ±yor. Train seti bÃ¶lmeden loss'u minimize etmeye Ã§alÄ±ÅŸÄ±rsak overfitting ile karÅŸÄ±laÅŸabiliriz ve istediÄŸimiz loss ve accuracy'i test sette alamayabiliriz. En iyi modeli, validation setteki loss oranÄ±na bakÄ±p oluÅŸturuyoruz, daha sonrasÄ±nda test sette test ediyoruz. EÄŸer hala train ve validation arasÄ±ndaki loss farkÄ± Ã§oksa, test sete geÃ§meye gerek yoktur, zaten model kÃ¶tÃ¼ Ã§alÄ±ÅŸÄ±yordur. Parametreleri deÄŸiÅŸtirmek gerekir. Ä°yi gÃ¼nler.1 month ago 3 people like this.Like ReportReply",
    " ->  1. sorunun cevabÄ± ÅŸÃ¶yle: mesela bir feature 1-10 arasÄ±nda deÄŸiÅŸiyor diÄŸeri 50-400 arasÄ±nda. bunlar modelimizi train ederken etki etme yÃ¼zdeleri daha farklÄ± oluyor. birisi daha Ã§ok etki ederken diÄŸeri daha az ediyor mesela. bu da accuracy'i dÃ¼ÅŸÃ¼rÃ¼yor. bu yÃ¼zden scale ederek etkilerini eÅŸitliyoruz..",
    "->  Biraz geÃ§ bir yanÄ±t oldu ama ÅŸÃ¶yle dÃ¼ÅŸÃ¼nebilirsin; bir modeli eÄŸitiyorsun test ediyorsun ve Ã§Ä±kan test sonucuna gÃ¶re hyperparametreleri tune ediyorsun. Bunu loss deÄŸerin iyice dÃ¼ÅŸene kadar tekrar tekrar yapÄ±yorsun. Bu durum overfitting tehlikesini barÄ±ndÄ±rÄ±r. Ã‡Ã¼nkÃ¼ modelini test sete gÃ¶re ayarlÄ±yorsun aslÄ±nda. KuÅŸlarÄ± tanÄ±yan bir modelin olduÄŸunu dÃ¼ÅŸÃ¼n ve dikkat etmeyip test setine Ã§oÄŸunlukla papaÄŸan resimleri koyduysan bu sefer modelini sÃ¼rekli papaÄŸanlarÄ± tanÄ±mak iÃ§in tune ettiÄŸinden modeli load edip kullanmayÄ± denediÄŸinde farklÄ± kuÅŸ tÃ¼rlerini tanÄ±madÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼rsÃ¼n. Bu tabii uÃ§ bir Ã¶rnek ama yine de nasÄ±l overfittinge yol aÃ§aÄŸÄ±nÄ± gÃ¶zlemlemek bu yoldan mÃ¼mkÃ¼n. YanlÄ±ÅŸÄ±m olabilir..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba,  Gradient descent algoritmasÄ±nda dataseti batchlere ayÄ±rdÄ±ktan sonra modele soktuÄŸumuzda her batch'in iÅŸlenmesinden sonra weight deÄŸeri gÃ¼ncelleniyor mu?  Yoksa tek seferde sokmuÅŸusuz gibi en son gÃ¼ncelleniyor, sadece dataseti parÃ§alar halinde iÅŸlemiÅŸ mi oluyoruz? EÄŸer bÃ¶yleyse bathe bÃ¶lmemiz nasÄ±l bir fark yaratabiliyor tek seferde deÄŸerlendirmekten?",
"comment": [
    "",
    "->  Merhaba, Evet, gÃ¼ncelleniyor. Mini-batch'lere ayÄ±rmamÄ±zÄ±n amacÄ± elimizde bÃ¼yÃ¼k bir veri seti olduÄŸu dÃ¼ÅŸÃ¼nÃ¼lÃ¼rse(1 milyon Ã¶rnekten oluÅŸan) mini-batch'lere ayÄ±rmak yerine, weight ve bias deÄŸerlerimizi bir kere gÃ¼ncellemek iÃ§in tÃ¼m veriyi iÅŸlemeye Ã§alÄ±ÅŸÄ±rsak loss deÄŸerimizi minimize etmek Ã§ok Ã§ok fazla zaman alabilir. Bu yÃ¼zden daha kÃ¼Ã§Ã¼k parÃ§alara ayÄ±rÄ±p o ÅŸekilde parametreleri gÃ¼ncellemek daha hÄ±zlÄ± ve efektif oluyor.1 month ago 9 people like this.Like ReportReply",
    " ->  \"if the batch size is 6, then the system recalculates the model's loss value and adjusts the model's weights and bias after processing every 6 examples.\" (bu CÃ¼mle 12 verilik bir veri seti iÃ§in SÃ¶ylenmiÅŸ yani tamamÄ±nÄ± almÄ±yor , 6 - 6 iÅŸliyor) First Steps With TF pratik kÄ±smÄ±nda yazan cÃ¼mleye gore, batch_size a baÄŸlÄ± olarak aÄŸÄ±rlÄ±klar gÃ¼ncellenmekte. Bu egzersizde her ÅŸey Ã§ok daha net hale geliyor. Ä°yi Ã§alÄ±ÅŸmalar.1 month ago 4 people like this.Like ReportReply",
    "-> ->  TeÅŸekkÃ¼r ederim ????  ->  GÃ¶zden kaÃ§Ä±rmÄ±ÅŸÄ±m teÅŸekkÃ¼r ederim ğŸ™‚1 month ago 3 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "-> uploaded 2 photos",
"quest": "Ä°yi AkÅŸamlar,  Task 4: Find the ideal combination of epochs and learning rate kÄ±smÄ±nda: learning_rate= 10  # Replace ? with a floating-point number epochs= 10   # Replace ? with an integer  Bu deÄŸerler ile label*feature grafiÄŸinde sorunun altÄ±ndaki solution kÄ±smÄ± ile benzer grafiÄŸi elde ediyorum. Ancak loss grafiÄŸinde bir anlÄ±k tepe deÄŸeri yapÄ±p ardÄ±ndan sÄ±fÄ±ra ulaÅŸÄ±yor. Bu durum yanÄ±ttan farklÄ±. BÃ¶yle bir durumun gerÃ§ek hayattaki projelerde etkisi kazanÃ§ veya zarar aÃ§Ä±sÄ±nda durumu ne olur ? Bir de okurken gÃ¶zden de kaÃ§Ä±rmÄ±ÅŸ olabilirim kayÄ±p grafiÄŸinin bu ÅŸekilde deÄŸil de bir parabol tarzÄ±nda olup alÃ§alan ÅŸekilde olmasÄ±nÄ±n gerekliliÄŸi neden ?   TeÅŸekkÃ¼r ederim",
"comment": [
    "",
    "->  Muhtemelen learning rate deÄŸeri 10 olduÄŸundan parametreleri (aÄŸÄ±rlÄ±k ve bias) gÃ¼ncellerken adÄ±m sayÄ±sÄ± bÃ¼yÃ¼k olduÄŸu iÃ§in yerel minimum noktasÄ±ndan daha uzaÄŸa gitmiÅŸtir. O sÄ±Ã§rama onu gÃ¶sterir. Genellikle learning rate oranÄ± daha kÃ¼Ã§Ã¼k seÃ§ilir. Ã–rneÄŸin 0.001 veya 0.01 gibi.1 month ago 3 people like this.Like ReportReply",
    "-> GerÃ§ek hayatta bir hedefin olduÄŸunu dÃ¼ÅŸÃ¼n (Ã¶rneÄŸin bir bakkal) .Sen ve bakkalÄ±n arasÄ±ndaki mesafe 200 metre olsun learning rate aynÄ± zamanda bir anlamda senin adÄ±m boyutun oluyor sen bakkala giderken learning rate'in Ã§ok yÃ¼ksekse sen 200 metre sonra durman gerekirken bakkalÄ± geÃ§ip gidiyorsun 300 metre ilerliyorsun mesela. Bu sefer bakkala ulaÅŸabilmek iÃ§in geriye gitmen gerekiyor geri dÃ¶nerken 100m geri gitmen gerekir ki(yani bu sefer baÅŸlangÄ±Ã§taki yÃ¶nÃ¼nÃ¼n tersine bakkalÄ± geÃ§tiÄŸin iÃ§in geri dÃ¶nÃ¼p bakkala doÄŸru) bakkala ulaÅŸabil ama sen yine adÄ±m boyun cok yÃ¼ksek olduÄŸu iÃ§in 150m gidip yine bakkalÄ± geÃ§iyorsun. AslÄ±nda sen 450m yol aldÄ±ÄŸÄ±n halde 200mlik hedefe bir tÃ¼rlÃ¼ ulaÅŸamadÄ±n Ã§Ã¼nkÃ¼ learning rate'in (adÄ±m boyun) Ã§ok yÃ¼ksek bunun iÃ§in bÃ¶yle bÃ¼yÃ¼k adÄ±m atarak hedefi tutturmaya Ã§alÄ±ÅŸmak yerine daha kÃ¼Ã§Ã¼k adÄ±mlarla daha uygun bir ÅŸekilde yaklaÅŸmaya Ã§alÄ±ÅŸÄ±yoruz. AyrÄ±ca burada Learning Rate' i deÄŸiÅŸtirip gÃ¶zlemlersen daha kalÄ±cÄ± olabilir gÃ¼zel anlatamamÄ±ÅŸ olabilrim. ğŸ™‚ https://developers.google.com/machine-learning/crash-course/fitter/graph",
    "Reducing Loss: Optimizing Learning Ratedevelopers.google.comhttps://developers.google.com/machine-learning/crash-course/fitter/graph1 month ago 2 people like this.Like ReportReply",
    " -> \"KayÄ±p grafiÄŸinin bu ÅŸekilde deÄŸil de bir parabol tarzÄ±nda olup alÃ§alan ÅŸekilde olmasÄ±nÄ±n gerekliliÄŸi neden ? \" kaybÄ± en aza indirirken belli bir deÄŸer aralÄ±klarÄ±nda weight - loss kontrolleri yapmamÄ±z isteniyor (learning rate) , aÅŸÄ±rÄ± sÄ±Ã§ramalardan kaÃ§Ä±nmak (yoldan Ã§Ä±kmamak) iÃ§in learning rate i Ã§ok yÃ¼ksek seÃ§miyor, aynÄ± zamanda modelimizin ilerleyebilmesi iÃ§in de aÅŸÄ±rÄ± dÃ¼ÅŸÃ¼k deÄŸerler seÃ§mekten kaÃ§Ä±nÄ±yoruz. Ä°ÅŸte bu yaklaÅŸÄ±mÄ± gÃ¶rselleÅŸtirdiÄŸimizde parabolik azalmayÄ± gÃ¶zÃ¼mÃ¼zde canlandÄ±rabiliriz. Bu arada Modelimiz her iterasyonda aÄŸÄ±rlÄ±k deÄŸerlerini kontrol ederken optimum deÄŸerleri kullanmaya Ã§alÄ±ÅŸÄ±yoruz. Bu deÄŸerler \"data dependent\" olduÄŸundan ve kesin bir \"learning rate - epoch - batch_size\" belirlenemeyeceÄŸinden bahsediyor kursta ama \"summary\" kÄ±smÄ±ndaki genel Ã¶nerilerin gÃ¼zel aÃ§Ä±klandÄ±ÄŸÄ±nÄ± ve ilerleyen iÃ§eriklerde de Ã§ok iÅŸimize yarayacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum. EÄŸer yanlÄ±ÅŸÄ±m varsa lÃ¼tfen dÃ¼zeltin. Ä°yi Ã‡alÄ±ÅŸmalar..",
    "->  \"KayÄ±p grafiÄŸinin bu ÅŸekilde deÄŸil de bir parabol tarzÄ±nda olup alÃ§alan ÅŸekilde olmasÄ±nÄ±n gerekliliÄŸi neden ? \" bu soru benimde aklÄ±ma takÄ±lmÄ±ÅŸtÄ±. ->  a ek olarak ÅŸÃ¶yle bir Ã§Ã¶zÃ¼m buldum ama ne kadar doÄŸru bilmiyorum. Loss eÄŸrisini Ã§izerkenki deÄŸiÅŸkenimiz w. Burada w ikinci dereceden bir deÄŸiÅŸken ve kat sayÄ±sÄ± pozitif. Bundan dolayÄ±da Ã§izdiÄŸimiz grafiÄŸin ÅŸekli yukarÄ± yÃ¶nlÃ¼ bir parabol olacaktÄ±r diye dÃ¼ÅŸÃ¼nÃ¼yorum..",
    "Mesut YÄ±lmaz ->  selam. Loss function da sabit olan, y' deÄŸil de y olmasÄ± gerekiyor. Yani y dediÄŸimiz, desired (wx+b sonucunda Ã§Ä±kmasÄ±nÄ± istediÄŸimiz) deÄŸer yani diÄŸer bir deyiÅŸle label'Ä±mÄ±z ve y' ise wx+b sonucunda tahmin ettiÄŸimiz deÄŸerdir. Ã–zetle loss bulurken yaptÄ±ÄŸÄ±mÄ±z ÅŸey, olmasÄ± gereken deÄŸere o anki w ve b ile ne kadar uzaÄŸÄ±z bunu bulmak. Ã‡Ä±kan farka gÃ¶re w ve b'yi gÃ¼ncelleyip bu ÅŸekilde devam edeceÄŸiz. YanlÄ±ÅŸÄ±m varsa dÃ¼zeltin lÃ¼tfen.1 month ago 2 people like this.Like ReportReply",
    "->  Evet orada bir hata olmuÅŸ, teÅŸekkÃ¼r ederim. Ancak w^2 nin katsayÄ±sÄ± yinede pozitif oluyor..",
    "-> CevaplarÄ±nÄ±z ve ilginiz iÃ§in teÅŸekkÃ¼r ederim. BugÃ¼n bir daha inceleyeceÄŸim.",
    " "
]
},
{
"question_isim": "-> uploaded 1 photo",
"quest": "Merhabalar, merak ettiÄŸim ÅŸey eÄŸitimin iÃ§indeki kodlama pratiÄŸi ile alakalÄ±... Acaba sÄ±navda bu modellerin tamamen kurulup, kodlanmasÄ± mÄ± istenecek yoksa daha Ã§ok yorumlama Ã¼zerine mi olacak?   Birde, bu resimde seÃ§tiÄŸim alanÄ± anlayamadÄ±m, bias bir hata deÄŸeri deÄŸil mi? neden eÄŸitiliyor?, SanÄ±rÄ±m o kÄ±sÄ±mda bir eksiklik seziyorum kendimde... Åimdiden teÅŸekkÃ¼r ederim cevaplarÄ±nÄ±z iÃ§in...",
"comment": [
    "",
    "->  BildiÄŸim kadarÄ±yla birden fazla bias kavramÄ± var. https://developers.google.com/machine-learning/glossary#bias bu linkteki bias kavramlarÄ±na bakabilirsin. Belki yardmcÄ± olur.",
    "Machine Learning Glossary Â |Â  Google Developersdevelopers.google.comCompilation of key machine-learning and TensorFlow terms, with beginner-friendly definitions..",
    "->  Merhaba,Buradaki bias deÄŸeri sanÄ±rsam hipotez denklemimizdeki(basit lineer regresyon denklemi -> h(x)=theta0+theta1.x) theta0 deÄŸeri yani grafiÄŸimizdeki Ã§izilen doÄŸrunun orgiirn noktasÄ±na olan uzaklÄ±ÄŸÄ±. Ã–rneÄŸin bias deÄŸerim yani theta0 deÄŸerim 1 olursa grafikteki doÄŸru y eksenini 1 noktasÄ±nda keser. (tam Ã§izmeyi beceremesem de resimdeki gibi). Bias'Ä±n amacÄ± bildiÄŸim kadarÄ± ile daha iyi genellememize ve modelimizi tek bir veri noktasÄ±na daha az duyarlÄ± hale getirmemize yardÄ±mcÄ± olmasÄ±dÄ±r.1 month ago 6 people like this.Like ReportReply",
    "->  bias terimi olmadan model orjinden geÃ§meye zorlanacaÄŸÄ± iÃ§in veriye uyumu dÃ¼ÅŸecektir. Bias terimi eklemek ve eÄŸitmek daha becerikli modeller Ã¼retmemize olanak saÄŸlÄ±yor.1 month ago 8 people like this.Like ReportReply",
    "-> ->  Yani bu bias deÄŸerleri de eÄŸitiliyor. Benim anlamadÄ±ÄŸÄ±m asÄ±l nokta buydu aslÄ±nda....",
    "->  Bias deÄŸeri y eksenini kestiÄŸi noktadÄ±r. ML de basit bir Ã¶rnek verecek olursak Linear Regression modelinin formÃ¼lÃ¼ y=b+wx dir. b=bias w=katsayÄ± x=baÄŸÄ±msÄ±z deÄŸiÅŸken y= baÄŸÄ±mlÄ± deÄŸiÅŸkendir. MaaÅŸ ve tecrÃ¼be adÄ±nda iki sÃ¼tunumuz olsun. EÄŸitilsin. 5 yÄ±llÄ±k tecrÃ¼beye sahip birisi kaÃ§ lira maaÅŸ alÄ±r diye sorumuz olsun. bias deÄŸerimiz 50, w deÄŸeri 1023 olsun. y=50+1023*5 y=5165 deÄŸerini buluruz.1 month ago 2 people like this.Like ReportReply",
    "->  Bu konu aslÄ±nda \"Descending into ML\" kÄ±smÄ±nÄ±n video dersinde(3/5) grafikle anlatÄ±lmÄ±ÅŸ bi daha izlemeni tavsiye ederim . AyrÄ±ca https://www.linkedin.com/pulse/derin-%C3%B6%C4%9Frenme-uygulamalar%C4%B1nda-temel-kavramlar-skor-ve-%C3%A7arkac%C4%B1/ bu yazÄ±yÄ± da inceleyebilirsin ğŸ™‚",
    "Derin Ã¶ÄŸrenme uygulamalarÄ±nda temel kavramlar : perceptron, skor fonksiyonu ve hata hesaplamasÄ±(loss function)www.linkedin.comPerceptron ve Lineer FonksiyonlarÂ  Lineer fonksiyonlar, y = W.x+ b ÅŸeklinde tanÄ±mlanan fonksiyonlardÄ±r.1 month ago 2 people like this.Like ReportReply",
    "-> Emekleriniz ve cevaplarÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederim....",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba iyi akÅŸamlar Ã§ok kÄ±sa ve basit bir soru soracaÄŸÄ±m.Kursun baÅŸÄ±nda lineer regresyondaki kesme parametresi olarak verilen bias parametresi bizim ileride bias variance trade off yapÄ±caÄŸÄ±mÄ±z bias ile aynÄ± kavram mÄ± ? AynÄ± ise iliÅŸkisini anlayamadÄ±m teÅŸekkÃ¼r ederim.",
"comment": [
    "",
    "-> Bir Ã¼stteki soruda ÅŸu ÅŸekilde cevap verilmiÅŸ bu soruya sanÄ±rÄ±m gÃ¶zÃ¼nÃ¼zden kaÃ§tÄ±:\"Buradaki bias deÄŸeri sanÄ±rsam hipotez denklemimizdeki(basit lineer regresyon denklemi -> h(x)=theta0+theta1.x) theta0 deÄŸeri yani grafiÄŸimizdeki Ã§izilen doÄŸrunun orgiirn noktasÄ±na olan uzaklÄ±ÄŸÄ±. Ã–rneÄŸin bias deÄŸerim yani theta0 deÄŸerim 1 olursa grafikteki doÄŸru y eksenini 1 noktasÄ±nda keser. (tam Ã§izmeyi beceremesem de resimdeki gibi). Bias'Ä±n amacÄ± bildiÄŸim kadarÄ± ile daha iyi genellememize ve modelimizi tek bir veri noktasÄ±na daha az duyarlÄ± hale getirmemize yardÄ±mcÄ± olmasÄ±dÄ±r.\".",
    "-> Merhaba Berk, Ä°kisi farklÄ± ÅŸeyler anladÄ±ÄŸÄ±m kadarÄ±yla. Ä°lki sadece parametre. Yani y=ax denklemini dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼mÃ¼zde bu denklem orijinden geÃ§ecektir. Lakin verilen data illa orijinden geÃ§mesi, her dataya uyum saÄŸlamayan doÄŸrular olacaÄŸÄ±ndan bias parametresi dediÄŸimiz Ã¶rn; y=ax+b gibi bir b (bias) ekliyoruz.Trade off ta kullanÄ±lan bias ise verinin Ã¶ÄŸrenilip Ã¶ÄŸrenilemediÄŸi ile ilgili..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar  Validation setin anlatÄ±ldÄ±ÄŸÄ± exerciseda validation set, training setin iÃ§inden ayrÄ±larak oluÅŸturulmuÅŸ. Benim Ã¶nceden Ã§alÄ±ÅŸtÄ±ÄŸÄ±m Andrew NG'in yapmÄ±ÅŸ olduÄŸu baÅŸka bir courseda Andrew hoca Ã¼zerine basa basa dev test ile test setin aynÄ± distributiondan gelmesi gerektiÄŸini belirtmiÅŸti her zaman. Benim bu noktada biraz kafam karÄ±ÅŸtÄ± aydÄ±nlatabilir misiniz?",
"comment": [
    "",
    "->  Merhaba, training setin iÃ§inden ayrÄ±larak oluÅŸturulmasÄ±, test ile validation set'in farklÄ± distributionlara sahip olmasÄ± anlamÄ±na gelmiyor. FotoÄŸraf verilerimiz olduÄŸunu dÃ¼ÅŸÃ¼nelim. Training setimiz telefon kamerasÄ±yla Ã§ekilen fotoÄŸraflardan oluÅŸuyor olsun. Validation setimizi de ordan ayÄ±rÄ±p oluÅŸturduk diyelim. Test setimizdeki veriler de telefon kamerasÄ±yla Ã§ekilmiÅŸ fotoÄŸraflardan oluÅŸuyorsa aynÄ± distribution'a sahip olmuÅŸ oluyorlar. Bence burada andrew ng'nin sÃ¶zÃ¼nÃ¼ inkar eden bir durum yok. (FotoÄŸraf Ã¶rneÄŸini ben de andrew ng'den gÃ¶rmÃ¼ÅŸtÃ¼m :))1 month ago 2 people like this.Like ReportReply",
    "->  ->  DoÄŸru diyorsunuz ben de dÃ¼ÅŸÃ¼ndÃ¼m ancak testset yerine train setten ayÄ±rÄ±nca acaba bilmediÄŸim bir ÅŸey mi var diye dÃ¼ÅŸÃ¼ndÃ¼m. TeÅŸekkÃ¼r ederim ğŸ™‚.",
    "->  ->  Supervised Learnin iÃ§in sÃ¶ylÃ¼yorum, test setinde label bulunmadÄ±ÄŸÄ± iÃ§in train setimizi train-test olarak ayÄ±rarak geliÅŸtirdiÄŸimiz modelin etkinliÄŸini test ediyoruz.1 month ago 2 people like this.Like ReportReply",
    "->  Train setimizi bÃ¶lerek test ve validation setlerini oluÅŸtururuz. Model eÄŸitilirlen test setini kullanarak val_acc ve val_loss gibi deÄŸerlerinie bakarak modelin etkinliÄŸini gÃ¶rebiliriz. Model eÄŸitimi bittikten sonra test setini kullanarak gerÃ§ek hayattaki Ã¶rnekleri tahmin/sÄ±nÄ±flandÄ±rma performansÄ±na bakarÄ±z..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar  gradient   magnitude'Ä±n ne olduÄŸunu tam anlamÄ±yla anlayamadÄ±m.Bu hazÄ±rladÄ±ÄŸÄ±mÄ±z modelin aÄŸÄ±rlÄ±ÄŸÄ± mÄ±dÄ±r yoksa farklÄ± bir ÅŸey midir ve bir de gradient magnitude ile learning rate arasÄ±ndaki iliÅŸki nasÄ±ldÄ±r ?  teÅŸekkÃ¼rler,",
"comment": [
    "",
    "->  Gradient deÄŸiÅŸimi ifade ediyor. Magnitude ise deÄŸiÅŸimin bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼ ifade ediyor. Learning rate fazla olduÄŸunda her bir iterasyonda grafik Ã¼zerinde minimuma (eÄŸimin 0 olduÄŸu nokta) ulaÅŸmaya Ã§alÄ±ÅŸÄ±rken daha bÃ¼yÃ¼k adÄ±mlar atacaÄŸÄ±mÄ±z iÃ§in; gradient magnitude ile learning rate doÄŸru orantÄ±lÄ± olmuÅŸ oluyor. Fakat deÄŸiÅŸimin fazla olmasÄ± her zaman iyi sonuÃ§lar vermeyebilir.1 month ago 8 people like this.Like ReportReply",
    "-> deÄŸiÅŸimin fazla olmasÄ±, eÄŸimin sÄ±fÄ±r olduÄŸu noktayÄ± kaÃ§Ä±racaÄŸÄ±n anlamÄ±na gelebilir..",
    "->  TeÅŸekkÃ¼r ederim.",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba. AnladÄ±ÄŸÄ±m kadarÄ± ile overfitting modelimizin verdiÄŸimiz training datasÄ±na Ã§ok yakÄ±n tahminler yapmaya Ã§alÄ±ÅŸmasÄ± ve bir bakÄ±ma predict yaparken kullanacaÄŸÄ± datanÄ±n da benzer Ã¶zelliklerde olacaÄŸÄ± yÃ¶nÃ¼nde bir Ã¶nyargÄ± oluÅŸturmasÄ±. Bunun Ã¶nÃ¼ne geÃ§mek iÃ§in data setimizi bir takÄ±m distrubition kurallarÄ±na gÃ¶re train ve test olarak ayÄ±rmamÄ±z gerektiÄŸi anlatÄ±lÄ±yor. Ancak overfitting'in nasÄ±l oluÅŸtuÄŸunu tam olarak oturtamadÄ±m. Biraz daha ayrÄ±ntÄ±lÄ± bir cevap alabilir miyim?",
"comment": [
    "",
    "-> Merhabalar. Overfitting, oluÅŸturulan modeller iÃ§in Ã¶nlem alÄ±nmasÄ± gereken problemlerin baÅŸÄ±nda yer alanlardan birisidir. Modeli eÄŸitirken her ne kadar shuffle yÃ¶ntemiyle veriler karÄ±ÅŸtÄ±rÄ±larak eÄŸitime sunulsa da, her bir Ã§evrimde yapÄ±lan denemeler sonrasÄ±nda bir sÃ¼re sonra modelin veriye aÅŸÄ±rÄ± uyum saÄŸlayacaÄŸÄ±, yani veriyi ezberleyeceÄŸi belirtiliyor. Bu durumda model Ã§ok baÅŸarÄ±lÄ± sonuÃ§lar Ã¼retebiliyor. Siz de modelin %99 oranÄ±nda baÅŸarÄ±lÄ± olduÄŸu gibi oranlar gÃ¶rebiliyorsunuz. Gelin gÃ¶rÃ¼n ki model, eÄŸitildiÄŸi veri setini ezberlediÄŸi iÃ§in o oranlara ulaÅŸÄ±yor. Bir nevi input deÄŸerlerine (her bir x iÃ§in) karÅŸÄ±lÄ±k gelecek aÄŸÄ±rlÄ±k (w) deÄŸerlerini ezberliyor da diyebiliriz. Ancak problem, modelin daha Ã¶nce hiÃ§ gÃ¶rmediÄŸi veri setinde ortaya Ã§Ä±kÄ±yor. Ã‡oÄŸu kiÅŸinin de Ã¼zerinde hemfikir olduÄŸu nokta, overfitting gerÃ§ekleÅŸmiÅŸ olan modellerin, diÄŸer modellerde aynÄ± baÅŸarÄ±mÄ± gerÃ§ekleÅŸtirmediÄŸi. Bunun iÃ§in ilk olarak, train ve test ayrÄ±mlarÄ± gerÃ§ekleÅŸtirildi. AnlatÄ±mda da gÃ¶rÃ¼ldÃ¼ÄŸÃ¼ Ã¼zere daha karmaÅŸÄ±k veri kÃ¼melerinde bu da yeterli olmadÄ±ÄŸÄ± iÃ§in, bu defa train-validation-test iÅŸlemi gerÃ§ekleÅŸtiriliyor. ÅÃ¶yle aÃ§Ä±klayayÄ±m:Elimizde 1000 veri olsun. Bunun 100-200 arasÄ±nda bir veriyi ayÄ±rÄ±yoruz ve modele hiÃ§ sokmuyoruz. Bu ayrÄ±m sÄ±rasÄ±nda elinizdeki sÄ±nÄ±flarÄ±n oranÄ±nÄ± korursanÄ±z iyi olur. Geriye kalan 800 veri iÃ§erisinden de yine %80-%20 gibi train ve validation verilerini ayÄ±rarak modelimizi eÄŸitiyoruz. Optimum sonuca ulaÅŸÄ±nca da modeli hiÃ§ gÃ¶rmediÄŸi veri Ã¼zerinde deniyoruz.TÃ¼m bunlar modelin elimizdeki veriyi ezberleyerek (bir nevi suni) yÃ¼ksek oranda baÅŸarÄ±m gÃ¶sterdiÄŸini beyan etmesinin Ã¶nÃ¼ne geÃ§ilmesi iÃ§in yapÄ±lÄ±yor. Kendi modelinizde de train sÄ±rasÄ±nda baktÄ±nÄ±z %100 baÅŸarÄ±ma ulaÅŸmaya baÅŸladÄ±, modeli gÃ¶zden geÃ§irmenizde fayda var.Hepimize iyi kurslar diliyorum.2 months ago 5 people like this.Like ReportReply",
    "-> Merhaba,Overfitting'i https://medium.com/data-science-tr/overfitting-underfitting-cross-validation-b47dfda0cf4e sitesinden alÄ±ntÄ±layacaÄŸÄ±m ÅŸu durumla aÃ§Ä±klayabilirim:\"3 gÃ¼n sonra istatistik sÄ±navÄ±na gireceÄŸinizi dÃ¼ÅŸÃ¼nÃ¼n. GeÃ§miÅŸ 10 yÄ±lÄ±n sorularÄ±nÄ±n olduÄŸu bir arÅŸiv var elinizde, sÄ±navÄ±n geÃ§miÅŸ senelere benzeyeceÄŸini dÃ¼ÅŸÃ¼nÃ¼yorsunuz ve bÃ¼tÃ¼n sorularÄ±-cevaplarÄ± ezberliyorsunuz.Burada eÄŸitim seti geÃ§miÅŸ 10 yÄ±lÄ±n sorularÄ±, model sÄ±navÄ±n geÃ§miÅŸ senelere benzeyeceÄŸini dÃ¼ÅŸÃ¼nmeniz, test seti hiÃ§ gÃ¶rmediÄŸimiz istatistik sÄ±navÄ±, baÅŸarÄ± kriteri aldÄ±ÄŸÄ±nÄ±z not. SÄ±nav sorularÄ± beklendiÄŸiniz gibi gelmez de kÃ¶tÃ¼ not alÄ±rsanÄ±z bu olaya overfitting denir.\"Bu aÃ§Ä±klamaya gÃ¶re eÄŸer modelimiz eÄŸitim iÃ§in kullandÄ±ÄŸÄ±mÄ±z veri setimiz Ã¼zerinde gereÄŸinden fazla Ã§alÄ±ÅŸÄ±p artÄ±k ezber yapmaya baÅŸlamÄ±ÅŸsa overfit oluÅŸur. Tabii overfit oluÅŸturan baÅŸka durumlar da vardÄ±r. (AÅŸaÄŸÄ±da aÃ§Ä±kladÄ±m.)Overfitting olduÄŸunda tahminler eÄŸitim veri seti iÃ§in harika sonuÃ§lar verirler ama eÄŸitim veri setinde olmayan durumlarla karÅŸÄ±laÅŸtÄ±klarÄ±nda nasÄ±l davranmasÄ± gerektiklerini bilmeyeceklerin bu pek efektif olmaz. Bizim amacÄ±mÄ±zda zaten eÄŸitim veri setinde olmayan deÄŸerleri tahmin edebilmek.Overfit oluÅŸturabilecek durumlar arasÄ±nda aÅŸaÄŸÄ±dakiler yer alabilir:1.Modelimiz Ã§ok karmaÅŸÄ±ktÄ±r ve gÃ¶zlem sayÄ±sÄ±ndan Ã§ok parametremiz vardÄ±r.2.Verisetimizde az eÄŸitim verisi vardÄ±r3. EÄŸitimi sÄ±rasÄ±nda o kadar Ã§ok iterasyon yapÄ±lmÄ±ÅŸtÄ±r ki eÄŸitim loss'umuz 0'a Ã§ok yaklaÅŸmÄ±ÅŸtÄ±r.Ne yapÄ±labilir?:1. Feature sayÄ±mÄ±zÄ± azaltmak. Birbirileri ile olan korelasyonu yÃ¼ksek kolonlar silinebilir veya bu deaturelarÄ± kullanarak yeni featurelar oluÅŸturulabilir (Ã–rneÄŸin veri setinizde bir evin geniÅŸliÄŸi ve bri evin yÃ¼ksekliÄŸi featurelarÄ± var ise bu iki feature deÄŸerini Ã§arpÄ±p alan feature'Ä± oluÅŸturabilirsiniz.)2.Verisetimize daha fazla veri ekleyebiliriz.3.RegÃ¼larizasyon(Regularization) yapabiliriz.Hatam veya yanlÄ±ÅŸÄ±m var ise dÃ¼zeltmelere aÃ§Ä±ÄŸÄ±m ğŸ™‚ Ä°yi Ã§alÄ±ÅŸmalar dilerim.",
    "Makine Ã–ÄŸrenmesi Dersleri 8: Cross Validationmedium.comOverfitting (High Variance).",
    "->  Merhaba Atilla. -> 'Ä±n da sÃ¶ylediÄŸi gibi overfitting, modelimizin train datasÄ±ndaki verilerden Ã¶grenirken en ince ayrÄ±ntÄ±sÄ±na kadar Ã¶grenmesi, aÅŸÄ±rÄ±ya kaÃ§masÄ± diyebiliriz. Ama bizim model oluÅŸtururken aradÄ±mÄ±z ÅŸey optimum deger olmalÄ± aksi takdirde test datamÄ±zdaki birÃ§ok veri modelimize %90 uysa bile %10'luk kÄ±smÄ± yÃ¼zÃ¼nden ki bu overfitting yÃ¼zÃ¼nden oldugunu varsayÄ±yorum yanlÄ±ÅŸ kabul edilecek ve baÅŸarÄ± oranÄ± hep %10 larda kalÄ±caktÄ±r. Bu olayÄ±n tam terside olabilir(Underfitting). Iterasyon tablosunda accuracy degerine bakarak en uygun model tÃ¼rÃ¼nÃ¼ belirlemek daha kolay olacaktÄ±r..",
    "->  CevaplarÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederim.2 months ago Like ReportReply",
    "->  Kurs hakkÄ±nda bir sorum daha olacak. Kodlar kurs boyunca hep bu ÅŸekilde (sadece dÃ¼zenleme yapacaÄŸÄ±mÄ±z yerler aÃ§Ä±k ve bloklarÄ±n iÅŸlevleri yazÄ±yor) mi devam ediyor yoksa sonraki derslerde kodlarÄ±n, kullanÄ±lan fonksiyonlarÄ±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±na dair aÃ§Ä±klamalarÄ± da var mÄ±? BazÄ± derslere baktÄ±m ama gÃ¶remedim.2 months ago Like ReportReply",
    "->  Verilen cevaplar pasta gibi Ã¼stÃ¼ne bir de Ã§ilek ekleyelim1 month ago 2 people like this.Like ReportReply",
    "->  Overfitting oluÅŸmasÄ±nÄ±nÄ± temel sebepleri ÅŸunlardÄ±r. Veri sayÄ±sÄ±nÄ±nÄ±z ve Ã§eÅŸitliliÄŸi az olmasÄ±, bias ve variance nin yÃ¼ksek veya dÃ¼ÅŸÃ¼k olmasÄ±, modelin karmaÅŸÄ±klÄ±ÄŸÄ± yÃ¼ksek olmasÄ±dÄ±r. Overfitting problemini Ã§Ã¶zmek iÃ§in genellikle kullanÄ±lan yÃ¶ntemler ÅŸunlardÄ±r; Data Augmentation (Veri ArttÄ±rma) yÃ¶ntemini kullanarak verilerin sayÄ±sÄ±nÄ± arttÄ±rabiliriz. Modelimizi Ã§ok karmaÅŸÄ±k deÄŸilde basit ÅŸekilde tutabilirsek overfitting engellenmiÅŸ olur. DiÄŸer bir yÃ¶ntem ise modelin train loss un azaldÄ±ÄŸÄ± validation loss un arttÄ±ÄŸÄ± epochda eÄŸitimin durdurulmasÄ±dÄ±r. Train Test Validation setlerinin oranÄ±nÄ± deÄŸiÅŸtirebiliriz. Mesela %70 Train %15 Validation %15 Test olarak ayÄ±rabiliriz. Train boyutunu Ã§ok tutmamak lazÄ±mdÄ±r..",
    "->  BazÄ± durumlarda yÃ¼ksek epoch sayÄ±sÄ±nÄ±n fazla olmasÄ± overfitting durumu yaratabilir, ezberlemeyi engelleyebilmek iÃ§in epoch sayÄ±sÄ±nÄ± dÃ¼zgÃ¼n ayarlamak gerekiyor ayrÄ±ca katmanlar arasÄ±ndaki geÃ§iÅŸleri azaltarak ezberlemenin Ã¶nÃ¼ne geÃ§ilebilir. Bunun iÃ§in dropout deÄŸerinin dÃ¼zgÃ¼n belirlenmesi gerekir..",
    "->  Bir ornek vererek aciklayayim.Bir ogerenciye matematikte belli bir soru seklini ogrettigimizi varsayalim.Bir kac ornek verdik anlattik, ogrencinin gayet iyi anladigini gorduk(training).Sonra ayni soru sekli uzerinde sadece sayilari degistirdik ogrenci soruyu cozebildi(validation).Son olarak sorunun seklini verdigimiz ornekler ogrenci tarafindan gercekten anlasildiysa cozebilecegi seviyede degistirdik, gorduk ki ogrenci yapamadi, hatta soruya dogru bile yaklasamadi.(Test)Yani verdigimiz ornekleri gercekten anlamamis, ezberlemis(overfitting).1 month ago 5 people like this.Like ReportReply",
    "->  Overfittingin temel sebebi modelinizdeki layer sayisi arttikca model derinlesir yani complex hale gelir.Kucuk bir training seti bu complex modeli train etmek icin kullanirsaniz kotu generalization yani overfitting meydana gelir.Bunun ustesinden L2 Regularization ve/veya Dropout(ayni anda kullanilmasi tavsiye edilemz) kullanarak gelinebilir.1 month ago 2 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "(LÃ¼tfen sorularÄ±m iÃ§in mazur gÃ¶rÃ¼nÃ¼zâ€¦. )   Bir Ã¶nceki sorunda ( <a class=\"ps-media-link\" href=\"http://community.globalaihub.com/community/status/1028-1028-1586434538/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://community.globalaihub.com/community/status/1028-1028-1586434538/</a> ) yazdÄ±ÄŸÄ±m gibi sadece epoch deÄŸerleri ile oynayarak  loss/rmse grafiÄŸininin eÄŸimini sÄ±fÄ±ra yaklaÅŸtÄ±rabiliyoruz   Ancak ilerleyen Ã¶rneklerde Task 4: Find the ideal combination of epochs and learning rate  (https://colab.research.google.com/github/google/eng-edu/blob/master/ml/cc/exercises/linear_regression_with_synthetic_data.ipynb#scrollTo=r63YkMx82WVr) ve Task 5: Adjust the batch Size (https://colab.research.google.com/github/google/eng-edu/blob/master/ml/cc/exercises/linear_regression_with_synthetic_data.ipynb#scrollTo=0NDET9e6AAbA) Ã–rneklerinde olduÄŸu gibi   Learning rate  Epochs batch_size   parametrelerini deÄŸiÅŸtirerek farklÄ± grafikler elde edebiliyoruzâ€¦.  YapÄ±lanâ€¦ <a class=\"ps-stream-post-more ps-js-content-excerpt-toggle\" href=\"#\">Read more</a></div><div class=\"ps-js-content-full\" style=\"\">(LÃ¼tfen sorularÄ±m iÃ§in mazur gÃ¶rÃ¼nÃ¼zâ€¦. )   Bir Ã¶nceki sorunda ( <a class=\"ps-media-link\" href=\"http://community.globalaihub.com/community/status/1028-1028-1586434538/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://community.globalaihub.com/community/status/1028-1028-1586434538/</a> ) yazdÄ±ÄŸÄ±m gibi sadece epoch deÄŸerleri ile oynayarak  loss/rmse grafiÄŸininin eÄŸimini sÄ±fÄ±ra yaklaÅŸtÄ±rabiliyoruz   Ancak ilerleyen Ã¶rneklerde Task 4: Find the ideal combination of epochs and learning rate  (https://colab.research.google.com/github/google/eng-edu/blob/master/ml/cc/exercises/linear_regression_with_synthetic_data.ipynb#scrollTo=r63YkMx82WVr) ve Task 5: Adjust the batch Size (https://colab.research.google.com/github/google/eng-edu/blob/master/ml/cc/exercises/linear_regression_with_synthetic_data.ipynb#scrollTo=0NDET9e6AAbA) Ã–rneklerinde olduÄŸu gibi   Learning rate  Epochs batch_size   parametrelerini deÄŸiÅŸtirerek farklÄ± grafikler elde edebiliyoruzâ€¦.  YapÄ±lan Ã¶rnekler simple linear regression olmasÄ±ndan dolayÄ±, feature/label grafiklerinde kÄ±rmÄ±zÄ± Ã§izginin mavi Ã§izgilerin Ã¼zerine oturmasÄ± ya da hatayÄ± minimize edecek ÅŸekilde oturmasÄ±na dikkat ettiÄŸimiz durumlarda bile;   1. yalnÄ±zca epochs deÄŸerini ayarlayarak Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±mÄ±z Ã¶rneklerde; epoch deÄŸeri 300 lerde eÄŸim sÄ±fÄ±rlanÄ±yor iken, learning rate, epochs ve batch_size parametrelerini deÄŸiÅŸtirerek yaptÄ±ÄŸÄ±mÄ±z Ã¶rneklerde epoch deÄŸeri 13- 17 aralÄ±ÄŸÄ±nda iken loss / rmse grafiÄŸinin eÄŸiminin sÄ±fÄ±rlandÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼yoruzâ€¦    Genel olarak amacÄ±mÄ±z learning rate, epochs ve batch_size parametrelerini ayarlayarak loss/rmse grafiÄŸinin eÄŸiminin min epoch deÄŸerinde sÄ±fÄ±rlanmasÄ±nÄ± mÄ± yakalamaktÄ±r..</div></div>",
"comment": [
    "",
    "->  Merhabalar,YazmÄ±ÅŸ olduÄŸunuz, yazacaÄŸÄ±nÄ±z her satÄ±r kodun size bir zaman maliyeti olur. Bu aÅŸamada asÄ±l amacÄ±mÄ±z loss/rmse grafiÄŸini minimize etmek evet ancak bunu yaparken en az adÄ±mda olmasÄ±nÄ± istiyoruz, Ã§Ã¼nkÃ¼ adÄ±m ne kadar azalÄ±rsa sonuca o kadar hÄ±zlÄ± ulaÅŸÄ±rÄ±z. Bu durumda asÄ±l amacÄ±mÄ±zÄ±n gerÃ§ek minimuma ulaÅŸmak deÄŸilde, en hÄ±zlÄ± ÅŸekilde optimal bir minumum deÄŸer elde etmek.Bunu basitÃ§e test edebilirsiniz: epoch iÃ§in 1000 seÃ§tiÄŸinizde eÄŸitim iÃ§in geÃ§en zaman ile 250 seÃ§meniz halinde geÃ§en zamanÄ± karÅŸÄ±laÅŸtÄ±rÄ±n. Tabi veri setinin Ã§ok kÃ¼Ã§Ã¼k olmasÄ±(12 sentetik gÃ¶zlemden oluÅŸmakta) muazzam bir zaman farkÄ± oluÅŸturmayacaktÄ±r. Ama birde bunu yÃ¼zbinlerce gÃ¶zlemden oluÅŸan bir sette yaptÄ±ÄŸÄ±nÄ±zÄ± dÃ¼ÅŸÃ¼nÃ¼n. Ä°lk yapacaÄŸÄ±nÄ±z ÅŸey, sonuca daha hÄ±zlÄ± ulaÅŸmanÄ±n yolunu aramak olacaktÄ±r.Ä°yi Ã§alÄ±ÅŸmalar.2 months ago 5 people like this.Like ReportReply",
    "->  ->  az sonra graikler ile gÃ¶stereceÄŸim anlatacaÄŸÄ±mÄ±2 months ago Like ReportReply",
    "-> ->  ayrÄ±ca bende sormak isterim bu soru devamÄ±nda ,hÄ±zlÄ± ulaÅŸmaya Ã§alÄ±ÅŸÄ±lmasÄ±nda ÅŸÃ¶yle bir ÅŸey takÄ±ldÄ± aklÄ±ma,aslÄ±nda demek istediÄŸim 1000 veri den 500 batchsize ve 2 iteration yapsam 1 epoch denk geliyor. Yani bir kere ileri ve geri aktarÄ±lÄ±yor deÄŸil mi? 250 batchsize 4 iteration yapsam yine 1 epoch olur. 2 epoch iÃ§in bunlar 500 batchsize 8 iteration olur dimi? Buda bir 8 iteration 8 batch demek galiba. Epochâ€™u artÄ±rÄ±nca zaman daha Ã§ok yer kaplÄ±yor gibi bununla birlikte iteration da fazlalaÅŸÄ±yor. Peki iterationlar mini-batch ihtiyaÃ§ duyar mÄ± peki learning_rate dahilinde, Ã§Ã¼nkÃ¼ bunlarda zamanÄ± gecikterecek olaylar dimi?2 months ago Like Reply Edit",
    "-> -> 250 batch size ile 2 iterasyonda batch size da deÄŸiÅŸiklik olmaz 250 olarak kalÄ±r, gerisinde sorun yok, ancak epoch ile sÄ±nÄ±rlayarak konuyu daha basit bir ÅŸekilde aÃ§Ä±klamaya Ã§alÄ±ÅŸmÄ±ÅŸtÄ±m. Batch size kÃ¼Ã§Ã¼ldÃ¼kÃ§e iterasyon artmakta, ayrÄ±ca learning_rate'ye gÃ¶re de epoch sÃ¼resi deÄŸiÅŸmekte. Ã–zetle dediÄŸiniz gibi batch_size ve learning_rate de gecikmeye sebep olmakta.Bu yÃ¼zden biz sadece epoch iÃ§in optimal deÄŸeri aramayacak, learning_rate, batch_size ve epoch Ã¼Ã§lÃ¼sÃ¼ iÃ§in optimal deÄŸerleri arayacaÄŸÄ±z.Basit bir Ã¶rnek vermek gerekirse: Direkt olarak Ã¶rnek Ã§alÄ±ÅŸmadan bakacak olursak: learning_rate=0.01 iken 350 epoch da optimum deÄŸere ulaÅŸÄ±rken, learning_rate = 0.14 olarak deÄŸiÅŸtirirsek 70 epoch gibi bir deÄŸerde minimum loss'a ulaÅŸmaktayÄ±z. Buraya batch size Ä± da ekleyip farklÄ± sonuÃ§lara ulaÅŸmak mÃ¼mkÃ¼n. Deneysel olarak hangi parametre ne kadar zaman kaybÄ±na sebep olmakta ayrÄ± ayrÄ± deneyerek gÃ¶zlemleyebilirsiniz. Tabi kÃ¼Ã§Ã¼k bir veri setinde olmasÄ±nÄ± tavsiye ederim :)Ä°yi Ã§alÄ±ÅŸmalar..",
    "->  TeÅŸekkÃ¼rler -> , cevap son derece yeterli ancak sentetik veri seti olduÄŸunu anlamak ile birlikte,AynÄ± veri seti Ã¼zerinden dÃ¼ÅŸÃ¼nÃ¼rsek ideal olan loss/rmse grafiÄŸi iÃ§in soruyorum... min epoch deÄŸerinde eÄŸimin sÄ±fÄ±rlanmasÄ± daha iyidir gibi bir sonuÃ§ mu Ã§Ä±karmamÄ±z lazÄ±m.....",
    "->  ->  Tam olarak Ã¶yle demeyelim min epoch dediÄŸimiz zaman epoch'un minimum olabileceÄŸi deÄŸer 1 olduÄŸu iÃ§in yanlÄ±ÅŸ anlaÅŸÄ±labilir. EÄŸimin sÄ±fÄ±rlanmasÄ±na olanak saÄŸlayan optimal epoch deÄŸeri iyidir gibi bir sonuÃ§ Ã§Ä±karabiliriz.2 months ago Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar;   Task 2: Increase the number of epochs (https://colab.research.google.com/github/google/eng-edu/blob/master/ml/cc/exercises/linear_regression_with_synthetic_data.ipynb#scrollTo=lLXPvqCRvgI4) uygulamasÄ±nÄ± yaparken   10 epoch deÄŸerinin Ã§alÄ±ÅŸmadÄ±ÄŸÄ± aÅŸikar,   (ki burada epoch vs RMSE grafiÄŸine baktÄ±ÄŸÄ±mÄ±zda bekletimiz grafiÄŸin eÄŸiminin sÄ±fÄ±ra yakÄ±nlaÅŸmasÄ± ya da sÄ±fÄ±r olmasÄ± )  Ancak sorun ÅŸu;  epoch= 450 deÄŸerini aldÄ±ÄŸÄ±mÄ±z zaman epoch deÄŸeri 300 ( +20) lerde iken eÄŸim sÄ±fÄ±rlanÄ±yor ve 450 epoch deÄŸerine kadar sÄ±fÄ±r olarak kalÄ±yor..  epoch=600 yaptÄ±ÄŸÄ±mÄ±zda da epoch deÄŸeri 350 - 375 arasÄ±nda iken eÄŸim sÄ±fÄ±rlanÄ±yor ve 600 epoch a kadar sÄ±fÄ±r eÄŸimle devam ediyor. Epoch deÄŸerinin makbul olanÄ± 450 midir? 600 mÃ¼dÃ¼r?   NOT: (Belki de soru ÅŸÃ¶yle olmalÄ± ) Deneyselâ€¦ <a class=\"ps-stream-post-more ps-js-content-excerpt-toggle\" href=\"#\">Read more</a></div><div class=\"ps-js-content-full\" style=\"\">Merhabalar;   Task 2: Increase the number of epochs (https://colab.research.google.com/github/google/eng-edu/blob/master/ml/cc/exercises/linear_regression_with_synthetic_data.ipynb#scrollTo=lLXPvqCRvgI4) uygulamasÄ±nÄ± yaparken   10 epoch deÄŸerinin Ã§alÄ±ÅŸmadÄ±ÄŸÄ± aÅŸikar,   (ki burada epoch vs RMSE grafiÄŸine baktÄ±ÄŸÄ±mÄ±zda bekletimiz grafiÄŸin eÄŸiminin sÄ±fÄ±ra yakÄ±nlaÅŸmasÄ± ya da sÄ±fÄ±r olmasÄ± )  Ancak sorun ÅŸu;  epoch= 450 deÄŸerini aldÄ±ÄŸÄ±mÄ±z zaman epoch deÄŸeri 300 ( +20) lerde iken eÄŸim sÄ±fÄ±rlanÄ±yor ve 450 epoch deÄŸerine kadar sÄ±fÄ±r olarak kalÄ±yor..  epoch=600 yaptÄ±ÄŸÄ±mÄ±zda da epoch deÄŸeri 350 - 375 arasÄ±nda iken eÄŸim sÄ±fÄ±rlanÄ±yor ve 600 epoch a kadar sÄ±fÄ±r eÄŸimle devam ediyor. Epoch deÄŸerinin makbul olanÄ± 450 midir? 600 mÃ¼dÃ¼r?   NOT: (Belki de soru ÅŸÃ¶yle olmalÄ± ) Deneysel Ã§alÄ±ÅŸmalar yapmam gerektiÄŸini ve bu deÄŸerlerin ileride Ã§ok daha net olarak belirleyebileceÄŸimizi biliyorum. Ancak ÅŸu an iÃ§in buna takÄ±lmak doÄŸrumudur? DeÄŸil midir?</div></div>",
"comment": [
    "",
    "->  Merhaba, bence bu deÄŸerlere takÄ±lmana gerek yok. Veri setinden veri setine bu parametreler farklÄ±lÄ±k gÃ¶sterebilir. BÃ¼yÃ¼k ihtimalle hiÃ§bir zaman bu kadar kÃ¼Ã§Ã¼k veri setleri ile Ã§alÄ±ÅŸmayacaksÄ±n. Temelleri anlayÄ±p, deneysel sonuÃ§lar Ã¼zerinde Ã§ok fazla zaman harcamamak gerektiÄŸini dÃ¼ÅŸÃ¼nÃ¼yorum.2 months ago Like ReportReply",
    " "
]
},
{
"question_isim": "->  ",
"quest": "Herkese Merhaba,  12 Nisan'da olacak olan Quiz'in belli bir zaman aralÄ±ÄŸÄ± var mÄ± ? Yoksa gÃ¼n iÃ§erisinde istediÄŸimiz zaman Quiz'e katÄ±labilir miyiz? Ä°yi Ã§alÄ±ÅŸmalar, saÄŸlÄ±klÄ± gÃ¼nler",
"comment": [
    "",
    "->  Merhaba Cengiz, evet belli bir zaman aralÄ±ÄŸÄ±nda olacak, detaylarÄ± size yarÄ±n gÃ¼n iÃ§inde bildirmiÅŸ oluruz, iyi Ã§alÄ±ÅŸmalar ğŸ™‚.",
    "->  ->  Hocam sÄ±nav saatleri belli oldu mu?.",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Herkese iyi gÃ¼nler. Biraz konu dÄ±ÅŸÄ±nda olacak ama kursta ilerlerken laptopa Tensorflow kurmaya karar verdim ancak ne kadar denediysem de hep hatayla karÅŸÄ±laÅŸtÄ±m. Anaconda,Pycharm vs. denedim ancak her defasÄ±nda hata aldÄ±m. Acaba daha Ã¶nce bu tarz hatayla karÅŸÄ±laÅŸÄ±p yardÄ±mcÄ± olabilen olur mu?  Hata mesajÄ±: ImportError: DLL load failed: Belirtilen modÃ¼l bulunamadÄ±.",
"comment": [
    "",
    "->  Ben spyder kullanÄ±yorum , bu tarz bi modÃ¼l yÃ¼kleme hatasÄ±yla karÅŸÄ±laÅŸmÄ±ÅŸtÄ±m . SpyderÄ± son sÃ¼rÃ¼mÃ¼ne gÃ¼ncelleyince problem Ã§Ã¶zÃ¼lmÃ¼ÅŸtÃ¼...",
    "->  Merhaba,Anaconda yÃ¼klÃ¼ ise makinanda, aynÄ± zamanda Anaconda Prompt gelmekte, Anaconda Prompt'u aÃ§tÄ±ÄŸÄ±n zaman(base) C:\\Users\\user_name> ile baÅŸlayan bir komut ekranÄ± aÃ§Ä±lacak,Bu ekranda iken console'ye \"pip install tensorflow\" yazarsan sorunsuz bir ÅŸekilde tensorflow kurulacaktÄ±r..",
    "->  ->  ve ->  Pycharm Ã¼zerinden kurmaya Ã§alÄ±ÅŸtÄ±ÄŸÄ±mda kurulurken Tensorflow kuruldu demesine raÄŸmen, programÄ±n derlenmesi sÄ±rasÄ±nda hata verdi. daha sonra pip ile kurduÄŸumda sorunsuz bir ÅŸekilde Ã§alÄ±ÅŸtÄ± bende de.",
    "->  ->  Merhaba, dediÄŸiniz gibi console'da \"pip install tensorflow\" ile install yaptÄ±m. SonrasÄ±nda yeniden Spider'da tensorflow'u import edemedim. AÅŸaÄŸÄ±daki hatayÄ± aldÄ±m. Ne yapmam gerekir? Ã‡ok teÅŸekkÃ¼rler..",
    "->  ->  Merhaba,1 - simply download MSVCP140.dll, unzip it and then paste it in system32 folder..2 - pip install tensorflow --upgrade --force-reinstall (Bu iÅŸlemi anaconda prompt Ã¼zerinde yapmanÄ±z gerekmekte)Bu iki adÄ±mÄ± dener misiniz, Ã¶nerilen Ã§Ã¶zÃ¼mler arasÄ±nda bulunmaktalar. Daha Ã¶nce karÅŸÄ±laÅŸmadÄ±ÄŸÄ±m iÃ§in kesin bir yol sÃ¶yleyemiyorum..",
    "->  ->  TeÅŸekkÃ¼rler ama baÅŸarÄ±lÄ± olamadÄ±m. BaÅŸka Ã§Ã¶zÃ¼mler bakÄ±yorum netten. Ã‡ok teÅŸekkÃ¼rler..",
    "->  Pycharm iÃ§in nasÄ±l bir indirme yÃ¶ntemi kullandÄ±n? Pycharm sÃ¼rÃ¼mÃ¼n kaÃ§? Python sÃ¼rÃ¼mÃ¼n kaÃ§?.",
    "->  Bende anaconda Ã¼zerinden kurdum daha sonra python IDLE iÃ§in cmd kÄ±smÄ±nda pip install numpy ve tensorflow yazÄ±nca sorunsuz Ã§alÄ±ÅŸtÄ± yani ÅŸuan hem spyder,jupyter hemde normal python IDLE Ã¼zerinde kullanabiliyorum, tensorflow web sitesindeki talimatlarÄ± dikkatlice uygularsanÄ±z sorunsuz Ã§alÄ±ÅŸacaktÄ±r..",
    "->  Herkese teÅŸekkÃ¼r ederim deÄŸerli yorumlarÄ± iÃ§in. GÃ¼nÃ¼n sonunda sorunu Ã§Ã¶zmÃ¼ÅŸ olmanÄ±n keyfini yaÅŸÄ±yorum. AnacondayÄ± silip tekrar kurdum ve farkettim ki sorun \"Microsoft Visual C++\" Ä±n gÃ¼ncel versiyonunun yÃ¼klÃ¼ olmamasÄ±ndan kaynaklÄ±ymÄ±ÅŸ.1 month ago 3 people like this.Like ReportReply",
    "->  Bende de 2.1 versiyonunda sorun Ã§Ä±kmÄ±ÅŸtÄ±. 2.0'a dÃ¶nÃ¼nce sorun Ã§Ã¶zÃ¼ldÃ¼. EÄŸer sizin versiyon da 2.1 ise onu kaldÄ±rÄ±p 2.0'Ä± yÃ¼klemenizi Ã¶neririm. 2.0 yÃ¼klemek iÃ§in pip install tensorflow==2.0.0 komutunu kullanabilirsiniz..",
    " "
]
},
{
"question_isim": "->",
"quest": "Merhaba arkadaÅŸlar, konuyu anlamakta biraz zorluk Ã§ekiyorum ama Ã¶rnek Ã¼stÃ¼nden sormak istedim. Åimdi elimde Ã§eÅŸitli ÅŸekillerde para birimlerim olan bir data set Ã¶rneÄŸi var (bu para birimleri labels oluyor) bide bu datasette paralarÄ±n aÄŸÄ±rlÄ±klarÄ±, boyutlarÄ± gibi Ã¶rnekler var (yani features). Ben bunlardan bir model oluÅŸturmak istersem (training) kullanmÄ±ÅŸ olduÄŸum ÅŸey labeled examples oluyor. Bunaâ€ firstmodelâ€ diyelim. BÃ¶ylelikle aÄŸÄ±rlÄ±ktan hangi para birimi olduÄŸunu soranlara (classification model) tahmin yÃ¼rÃ¼tebiliyorum (suprevised learning). Modeli oluÅŸturduktan sonra, para birimi verilmeyen ama features verilen bir â€œbaÅŸkaâ€ datasetti, â€œfirstmodelâ€ dediÄŸimiz datasete uyguladÄ±ÄŸÄ±mda ise unlabeled examples iÃ§in inference yapmÄ±ÅŸ oluyorum buda â€œsecondmodelâ€ olsun. Bu â€œsecondmodelâ€ ise bir kullanÄ±cÄ±nÄ±n gÃ¶zÃ¼ kapalÄ± ÅŸekilde TL parabirimini en hÄ±zlÄ± seÃ§me olasÄ±lÄ±ÄŸÄ±nÄ± nedir sorusuna tahmin yÃ¼rÃ¼tebiliyor olsun.â€¦ <a class=\"ps-stream-post-more ps-js-content-excerpt-toggle\" href=\"#\">Read more</a></div><div class=\"ps-js-content-full\" style=\"\">Merhaba arkadaÅŸlar, konuyu anlamakta biraz zorluk Ã§ekiyorum ama Ã¶rnek Ã¼stÃ¼nden sormak istedim. Åimdi elimde Ã§eÅŸitli ÅŸekillerde para birimlerim olan bir data set Ã¶rneÄŸi var (bu para birimleri labels oluyor) bide bu datasette paralarÄ±n aÄŸÄ±rlÄ±klarÄ±, boyutlarÄ± gibi Ã¶rnekler var (yani features). Ben bunlardan bir model oluÅŸturmak istersem (training) kullanmÄ±ÅŸ olduÄŸum ÅŸey labeled examples oluyor. Bunaâ€ firstmodelâ€ diyelim. BÃ¶ylelikle aÄŸÄ±rlÄ±ktan hangi para birimi olduÄŸunu soranlara (classification model) tahmin yÃ¼rÃ¼tebiliyorum (suprevised learning). Modeli oluÅŸturduktan sonra, para birimi verilmeyen ama features verilen bir â€œbaÅŸkaâ€ datasetti, â€œfirstmodelâ€ dediÄŸimiz datasete uyguladÄ±ÄŸÄ±mda ise unlabeled examples iÃ§in inference yapmÄ±ÅŸ oluyorum buda â€œsecondmodelâ€ olsun. Bu â€œsecondmodelâ€ ise bir kullanÄ±cÄ±nÄ±n gÃ¶zÃ¼ kapalÄ± ÅŸekilde TL parabirimini en hÄ±zlÄ± seÃ§me olasÄ±lÄ±ÄŸÄ±nÄ± nedir sorusuna tahmin yÃ¼rÃ¼tebiliyor olsun. (regression)(unsupervised learning). Bu anlattÄ±ÄŸÄ±m doÄŸrumu dur? Yani bir etiketsiz veri datasetini eÄŸitmek istersem yada geliÅŸtirmek istersem, Ã¶nceden etiketli bir data setiyle birleÅŸtirmem mi lazÄ±m, Ã§Ä±karÄ±m iÃ§in? yoksa bu ikiside farklÄ± datasetler olabilir ve ikiside farklÄ± iÅŸlerde kullanÄ±labilir mi? Ã¶rneÄŸin bir firma \"firstmodel\" kullanarak sadece para tahmini yaparken \"secondmodel\" baÅŸka bir firmada grublama iÃ§in kullanÄ±labilir mi? BurasÄ± iyice karÄ±ÅŸtÄ± bende, yanlÄ±ÅŸÄ±m var ise lÃ¼tfen dÃ¼zeltir misiniz?</div></div>",
"comment": [
    "",
    "->  Merhaba, AslÄ±nda bahsettiÄŸin first model ve second model aynÄ± model. First modelde veri setiyle model oluÅŸturup eÄŸitiyorsun. Second model dediÄŸin ÅŸey bilinen deÄŸerlerden bilinmeyen deÄŸeri tahmin etme. Model kurarken test datasÄ±nda model doÄŸruluÄŸunu test ederken yapÄ±lan iÅŸlem. Regresyon ile sÄ±nÄ±flama problemleri zaten ayrÄ± konular. SÄ±nÄ±flama birbiri ile kÄ±yas yapÄ±lamayan haliyle ortalamasÄ± alÄ±namayan deÄŸiÅŸkenler iÃ§in yapÄ±lÄ±r(Ã¶rneÄŸin: boy ve kilodan cinsiyet tahmin. KadÄ±nlar ve erkeklerin ortalamasÄ±nÄ± alÄ±p %30 kadÄ±n %70 erkek diyemezsin. Ä°kisinden birini seÃ§mek zorundasÄ±n nihai tahminde). Regresyon modelleri ise sÃ¼rekli deÄŸerler alabilen bir deÄŸiÅŸken tahmin edilirken kullanÄ±lÄ±r.2 months ago 7 people like this.Like ReportReply",
    "-> Merhabalar,Sizin Ã¶rnekleriniz Ã¼zerinden devam ederek aÃ§Ä±klamaya Ã§alÄ±ÅŸayÄ±m, Firstmodel iÃ§in sÃ¶ylediÄŸiniz doÄŸru, supervised learning, sonucunun ne olduÄŸunu bildiÄŸimiz veri ile algoritmamÄ±zÄ± eÄŸitip, ileriye dÃ¶nÃ¼k olarak elimize gelecek olan verilerin classification iÃ§in hangi sÄ±nÄ±fa, regression iÃ§in ise hangi deÄŸere sahip olduÄŸunu tahmin etmemiz aÅŸamalarÄ±nÄ± iÃ§ermektedir. Yani Ã¶zetle Supervised learning'de yaptÄ±ÄŸÄ±mÄ±z SONUCU BÄ°LÄ°NEN(Etiketlerimiz oluyor.) geÃ§miÅŸ tecrÃ¼belerden Ã¶ÄŸrenerek, geleceÄŸe yÃ¶nelik tahminde bulunmak.Ancak second model iÃ§in vermiÅŸ olduÄŸunuz Ã¶rnekte ki insan/ kullanÄ±cÄ± her ne kadar gÃ¶zÃ¼ kapalÄ± olsa bile TL parabimini seÃ§me olasÄ±lÄ±ÄŸÄ±ndan bahsediyorsak da Supervised Regression olur Ã§Ã¼nkÃ¼ kullanÄ±cÄ±nÄ±n TL etiketine ait feature bilgisine sahip olmasÄ± lazÄ±m aksi takdirde bu olasÄ±lÄ±k hesabÄ± oldukÃ§a basit bir ÅŸekilde sÃ¶ylenebilir(toplam TL banknotu sayÄ±sÄ±nÄ±n veri seti bÃ¼yÃ¼klÃ¼ÄŸÃ¼ne oranÄ±dÄ±r.). Unsupervised Learning iÃ§in ne yazÄ±k ki regression ile alakalÄ± bir kaynak gÃ¶rmÃ¼ÅŸ deÄŸilim bu kÄ±sÄ±m yanlÄ±ÅŸ olabilir. BildiÄŸim kadarÄ± ile Unsupervised learning iÃ§in etiket bilgisine ihtiyaÃ§ yoktur. AmaÃ§ ortak Ã¶zelliklere sahip olan kÃ¼meleri ortaya Ã§Ä±karmak olduÄŸu iÃ§in, Ã¶rneÄŸinizi eÄŸer kullanÄ±cÄ±nÄ±n gÃ¶zÃ¼ kapalÄ± bir ÅŸekilde paralarÄ± kÃ¼melemesi olursa bu unsupervised learning'e Ã¶rnek olacaktÄ±r. Bu durumda kullanÄ±cÄ±nÄ±n yapacaÄŸÄ± iÅŸlem her bir banknotu eline alarak birbirleri ile kÄ±yaslamak sureti ile kendisine aynÄ± hissi veren banknotlarÄ± aynÄ± gruplara koymak olacaktÄ±r.2 months ago 10 people like this.Like ReportReply",
    "-> Ã‡ok teÅŸekkÃ¼r ederim ->  ve ->  ,2 months ago Like Reply Edit",
    " "
]
},
{
"question_isim": "->  uploaded 1 photo",
"quest": "Merhabalar arkadaÅŸlar, Bir soru sormayacaÄŸÄ±m ancak Simple Lineer Regresyon Ã§alÄ±ÅŸÄ±rken farkettiÄŸim bir mantÄ±k hatasÄ±nÄ± paylaÅŸmak istedim.  Linear Regression with Synthetic Data alÄ±ÅŸtÄ±rmasÄ±nÄ± incelerken, train_model()'de batch_size parametresine fonksiyona parametre olarak gelen batch_size deÄŸeri atanmamÄ±ÅŸ onun yerine None deÄŸeri atanmÄ±ÅŸ. AlÄ±ÅŸtÄ±rmanÄ±n sonuna doÄŸru batch_size ile alakalÄ± dÃ¼zenleme yapmamÄ±zÄ± en kÃ¼Ã§Ã¼k hangi deÄŸerde Ã§alÄ±ÅŸabildiÄŸini bulmamÄ±zÄ± istemiÅŸ. Bu hali ile batch_size iÃ§in biz 0.0001 gibi bir deÄŸer bile girsek hata almamÄ±z gerekirken hatasÄ±z bir ÅŸekilde Ã§alÄ±ÅŸacaktÄ±r. Ã‡Ã¼nkÃ¼ varsayÄ±lan olarak model bÃ¼tÃ¼n data ile train iÅŸlemini gerÃ§ekleÅŸtirmekte.     Ä°yi Ã§alÄ±ÅŸmalar.",
"comment": [
    "",
    "->  Bilgilendirme iÃ§in teÅŸekkÃ¼rler furkan bey..",
    "->  Ã–nemli bir bilgilendirme. Ben de model fonksiyonlarÄ±na bakarken fark ettim.def train_model() fonksiyonunu;batch_size=None => batch_size=batch_size,ÅŸeklinde gÃ¼ncelleyince, batch size deÄŸikliÄŸinin etkileri gÃ¶zÃ¼kmekte..",
    " "
]
},
{
"question_isim": "Merve Horoz uploaded 2 photos",
"quest": "Merhabalar, yukarÄ±daki \"Adjust the batch size\" Ã¶rneÄŸinde batch size'Ä± 1 olarak seÃ§tiÄŸimde loss'u 2,3724 MSE ise 1,54 olarak hesaplandÄ±. Batch size'Ä± 4 olarak seÃ§tiÄŸimde ise daha dÃ¼ÅŸÃ¼k loss ve MSE'ye sahip oldum (loss = 0.8753 MSE = 0.93) . Cevap olarak en kÃ¼Ã§Ã¼k batch size'Ä± 1 olarak seÃ§ebileceÄŸimiz gÃ¶sterilmiÅŸ.  CevabÄ± 1 olarak gÃ¶stererek bize ne aÃ§Ä±klanmak istenmiÅŸ? Daha dÃ¼ÅŸÃ¼k loss ve MSE ' ye sahip olduÄŸumuzda daha doÄŸru size'Ä± bulduÄŸumuz anlamÄ±na geldiÄŸini sÃ¶yleyemez miyiz?",
"comment": [
    "",
    "->  Merhaba, 100 epoch'ta converge edecek ÅŸekilde seÃ§ebileceÄŸiniz en kÃ¼Ã§Ã¼k integer deÄŸer nedir diye soruyor. Cevap iÃ§in o yÃ¼zden 1 yazmÄ±ÅŸ, loss ve mse deÄŸerlerine dikkat ederek yazmamÄ±ÅŸ.2 months ago Like ReportReply",
    "->  Ä°lk gÃ¶rÃ¼nteki en son paragrafta,100 epochs ta bile modelin 'converge' yani optimuma yakÄ±nsamÄ±ÅŸ duruma gelmesi iÃ§in verebileceÄŸimiz en kÃ¼Ã§Ã¼k batch_size sorulmuÅŸ.Problem Ã¶zÃ¼nde 1 bile yetebilmiÅŸ bunu gÃ¶stermeye Ã§alÄ±ÅŸÄ±yor aslÄ±nda.Problem iÃ§in belki de 4 ten daha optimal bir deÄŸer vardÄ±r,ancak batch_size=1 olarak kabul edildiÄŸinde de model,optimale yaklaÅŸabilmiÅŸ. batch_size bir hyperparametre olduÄŸu iÃ§in,kesin ve net bir deÄŸeri vardÄ±r diyemeyiz.LÃ¼tfen eksik veya yanlÄ±ÅŸ ifade ettiÄŸim bir ÅŸey varsa uyarÄ±n. ğŸ™‚.",
    "Merve Horoz Ã‡ok teÅŸekkÃ¼rler ->  ->  ..",
    "->  http://community.globalaihub.com/community/status/618-618-1586424145/#comment.2599.2784.2784.",
    " "
]
},
{
"question_isim": "-> uploaded 1 photo",
"quest": "Herkese iyi Ã§alÄ±ÅŸmalar,attÄ±ÄŸÄ±m gÃ¶rÃ¼ntÃ¼deki anormal olan parametreyi aÃ§Ä±kÃ§asÄ± pek anlayamadÄ±m,bu deÄŸerleri gÃ¶z Ã¶nÃ¼nde bulundururken 1000 e bÃ¶lÃ¼nmÃ¼ÅŸ Ã¶lÃ§ekli olan deÄŸeri ile mi kÄ±yaslÄ±yacaÄŸÄ±z ?",
"comment": [
    "",
    "-> Burada benim anladÄ±ÄŸÄ±m yanlÄ±ÅŸlÄ±k ÅŸu; Ã–ncelikle oradaki deÄŸerlerin anlamlarÄ±nÄ± sÃ¶yleyim.mean: ortalama,std:standart sapma,gerisi ÅŸÃ¶yle hesaplanÄ±yor elimizde 1den 9a kadar sayÄ±lar olsun(kÃ¼Ã§Ã¼kten bÃ¼yÃ¼ÄŸe doÄŸru sÄ±ralanmÄ±ÅŸ ÅŸekilde veriler karÄ±ÅŸÄ±ksa Ã¶nce sÄ±ralanmalÄ±) [1-2-3-4-5-6-7-8-9] Burada min:en kÃ¼Ã§Ã¼k yani (1) deÄŸeri oluyor max: en bÃ¼yÃ¼k yani (9) deÄŸeri oluyor. %50 medyan(ortanca):5 deÄŸeri oluyor sÄ±ralayÄ±nca ortadaki %25: 1. Ã§eyreklik deÄŸerimiz yani (3) oluyor. %75: 7 deÄŸerimiz oluyor. Åimdi bu bilgilere gÃ¶re tablodaki yorumum ÅŸÃ¶yle: total_rooms feature'Ä±nÄ±n deÄŸerlerine bakÄ±nca her Ã§eyrek iÃ§in deÄŸerleri sÄ±rasÄ±yla 2-1462-2127-3151-37937 yani her Ã§eyrekte genellikle 1000 civarÄ± bir deÄŸiÅŸim olurken %75den max a geÃ§erken yaklasÄ±k 34000 lik bir deÄŸiÅŸim olmuÅŸ. Bu da birÃ§ok nedenden dolayÄ± olabilir yani aslÄ±nda 3793 gibi bir sayÄ± yazarken yanlÄ±ÅŸlÄ±kla fazla yazÄ±lmÄ±s olabilir.(AyrÄ±ca EÄŸer gerÃ§ekte bÃ¶yle bir deÄŸer var ve diÄŸer bÃ¼tÃ¼n deÄŸerler bu deÄŸerden uzaksa istatistikte bazen bÃ¶yle sapan deÄŸerler veri setinden Ã§Ä±karÄ±larak gÃ¶z ardÄ± edilebiliyor.)Mesela housing_median_age,median_income ve median_house_value kÄ±smÄ±nda herÅŸey normal gibi fakat total_rooms taki gibi bir anormallik ayn ÅŸekilde total_bedrooms,population ve households da da gÃ¶rÃ¼lÃ¼yor. Benim bildiklerim ile anladÄ±ÄŸÄ±m ve yorumamlamam budur. YanlÄ±ÅŸÄ±m varsa beni de dÃ¼zeltirseniz sevinirim. Ä°yi Ã§alÄ±ÅŸmalar dilerim.2 months ago 9 people like this.Like ReportReply",
    "-> Merhaba Emre,Cemhan'Ä±n sÃ¶ylediklerine bir ekleme yapmak istedim. Bu konuda bahsedilen istatistikte outlier yani aykÄ±rÄ± deÄŸer olarak geÃ§iyor. Elimizdeki verileri kÃ¼Ã§Ã¼kten bÃ¼yÃ¼ÄŸe sÄ±ralayÄ±nca en ortadaki deÄŸer medyan(Q2 veya 50th percentile), medyan ile minimum ortasÄ±ndaki deÄŸer first quartile(Q1 veya 25th percentile), son olarak medyan ile maksimum ortasÄ±ndaki deÄŸer ise third quartile(Q3 veya 75th percentile) olarak geÃ§er. Bu deÄŸerlere bakarak veri setimizin daÄŸÄ±lÄ±mÄ± hakkÄ±nda az Ã§ok bilgi sahibi olabiliriz.Gelelim en baÅŸta bahsettiÄŸim outlier tanÄ±mlamasÄ±na. Verisetimizdeki aykÄ±rÄ± deÄŸerleri saptarken aÅŸaÄŸÄ±daki formÃ¼lÃ¼ kullanÄ±yoruz(birkaÃ§ farklÄ± yaklaÅŸÄ±m var ancak en basiti):IRQ = (Q3 - Q1)Upper fence = Q3 + 1.5*IRQ, lower fence = Q1 - 1.5*IRQOutlierlar bu upper fence ve lower fence yani sÄ±nÄ±rlarÄ±nÄ±n dÄ±ÅŸÄ±nda kalan deÄŸerler oluyor. Bunlar ise bizim verisetimizi bozabilecek deÄŸerler. Tabi bu deÄŸerlerin model eÄŸitiminde kullanÄ±lÄ±p kullanÄ±lmayacaÄŸÄ± data scientistin tecrÃ¼be ve Ã¶ngÃ¶rÃ¼sÃ¼ne kalÄ±yor. AÅŸaÄŸÄ±da datasetteki median_income deÄŸerleri ile Ã§izilmiÅŸ bir box plot Ã¶rneÄŸi paylaÅŸtÄ±m. Bu grafik ile yukarÄ±da bahsettiÄŸim tÃ¼m deÄŸerleri veri Ã¼zerinde gÃ¶rebiliyoruz, upper fence Ã¼zerinde kalan tÃ¼m deÄŸerler outlier oluyor.Ä°yi Ã§alÄ±ÅŸmalar..",
    "-> TeÅŸekkÃ¼rler ğŸ™‚2 months ago Like ReportReply",
    "->  ->  'un yorumunda bahsettiÄŸi veri bilimcinin tecrÃ¼be ve Ã¶ngÃ¼rsÃ¼ne kalma durumunu birazcÄ±k aÃ§mak istiyorum. AÅŸÄ±rÄ± deÄŸerleri gÃ¶rdÃ¼ÄŸÃ¼mÃ¼zde onlarÄ± veri setinden Ã§Ä±karÄ±p Ã§Ä±karmama noktasÄ±nda oldukÃ§a dikkatli olmak gerekiyor. EÄŸer aÅŸÄ±rÄ± deÄŸer veri giriÅŸinden kaynaklÄ± bir hataysa bunu veri setinden Ã§Ä±karabilirsin. Ã–rneÄŸin ilkÃ¶ÄŸretim Ã¶ÄŸrencilerinden elde edilen bir veride 45 yaÅŸ hatalÄ± bir veri giriÅŸi diyebiliriz. Ev fiyatlarÄ±nÄ± dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼mÃ¼zde diyelim ki 1 milyon deÄŸerinde bir ev ile karÅŸÄ±laÅŸtÄ±k. Bunun Ã¶ncelikle bir outlier(aykÄ±rÄ± deÄŸer) mi yoksa extreme value (uÃ§ deÄŸer) mi olduÄŸuna karar vermelisin. Diyelim ki evin oda sayÄ±sÄ± 25, banyo sayÄ±sÄ± 5, salon sayÄ±sÄ± 3 gibi deÄŸerler bu durumda bu evin fiyatÄ± bir uÃ§ deÄŸer( extreme value) olarak deÄŸerlendirilir. Ancak ev 2 oda bir salon ve diÄŸer Ã¶zellikleri de ortalama deÄŸerler bu durumda veri giriÅŸinde bir hata olma ihtimali daha yÃ¼ksektir.1 month ago 2 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar tam olarak kurs iÃ§eriÄŸi ile ilgili deÄŸil ama aklÄ±ma takÄ±lan bir konu var.  MentorlÃ¼k programÄ± kapsamÄ±nda belirlenen tarihlerde kurs konularÄ±nda lecture ve coding egzersizlerinden 1 hafta geri kalÄ±ndÄ±ÄŸÄ± takdirde programdan Ã§Ä±karÄ±lacaÄŸÄ± belirtiliyor. Bunun kontrolÃ¼ nasÄ±l yapÄ±lÄ±yor ? Ã‡Ã¼nkÃ¼ kurs platformunda First Step with Tf kÄ±smÄ±na geldim ancak her girdiÄŸimde sanki kursa yeni baÅŸlamÄ±ÅŸÄ±m gibi aÃ§Ä±lan bir platform var. Udemy gibi izlenen derslerin iÅŸaretlenmesi gibi bir durum yok. Ben mi yanlÄ±ÅŸ bir giriÅŸ biÃ§imi izliyorum yoksa herkes iÃ§in bÃ¶yle mi ? CevaplarsanÄ±z sevinirim, yanlÄ±ÅŸ bir yol izliyorsam dÃ¼zeltmek isterim",
"comment": [
    "",
    "->  Merhaba, herkes iÃ§in bÃ¶yle, Kontrol ise sanÄ±rÄ±m sÄ±navdaki baÅŸarÄ±ya gÃ¶re yapÄ±lacak, baÅŸka bir yol yok gibi duruyor.2 months ago Like ReportReply",
    "->  evet ilerlemeleri bizim takip etmemiz gerekiyor sanÄ±rÄ±m.2 months ago Like ReportReply",
    "->  TeÅŸekkÃ¼r ederim, iyi Ã§alÄ±ÅŸmalar2 months ago Like ReportReply",
    "->  kaldÄ±ÄŸÄ± yerden devam etmemesi kÃ¶tÃ¼ olmuÅŸ sanÄ±rÄ±m ona yapabileceÄŸimiz bir ÅŸey yok.2 months ago Like ReportReply",
    "->  Merhabalar, Ã¼cretsiz bir kurs olduÄŸu iÃ§in progress takibi kayÄ±t altÄ±na alÄ±namÄ±yor ne yazÄ±k ki.. BaÅŸarÄ± deÄŸerlendirmesini her haftaki testlere katÄ±lÄ±m durumunuza ve final sÄ±navÄ±nda alacaÄŸÄ±nÄ±z puana gÃ¶re yapacaÄŸÄ±z.2 months ago Like ReportReply",
    " "
]
},
{
"question_isim": " ->  uploaded 1 photo",
"quest": "Merhabalar,   Reducing Loss: Playground exercise'da, eklemiÅŸ olduÄŸum resimde de gÃ¶rÃ¼ldÃ¼ÄŸÃ¼ Ã¼zere, bize verilen datalardan dÃ¶rdÃ¼ncÃ¼sÃ¼nÃ¼n eÄŸitimi iÃ§in kullanabileceÄŸim optimum deÄŸerler (batch size, learning rate... ) hakkÄ±nda Ã¶neride bulunabilecek var mÄ±?   TeÅŸekkÃ¼rler, iyi Ã§alÄ±ÅŸmalar herkese.",
"comment": [
    "",
    "->  Bence en iyisi deneysel olarak Ã§alÄ±ÅŸÄ±p,verdiÄŸin parametreler ve hiperparametreler arasÄ±ndaki iliÅŸkiyi gÃ¶zlemlemek olacaktÄ±r.Optimum deÄŸerler kullanÄ±p,optimum sonuca ulaÅŸtÄ±ÄŸÄ±n senaryonun Ã§ok eÄŸlenceli ve eÄŸitici olamayacaÄŸÄ± dÃ¼ÅŸÃ¼ncesindeyim ğŸ™‚.",
    " ->  ->  Kesinlikle katÄ±lÄ±yorum, dÃ¶rt veri seti Ã¼zerinde de birÃ§ok deÄŸer denedim ve gÃ¶zlemledim fakat sonuncusunda optimum deÄŸil optimuma yakÄ±n bir ÅŸeyler bile bulamadÄ±m. YanÄ±tÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederim. ğŸ™‚.",
    "->  Bu kÄ±sÄ±m neural network ile ilgili alÄ±ÅŸtÄ±rma kÄ±smÄ± bu alÄ±ÅŸtÄ±rmaya neural network kÄ±smÄ±nda sonra bakÄ±lÄ±r diye dÃ¼ÅŸÃ¼nÃ¼yorum .yinede yapmak istersen featurelarÄ± deÄŸiÅŸtirerek sÃ¶yle biÅŸey elde ettim.",
    "->  https://www.coursera.org/learn/deep-learning-business/discussions/weeks/6?sort=lastActivityAtDesc&page=1&q= attÄ±ÄŸÄ±m linkteki Ã¼cretsiz kursun discussion formunda deÄŸerleri paylaÅŸanlar olmuÅŸtu bunun iÃ§in gÃ¶z atabilirsin",
    "Coursera | Online Courses From Top Universities. Join for Freewww.coursera.org3,000+ courses from schools like Stanford and Yale - no application required. Build career skills in data science, computer science, business, and more..",
    "-> Merhaba,Bu spiral dataset ile oynarken input feature olarak polar koordinatlarÄ±n (r,Î¸) iÅŸe yarayabileceÄŸini dÃ¼ÅŸÃ¼ndÃ¼m.playground.tensorflow.org daki input feature'lar sabit ancak kaynak koduna istediÄŸiniz feature'Ä± basitÃ§e ekleyebiliyorsunuz.playground reposunu forklayÄ±p aÅŸaÄŸÄ±daki modifikasyonu yapÄ±nca, az sayÄ±da neuron ve layer kullanarak oldukÃ§a baÅŸarÄ±lÄ± sonuÃ§ alÄ±nÄ±yor.https://github.com/cankut/playground/commit/b982c86e0d89f42b68fcda8be70cdc78df56583f",
    "Tensorflow â€” Neural Network Playgroundplayground.tensorflow.orgTinker with a real neural network right here in your browser.1 month ago 3 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba, kursun ilk haftasÄ±nda bulunan First Step with TF bÃ¶lÃ¼mÃ¼ndeki alÄ±ÅŸtÄ±rma kodlarÄ±nÄ± Python'a aktardÄ±m. Hem arkadaki kodlarÄ± gÃ¶rmek hem de biraz elleri kirletmek iÃ§in iyi olacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼mden sizinle de paylaÅŸmak istiyorum. Fakat, plot_the_loss_curve kÄ±smÄ±nda bir hatayla karÅŸÄ±laÅŸÄ±yorum, bunun Ã§Ã¶zÃ¼m arama yeri burasÄ± deÄŸil sanÄ±rÄ±m ama en azÄ±ndan diÄŸer kÄ±sÄ±mlar Ã§alÄ±ÅŸÄ±yor. Ä°yi Ã§alÄ±ÅŸmalar dilerim. <a class=\"ps-media-link\" href=\"https://github.com/oguzhari/GoogleMLCrashCourse\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">https://github.com/oguzhari/GoogleMLCrashCourse</a>",
"comment": [
    "",
    "->  ML kÄ±smÄ±ndan Ã§ok anlamÄ±yorum ama sayfanÄ±zda yayÄ±nlamÄ±ÅŸ olduÄŸunuz koddaepochs = 10ile epochs deÄŸerini integer olarak tanÄ±mlÄ±yorsunuz, rmse ise bir dizi olarak ki kodunuzu Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±mda 10 elemanlÄ± bir dizi olarak geliyor. tek deÄŸer ile 10 elemanlÄ± bir diziyi aynÄ± grafiÄŸe oturtmaya Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z iÃ§in hata veriyor olabilir....",
    "->  Ã‡ok teÅŸekkÃ¼rler.2 months ago Like ReportReply",
    "->  Merjaba, ->  hocamÄ±n da sÃ¶ylediÄŸi gibi epochs deÄŸeri sizin kodunuzda scalar bir deÄŸer olarak yani 10 olarak gelmiÅŸ. GrafiÄŸi Ã§izebilmek iÃ§in rmse ve epochs deÄŸerlerinin ilk boyutlarÄ±nÄ±n aynÄ± olmasÄ± gerekiyor. (len(epochs) ve len (rmse) ile kontrol edebilirsiniz.) Github kodunuzu forklayÄ±p sorunu giderdim ve pull request oluÅŸturdum. GÃ¶zden geÃ§irdikten sorna uygun gÃ¶rÃ¼rseniz pull requesti kabul edip yazdÄ±ÄŸÄ±m dÃ¼zeltme kodu ile sizin yazdÄ±ÄŸÄ±nÄ±z kodlarÄ± birleÅŸtirebilirsiniz.Edit: @->  hocamÄ±n belirttiÄŸi kÄ±smÄ± -> 'Ã¼ kodun iÃ§inde referans gÃ¶stererek dÃ¼zenledim..",
    " -> ->  Merhaba, katkÄ±nÄ±z iÃ§in Ã§ok teÅŸekkÃ¼r ederim..",
    "->  -> Merhabalar,Hata ile alakalÄ± deÄŸil ancak kodunu incelediÄŸim zaman train model de batch_size = None olarak yazÄ±lmÄ±ÅŸ. Bu durumda my_batch_size deÄŸiÅŸkenini ne kadar deÄŸiÅŸtirirsek deÄŸiÅŸtirelim biz bÃ¼tÃ¼n batch_size deÄŸerini her zaman data boyutuna eÅŸit almÄ±ÅŸ olacaÄŸÄ±z. batch_size yi parametre olarak aldÄ±ÄŸÄ±n batch_size ye eÅŸitlersen farklÄ± batch'lerde nasÄ±l sonuÃ§lar Ã¼retildiÄŸini gÃ¶zlemleyebilirsin.Hata iÃ§inde basit bir ÅŸekilde np.arange(1,ecpocs+1) yaparsan sorun Ã§Ã¶zÃ¼lecektir diye dÃ¼ÅŸÃ¼nÃ¼yorum.EDIT: HatanÄ±n kaynaÄŸÄ±nÄ± ÅŸimdi buldum, Ã¶rnek olarak paylaÅŸÄ±lmÄ±ÅŸ olan kodda train_model() fonksiyonunda epochs update edilmekte, Colab Ã¼zerinde ki kodda bunu gÃ¶rebilirsin. epochs update iÅŸlemini:# The list of epochs is stored separately from the# rest of history.epochs = history.epochÅŸeklinde yapÄ±lmakta bÃ¶ylece geriye epochs iÃ§in bir skaler dÃ¶ndÃ¼rmek yerine liste dÃ¶ndÃ¼rÃ¼yor train_model fonksiyonu..",
    " -> ->  Ã‡ok teÅŸekkÃ¼r ederim2 months ago Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Herkese, iyi akÅŸamlar. Goldilocks learning kavramÄ±nÄ± tam olarak anladÄ±ÄŸÄ±mÄ± dÃ¼ÅŸÃ¼nmÃ¼yorum. AnladÄ±ÄŸÄ±m kadarÄ±yla en az sayÄ±da adÄ±mla minumum local deÄŸere ulaÅŸtÄ±ÄŸÄ±mÄ±z learning rate deÄŸeri goldilocks oranÄ±na eÅŸittir diyebilir miyiz? Yoksa bu ifadem yanlÄ±ÅŸ mÄ±dÄ±r?",
"comment": [
    "",
    "-> Burada dÃ¼n tartÄ±ÅŸÄ±ldÄ±.Bakabilirsiniz. http://community.globalaihub.com/community/status/1043-1043-1586253928/#comment.2355.2369.23692 months ago Like ReportReply",
    "->  ->PostlarÄ± incelemiÅŸtim ama gÃ¶zÃ¼mden kaÃ§Ä±rmÄ±ÅŸ olmam lazÄ±m teÅŸekkÃ¼rler..",
    "->  Ã–nceki baÅŸlÄ±kta learning rate kavramÄ±na ait aÃ§Ä±klamalar var ancak kurstaki sorunun cevabÄ± olan 1.6 yÄ± nasÄ±l bulduÄŸumuzu aÃ§Ä±klayan arkadaÅŸlarÄ±n bir gÃ¶nderisini gÃ¶remedim. YardÄ±mcÄ± olacak birisi olursa sevinirim..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Herkese merhaba! AnladÄ±ÄŸÄ±mÄ± dÃ¼ÅŸÃ¼nmekle beraber emin olamadÄ±ÄŸÄ±m ufak ayrÄ±ntÄ±larÄ± sizlere danÄ±ÅŸmak istedim .AnladÄ±ÄŸÄ±m kadarÄ±yla \"mini-batch\" parametresiyle aÄŸa girecek olan veri sayÄ±sÄ±nÄ± belirliyoruz ve her bir epochta bu sayÄ±da veri iÅŸleniyor . Her  epochta seÃ§ilen veriler Ã¼zerinden aÄŸÄ±rlÄ±klar hesaplanÄ±yor ve epoch sonunda backpropation ile son gÃ¼ncelleme yapÄ±lÄ±yor. AklÄ±ma takÄ±lan kÄ±sÄ±m Ã¶ncelikle her epochta mini-batch boyutunda seÃ§ilen veriler farklÄ± ve rastgele mi oluyor , Ã¶zellikle farklÄ± olmasÄ±na dikkat ediliyor mu  ? Bir diÄŸer detay is ÅŸu ; her epochta , bir Ã¶nceki aÄŸÄ±rlÄ±klar Ã¼zerinden gÃ¼ncelleme yaparak ilerleniyor deÄŸil mi ?",
"comment": [
    "",
    "->  Merhabalar,Her epoch ta toplamda aynÄ± veriler (toplam train veri setiniz) kullanÄ±lacaÄŸÄ±ndan her mini-batch te rastgele veya sÄ±ralÄ± seÃ§miÅŸ olmanÄ±z Ã§ok fark ettirmeyecektir.Epoch sonunda tÃ¼m train verniz elden geÃ§irilmiÅŸ olacak.Sorunuzda daha Ã¶nemli olan kÄ±sÄ±m ÅŸurasÄ± her epoch ta hesaplanan aÄŸÄ±rlÄ±klar bir sonraki epoch ta gÃ¼ncellenmeye devam edilecek ki daha iyi bir yakÄ±nsama olsun.Her seferinde aÄŸÄ±rlÄ±klarÄ± yeniden set edip her batch te hesaplarsanÄ±z her epoch sonucunda yaklaÅŸÄ±k aynÄ± yakÄ±nsamayÄ± yapmÄ±ÅŸ olursunuz. (Rastgelelik ten dolayÄ± ÅŸanslÄ±ysanÄ±z en iyi aÄŸÄ±rlÄ±klarÄ± bulursunuz ama bu Ã§ok Ã§ok iyi ÅŸans iÅŸi)SonuÃ§ olarak;AÄŸÄ±rlÄ±klar her epoch ta ve her batch te gÃ¼ncellenerek ilerleniyor.SaygÄ±larÄ±mlaMehmet.",
    "->  Ã–ncelikle cevabÄ±nÄ±z iÃ§in teÅŸekkÃ¼rler .Yani her epochta aslÄ±nda bir Ã¶ncekinde iÅŸlenen veri tekrar iÅŸleniyor ... (Ben her epochta farklÄ± veriler iÅŸleniyordur ve bu iÅŸlenen veriler de rastgele ve bir Ã¶ncekinden farklÄ± olacak ÅŸekilde seÃ§iliyordur diye dÃ¼ÅŸÃ¼nmÃ¼ÅŸtÃ¼m ) yani sonuÃ§ olarak mini-batch parametresiyle belirlediÄŸimiz sayÄ± kadar veri deÄŸerlendirmiÅŸ oluyoruz .Ama bu kÄ±sÄ±mda anlamadÄ±ÄŸÄ±m ben daha kÃ¼Ã§Ã¼k bir veri seti oluÅŸturmak varken neden mini-batch parametresi kullanmÄ±ÅŸ oluyorum ?2 months ago Like ReportReply",
    "->  \"Derin Ã¶ÄŸrenme uygulamalarÄ±nda, veri setinde bulunan tÃ¼m verileri aynÄ± anda iÅŸleyerek Ã¶ÄŸrenme, zaman ve bellek aÃ§Ä±sÄ±ndan maliyetli bir iÅŸtir. Ã‡Ã¼nkÃ¼ Ã¶ÄŸrenmenin her iterasyonunda geriyeyayÄ±lÄ±m (â€œbackpropagationâ€) iÅŸlemi ile aÄŸ Ã¼zerinde geriye dÃ¶nÃ¼k olarak gradyan (â€œgradient descentâ€) hesaplamasÄ± yapÄ±lmakta ve aÄŸÄ±rlÄ±k deÄŸerleri bu ÅŸekilde gÃ¼ncellenmektedir. Bu hesaplama iÅŸleminde veri sayÄ±sÄ± ne kadar fazla ise hesaplama da o oranda fazla sÃ¼rmektedir. Bu problemi Ã§Ã¶zmek iÃ§in; veri seti kÃ¼Ã§Ã¼k gruplara ayrÄ±lmakta ve Ã¶ÄŸrenme iÅŸlemi seÃ§ilen bu kÃ¼Ã§Ã¼k gruplar Ã¼zerinde yapÄ±lmaktadÄ±r. Bu ÅŸekilde birden fazla girdinin parÃ§alar halinde iÅŸlenmesi â€œmini-batchâ€ olarak adlandÄ±rÄ±lmaktadÄ±r.\".",
    "->  https://medium.com/deep-learning-turkiye/derin-ogrenme-uygulamalarinda-en-sik-kullanilan-hiper-parametreler-ece8e9125c4",
    "Derin Ã–ÄŸrenme UygulamalarÄ±nda En SÄ±k kullanÄ±lan Hiper-parametrelermedium.comDerin Ã–ÄŸrenme UygulamalarÄ±nda En SÄ±k kullanÄ±lan Hiper-parametreler ve Bu Parametrelerin BazÄ± Temel Ã–zellikleri..",
    "->  ->  sorduÄŸun soru benim de kafama takÄ±lmÄ±ÅŸtÄ±.SanÄ±rÄ±m zaman ve bellek aÃ§Ä±sÄ±ndan maliyetli olacaÄŸÄ±ndan dolayÄ±.2 months ago Like ReportReply",
    "->  ->  aynÄ± yazÄ±yÄ± ben de inceledim ama en son yorumumda sorduÄŸum soruya yanÄ±t bulamadÄ±m maalesef . Acaba bazÄ± ÅŸeyleri tam olarak anlayamadÄ±m mÄ± yoksa sadece bÃ¼yÃ¼k veri setlerini uÄŸraÅŸmadan kÃ¼Ã§Ã¼ltmek iÃ§in uygulanan bir yaklaÅŸÄ±m mÄ± emin olamadÄ±m.2 months ago Like ReportReply",
    "->  ->  Benim de anladÄ±ÄŸÄ±m kadarÄ±yla yapÄ±lan yaklaÅŸÄ±m ÅŸunun gibi; Mesela seÃ§im dÃ¶neminde istatistik ÅŸirketleri seÃ§im anketleri yapÄ±yor ve hangi adayÄ±n ne kadar oy alacaÄŸÄ±nÄ± tahmin etmeye Ã§alÄ±ÅŸÄ±yorlar.Bunu yaparken kitle=BÃ¼tÃ¼n halk ama bunu yapmak Ã§ok fazla zaman ve imkan gerektirdiÄŸi iÃ§in bunun yerine belirli Ã¶rneklem bÃ¼yÃ¼klÃ¼ÄŸÃ¼ ile hareket edip genelleme yapÄ±yorlar. Bu sonuÃ§ kesinlikle kitlenin sonucu deÄŸil kitlenin bir alt kÃ¼mesi olarak alÄ±nan Ã¶rneklemin sonucu oluyor. Fakat kitleyi temsil Ã¶zelliÄŸi taÅŸÄ±yor. EÄŸer veri sayÄ±mÄ±z Ã§ok deÄŸilse kitle ile iÅŸlem yapmak her zaman daha iyidir en doÄŸru sonucu verir. Fakat veri sayÄ±mÄ±z Ã§ok fazla (milyonlarca veya milyarlarca veri varsa) bunla uÄŸraÅŸmak yerine onu temsil edebilecek bir alt kÃ¼me alarak genelleme yapmaya Ã§alÄ±ÅŸÄ±yoruz..",
    "->  ->  1 epoch tÃ¼m verinin iÅŸlenmesi anlamÄ±na geliyor. DolayÄ±sÄ±yla veri setimizdeki her bir veri her epoch'ta tekrar iÅŸlenmiÅŸ oluyor. mini-batch-size = 100 ise ve 1000 adet verimiz varsa, 1 epoch iÃ§in 1000 / 100 = 10 iterasyona ihtiyacÄ±mÄ±z var.2 months ago 5 people like this.Like ReportReply",
    "->  ->  cevabÄ±nÄ±z iÃ§in teÅŸekkÃ¼rler ÅŸu an her ÅŸey netleÅŸmiÅŸ oldu benim iÃ§in..",
    "->  Merhabalar,->  Her epochta bÃ¼tÃ¼n setin Ã¼zerinden geÃ§iyoruz ancak amacÄ±mÄ±z Loss'u minimize etmek olduÄŸundan sÄ±ralÄ± seÃ§im yapacak olursak istediÄŸimiz sonuca ulaÅŸmamÄ±z oldukÃ§a zorlaÅŸacaktÄ±r. Elimizde bulunan seti en iyi ÅŸekilde Ã¶rnekleyen batch veya batch'ler ile minimum loss deÄŸerine ulaÅŸabiliriz. Yani her bir epoch da batch size kadar veri rastgele seÃ§ilmektedir ki Stochastic bu rastgeleliÄŸin varlÄ±ÄŸÄ±na iÅŸaret iÃ§in bulunmaktadÄ±r.->  Daha kÃ¼Ã§Ã¼k bir veri seti oluÅŸturmak varken neden mini-batch kullanÄ±yoruz sorusunun cevabÄ± ise, daha kÃ¼Ã§Ã¼k bir set oluÅŸturmak elinde olan veri setini daha az sayÄ±da gÃ¶zlem ile Ã¶rneklemek demek oluyor. En doÄŸru Ã¶rneklemi ve Ã¶rneklem bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼ tespit mini-batch ile kÄ±yaslandÄ±ÄŸÄ±nda daha maliyetli olacaÄŸÄ± iÃ§in mini-batch kullanÄ±yoruz..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Selamlar herkese, kursta ilerlerken Gradient Descent ve benzeri algoritmalarda TÃ¼rev,Ä°ntegral... gibi Calculus 1-2 konularÄ± ve ilerleyen bÃ¶lÃ¼mlerde ise Linear Algebra,Statistics,Probability gibi konularÄ±n algoritmayÄ± anlamak iÃ§in bilinmesi gerektiÄŸini gÃ¶rdÃ¼m. 10. sÄ±nÄ±f olduÄŸumdan saydÄ±ÄŸÄ±m bu konularÄ±n hemen hemen hiÃ§birini okulda gÃ¶rmedim ki zaten matematik anlamÄ±nda sadece okula gÃ¼venmek yanlÄ±ÅŸ olur. Kendi baÅŸÄ±ma bu konularÄ± Ã§alÄ±ÅŸmaya karar verdim, ingilizce / tÃ¼rkÃ§e bu konularÄ± Ã§alÄ±ÅŸabileceÄŸim kaynaklar Ã¶nerebilir misiniz? HaftalÄ±k olarak konularÄ±n gerisinde kalmayacak ÅŸeklide ama yeterli matematik altyapÄ±sÄ±nÄ± da Ã¶ÄŸrenerek ilerlemek istiyorum. TeÅŸekkÃ¼rler...",
"comment": [
    "",
    "->  https://www.youtube.com/watch?v=DJ7DoGoU9E0&list=PLcNWqzWzYG2vUwIrhpYTwqm0qboR5yQRALineer Cebir : Lineer Denklem Sistemleri ve Matrisler ile GÃ¶sterimi (www.buders.com)www.youtube.comBUders Ã¼niversite matematiÄŸi derslerinden lineer cebir dersine ait \"Lineer Denklem Sistemleri ve Matrisler ile GÃ¶sterimi\" videosudur. HazÄ±rlayan: Kemal Duran....",
    "->  bende lisede ve Ã¼niversitede bu konularÄ±n Ã§oÄŸunu hiÃ§ gÃ¶rmedim. ben Ã§ok faydasÄ±nÄ± gÃ¶rdÃ¼m gÃ¶rÃ¼yorum her aradÄ±ÄŸÄ±n konu iÃ§in videolar var inÅŸallah iÅŸinize yarar..",
    "->  ->  TamamdÄ±r, teÅŸekkÃ¼rler2 months ago Like ReportReply",
    "AYÅE DUMAN BirkaÃ§ tane kaynak Ã¶nerebilirim senin iÃ§in umarÄ±m faydasÄ±nÄ± gÃ¶rÃ¼rsÃ¼n. Youtube Ã¼zerinden jbstatistics kanalÄ±na bakmanÄ± Ã¶neririm. Ã–zellikle istatistik , olasÄ±lÄ±k gibi konularda anlamanÄ± kolaylaÅŸtÄ±racak bir kanal. http://tutorial.math.lamar.edu/ bu site Ã¼zerinden de temel calculus konularÄ±nÄ± anlamanda sana yardÄ±mcÄ± olacak problemler ve Ã§Ã¶zÃ¼mler yer alÄ±yor. Bunu da incelemeni Ã¶neririm..",
    "AYÅE DUMAN Professor Leonard 'da aynÄ± zamanda Youtube'da bir kanalÄ± olan ve anlatÄ±mÄ± son derece iyi olan bir hoca. Bu kanala da bakmanÄ± tavsiye ediyorum. Ä°yi Ã§alÄ±ÅŸmalar..",
    "->  AYÅE DUMAN Ã–nerileriniz iÃ§in saÄŸolun ğŸ™‚2 months ago Like ReportReply",
    "->  https://mml-book.github.io/book/mml-book.pdfBu kitapta gerekli konularÄ± bulabilirsin. AyrÄ±ca Matematik DÃ¼nyasÄ± Dergisinin her bir konu ile ilgili sayÄ±larÄ±nÄ± edinebilirsin..",
    "->  Bu konseptleri Ã¶ÄŸrenmem iÃ§in (oturup kaÄŸÄ±t kalemle iÅŸlem yapmama pek fayda saÄŸlamasa da) 3blue1brown'un Essence of Calculus serisinin Ã§ok faydasÄ± olmuÅŸtu bana. Limit, tÃ¼rev, integral kavramlarÄ±nÄ±n ne olduÄŸunu ve aralarÄ±ndaki iliÅŸkiyi anlamama Ã§ok yardÄ±mcÄ± oldu. Ä°zlemeni tavsiye ederim..",
    "->  Kaynak ismi verip kendini o kaynakla kÄ±sÄ±tlamamanÄ± Ã¶neririm. Eksik olduÄŸun konularla alakalÄ± bir liste yapÄ±p YouTube Ã¼zerinden aratabilirsin bence.2 months ago Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Ã–ncelikle herkese merhabalar ve iyi Ã§alÄ±ÅŸmalar. AklÄ±mda Epoch ve Batch size ile ilgili bir soru takÄ±ldÄ±. Åimdi anladÄ±ÄŸÄ±m kadarÄ±yla verimiz bÃ¼yÃ¼k olduÄŸunda tÃ¼m bu veriyi batch olarak gradient descent algoritmasÄ±na sokmamÄ±z performans ve hÄ±z aÃ§Ä±sÄ±ndan problemlere neden olacaktÄ±r. Bu yÃ¼zden verisetini kÃ¼Ã§Ã¼k batchlere bÃ¶lÃ¼p Ã¶yle algoritmamÄ±za sokmamÄ±z daha iyi olacaktÄ±r. BÃ¶ldÃ¼ÄŸÃ¼mÃ¼z veri boyutlarÄ± batch size, TÃ¼m veri setinin itere edilmesi iÅŸlemi epoch, tÃ¼m batchlerin epoch'a sokulma adÄ±mlarÄ± da iterasyon oluyor. Åimdi benim anlayamadÄ±ÄŸÄ±m ÅŸey, benim elimde 10000 verim var ise ve ben bu verileri 100'er batchlere bÃ¶lmek istiyorsam 1 epoch'un tamamlanmasÄ± iÃ§in gereken iterasyon sayÄ±sÄ± 100 olacak. Ve ben 10 kez epoch yapÄ±lmasÄ±nÄ± istiyorum yani toplamda tÃ¼m epochlarÄ±n tamamlanmasÄ± iÃ§in 1000 iterasyon yapÄ±lacak. Ben batch size'Ä±mÄ± 200 yaparsam ve epoch sayÄ±mÄ± da 20 yaparsam toplamda yapÄ±lan itere sayÄ±sÄ± mantÄ±ken aynÄ± olacak.â€¦ <a class=\"ps-stream-post-more ps-js-content-excerpt-toggle\" href=\"#\">Read more</a></div><div class=\"ps-js-content-full\" style=\"\">Ã–ncelikle herkese merhabalar ve iyi Ã§alÄ±ÅŸmalar. AklÄ±mda Epoch ve Batch size ile ilgili bir soru takÄ±ldÄ±. Åimdi anladÄ±ÄŸÄ±m kadarÄ±yla verimiz bÃ¼yÃ¼k olduÄŸunda tÃ¼m bu veriyi batch olarak gradient descent algoritmasÄ±na sokmamÄ±z performans ve hÄ±z aÃ§Ä±sÄ±ndan problemlere neden olacaktÄ±r. Bu yÃ¼zden verisetini kÃ¼Ã§Ã¼k batchlere bÃ¶lÃ¼p Ã¶yle algoritmamÄ±za sokmamÄ±z daha iyi olacaktÄ±r. BÃ¶ldÃ¼ÄŸÃ¼mÃ¼z veri boyutlarÄ± batch size, TÃ¼m veri setinin itere edilmesi iÅŸlemi epoch, tÃ¼m batchlerin epoch'a sokulma adÄ±mlarÄ± da iterasyon oluyor. Åimdi benim anlayamadÄ±ÄŸÄ±m ÅŸey, benim elimde 10000 verim var ise ve ben bu verileri 100'er batchlere bÃ¶lmek istiyorsam 1 epoch'un tamamlanmasÄ± iÃ§in gereken iterasyon sayÄ±sÄ± 100 olacak. Ve ben 10 kez epoch yapÄ±lmasÄ±nÄ± istiyorum yani toplamda tÃ¼m epochlarÄ±n tamamlanmasÄ± iÃ§in 1000 iterasyon yapÄ±lacak. Ben batch size'Ä±mÄ± 200 yaparsam ve epoch sayÄ±mÄ± da 20 yaparsam toplamda yapÄ±lan itere sayÄ±sÄ± mantÄ±ken aynÄ± olacak. Bu iki deÄŸer kÃ¼meleri iÃ§in de gradient descent algoritmasÄ± matematiksel olarak aynÄ± oranda mÄ± minimuma yakÄ±nsar? (Train esnasÄ±nda Ã§evresel fakÃ¶rler olan cpu gpu hÄ±zlarÄ± vs gibi ÅŸeyleri ayrÄ± tuttuÄŸumuzda). Åimdiden teÅŸekkÃ¼r ederim. Edit: Ã–mer TÃ¼ksoy'un dÃ¼zeltmesi ile sorudaki matematiksel hatalar dÃ¼zeltilmiÅŸtir. (Batch size ve epoch deÄŸerleri)</div></div>",
"comment": [
    "",
    "Sercan Sari Muhtemelen aynÄ± oranda minimuma yakÄ±nsamaz, kesinlikle deneyip gÃ¶rmek gerek ama. farklÄ± batch size'lar ile Ã§alÄ±ÅŸtÄ±rÄ±p optimum sonucu elde etmek en mantÄ±klÄ±sÄ± olacaktÄ±r..",
    "->  Bence; Ä°teresyon sayÄ±sÄ± eÅŸit olucak ama batch_size=100 alÄ±nca epoch 10 alÄ±nca her bir weight'i 10 kere gÃ¼ncellerken batch_size=200 alÄ±p epoch 5 alÄ±nca her bir weight'i 5 kere gÃ¼ncelleyecek dolayÄ±sÄ±yla muhtemelen 10 epoch yapÄ±nca loss 5 epocha gÃ¶re biraz daha kÃ¼Ã§Ã¼k olacaktÄ±r. KÄ±sacasÄ± epoch 5 ise loss function 5 kere gÃ¼ncellenirken epoch 10 iken 10 kere gÃ¼ncellenecek. DolayÄ±sÄ±yla farklÄ± olacaktÄ±r. Benim dÃ¼ÅŸÃ¼ncem bu yÃ¶nde yanlÄ±ÅŸ dÃ¼ÅŸÃ¼nÃ¼yorsam hocalarÄ±mÄ±z beni de dÃ¼zeltirse sevinirim..",
    "->  ->  Merhaba,Sorulan soruya aÅŸaÄŸÄ±da yanÄ±t verirken batch ve epoch kavramlarÄ±nÄ± aÃ§Ä±kladÄ±m. Burada ufak bir yanlÄ±ÅŸ anlaÅŸÄ±lma var sanÄ±rÄ±m, iterasyonlar yani gÃ¼ncellemeler her bir epoch baÅŸÄ±na deÄŸil her bir batch_size baÅŸÄ±na yapÄ±lÄ±yor.Ä°yi Ã§alÄ±ÅŸmalar..",
    "->  CevaplarÄ±nÄ±z iÃ§in Ã§ok teÅŸekkÃ¼r ederim. Epoch gÃ¼ncelleme sayÄ±sÄ± Ã§ok aÅŸÄ±rÄ± olmamak kaydÄ±yla daha fazla olduÄŸunda daha Ã§ok yakÄ±nsayacaÄŸÄ± bana da mantÄ±klÄ± geldi. EÄŸer bir hatamÄ±z varsa bizi dÃ¼zeltmekten Ã§ekinmeyin. Tekrardan teÅŸekkÃ¼r ederim..",
    "-> Merhaba Fethi,Soruna geÃ§meden Ã¶nce batch ve epoch iÃ§in net tanÄ±mlamalar yapalÄ±m: Batch, bir modeli eÄŸitirken 1 iterasyonda (weight update) kullandÄ±ÄŸÄ±n sample sayÄ±sÄ±dÄ±r. Daha aÃ§Ä±klayÄ±cÄ± olmasÄ± aÃ§Ä±sÄ±ndan, 10.000 veri iÃ§in 100 batch seÃ§ersen 1 epoch iÃ§erisinde 100 kere iterasyon yapmÄ±ÅŸ olursun, bu iterasyon sayÄ±sÄ± 200 batch iÃ§in 50 olur. Epoch ise bir modelin tÃ¼m data ile kaÃ§ kere eÄŸitileceÄŸidir.Sorunda verdiÄŸin Ã¶rnekte ufak bir yanlÄ±ÅŸ var, orayÄ± dÃ¼zeltelim. 10.000 veri, 100 batch ve 10 epoch toplam 1.000 iterasyon (10.000/100*10) yapar. VerdiÄŸin ikinci Ã¶rnekteki 200 batch ve 5 epoch ise 10.000/200*5 = 250 iterasyon yapar. DolayÄ±sÄ±yla ikinci Ã¶rnekte de aynÄ± itersyon sayÄ±sÄ±nÄ± saÄŸlamak istiyorsan epoch deÄŸerini 20 seÃ§melisin.Åimdi modelleri karÅŸÄ±laÅŸtÄ±rmaya geÃ§ebiliriz. Tamamen aynÄ± ÅŸartlar altÄ±nda Ã§alÄ±ÅŸan iki farklÄ± model eÄŸittim. EÄŸitirken 50 adet 'feature'a sahip 10.000 satÄ±r iÃ§eren ve uniform daÄŸÄ±lmÄ±ÅŸ bir data kullandÄ±m. DatanÄ±n sÄ±nÄ±flarÄ± ise 0 ve 1 olmak Ã¼zere iki adet. Modellerin her ikisi de tek hidden layerdan oluÅŸuyor ve 64 adet nÃ¶rona sahip. Sorunun yanÄ±tÄ±nÄ± daha net gÃ¶rebilmek iÃ§in ilk modeli 100 batch, 50 epoch seÃ§erek, ikinci modeli ise 200 batch, 100 epoch seÃ§erek eÄŸittim.AÅŸaÄŸÄ±da iki modelin karÅŸÄ±laÅŸtÄ±rmasÄ±nÄ± gÃ¶rebilirsin. Her iki model de toplam 5.000 iterasyon yaptÄ±ÄŸÄ± anda (mavi ve yeÅŸil) train losslar iÃ§in aynÄ± oranda yakÄ±nsamÄ±yorlar ama arada ciddi bir fark da yok diyebiliriz. Tabii burada train datasÄ± Ã¼zerinden loss aldÄ±ÄŸÄ±mÄ±zÄ± unutmayalÄ±m.FarklÄ± batch sayÄ±larÄ± ile aynÄ± epoch arasÄ±ndaki iliÅŸkiyi de turuncu ve yeÅŸil Ã§izimleri karÅŸÄ±laÅŸtÄ±rarak inceleyebilirsin.2 months ago 17 people like this.Like ReportReply",
    "->  ->  Merhaba,CevabÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederim. Ben kafamda epoch ve batch size deÄŸerlerini ters orantÄ±lÄ± olarak dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼m iÃ§in hem basit matemaitiksel iÅŸlemimde hem de sorumda bir hata oluÅŸmuÅŸtu onu da aydÄ±nlattÄ±ÄŸÄ±nÄ±z iÃ§in ayrÄ±ca teÅŸekkÃ¼r ederim..",
    " "
]
},
{
"question_isim": "->  uploaded 1 photo",
"quest": "Merhabalar, ben kurstaki Reducing loss (iterative approach) bÃ¶lÃ¼mÃ¼nÃ¼ tam olarak anlayamadÄ±m, iÅŸaretlediÄŸim yerdeki denklemleri ve devamÄ±nÄ± bana aÃ§Ä±klayabilir misiniz, ve iÅŸaretlediÄŸim yer tÃ¼rev midir, tÃ¼revse bunu Ã§Ã¶zmem iÃ§in gerekli olan tÃ¼rev bilgisini nasÄ±l Ã¶ÄŸrenebilirim daha liseliyim, eÄŸer kÄ±saysa sizler aÃ§Ä±layabilir misiniz?  TeÅŸekkÃ¼r ederim.",
"comment": [
    "",
    "->  TÃ¼rev deÄŸil, y' modelin tahmini, y ise gerÃ§ek deÄŸeri..",
    "->  y' tÃ¼rev deÄŸil fakat tÃ¼rev de kullanÄ±lÄ±yor gradient hesaplarken, en azÄ±ndan basit olarak Ã¶ÄŸrenmen yararÄ±na olur. Oradaki denklemde tahmin yaparken tek feature(x1) kullanarak tahmin yapÄ±lmÄ±ÅŸ. Bunu ev fiyatÄ± belirlerken oda sayÄ±sÄ± olarak dÃ¼ÅŸÃ¼nebilirsin, yani o formÃ¼lde sadece oda sayÄ±sÄ±nÄ± dikkate alarak ev fiyatÄ±nÄ± tahmin etmeye Ã§alÄ±ÅŸÄ±yor. W ve b deÄŸerleri de ilk olarak 0 atanmÄ±ÅŸ. y' yani tahmin deÄŸerimiz de formÃ¼lde deÄŸerleri yerine yazdÄ±ÄŸÄ±mÄ±zda 0 Ã§Ä±kacak doÄŸal olarak. GerÃ§ek ev fiyatÄ± 0 olamayacaÄŸÄ±ndan hata deÄŸerimiz Ã§ok yÃ¼ksek Ã§Ä±kacak ve w ve b deÄŸerlerimizi hata deÄŸerimiz(loss) azalacak ÅŸekilde tekrar tekrar gÃ¼ncelleyeceÄŸiz. Gradient Descent ve Loss kÄ±sÄ±mlarÄ±nda daha detaylÄ± olarak bunlardan bahsediyor. OralarÄ± okuduÄŸunda kafanda daha iyi canlanabilir. Lisedeyken bÃ¶yle ÅŸeylerle uÄŸraÅŸmaya baÅŸlaman sÃ¼per, tebrik ederim ğŸ™‚2 months ago 5 people like this.Like ReportReply",
    "->  ->  Åimdi anladÄ±m, yardÄ±mÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederim.",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Herkese merhablar, bÃ¶yle basit bir soruyla sizi meÅŸgul ettiÄŸim iÃ§in Ã¶zÃ¼r dilerim ama multiple linear regression Ã§alÄ±ÅŸÄ±rken lineer modellerin genel olarak kolay aÃ§Ä±klanabilir olduÄŸunu fakat kolay aÃ§Ä±klanabilirliÄŸin Ã§oÄŸu zaman accuracy'den feragat etmeyi gerektirdiÄŸini Ã¶ÄŸrendim. Lineer modeli daha esnek bir hale getirmek veya tutarlÄ±lÄ±ÄŸÄ± arttÄ±rmak iÃ§in iki baÄŸÄ±msÄ±z deÄŸiÅŸkeni birbiri ile Ã§arpÄ±p modele ekleyebileceÄŸimizi Ã¶ÄŸrendim. Bu yeni eklenen terime \"interaction term\" denildiÄŸini Ã¶ÄŸrendim. Fakat yine de hangi koÅŸullar altÄ±nda, neden bÃ¶yle bir iÅŸlemi yapacaÄŸÄ±mÄ±zÄ± ve nasÄ±l Ã§oklu baÄŸÄ±msÄ±z deÄŸiÅŸkenler Ã¼zerinde yapacaÄŸÄ±mÄ±zÄ± kafamda oturtup bunu kullanabileceÄŸimiz bir Ã¶rnek bulamadÄ±m. Rica etsem bu tekniÄŸi kÄ±sa bir ÅŸekilde aÃ§Ä±klayÄ±p, kullanabileceÄŸimiz bir Ã¶rnek verir misiniz?",
"comment": [
    "",
    "->  Benim bildiÄŸim kadarÄ±yla baÄŸÄ±mlÄ± deÄŸiÅŸkene en az etki eden deÄŸiÅŸkenler Ã¼zerinden etkisiz olanlarÄ± ya modelden Ã§Ä±karmalÄ±yÄ±z yada dÃ¶nÃ¼ÅŸtÃ¼rme iÅŸlemleri uygulanabilir. Ã–rnek vermek gerekirse Ã§oklu boyut problemi veya Ã§oklu doÄŸrusal baÄŸlantÄ± problemi gibi problemlerde ilgi deÄŸiÅŸkenleri azaltmamÄ±z gerekebilir.Bunun iÃ§in PCA , lassa ridge gibi methodlar kullanÄ±labilir. sizin dediÄŸiniz deÄŸiÅŸkenleri Ã§arpmakta ayrÄ± bir method olabilir , o konu hakkÄ±nda kesin bir bilgim yok.Ã–zetle asÄ±l amaÃ§ en etkili ve etkin baÄŸÄ±msÄ±z olan deÄŸiÅŸkenleri kullanmak. YanlÄ±ÅŸÄ±m varsa lÃ¼tfen mentor arkadaÅŸlar dÃ¼zeltsin.2 months ago Like ReportReply",
    "-> ->  Ã–ncelikle cevapladÄ±ÄŸÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederim, benim bahsettiÄŸim metot'da deÄŸiÅŸken azaltma yok gibime geldi.ÅÃ¶yle bir modelimiz olsun:y = Î²1*x1 + Î²2*x2Biz burada bahsettiÄŸim gibi bir interaction term eklemek istersek modelimizin son hali ÅŸu ÅŸekilde olur:y = Î²1*x1 + Î²2*x2 + Î²3*x1*x2AnladÄ±ÄŸÄ±m kadarÄ±yla bir \"interaciton\" baÄŸÄ±msÄ±z bir deÄŸiÅŸkenin baÅŸka bir baÄŸÄ±msÄ±z deÄŸiÅŸkenin deÄŸerine gÃ¶re baÄŸÄ±mlÄ± deÄŸiÅŸkene yaptÄ±ÄŸÄ± deÄŸiÅŸiklik deÄŸiÅŸiyorsa var oluyor. Mesela ÅŸÃ¶yle bir durumu inceleyelim bir ilacÄ±mÄ±z olsun ve bu ilacÄ±mÄ±zÄ±n salgÄ±lattÄ±ÄŸÄ± kolestrol miktarÄ±na bakalÄ±m ve kolestrol miktarÄ±nÄ± tahmin etmeye Ã§alÄ±ÅŸalÄ±m. EÄŸer ilacÄ±n alÄ±nan dozu (baÄŸÄ±msÄ±z bir deÄŸiÅŸken) 'na gÃ¶re salgÄ±lanan kolestrol miktarÄ± baÅŸka bir baÄŸÄ±msÄ±z deÄŸiÅŸken olan cinsiyet deÄŸiÅŸkenine gÃ¶re farklÄ±lÄ±k gÃ¶steriyorsa burada interaction term kullanmamÄ±z gerekiyor. Ã–rnek olarak bu ilaÃ§ Ã¶rneÄŸinden devam edelim.Cinsiyetin salgÄ±lanan doza etkisi olmadÄ±ÄŸÄ± durumdaki modelimiz:y = Î± + Î²1 âˆ— doz ÅŸeklinde olurduCinsiyetin etkisi olsaydÄ± ama interaction ile alakasÄ± olmasaydÄ± (hangi cinsiyet olduÄŸu farketmeden alÄ±nan doz her iki cinsiyet'de de aynÄ± bÃ¼yÃ¼meyi saÄŸlasaydÄ±):y = = Î± + Î²1 âˆ— doz + Î²2 * cinsiyet (burada cinsiyet dummy variable olarak kabul ediliyor)Cinsiyetin etkisi interaction ile birlikte olsaydÄ±:y = Î± + Î²1 âˆ— doz + Î²2 * cinsiyet + Î²3 Ã— doz âˆ— cinsiyetÄ°sterseniz bunlarÄ±n grafiÄŸini Ã§izmeyi deneyip aklÄ±nÄ±zda daha da oturmasÄ±nÄ± saÄŸlayabilirsiniz.Ama verdiÄŸim tÃ¼m bu Ã¶rnekler 2. baÄŸÄ±msÄ±z deÄŸiÅŸkenin bir dummy variable olduÄŸu durumlardÄ±. SayÄ±sal bir deÄŸer olsaydÄ± nasÄ±l olurdu, veya gerÃ§ek hayatta bu tÃ¼r bir metodu nasÄ±l kullanabilirim hala daha anlayamadÄ±m. EÄŸer bir yanlÄ±ÅŸÄ±m varsa veya eklemek istedikleri bir yer varsa deÄŸerli mentÃ¶rlerimiz yardÄ±mcÄ± olabilir mi? CevabÄ±nÄ±zÄ± 4 gÃ¶zle bekliyorum. SaÄŸolun...2 months ago Like ReportReply",
    "-> Merhabalar,Bu durumu en iyi aÃ§Ä±klayan konunun 'kernel trick' olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yorum.https://towardsdatascience.com/truly-understanding-the-kernel-trick-1aeb11560769Bu makaledeki ÅŸu resimdeki data seti inceleyecek olursak. (https://miro.medium.com/max/1440/1*eU9PzjVcLNbNEzBC2g_iWg.jpeg)Bu data set doÄŸrusal olarak sÄ±nÄ±flandÄ±rÄ±labilir deÄŸil. Bunun iÃ§in Ã¶rneÄŸin Ã¶zelliklerimizin x ekseninin X, y eksenin de Y Ã¶zelliÄŸi olduÄŸunu varsayarsak (0,0) noktasÄ±nÄ± merkez gibi gÃ¶rÃ¼nÃ¼yor.Her Ã¶rneÄŸin merkeze olan uzaklÄ±ÄŸÄ±nÄ± tanÄ±mlayacak bir yeni Ã¶zellik tanÄ±mladÄ±ÄŸÄ±mÄ±zÄ± dÃ¼ÅŸÃ¼nelim sqrt((xi-x0)**2 + (yi-y0)**2) ÅŸeklinde hesaplanan yeni bir Ã¶zelliÄŸimiz olunca aslÄ±nda saÄŸdaki ÅŸekil elde edilmiÅŸ olacak.SaÄŸdaki ÅŸekilde doÄŸrusal olarak ayrÄ±ÅŸtÄ±rÄ±labilir bir probleme dÃ¶nÃ¼ÅŸÃ¼yor.ArtÄ±k kÄ±saca (yaklaÅŸÄ±k olarak - aynÄ± Ã¶rneÄŸe gÃ¶re-) yeni Ã¶zelliÄŸe gÃ¶re 0.5 deÄŸerinden kÃ¼Ã§Ã¼kler bir sÄ±nÄ±fa ait bÃ¼yÃ¼kler diÄŸer sÄ±nÄ±fa aittir sÃ¶ylenebilir (Bu dataya bakarak bizim gÃ¶zle gÃ¶rdÃ¼ÄŸÃ¼mÃ¼z tabikide).Ä°yi Ã§alÄ±ÅŸmalar,Mehmet",
    "Truly Understanding the Kernel Trick with fundamentalstowardsdatascience.comIn this post, we will learn the fundamentals behind the Kernel Trick. How it works? How the Kernel Trick finds similarity (or distance) inâ€¦.",
    "-> Soru oldukÃ§a gÃ¼zel.Ã–ncelikle deÄŸiÅŸkenlerin birlikte ele alÄ±nmasÄ± (x1 * x2) Ã§alÄ±ÅŸÄ±lan konu iÃ§in mantÄ±klÄ± bir yaklaÅŸÄ±m olmalÄ±.Regresyon modellerinde hangi modeli kullanmamÄ±z gerektiÄŸi sorusu ile karÅŸÄ±laÅŸtÄ±ÄŸÄ±mÄ±zda modelin R^2' (Belirlilik katsayÄ±sÄ±) (Coefficient of Determination)sini kullanÄ±rÄ±z. Daha yÃ¼ksek R^2 daha aÃ§Ä±klayÄ±cÄ± model demektir. R^2 0 ile 1 arasÄ±nda deÄŸiÅŸen deÄŸerler alÄ±r. Ã–rneÄŸin bir regresyon modelinin R^2 si 0.72 Ã§Ä±kmasÄ± baÄŸÄ±mlÄ± deÄŸiÅŸkendeki deÄŸiÅŸimin yÃ¼zde 72'si model tarafÄ±ndan aÃ§Ä±klanÄ±yor ÅŸeklinde yorumlanabilir. Burada Ã§ok Ã§ok Ã¶nemli bir nokta bir modelin veriye uyumunu deÄŸerlendirmek iÃ§in bir tek R^2'ye gÃ¼venmemek gerek. Ä°statistikÃ§iler hata terimlerinin daÄŸÄ±lÄ±mÄ±, katsayÄ±larÄ±n anlamlÄ±lÄ±ÄŸÄ±, tahminlerin gÃ¼ven aralÄ±ÄŸÄ± gibi farklÄ± teknikler ile de modellerinin kalitesini Ã¶lÃ§erler.Basit bir regresyon modeli (y = beta0*x1 + beta1*x2) nin belli bir R^2 si var buna baÄŸÄ±msÄ±z deÄŸiÅŸkenlerin birlikte Ã¶lÃ§Ã¼mlerini eklersek (y = beta0*x1 + beta1*x2 + beta2*x1*x2) acaba daha iyi bir model elde eder miyiz ?Bunun cevabÄ± iÃ§in R^2 ye baÅŸvurmak yeterli mi ? Maalesef deÄŸil. Ã‡Ã¼nkÃ¼ bir modele yeni terimler eklemek her zaman R^2 yi yÃ¼kseltir. Bu yÃ¼zden yeni terim eklediÄŸimizde modelin veriye uyumunu kontrol etmek iÃ§in terim sayÄ±sÄ±nÄ±n etkisinden arÄ±ndÄ±rÄ±lmÄ±ÅŸ DÃ¼zeltilmiÅŸ Belirlilik KatsayÄ±sÄ± (Adjusted R^2) kullanÄ±lmalÄ±dÄ±r. Daha yÃ¼ksek Adjusted R^2 daha iyi model demek..",
    "->  Bunun yanÄ±nda model katsayÄ±larÄ±nÄ±n anlamlÄ±lÄ±ÄŸÄ±nÄ± test edip eÄŸer interaction_term'in katsayÄ±sÄ± istatisiksel olarak anlamlÄ± ise (p<0.05) ise modeline eklemelisin.Not: Python'da yukarÄ±da verilen hesaplamalar kolaylÄ±kla yapÄ±labiliyor.GerÃ§ek bir Ã¶rnek olarak cinsiyet yerine baÅŸka bir ilaÃ§ dÃ¼ÅŸÃ¼nebilirsin. Ä°laÃ§lar ayrÄ± ayrÄ± kullanÄ±ldÄ±klarÄ±nda etkileri olumlu olsun ama beraber kullanÄ±ldÄ±klarÄ±nda girdikleri tepkime sonucu Ã¼rettikleri baÅŸka bir kimyasal yÃ¼zÃ¼nden olumsuz etki gÃ¶stersin. Bu tip bir durumda bu iki ilacÄ±n birlikte ele alÄ±nÄ±p regresyon modeline eklenmeleri gerekir..",
    "->  ->  Ã‡ok net anlatmÄ±ÅŸsÄ±nÄ±z, teÅŸekkÃ¼rler..",
    " -> BulunduÄŸum sektÃ¶rden (sigortacÄ±lÄ±k) ÅŸÃ¶yle bir Ã¶rnek ile aÃ§Ä±klayabilirim.AraÃ§larÄ±n kasko fiyatlarÄ±nÄ± tahminlemek iÃ§in genelleÅŸtirilmiÅŸ lineer modeller kullanÄ±rÄ±z. AslÄ±nda sÃ¶ylemde basitleÅŸtirmek istersek olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ± deÄŸiÅŸtirilmiÅŸ multi lineer regresyon. Ã–rneÄŸe gelecek olursak sÃ¼rÃ¼cÃ¼lerin yaÅŸÄ± ve cinsiyeti bilgileri ile kasko fiyatlarÄ±nÄ± tahmin ettiÄŸimizi dÃ¼ÅŸÃ¼nelim. Fiyatlar regresyon modellerinde erkeklerde 45-50 li yaÅŸlarda, kadÄ±nlarda 40 - 45li yaÅŸlarda bir tÄ±k yÃ¼ksek tahminlenir. Bunun sebebi ise araÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda bu yaÅŸlardaki insanlarÄ±n Ã§ocuklarÄ±nÄ±n genÃ§lik dÃ¶nemlerinde olduÄŸu ve araÃ§larÄ± izinsiz alarak kazalar yapÄ±klarÄ± ÅŸeklinde aÃ§Ä±klanÄ±r. Bu durum herkes iÃ§in geÃ§erli olmayacaÄŸÄ±ndan o yaÅŸlar iÃ§in interaction yapÄ±lmasÄ± gerekmektedir. cinsiyet ve yaÅŸ Interaction'Ä± sonrasÄ± elle bir miktar modele mÃ¼dahale edilerek fiyattaki bu artÄ±ÅŸ bir miktar tÃ¶rpÃ¼lenir. Interaction kurmazsanÄ±z yaÅŸ ve cinsiyet baÄŸÄ±msÄ±z deÄŸiÅŸkenlerini birlikte etkileÅŸime sokamaz ve yalnÄ±zca istediÄŸiniz noktaya mÃ¼dahale edemezsiniz. Interaction'da zaten etkileÅŸim anlamÄ±na gelmektedir. Modellerde doÄŸrusunu bildiÄŸiniz ve dÃ¼zeltebileceÄŸiniz istisna durumlar iÃ§in belirli deÄŸiÅŸkenler arasÄ±nda kullanÄ±rsÄ±nÄ±z. UmarÄ±m bir miktar aÃ§Ä±klayabilmiÅŸimdir.2 months ago 5 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "Enes Zengin",
"quest": "Learning Rate kÄ±smÄ±nda bir grafik var, learning rate'i kendimiz ayarlayÄ±p lossu minimize edebiliyoruz. Kafama takÄ±lan bÃ¼yÃ¼k bir learning rate seÃ§mek burda avantajlÄ± gibi gÃ¶zÃ¼kÃ¼yor, ilk adÄ±mÄ± bÃ¼yÃ¼k atÄ±yor minimum lossa yaklaÅŸtÄ±kÃ§a adÄ±m bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼ azaltÄ±p hedefe ulaÅŸÄ±yor. Bunun normalde mÃ¼mkÃ¼n olmamasÄ± gerekiyor sanÄ±rÄ±m, Rate eÄŸitim boyu aynÄ± kalmasÄ± gerekmez mi?",
"comment": [
    "",
    "->  Learning rate orada da eÄŸitim boyunca aynÄ±, orada adÄ±m olarak gÃ¶rdÃ¼klerin gradient descent sonucu oluÅŸan deÄŸerler. Gradient descent iÅŸleminde local minimuma yaklaÅŸÄ±ldÄ±kÃ§a vektÃ¶rlerin boyu kÄ±salÄ±r.AÅŸaÄŸÄ±da linkini koymuÅŸ olduÄŸum videoyu izlersen kafanda biraz daha oturacaktÄ±r. AnlatÄ±lan ders Gradient, dolayÄ±sÄ±yla oklar local minimuma doÄŸru deÄŸil local maximuma doÄŸru gidiyor. Ancak biz lossu minimize etmeye Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z iÃ§in bu vektÃ¶rlerin negatiflerini kullanÄ±yoruz.https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/gradient-and-directional-derivatives/v/gradient-and-graphs",
    "Gradient and graphs (video) | Khan Academywww.khanacademy.orgLearn how the gradient can be thought of as pointing in the \"direction of steepest ascent\". This is a rather important interpretation for the gradient.Â 2 months ago 5 people like this.Like ReportReply",
    "->  learning rate ile costun tÃ¼rvini Ã§arpÄ±yoruz cost azaldÄ±kÃ§a learning ratein etkiside azalÄ±yor gibi anladÄ±m ben.Weight = Weight - (learning rate)x(costun tÃ¼revi)2 months ago Like ReportReply",
    "->  ->  cost ile mean square errorÃ¼ kastettim. Bide yukarÄ±da cost azaldÄ±kÃ§a deÄŸilde costun tÃ¼revi azaldÄ±kÃ§a demek istedim. Minimuma yaklaÅŸtÄ±kÃ§a costun tÃ¼revi azalÄ±yor, tÃ¼rev azaldÄ±kÃ§a learning rate ile Ã§arpÄ±mÄ± daha az deÄŸiÅŸikliÄŸe sebep oluyor..",
    "-> ->  Kursta gradient olarak adlandÄ±rdÄ±ÄŸÄ±mÄ±z deÄŸiÅŸken cost'un tÃ¼revi dediÄŸiniz deÄŸer mi? Bu fonksiyonun adÄ± cost olarak mÄ± geÃ§iyor?2 months ago Like ReportReply",
    "->  ->  Eger cost , mean square error dersek yanlis olur.Hedefimiz prediction ise MSE, ancak classification ise Categorical Cross Entropy ya da Binary Cross Entropy olabilir.Yani cost function probleme gore degisir.Buun disinda soylediklerinize katiliyorum.2 months ago Like ReportReply",
    "-> Learning rate sabitken bile adÄ±mlar itere edildikÃ§e kÄ±salÄ±r Ã§Ã¼nkÃ¼ gradient descent fonksiyonunda cost fonksiyonumuzun derivative'Ä° alÄ±nÄ±r ve bu deÄŸerimiz*learning rate theta deÄŸerimizden Ã§Ä±karÄ±lÄ±r. Theta deÄŸeri dediÄŸimiz deÄŸer bizim minimize edilmiÅŸ cost function deÄŸerimizdir. Ã–rneÄŸin theta1 lineer regresyon formÃ¼lÃ¼ndeki (y=ax1+bx2+cx3) x1 deÄŸerini temsil eder. x2 ve x3 iÃ§in de deÄŸerler aynÄ±dÄ±r.(Burada 3 tane feature'Ä±mÄ±z varmÄ±ÅŸ gibi kabul ettiÄŸimiz iÃ§in x3'e kadar gittik. Bu featurelar daha az veya daha fazla olabilir.) Yani her iterede bir sonraki theta deÄŸeri daha az kÄ±salÄ±r. Resimde formÃ¼lÃ¼ gÃ¶rebilirsiniz. Learning rate iÃ§in kesinleÅŸmiÅŸ bir deÄŸer yoktur, veri setine gÃ¶re en optimum learning rate deÄŸeri deÄŸiÅŸir. Learning rate olmasÄ± gerekenden bÃ¼yÃ¼k olursa minimum local deÄŸerini Ä±skalar ve bÃ¶ylece aslÄ±nda minimum deÄŸere yaklaÅŸacaÄŸÄ±na uzaklaÅŸmÄ±ÅŸ olur. Learning rate deÄŸerimiz Ã§ok kÃ¼Ã§Ã¼k olursa da minimuma ulaÅŸmak Ã§ok fazla vakit alÄ±r. AslÄ±nda orada deÄŸiÅŸen ÅŸey learning rate deÄŸil derivative'i alÄ±nmÄ±ÅŸ fonksiyonun azalma sayÄ±sÄ±dÄ±r. Ã–rneÄŸin 10x^2 deÄŸerinin derivative'ini alÄ±rsanÄ±z 20x olur. Yani ilk iterede 10x^2-20x kadarlÄ±k bir azalma olmuÅŸ. Tekrar 20x'in derivative'ini alÄ±rsanÄ±z deÄŸer 20 olur yani burada da 20x-20'lik bir azalma olmuÅŸ. (10x^2-20x) > (20x-20). Bu nedenle atÄ±lan stepler de itere boyunca kÃ¼Ã§Ã¼lÃ¼r.2 months ago 21 people like this.Like ReportReply",
    " ->  AslÄ±nda ÅŸÃ¶yle dÃ¼ÅŸÃ¼nÃ¼lebilir, bir arazide su birikintisini arÄ±yorsunuz ve learning rate sizin adÄ±mÄ±nÄ±zÄ±n mesafesi olsun. Su birikintisine yaklaÅŸana kadar bÃ¼yÃ¼k bÃ¼yÃ¼k adÄ±mlar atÄ±yorsunuz mesela 5 metre diyelim ama artÄ±k su bitikintisine 3 metre uzakatasÄ±nÄ±z. 5 metre adÄ±m atÄ±nca diÄŸer tarafta 2 metre uzaktasÄ±nÄ±z. Bir tÃ¼rlÃ¼ yaklaÅŸamÄ±yorsunuz. Mecburen adÄ±m mesafenizi 5 metreden daha kÃ¼Ã§Ã¼k hale getirmelisiniz ki mesela 1 metre olsun. 2 metre uzaklÄ±ktan sonra 2 iterasyon sonra yani 2 adÄ±m sonra artÄ±k su birikintisindesiniz.En baÅŸÄ±nda da adÄ±mÄ±nÄ±zÄ± 1 metre atabilirdiniz ama su birikintisine ulaÅŸana kadar Ã§ok adÄ±m atmÄ±ÅŸ olurdunuz. Bu da sizi yani sistemi yorardÄ±. AmacÄ±mÄ±z minimum adÄ±mla su birikintisine ulaÅŸmak aslÄ±nda. BÃ¶yle dÃ¼ÅŸÃ¼nebilirsiniz.2 months ago 13 people like this.Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Learning rate, batch ve epoch deÄŸerlerinim optimumunu bulmak iÃ§in her zaman deneysel bir yol mu izlemeliyiz ? Bu deÄŸerleri bulmanÄ±n deneysel yoldan farklÄ± olarak formÃ¼l yada farklÄ± bir yolla bulmak mÃ¼mkÃ¼n mÃ¼?",
"comment": [
    "",
    "->  BunlarÄ± bulmanÄ±n direk bir formÃ¼lÃ¼ yok ne yazÄ±k ki. SÄ±fÄ±rdan bir algoritma geliÅŸtirmiyorsanÄ±z genelde kullandÄ±ÄŸÄ±nÄ±z algoritmanÄ±n makalelerinde bu tarz deÄŸerler en alt sayfada paylaÅŸÄ±lÄ±r(veya makale iÃ§erisinde). Tabiki bu yaptÄ±ÄŸÄ±nÄ±z uygulamanÄ±n tÃ¼rÃ¼ ve elinizde ki verinin yoÄŸunluÄŸuna gÃ¶re Ã§ok deÄŸiÅŸim gÃ¶steriyor. AslÄ±nda iÅŸin mÃ¼hendislik kÄ±smÄ± bunlarla oynayÄ±p(hyperparamer tuning) ve belirli optimizasyonlar yaparak(Ã¶rneÄŸin modelin eÄŸitilme sÃ¼resi - deneme sÃ¼reniz - hesaplama gÃ¼cÃ¼ kullanÄ±mÄ± vs ) optimal deÄŸerleri seÃ§mekteKÄ±sacasÄ± , direk formÃ¼l yok ama yapÄ±lmÄ±ÅŸ Ã§alÄ±ÅŸmalarÄ± incelemek en yararlÄ±sÄ±..",
    " ->  Bunu ben de merak ediyorum. Lakin her veri kÃ¼mesi ve iÃ§erisindeki gÃ¼rÃ¼ltÃ¼ vs. gibi faktÃ¶rler farklÄ± olduÄŸundan sanÄ±rÄ±m bir formÃ¼lÃ¼ yok. Kursta da belirtildiÄŸi gibi, gÃ¶zetimli Ã¶ÄŸrenmede (supervised learning) bir makine Ã¶ÄŸrenme algoritmasÄ± birÃ§ok Ã¶rneÄŸi inceleyerek kaybÄ± en aza indiren en iyi modeli bulmaya Ã§alÄ±ÅŸÄ±yor. Bu sÃ¼rece de ampirik risk minimizasyonu (empirical risk minimization) deniyor. Ampirik = Deneysel yani deneyerek bulmak gerekiyor diye biliyorum. LÃ¼tfen hatam varsa dÃ¼zeltiniz. Ä°yi gÃ¼nler????..",
    "->  En iyi learning rate deÄŸerinin ne olduÄŸunu bulmak iÃ§in analitik bir yÃ¶ntem yok. Bunun iÃ§in diÄŸerlerine gÃ¶re daha iyi olan learning rate'i deneysel yol izleyerek buluyoruz..",
    "->  BÃ¼yÃ¼k bir veri setinde bu deÄŸerleri bulmak deneyerek bulmak zaman kaybÄ±na neden olabilir baya2 months ago Like ReportReply",
    "->  ->  Deneyerek bulmak yerine akademik Ã§alÄ±ÅŸmalarda Ã§ok kullanÄ±lan deÄŸerleri deneyip sonuÃ§larÄ± inceledikten sonra hangi kÄ±sÄ±mlarda yanlÄ±ÅŸ tahminler veiryor ona gÃ¶re tune / ince ayar Ã§ekmeniz gerekir.",
    "->  https://arxiv.org/pdf/1506.01186.pdf ÅŸu yayÄ±nÄ± okumanÄ± tavsiye ederimhttps://arxiv.org/pdf/1506.01186.pdfarxiv.orghttps://arxiv.org/pdf/1506.01186.pdf.",
    "Ramazan Kartal Hiper parametre analizi icin 'Grid Search' konusuna bakabilirsin. https://medium.com/deep-learning-turkiye/derin-ogrenme-uygulamalarinda-model-dogrulama-ve-hiper-parametre-secim-yontemleri-823812d95f3",
    "Derin Ã–ÄŸrenme UygulamalarÄ±nda Hiper Parametre SeÃ§im YÃ¶ntemlerimedium.comDerin Ã¶ÄŸrenme uygulamalarÄ±nda hiper parametreler yazÄ± serisinin ilk bÃ¶lÃ¼mÃ¼nde, derin Ã¶ÄŸrenme uygulamalarÄ±nda en sÄ±k kullanÄ±lan hiperâ€¦.",
    "Muhammed Fatih GÃ¼ltekin Optuna diye bir kÃ¼tÃ¼phane var bakabilirsin.",
    "-> Grid search, random search veya informed search gibi metodolojilere bakÄ±labilir. Tabi bunlar da deneme temelli yÃ¶ntemler.2 months ago Like ReportReply",
    "Ramazan ÃœnlÃ¼ Learning rate iÃ§in kesin bir kural yok. Ancak gradient descentâ€™Ä±n mantÄ±ÄŸÄ± gereÄŸi hangi deÄŸeri seÃ§erseniz seÃ§in optimum noktaya yaklaÅŸtÄ±kÃ§a etki deÄŸeri kademeli olarak azalÄ±r. Ã‡ok kÃ¼Ã§Ã¼k deÄŸerler seÃ§ildiÄŸinde local minumuma dÃ¼ÅŸme riski artar. 0.01 0.001 gibi deÄŸerler yeterince iÅŸ gÃ¶rÃ¼yor genelde.Epoch iÃ§in bayesian error ile eÄŸitim setindeki hata karÅŸÄ±laÅŸtÄ±rÄ±labilir. EÄŸer yeterince veriniz varsa, aÄŸ yeterince bÃ¼yÃ¼kse ancak bayesian error ile eÄŸitim setindeki hata farkÄ± yÃ¼ksekse epoch sayÄ±sÄ±nÄ±n artÄ±rÄ±lmasÄ±nÄ±n fayda saÄŸlayacaÄŸÄ± sonucuna varÄ±labilir..",
    "->  Ramazan ÃœnlÃ¼ 'Epoch icin Bayesian error ile egitim setindeki hata karsilastirilabilir ' ifadesini hic anlayamadim.Egitim seti derken egitim sirasinda demek istediniz sanirim.Egitim sirasindaki hata derken loss dan bahsediyorsunuz saniyorum.Soylemek istediginiz: Hedefiniz prediction yapmaksa Mean Square Error kullanarak hesaplayacaginiz loss degerine bakilarak epoch konusunda karar verebilirsiniz gibi birsey sanirim.2 months ago Like ReportReply",
    "->  Deneyerek learning rate gibi hyperparametrelerin optimum degerini bulmaya calismanin zaman tuketici bir is oldugunu gozonune aldigimizda,bu isin basinda oldugumuzu varsayarak en iyi yontem uzmanlarca denenmis kullanagelinene basvurmak olabilir diye dusunuyorum.Mesela Adam optimizer ile learning_rate=1e-3 kullaniyorum ya da yukarida soylendigi gibi 0.01 ya da 0.001 seciyorum genellikle...",
    " "
]
},
{
"question_isim": " -> ",
"quest": "Merhaba! Reducing Loss konusuna Ã§alÄ±ÅŸÄ±rken Gradient Descent ve Stochastic Gradient Descent arasÄ±ndaki farkÄ± tam anlayamadÄ±m. Bana bu konuda yardÄ±mcÄ± olabilir misiniz?",
"comment": [
    "",
    "->  Merhaba, bu sorunun aynÄ±sÄ± sorulmuÅŸtu ->  arkadaÅŸÄ±mÄ±z tarafÄ±ndan. O post'u okursan soruna yanÄ±t bulabilirsin bence..",
    " ->  ->  Onu okumuÅŸtum ama orda mini-batch SGD ve SGD arasÄ±ndaki fark sorulmuÅŸ ve yanÄ±t olarak batch ifadesi aÃ§Ä±klanmÄ±ÅŸ daha Ã§ok fakat ben GD ve SGDyi sormuÅŸtum bildiÄŸim kadarla bu ikisinde batch size hiperparametresi girilmiyor bu yÃ¼zden sorumun yanÄ±tÄ±nÄ± tam alamadÄ±m ama yine de teÅŸekkÃ¼rler yanÄ±tÄ±n iÃ§in.",
    "->   ->  Gradient Descent loss'u minimize etmek iÃ§in kullanÄ±lan yÃ¶ntemin adÄ±. Stochastic Gradient Descent ise loss'u minimize ederken veri setimizdeki her bir Ã¶rneÄŸimiz iÃ§in gradient descent'in bir adÄ±m atmasÄ± anlamÄ±na geliyor. Yani tek bir Ã¶rneÄŸe bakarak loss'taki deÄŸiÅŸimi hesaplayÄ±p parametreleri gÃ¼ncelliyor. Gradient Descent'in Ã¶nÃ¼ne gelen kelimeler, kaÃ§ tane Ã¶rneÄŸi dikkate alarak iterasyon yapacaÄŸÄ±mÄ±zÄ± belirtiyor. AslÄ±nda SGD, batch-size'in 1 e eÅŸit olduÄŸunu belirtmek iÃ§in kullanÄ±lan Ã¶zel bir isim sadece.2 months ago 16 people like this.Like ReportReply",
    " ->  ->  ÅŸimdi anladÄ±m teÅŸekkÃ¼r ederim.",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba. Train-Test setlerimizi ayÄ±rÄ±rken, videoda 1 milyar datamÄ±z olsa dahi %10 test %90 train olarak ayÄ±rmaktan bahsediliyor. 1 milyar gayet bÃ¼yÃ¼k bir rakam. Bu ÅŸekilde ayÄ±rmak eskiden(kÃ¼Ã§Ã¼k datasetler iÃ§in) mantÄ±klÄ±ydÄ± ama artÄ±k bir Ã§ok konuda big data mevcut. Bunu %98 train, %1 test(10 milyon!), %1 validation(10 milyon!) olarak ayÄ±rmamÄ±z daha mantÄ±klÄ± olmaz mÄ±?",
"comment": [
    "",
    "->  Evet ben de andrew ng deep learning kursunda dediÄŸiniz gibi 98-1-1 ÅŸeklinde yapÄ±lmasÄ±nÄ±n daha mantÄ±klÄ± olduÄŸunu duymuÅŸtum ğŸ™‚.",
    "-> Ã–ncelikle literatÃ¼rde bu konu Ã¼zerinde net bir fikir birliÄŸine varÄ±lmÄ±ÅŸ deÄŸil. Kimi araÅŸtÄ±rmacÄ±lar 80:20 oranÄ±nÄ± benimserken kimileri 90:10 bazÄ±larÄ± 70:30 oranlarÄ±nÄ±n daha iyi sonuÃ§lar vereceÄŸini iddia ediyorlar. Andrew Ng Ã§ok bÃ¼yÃ¼k veri setlerinde 98:1:1 ve hatta 99:0.5:0.5 oranlarÄ±nÄ±n kullanÄ±lmasÄ± gerektiÄŸini ifade ediyor. Klasik makine Ã¶ÄŸrenmesi algoritmalarÄ±nda veri miktarÄ± arttÄ±kÃ§a baÅŸarÄ± oranÄ± belli bir noktadan sonra dÃ¼zlÃ¼ÄŸe ulaÅŸmakta, derin Ã¶ÄŸrenme algoritmalarÄ±nda ise veri miktarÄ± arttÄ±kÃ§a baÅŸarÄ±nÄ±n artÄ±ÅŸÄ± daha doÄŸrusal. Bu yÃ¼zden klasik makine Ã¶ÄŸrenmesi algoritmalarÄ± kullanÄ±yorsanÄ±z train:test oranÄ±nÄ± biraz daha dÃ¼ÅŸÃ¼k tutabilirsiniz. Derin Ã¶ÄŸrenme algoritmalarÄ±nda ise eÄŸitime mÃ¼mkÃ¼n mertebe daha fazla veri saÄŸlamak daha baÅŸarÄ±lÄ± sonuÃ§ demek.Tabii ki gerÃ§ek bir uygulamada en gÃ¼zeli farklÄ± oranlarÄ± deneyip sonuÃ§larÄ± karÅŸÄ±laÅŸtÄ±rmak.AyrÄ±ca ek olarak toplamda ne kadar veri kullanmalÄ±yÄ±m sorusunu kendinize sorabilirsiniz.Bir modelin eÄŸitimi iÃ§in ne kadar veri gerektiÄŸi Ä°statistiksel Ã–ÄŸrenme Teorisi (Statistical Learning Theory) ile Ã§Ã¶zÃ¼lebilecek bir problem. Bu bÃ¼yÃ¼klÃ¼k kullanacaÄŸÄ±nÄ±z modelin karmaÅŸÄ±klÄ±ÄŸÄ±, parametreler arasÄ±ndaki iliÅŸkiler, gÃ¼rÃ¼ltÃ¼lÃ¼ veri miktarÄ± ve her bir deÄŸiÅŸkenin varyansÄ± gibi Ã§eÅŸitli etmenlere baÄŸlÄ±.Peki bunlarÄ± bilmeden bir makine Ã¶ÄŸrenmesi algoritmasÄ± geliÅŸtirilebilir mi? Sorunun cevabÄ± evet. Her problem farklÄ±dÄ±r. En gÃ¼zel yÃ¶ntem farklÄ± oranlarÄ± deneyip sonuÃ§larÄ± karÅŸÄ±laÅŸtÄ±rmak.2 months ago 13 people like this.Like ReportReply",
    "->  Test ve validation datasÄ±nÄ± o kadar bÃ¼yÃ¼k tutmanÄ±n Ã§ok bir manasÄ± yok. DediÄŸiniz gibi 10 milyon test datasÄ± pek kullanÄ±ÅŸlÄ± deÄŸil. Belirli bir boyutlara ulaÅŸtÄ±ÄŸÄ±nÄ±zda o oranlarÄ± kendinize gÃ¶re ÅŸekillendirebilirsiniz. GerÃ§ek hayat uygulamalarÄ± yaparken \"benchmark\" datasetleri gibi elinizde Ã§ok data bulunmayabiliyor..",
    "->  ->  %1i 10 milyon yapÄ±yor, sÃ¶ylendiÄŸi gibi %10 teste ayÄ±rsak 100 milyon test datasÄ± olacak.2 months ago Like ReportReply",
    "->  ->  Onu hesaplamadÄ±m tabi direk yazÄ±lan oranÄ± aldÄ±m ama genelde 10 bin yeterli bir sayÄ±. 100 Milyonluk kaliteli etiketli veri (resim olarak dÃ¼ÅŸÃ¼nÃ¼rsek) Ã§oÄŸu zaman elde edebildiÄŸimiz bir veri deÄŸil. Benchmark , algoritmalarÄ±n denendiÄŸi datasetlerde ancak bÃ¶yle veri olabiliyor.2 months ago Like ReportReply",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhabalar. Goldilocks learning rate deÄŸeri tam olarak nedir ve nasÄ±l bulunur? Tam anlayamadÄ±m aÃ§Ä±klayabilir misiniz ? TeÅŸekkÃ¼rler.  <a href=\"https://community.globalaihub.com/community/hashtag/goldilocks/\"><span class=\"ps-stream-hashtag\">#goldilocks</span></a>",
"comment": [
    "",
    "-> Bunun iÃ§in Ã¶ncelikle Goldilocks prensibinin tanÄ±mÄ±na bakmamÄ±z gerekiyor. http://www.tolgaakkus.com/goldilocks-prensibi-79-gun/ websitesinden aldÄ±ÄŸÄ±m kÄ±sa bir Ã¶zeti alÄ±ntÄ±lamak istiyorum.\"Ormanda yaÅŸayan Ã¼Ã§ kiÅŸilik bir ayÄ± ailesi var. Anne ayÄ± yaptÄ±ÄŸÄ± Ã§orbalarÄ± tabaklara doldurur ve Ã§orbalar soÄŸuyana kadar ailecek dÄ±ÅŸarÄ± Ã§Ä±karlar. O sÄ±rada dÄ±ÅŸarda gezen minik kÄ±z Goldilocks evi gÃ¶rÃ¼nce iÃ§eri girer ve Ã§orbalara ile karÅŸÄ±laÅŸÄ±r. Ã–nce bÃ¼yÃ¼k tabaktaki baba ayÄ±nÄ±n Ã§orbasÄ±na bakar ama aÄŸzÄ± yanar, sonra orta tabaktaki anne ayÄ±nÄ±n Ã§orbasÄ±na bakar yine aÄŸzÄ± yanar, en son kÃ¼Ã§Ã¼k tabaktakini iÃ§er, kÃ¼Ã§Ã¼k Ã§orba her ÅŸeyi ile tam Goldilocksâ€™a gÃ¶redir.\"Buna gÃ¶re burada Goldilocks learning rate aslÄ±nda gradient descent algoritmamÄ±zÄ±n en optimizasyonlu duruma gelmesi iÃ§in gereken learning rate deÄŸeridir. Goldilocks prensibini hatÄ±rlarsak burada Goldilocks kendi aÄŸzÄ±nÄ±n yanmayacaÄŸÄ± optimum tabak bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼ bulup ondan Ã§orba iÃ§iyordu.Learning rate ise gradient descent algoritmamÄ±zda her bir iterasyonda optimum deÄŸere atÄ±lacak adÄ±m bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼ temsil eder. Ama Ã¶nemli bir not vermek istiyorum; itere edildikÃ§e optimuma atÄ±lan adÄ±mlar azalÄ±r bunun nedeni cost function'Ä±mÄ±zÄ±n her derviative'de daha da kÃ¼Ã§Ã¼lmesidir. YalnÄ±z bu sizi yanÄ±ltmasÄ±n, learning rate'i seÃ§erken bu adÄ±m kÃ¼Ã§Ã¼lmelerine gÃ¼venmemeliyiz Ã§Ã¼nkÃ¼ bahsettiÄŸim bu kÃ¼Ã§Ã¼lmeler 2-3 iterasyonda olan ÅŸeyler deÄŸil ve learning rate her iterasyonda atÄ±lacak adÄ±mÄ±n bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼ simgelediÄŸi iÃ§in learning rate'Ä° kÃ¼Ã§Ã¼k seÃ§erseniz algoritmanÄ±z Ã§ok yavaÅŸ, Ã§ok bÃ¼yÃ¼k seÃ§erseniz de optimum noktayÄ± aÅŸacaÄŸÄ± iÃ§in yanlÄ±ÅŸ Ã§alÄ±ÅŸacaktÄ±r. Uygun learning rate'i bulmak iÃ§in ise bir Ã§ok yÃ¶ntem mevcut:Sabit deÄŸer olarak belirlenebilir, ya da adÄ±m adÄ±m artan bir deÄŸer olarak da belirlenebilir (Ã¶rneÄŸin belli bir Ã¶ÄŸrenme adÄ±mÄ±na kadar 0.001 o adÄ±mdan sonra 0.01 gibi), momentum deÄŸerine baÄŸlÄ± olarak belirlenebilir ya da adaptif algoritmalar tarafÄ±ndan Ã¶ÄŸrenme esnasÄ±nda Ã¶ÄŸrenilebilir.Burada benim hakim olduÄŸum yÃ¶ntem bir deÄŸer aralÄ±ÄŸÄ± belirleyip o deÄŸer aralÄ±ÄŸÄ±nda kalan deÄŸerleri learning rate deÄŸeri olarak verip algoritmayÄ± denemek. Ã–rneÄŸin 0.1-1 arasÄ±nda bir aralÄ±k seÃ§tiÄŸinizde ve gradient descent algoritmasÄ±nda learning rate olarak verdiÄŸinizde Ã§Ä±kan sonucun optimuma yaklaÅŸma step sayÄ±sÄ±, optimumdan uzaklaÅŸma durumlarÄ±na gÃ¶re doÄŸru aralÄ±ÄŸÄ± seÃ§ebilirsiniz. EÄŸer bu aralÄ±kta learning rate bulamazsanÄ±z aralÄ±ÄŸÄ±nÄ±zÄ± geniÅŸletebilirsiniz. DiÄŸer learning rate bulma yÃ¶ntemleri ile ilgili bir bilgiye sahip deÄŸilim maalesef ama olunca burayÄ± gÃ¼ncellerim ğŸ™‚ YanlÄ±ÅŸÄ±ÄŸÄ±m eksiÄŸim olursa lÃ¼tfen dÃ¼zeltmekten eklemekten Ã§ekinmeyin, umarÄ±m aÃ§Ä±klayÄ±cÄ± olmuÅŸtur :)Ã–nemli bir trivia: Gradient Descent algoritmamÄ±z ne kadar optimumsa grafiÄŸimizdeki cost function Ã§izgimiz o kadar dÃ¼zdÃ¼r ve eÄŸimi yoktur. Derivative de zaten eÄŸim almak demek olduÄŸu iÃ§in artÄ±k alÄ±nacak bir eÄŸimi kalmadÄ±ÄŸÄ±ndan artÄ±k iterasyonlar optimum deÄŸere ulaÅŸtÄ±ktan sonra cost function deÄŸerimizi kÃ¼Ã§Ã¼ltmeyecektir. Buradan ÅŸÃ¶yle trivia bir ÅŸey sÃ¶yleyebilirim. EÄŸer Gradient Descent algoritmamÄ±z lokal minimum deÄŸerine ulaÅŸtÄ±ysa ve bulunduÄŸu lokal minimumdan daha optimum bir lokal minimum deÄŸeri varsa bir sonraki iterasyonda daha optimum olan lokal minimum deÄŸerine yaklaÅŸmaz, bulunduÄŸu noktada kalÄ±r. Resimdeki denklemi incelediÄŸinizde optimuma ulaÅŸan cost function deÄŸerinin eÄŸimi (derivative'i) sÄ±fÄ±r olacaÄŸÄ± iÃ§in (resimdeki grafikte mevcut) thetaj=thetaj olur yani deÄŸer deÄŸiÅŸmez.2 months ago 36 people like this.Like ReportReply",
    "->  ->  TeÅŸekkÃ¼r ederim.",
    " ->  Merhaba. AnladÄ±ÄŸÄ±m ve araÅŸtÄ±rdÄ±ÄŸÄ±m kadarÄ±yla; Goldilocks Prensibi, matematik ve istatistikte \"Bias ve varyanstan gelen hatalarÄ± azaltmak iÃ§in 'mÃ¼kemmel esnekliÄŸi' temsil eden doÄŸrusal regresyon modelini\" ifade ediyor. Yani olabilecek en iyi modeli ifade ediyor. Kursta da belirtildiÄŸi gibi Goldilocks deÄŸeri, olabilecek en iyi learning rate deÄŸeridir ve kayÄ±p fonksiyonunun ne kadar dÃ¼z olduÄŸu ile ilgili olan bir ÅŸeydir. KayÄ±p fonksiyonunun gradient'inin bÃ¼yÃ¼klÃ¼ÄŸÃ¼ne gÃ¶re, o bÃ¼yÃ¼klÃ¼ÄŸÃ¼ telafi etmek iÃ§in ona gÃ¶re learning rate seÃ§iliyor. Ben bÃ¶yle anladÄ±m, yanlÄ±ÅŸÄ±m veya eksiÄŸim olabilir. Tabii ki eleÅŸtiriye ve dÃ¼zeltmelere aÃ§Ä±ÄŸÄ±m. Ä°lk soru cevaplama deneyimim, mentorlarÄ±mÄ±z daha iyi cevabÄ± verecektir????. Ä°yi gÃ¼nler.2 months ago 12 people like this.Like ReportReply",
    "->   ->  TeÅŸekkÃ¼r ederim.",
    "->  ArkadaÅŸlar goldilocks kavramÄ±nÄ± learning rate ile birlikte aÃ§Ä±klamÄ±ÅŸ ama kurstaki sorunun cevabÄ± olan 1.6 deÄŸerini nasÄ±l bulduÄŸumuza deÄŸinmemiÅŸ. Bu konuya aÃ§Ä±klÄ±k getirebilecek bir arkadaÅŸÄ±mÄ±z var mÄ±dÄ±r ?.",
    "->  Merhabalar, eklediÄŸim gÃ¶rselde aÃ§Ä±klamaya Ã§alÄ±ÅŸtÄ±m.1 month ago 2 people like this.Like ReportReply",
    "->  EÄŸitimin bir kÄ±smÄ±nda ÅŸu geÃ§iyordu: \"MÃ¼kemmel Ã¶ÄŸrenme oranÄ±nÄ± bulmak ÅŸart deÄŸildir 'yeterince' hÄ±zlÄ± yakÄ±nsayacak deÄŸer seÃ§mek yeterlidir.\" Belirli Ã¶ÄŸrenme oranlarÄ±nÄ± seÃ§mek Ã§oÄŸu zaman iÅŸe yarÄ±yormuÅŸ. Andrew NG'den hatÄ±rladÄ±ÄŸÄ±m kadarÄ±yla 0.03 0.01 0.1 0.3 deÄŸerleri gibi.1 month ago 3 people like this.Like ReportReply",
    "->  Cevaplar iÃ§in teÅŸekkÃ¼rler ancak bu soruda nasÄ±l 1.6 cevabÄ±nÄ± bulduÄŸumuzu aÃ§Ä±klamÄ±yor:) soÄŸuk Ä±lÄ±k ve sÄ±cak deÄŸerlerine sÄ±rasÄ±yla 1,2 ve 3 verdikten sonra mÄ± bu learning rate oranÄ±nÄ± bulacaÄŸÄ±z bu Ã¶rnekte ?.",
    "->  ->  Merhaba, 1.6 olmasÄ±nÄ±n sebebi gradient descent fonksiyonumuzun sadece bir adÄ±mda optimum deÄŸere ulaÅŸmasÄ±ndandÄ±r. AmacÄ±mÄ±z olabilecek en kÄ±sa sÃ¼rede ve adÄ±mda minimum noktasÄ±na gitmek. Learning rate'imiz minimum deÄŸere atacaÄŸÄ±mÄ±z adÄ±mÄ± simgelediÄŸi iÃ§in 1.6 bÃ¼yÃ¼klÃ¼ÄŸÃ¼nde adÄ±m bizi tek seferde minimuma gÃ¶tÃ¼rdÃ¼. Burada Learning Rate deÄŸeri deneme yanÄ±lma ile bulunur kesin olarak her modelde 1.6'dÄ±r veya sabittir diyemeyiz. Ä°yi Ã§alÄ±ÅŸmalar dilerim.1 month ago 3 people like this.Like ReportReply",
    "->  ->  Ã–rnek, bize orada Ã¶ÄŸrenme oranÄ±ndaki deÄŸiÅŸimin adÄ±m sayÄ±sÄ±nÄ± nasÄ±l deÄŸiÅŸtirdiÄŸini gÃ¶stermek iÃ§in konulmuÅŸ sadece. Yani her iterasyonda en iyi deÄŸeri bulmak zorunda deÄŸiliz. Ne Ã§ok bÃ¼yÃ¼k olsun ne de Ã§ok kÃ¼Ã§Ã¼k orta deÄŸerler iÅŸimizi gÃ¶rÃ¼yor. Ã–nceki yorumda yazdÄ±ÄŸÄ±m gibi genelde ilk denen deÄŸerler var. Bu deÄŸerlere gÃ¶re arttÄ±rÄ±p azaltacaÄŸÄ±mÄ±za karar veriyoruz..",
    "->  ->  teÅŸekkÃ¼rler yanÄ±t iÃ§in.Ben buna yakÄ±n bir dÃ¼ÅŸÃ¼ndÃ¼m ve sonucun 1.5 olabileceÄŸini varsaydÄ±m. Cevap olarak 1.6 yazÄ±nca kaÃ§Ä±rdÄ±ÄŸÄ±m bir ÅŸey olabilir diye sormak istedim teÅŸekkÃ¼rler..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Ä°lk soruyu soracak olmanÄ±n verdiÄŸi heyecanÄ±ndan dolayÄ± yanlÄ±ÅŸ bir ÅŸekilde sorarsam kusuruma bakmayÄ±n. BugÃ¼n ki Ã§alÄ±ÅŸmamda Reducing Loss ile alakalÄ± kafamda takÄ±lan konu Stochastic Loss ile mini batch loss function arasÄ±ndaki farkÄ± Ã§ok iyi anlayamadÄ±m. Bana bu konuda yardÄ±mcÄ± olabilir misiniz?  <a href=\"https://community.globalaihub.com/community/hashtag/reducingloss/\"><span class=\"ps-stream-hashtag\">#reducingloss</span></a>  <a href=\"https://community.globalaihub.com/community/hashtag/minibatch/\"><span class=\"ps-stream-hashtag\">#minibatch</span></a>",
"comment": [
    "",
    "-> Merhaba.Ã–zetle ÅŸunu sÃ¶yleyebilirim.Derin Ã¶ÄŸrenmede veri setinde bulunan tÃ¼m verileri aynÄ± anda iÅŸleyerek Ã¶ÄŸrenme maliyetli bir iÅŸ.Veri sayÄ±sÄ± ne kadar fazla ise hesaplama da o oranda fazla sÃ¼rmekte.Bu problemi Ã§Ã¶zmek iÃ§in veri seti kÃ¼Ã§Ã¼k gruplara ayrÄ±lmakta ve Ã¶ÄŸrenme iÅŸlemi seÃ§ilen bu kÃ¼Ã§Ã¼k gruplar Ã¼zerinde yapÄ±lmakta.Birden fazla girdinin parÃ§alar halinde iÅŸlenmesi â€œmini-batchâ€ olarak adlandÄ±rÄ±lmakta.Yani Stochastic gradient descent ile veriyi tekbir bÃ¼tÃ¼n olarak incelerken Mini-batch stochastic gradient descent ile daha kÃ¼Ã§Ã¼k parÃ§alara ayÄ±rarak inceleniyor..",
    "-> eski izlediÄŸim videolarÄ±da gÃ¶z Ã¶nÃ¼nde bulundurarak mini batch parametresini kullanÄ±rken veriyi kÃ¼Ã§Ã¼k kÃ¼Ã§Ã¼k ayÄ±rÄ±p modele yavaÅŸ yavaÅŸ veriyor diyebiliriz fakat burada bazÄ± veriler uygun iken bazÄ± veriler uygun olmayabilir bu yÃ¼zden gÃ¼rÃ¼ltÃ¼ Ã§ok olur burada Ã¶nemli olan anladÄ±ÄŸÄ±m kadarÄ±yla learning rate deÄŸeri Ã¶nem kazanÄ±yor onuda 1 yaptÄ±ÄŸÄ±mÄ±zda stochastic parametresi ile aynÄ± iÅŸi yapmÄ±ÅŸ oluyoruz bende eÄŸitimden kalan bilgilerim ile cevap vermeye Ã§alÄ±ÅŸtÄ±m umarÄ±m birÅŸeyleri doÄŸru anlamÄ±ÅŸÄ±zdÄ±r ğŸ™‚ iyi Ã§alÄ±ÅŸmalar.",
    "->  stochastic gradient descent Ã¶ÄŸrenme iÅŸlemini yaparken sadece tek bir Ã¶rneÄŸe bakmÄ±yor mu ? ->.",
    "-> Veri setine bÃ¼tÃ¼n olarak bakÄ±yor..",
    "->  Stochastic gradient descent (SGD) takes this idea to the extreme--it uses only a single example (a batch size of 1) per iteration. Given enough iterations, SGD works but is very noisy. The term \"stochastic\" indicates that the one example comprising each batch is chosen at random yazÄ±yor da o yÃ¼zden sordum. sizin dediÄŸiniz bÃ¼tÃ¼n olarak bakmasÄ±na batch gradient descent deniyor diye biliyorum. ->.",
    " ->  Biraz araÅŸtÄ±rdÄ±ÄŸÄ±m kadarÄ±ylaSchoastic gredient decent ile her iterasyonda sadece bir veri Ã¼zerinde iÅŸlem yapÄ±yoruz.BÃ¼tÃ¼n olarak bakmasÄ±na batch gredient descent deniyor.(AslÄ±nda Mini-batch deÄŸerini eÄŸitim kÃ¼mesinde bÃ¼tÃ¼n eleman sayÄ±sÄ± kadar yaparsak, eÄŸitim kÃ¼mesindeki tÃ¼m veriler eÄŸitime gireceÄŸi iÃ§in yapÄ±lan iÅŸlem de yine â€œbatch gredient descentâ€ oluyor.)Mini-batch stochastic gradient descentte ise seÃ§ilen deÄŸerin 1 ile eÄŸitim kÃ¼mesindeki veri sayÄ±sÄ± arasÄ±nda ne Ã§ok kÃ¼Ã§Ã¼k ne de Ã§ok bÃ¼yÃ¼k olmayan bir deÄŸer olarak belirlenmesi gerekiyor. ( Crash course da yanlÄ±ÅŸ hatÄ±rlamÄ±yorsam 100 ile 1000 arasÄ±nda demiÅŸti. Elimizdeki veriyi yÃ¼zlÃ¼k , binlik ÅŸekilde parÃ§alara ayrÄ±ldÄ±ÄŸÄ±mÄ±zÄ± dÃ¼ÅŸÃ¼nÃ¼n).Bu konuyu ben de bugÃ¼n yeni Ã¶ÄŸrendim. LÃ¼tfen herhangi bir hatam varsa belirtiniz ????2 months ago 5 people like this.Like ReportReply",
    "-> Gradient Descent algoritmasÄ± Cost Function'Ä±mÄ±zÄ± optimize etmek iÃ§in uyguladÄ±ÄŸÄ±mÄ±z bir algoritmadÄ±r. Optimizasyonu ise cost function'Ä±mÄ±zÄ±n sÃ¼rekli derivative'ini alarak yapmaktadÄ±r. Cost functionÄ±mÄ±z ise aslÄ±nda tÃ¼m tahmin edilen y deÄŸerleri-gerÃ§ek y deÄŸerlerinin karelerinin toplamÄ±/(veri sayÄ±sÄ± * 2). (Resim olarak ekledim. 2m olmasÄ±nÄ±n sebebi derivative alÄ±nÄ±rken kolaylÄ±k saÄŸlanmasÄ± iÃ§indir.)Gradient Descent formÃ¼lÃ¼mÃ¼ze baktÄ±ÄŸÄ±mÄ±zda ise (Resim olarak ekledim.) Cost function'Ä±mÄ±zÄ±n derivative'inin alÄ±ndÄ±ÄŸÄ±nÄ± ve bunun optimize olana kadar devam ettiÄŸini yani iterative olarak yaptÄ±ÄŸÄ±nÄ± gÃ¶zlemleyebiliriz. Gradient Descent formÃ¼l resmindeki kÄ±rmÄ±zÄ± alan ise bizim cost function'Ä±mÄ±zdÄ±r. Gradient Descent algoritmamÄ±z her iterasyonda cost function'Ä±mÄ±zÄ±n derivative'ini alÄ±r. Bu iterasyon sÄ±rasÄ±nda itere edilen cost functionÄ±mÄ±zÄ±n range'ini belirleyebiliriz. Bu range Ã§eÅŸitlerine gÃ¶re de Gradient Descent ayrÄ±lÄ±r. Ã–rneÄŸin;Batch Gradient Descent: Her iterasyonda tÃ¼m veri seti iÃ§in cost function hesaplar ve hepsinin derivative'ini alÄ±r. Veri fazlalaÅŸtÄ±kÃ§a bu yÃ¶ntem yavaÅŸlar.Mini-Batch Gradient Descent: Her iterasyonda tÃ¼m veri setini almak yerine veri setinin belli bir kÄ±smÄ± iÃ§in cost function hesaplayÄ±p derivative'ini alÄ±r.Stochastic Gradient Descent: Her iterasyonda verisetinden sadece bir Ã¶rnek iÃ§in cost function hesaplayÄ±p derivative'ini alÄ±r.EÄŸer bir hatam veya eksiÄŸim olduysa dÃ¼zeltmelere aÃ§Ä±ÄŸÄ±m ğŸ™‚ UmarÄ±m aÃ§Ä±klayÄ±cÄ± olmuÅŸtur ğŸ™‚2 months ago 22 people like this.Like ReportReply",
    "->  ->  harika aÃ§Ä±klamanÄ±z iÃ§in Ã§ok teÅŸekkÃ¼r ederim. cost fonksiyonunu pythonda yazarken loss = np.sum(deltas**2) / 2 / observations olarak ifade ettiÄŸimizi hatÄ±rladÄ±ÄŸÄ±m iÃ§in yazma gereÄŸi duydum. hatam olabilir olursa lÃ¼tfen bildirmekten Ã§ekinmeyin. Fethi hocam yukarÄ±da \"y deÄŸerleri-gerÃ§ek y deÄŸerlerinin karelerinin toplamÄ±/ortalamadÄ±r\" demiÅŸsiniz. burdan anladÄ±ÄŸÄ±m kadarÄ±yla \"ortalama = m\" deÄŸeri oluyor yukardaki verdiÄŸiniz resim ekine gÃ¶re de. benim anladÄ±ÄŸÄ±m m = gÃ¶zlem sayÄ±sÄ± demek. acaba cost fonksiyonu iÃ§in \"karesi alÄ±nmÄ±ÅŸ farklarÄ±n, toplamÄ±nÄ±n, ortalamasÄ±\" mÄ± demek istediniz de ben anlayamadÄ±m tam olarak kafam karÄ±ÅŸtÄ±. Ã§ok yeni olduÄŸum iÃ§in burda verilen cevaplar bazen aklÄ±mda kural olarak kalabiliyor.",
    "->  ->  Merhaba Ã¶ncelikle cevabÄ±nÄ±z iÃ§in Ã§ok teÅŸekkÃ¼r ederim. Evet orada bir hata yapmÄ±ÅŸÄ±m ve bu cevabÄ± yazdÄ±ktan sonra da dÃ¼zeltmesini yapacaÄŸÄ±m. Oradaki M, verisetindeki veri sayÄ±sÄ± oluyor yani sizden alÄ±ntÄ±layarak ve biraz dÃ¼zenleyerek ÅŸu Ã§Ä±karÄ±mÄ±nÄ±zÄ± onaylayabilirim: \"cost fonksiyonu \"karesi alÄ±nmÄ±ÅŸ farklarÄ±n karelerinin toplamÄ± deÄŸerinin veri boyutu*2 'ye bÃ¶lÃ¼nmesidir. Ã–rneÄŸin verisetimde 100 deÄŸer var ise bu 100 deÄŸer iÃ§n tahmin edilen deÄŸer - olmasÄ± gereken deÄŸerlerinin karelerinin toplamÄ± / (2*100) yaptÄ±ÄŸÄ±mzda cost function deÄŸerimizi bulabiliyoruz. (2 olmasÄ±nÄ±n sebebi kareli deÄŸerin derivative'i alÄ±ndÄ±ÄŸÄ±nda iÅŸlem kolaylÄ±ÄŸÄ± saÄŸlamak) Fark toplamlarÄ±/(Ã¶rnek sayÄ±sÄ±*2)=cost function deÄŸeri bulunuyor yazmam gerekirken uykusuzluÄŸun da vermiÅŸ olduÄŸu bir hal ile yanlÄ±ÅŸ yazmÄ±ÅŸÄ±m ğŸ™‚ EÄŸer anlatamadÄ±ÄŸÄ±m bir yer var ise lÃ¼tfen yazmaktan Ã§ekinmeyin ğŸ™‚.",
    "-> Veri setindeki tÃ¼m verileri aynÄ± anda iÅŸlemek, hem zaman hem de bellek aÃ§Ä±ÅŸÄ±ndan Ã§ok maliyetli bir sÃ¼reÃ§tir. Maliyeti minimize etmek, tahmine baÄŸlÄ± hata oranÄ±nÄ± en aza indirmek iÃ§in de en uygun aÄŸÄ±rlÄ±k deÄŸerlerini bulmaya Ã§alÄ±ÅŸÄ±yoruz. Bunu da gradient descent optimizasyonu ile yapÄ±yoruz. Veri miktarÄ± ne kadar fazla ise bu hesaplama da o kadar uzun sÃ¼rÃ¼yor. DolayÄ±sÄ±yla veri setini kÃ¼Ã§Ã¼k gruplara ayÄ±rarak Ã¶ÄŸrenme iÅŸlemini bu kÃ¼Ã§Ã¼k gruplar Ã¼zerinden devam ettiriyoruz. Bu ÅŸekilde verinin kÃ¼Ã§Ã¼k gruplar halinde iÅŸlenmesi mini-batch olarak adlandÄ±rÄ±lÄ±yor. Mini-batch parametresi olarak belirtilen deÄŸer, modelin aynÄ± anda kaÃ§ veriyi iÅŸleyeceÄŸini belirtiyor. Veri genelde 10-1000 arasÄ±nda random seÃ§ilmiÅŸ Ã¶rneklere bÃ¶lÃ¼nerek iÅŸleniyor. Mini-batch deÄŸerini 1 olarak belirlediÄŸimizde de alabileceÄŸi en kÃ¼Ã§Ã¼k deÄŸeri almÄ±ÅŸ oluyor, buna da stochastic gradient descent diyoruz. Yani her iterasyonda sadece tek bir veri Ã¼zerinde iÅŸlem yapÄ±lmasÄ± durumu. Her iki uygulamanÄ±n da, min-batch ve stochastic, kendi iÃ§inde artÄ±/eksi yanlarÄ± var. Ã–nemli olan burada sizin veri setiniz ve belleÄŸinize en uygun batch deÄŸerini belirlemeniz. Bunun iÃ§in de ayrÄ±ca belli kriterler var zaten.2 months ago 42 people like this.Like ReportReply",
    "->  ->  AslÄ± HanÄ±m bu batch deÄŸerin belirlemede belli kriterler nedir? Ã–rneÄŸin makinenin core sayÄ±sÄ± felan mÄ± ya da ekstra veri Ã¼zerinden de bir kriter oluÅŸturulabiliyor mu?.",
    "-> ->  Bununla ilgili ÅŸÃ¶yle bir liste paylaÅŸayÄ±m sizinle;-Mini-batch deÄŸerinin seÃ§iminde en uygun deÄŸer 1 ile eÄŸitim kÃ¼mesindeki tÃ¼m verilerin sayÄ±sÄ± arasÄ±nda ne Ã§ok kÃ¼Ã§Ã¼k ne de Ã§ok bÃ¼yÃ¼k olmayan bir deÄŸer belirlenmelidir. Bu hÄ±zlÄ± ÅŸekilde Ã¶ÄŸrenmeyi saÄŸlayacaktÄ±r.-Batch sizeâ€™Ä±n bÃ¼yÃ¼k olmasÄ±, daha doÄŸru gradyan deÄŸerinin hesaplanmasÄ±nÄ± saÄŸlamaktadÄ±r. Bu durum da linerizasyonu azaltmaktadÄ±r.-Belirlenen batch deÄŸerinin GPU belleÄŸine sÄ±ÄŸmasÄ± gerekiyor. Bu nedenle batch boyutu 2â€™nin katlarÄ± ÅŸeklinde belirlenmelidir; 2, 4, 8, 16, 32, â€¦ 512 vb. Bu ÅŸekilde belirlenmemiÅŸse baÅŸarÄ±mda ani dÃ¼ÅŸÃ¼ÅŸler yaÅŸanabilir.-Batch size genelde 64 ile 512 arasÄ±nda 2'nin katÄ± olan deÄŸerlerden belirleniyor.-EÄŸitim kÃ¼mesindeki eleman sayÄ±sÄ± kÃ¼Ã§Ã¼kse (yani 2000'den az ise) eÄŸitim kÃ¼mesindeki tÃ¼m elemanlar aynÄ± anda kullanÄ±labilir. Yani batch gradyan hesaplamasÄ± yapÄ±labilir.-EvriÅŸimsel sinir aÄŸlarÄ± (Convolutional Neural Networks) batch deÄŸerine karÅŸÄ± hassastÄ±r. Batch deÄŸerindeki kÃ¼Ã§Ã¼k deÄŸiÅŸiklikler baÅŸarÄ±mda bÃ¼yÃ¼k etkiler oluÅŸturabilir.-Batch boyutunun diÄŸer bir kÄ±stasÄ± da bellek boyutudur. EÄŸer kÃ¼Ã§Ã¼k belleÄŸe sahip ortamda Ã§alÄ±ÅŸÄ±yorsanÄ±z, batch bÃ¼yÃ¼k tutmakta zorlanabilirsiniz. Bu nedenle modeli tasarlarken Ã¶ncesinde kullanabileceÄŸiniz maksimum batch deÄŸeri hesaplamak verimli olacaktÄ±r.-Batch size kÃ¼Ã§Ã¼k olmasÄ± iyileÅŸtirme (reguralization) etkisi yaratmaktadÄ±r. Modele veri bÃ¼yÃ¼k gruplar halinde verildiÄŸinde ezberleme daha fazla oluyor.-Batch iÅŸleminde, veri seti batch deÄŸeri olarak belirlenen deÄŸere gÃ¶re parÃ§alara ayrÄ±lmakta ve her iterasyonda modelin eÄŸitimi bu parÃ§a Ã¼zerinden yapÄ±lmaktadÄ±r. Bununla birlikte bazÄ± durumlarda veri kendi iÃ§inde gruplanmÄ±ÅŸ olabilmektedir. Bu durum veri seti iÃ§inde korelasyon oluÅŸturacak; bu veri setinden seÃ§ilecek test setin de yÃ¼ksek baÅŸarÄ±m vermesini saÄŸlayacak bÃ¶ylece ezberleme (â€œoverfittingâ€) olacaktÄ±r. Bunu Ã¶nlemek iÃ§in eÄŸitim baÅŸlamadan veri seti parÃ§alara ayrÄ±lmadan Ã¶nce veri seti karÄ±ÅŸtÄ±rÄ±lmalÄ±dÄ±r (shuffle). Batch seÃ§iminde verilerin rastgele seÃ§ilmesi Ã¶nemlidir.2 months ago 15 people like this.Like ReportReply",
    "->  ->  2'nin katÄ± deÄŸil de 2'nin kuvveti yazmak istediniz sanÄ±rÄ±m2 months ago Like ReportReply",
    "->  ->  evet ğŸ™‚2 months ago Like ReportReply",
    "->  ->  teÅŸekkÃ¼rler verdiÄŸiniz bilgiler iÃ§in.",
    "->  ->  Ã‡ok teÅŸekkÃ¼r ederim AslÄ± HanÄ±m..",
    "->  ->  AslÄ± hanÄ±m Ã§ok anlaÅŸÄ±lÄ±r bir dille aÃ§Ä±klamÄ±ÅŸsÄ±nÄ±z yavaÅŸ yavaÅŸ aÅŸina olan bizler iÃ§in Ã§ok gÃ¼zel bir kolaylÄ±k bu teÅŸekkÃ¼rler..",
    "->  AydÄ±nlatÄ±cÄ± aÃ§Ä±klamalarÄ±nÄ±z iÃ§in herkese Ã§ok teÅŸekkÃ¼r ederim. Ã‡ok faydalÄ± oluyor..",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Bu akÅŸam canlÄ± yayÄ±nÄ±mÄ±za katÄ±lan herkese teÅŸekkÃ¼r ederiz. KaÃ§Ä±ranlar aÅŸaÄŸÄ±daki linkten canlÄ± yayÄ±nÄ± izleyebilirsiniz.  <a class=\"ps-media-link\" href=\"https://www.youtube.com/watch?v=hXHoODCweRo\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">https://www.youtube.com/watch?v=hXHoODCweRo</a>",
"comment": [
    "",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Teknik bir aksaklÄ±k yaÅŸadÄ±k. Kusura bakmayÄ±n. Ã‡Ã¶zmeye Ã§alÄ±ÅŸÄ±yoruz. Ã‡Ã¶zebilirsek 20:30'da baÅŸlayacaÄŸÄ±z.  CanlÄ± yayÄ±n yapacaÄŸÄ±mÄ±z kanal linki: <a class=\"ps-media-link\" href=\"https://www.youtube.com/channel/UCpB-u_FJegcM0WrMtr-W27w/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">https://www.youtube.com/channel/UCpB-u_FJegcM0WrMtr-W27w/</a>",
"comment": [
    "",
    " "
]
},
{
"question_isim": "-> ",
"quest": "CANLI YAYIN LÄ°NKÄ°: <a class=\"ps-media-link\" href=\"https://www.youtube.com/channel/UCpB-u_FJegcM0WrMtr-W27w\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">https://www.youtube.com/channel/UCpB-u_FJegcM0WrMtr-W27w</a>",
"comment": [
    "",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Merhaba, iyi haftalar!  BugÃ¼n itibariyle ML Crash Course programÄ±mÄ±za baÅŸlÄ±yoruz. Program ile ilgili haftalÄ±k hedefleri ve Ã¶nemli tarihleri ekte paylaÅŸtÄ±ÄŸÄ±m formda bulabilirsiniz. TakÄ±ldÄ±ÄŸÄ±nÄ±z bir kÄ±sÄ±m olursa  lÃ¼tfen bu postun altÄ±na belirtin, herkesin bilgilenmesi aÃ§Ä±sÄ±ndan buradan yanÄ±tlayalÄ±m. AramÄ±za tekrar hoÅŸgeldiniz :) Verimli bir sÃ¼reÃ§ olsun hepimize, iyi Ã§alÄ±ÅŸmalar dilerim.  <a class=\"ps-media-link\" href=\"http://community.globalaihub.com/mlcc-yol-haritasi_642020/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://community.globalaihub.com/mlcc-yol-haritasi_642020/</a>",
"comment": [
    "",
    "->  TeÅŸekkÃ¼rler bilgilendirme iÃ§in ğŸ™‚.",
    "-> TeÅŸekkÃ¼rler..",
    "->  Merhaba, kurstaki ilerlememi kaydedemiyorum, Ã§Ä±ktÄ±ÄŸÄ±m anda sÄ±fÄ±rlÄ±yor, bir Ã¶neriniz var mÄ± acaba ?2 months ago Like ReportReply",
    "->  ->  Merhabalar, Google'Ä±n ilgili serisinden olan bu kursun Ã¶yle bir uygulamasÄ± yok ne yazÄ±k ki.. KaldÄ±ÄŸÄ±nÄ±z yeri not ederek ilerleyebilirsiniz ğŸ˜‰.",
    "-> -> TeÅŸekkÃ¼rler.",
    "-> Ã¶z Ã–ncelikle merhaba ilginiz iÃ§in hepinize Ã§ok teÅŸekkÃ¼r ederim. BirkaÃ§ arkadaÅŸÄ±m ingilizce devam edeceÄŸinizi dÃ¼ÅŸÃ¼nerek kayÄ±t dahi yaptÄ±rmamÄ±ÅŸlar. SormamÄ± istediler iletiÅŸim Ä°ngilizce mi olacak ?2 months ago Like ReportReply",
    "->  -> Ã¶z merhaba, teÅŸekkÃ¼r ederiz. Bu hub Ä±n iÃ§inde TÃ¼rkÃ§e iletiÅŸim kurabilirsiniz, kursun kendisi Ä°ngilizce yalnÄ±zca ğŸ™‚2 months ago Like ReportReply",
    " ->  teÅŸekkÃ¼rler ????2 months ago Like ReportReply",
    " ->  Merhaba, haftalÄ±k mini quziler ve genel deÄŸerlendirme sÄ±navÄ± da mÄ± ingilizce olacak acaba?2 months ago Like ReportReply",
    "->  TeÅŸekkÃ¼rler..",
    "-> TeÅŸekkÃ¼rler.",
    "->  TeÅŸekkÃ¼rler.",
    "->  TeÅŸekkÃ¼rler.",
    "->  Ã¶ncelikle emeÄŸiniz ve ilginiz iÃ§in teÅŸekkÃ¼rler ğŸ™‚ videolarÄ± izlediÄŸimizin kontrolÃ¼nÃ¼ nasÄ±l yapacaksÄ±nÄ±z ya da bÃ¶yle bir kontrol sistemi var mÄ±? yoksa sadece haftalÄ±k testlere ve ay sonundaki test sonucuna gÃ¶re mi sertifika verilecek?.",
    "->  ->  Merhaba AslÄ± hanÄ±m, biz teÅŸekkÃ¼r ederiz ğŸ™‚ videolar iÃ§in bir kontrol yapmayacaÄŸÄ±z, onlar sizin farklÄ± alanlardaki AI Ã§alÄ±ÅŸmalarÄ± hakkÄ±nda bilgi sahibi olabilmeniz, gerÃ§ek dÃ¼nyada kimler hangi alanlarda neler yapÄ±yor, bunlarÄ± ilk aÄŸÄ±zdan dinleyip o kiÅŸilerle tanÄ±ÅŸma, soru sorabilme fÄ±rsatÄ± bulabilmeniz iÃ§in belirttiÄŸimiz bir tavsiye ğŸ™‚ Bir de evet, haftalÄ±k testlere katÄ±lÄ±mÄ±nÄ±za ve program sonundaki sÄ±nav durumunuza gÃ¶re deÄŸerlendirme yapÄ±lacak.2 months ago Like ReportReply",
    "-> -> SÄ±nav saati ile ilgili paylaÅŸÄ±m yapÄ±ldÄ± mÄ±? TeÅŸekkÃ¼rler.1 month ago 10 people like this.Like ReportReply",
    "->  -> -> SÄ±nav belirli bir saat aralÄ±ÄŸÄ±nda olmayacak, sabah mail adreslerinize bir link gÃ¶ndereceÄŸim. YarÄ±n sabah 10 ile akÅŸam 10 arasÄ±nda istediÄŸiniz saatte girebilirsiniz. Linke girdiÄŸinizde 45 dk sÃ¼reniz ve timer olacak, sÃ¼re bittikten sonra tekrar sisteme girme ÅŸansÄ±nÄ±z olmayacaktÄ±r.1 month ago 5 people like this.Like ReportReply",
    "->  Merhabalar,Benim sisteme eriÅŸimim henÃ¼z aÃ§Ä±ldÄ±. Birinci hafta konularÄ±na yeni baÅŸladÄ±m. Bizim sÃ¼recimiz nasÄ±l olacak acaba?.",
    " "
]
},
{
"question_isim": "->  uploaded 1 photo",
"quest": "Merhabalar! Bu akÅŸam 21:00'de Facebook AI' da Yapay Zeka AraÅŸtÄ±rma MÃ¼hendisi olarak Ã§alÄ±ÅŸan TuÄŸÃ§e TaÅŸÃ§Ä± ile Sinirbilim ve Yapay Zeka Ã¼zerine konuÅŸuyor olacaÄŸÄ±z. Birazdan baÅŸlayacak canlÄ± yayÄ±nÄ±mÄ±zÄ± kaÃ§Ä±rmayÄ±n âœ¨  <a class=\"ps-media-link\" href=\"https://www.youtube.com/channel/UCpB-u_FJegcM0WrMtr-W27w\" rel=\"nofollow\" target=\"_blank\">https://www.youtube.com/channel/UCpB-u_FJegcM0WrMtr-W27w</a>",
"comment": [
    "",
    "->  Ã‡ok gÃ¼zel bir yayÄ±ndÄ±. Ellerinize saÄŸlÄ±k ğŸ™‚.",
    "->  ->  TeÅŸekkÃ¼r ederiz ğŸ™‚.",
    " "
]
},
{
"question_isim": "-> ",
"quest": "Ä°yi akÅŸamlar herkese. UmarÄ±m saÄŸlÄ±ÄŸÄ±nÄ±z ve keyfiniz yerindedir. Mentorluk programÄ±yla ilgili kafanÄ±zda soru iÅŸareti varsa bu paylaÅŸÄ±mÄ±n altÄ±nda sorabilirsiniz.",
"comment": [
    "",
    "->  Biz sizin yÃ¶nlendirmeleriniz dahilinde kursu yapacaÄŸÄ±z ve herhangi bir sorumuz olursa size danÄ±ÅŸabileceÄŸiz deÄŸil mi? KaÃ§Ä±rdÄ±ÄŸÄ±m bir ÅŸey var mÄ±?.",
    "->  ->  Evet, tam olarak ÅŸekilde olacak..",
    "->  ->  Ã‡ok teÅŸekkÃ¼rler iyi akÅŸamlar dilerim..",
    "->  ->  http://community.globalaihub.com/community/status/176-176-1586157026/ bu posttan detaylara ulaÅŸabilirsiniz..",
    "->  ->  Mehmet bey teÅŸekkÃ¼rler ğŸ™‚2 months ago Like ReportReply",
    "->  Merhaba iyi akÅŸamlar , sÃ¼recin tam olarak nasÄ±l ilerleyeceÄŸi hakkÄ±nda ayrÄ±ntÄ±lÄ± bir paylaÅŸÄ±m yapÄ±lacak mÄ± tam olarak nasÄ±l ilerleyeceÄŸiz ?.",
    "->  ->  AyrÄ±ntÄ±lÄ± bilgilendirmeyi burada bulabilirsiniz: http://community.globalaihub.com/community/status/14-14-1584877078/.",
    "->  ->  HaftalÄ±k program ve diÄŸer detaylar --> http://community.globalaihub.com/community/status/176-176-1586157026/2 months ago Like ReportReply",
    "->  ->  TeÅŸekkÃ¼r ederim2 months ago Like ReportReply",
    "->  SanÄ±rÄ±m pazartesi gÃ¼nÃ¼ baÅŸlayacak. Pazartesi'ye kadar yapabileceÄŸimiz bir ÅŸey var mÄ±?.",
    "->  ->  EÄŸitimin Ã¶n gereksimlerini https://developers.google.com/machine-learning/crash-course/prereqs-and-prework adresinde bulabilirsiniz. Varsa eksiklerinizi giderebilirsiniz.",
    "Prerequisites and Prework Â |Â  Machine Learning Crash Coursedevelopers.google.comhttps://developers.google.com/machine-learning/crash-course/prereqs-and-prework.",
    "->  ->  Merhaba, gereksinimlerin en alt bÃ¶lÃ¼mÃ¼nde Bash Terminal bÃ¶lÃ¼mÃ¼ var. Konuya dair aÃ§Ä±kÃ§asÄ± hiÃ§bir fikrim yoktu fakat biraz araÅŸtÄ±rma yaptÄ±m. OkuduklarÄ±m doÄŸrultusunda sadece ilgili kavramlarÄ±n ne olduÄŸunu anladÄ±m. Sizce bash Ã¼zerinde bir Ã§alÄ±ÅŸma gerekiyor mu yoksa bildiÄŸimiz comman window kullanÄ±mÄ± mÄ± olacak? TeÅŸekkÃ¼r ederim..",
    "->  ->  Bash kullanÄ±mÄ± hem localde hem de Ã¶zellikle cloud makinelerde Ã§ok Ã¶nemli. O yÃ¼zden bu konularda eksiÄŸiniz varsa mutlaka tamamlayÄ±n derim. Zaten paylaÅŸtÄ±ÄŸÄ±m linkte 3 tane gÃ¼zel referans kaynak var. OnlarÄ± bir yandan Ã§alÄ±ÅŸmanÄ±zÄ± ÅŸiddetle Ã¶neririm..",
    "->  ->  PaylaÅŸtÄ±ÄŸÄ±nÄ±z linkleri bulamadÄ±m atabilir misiniz?.",
    "->  EÄŸitim ile ilgili toplu bir ilerleme mi planlanÄ±yor yoksa herkes kendi takvimini mi oluÅŸturacak? Ã–rnek verecek olursam; haftalÄ±k belirli bir bÃ¶lÃ¼me kadar ilerlenilmesini mi isteyeceksiniz yoksa herkes kursunu devam ettirirken buradan sorularÄ±nÄ± mÄ± soracak? Bu sorularÄ±n cevabÄ±nÄ± muhtemelen Pazartesi gÃ¼nÃ¼ anlayacaktÄ±m ama Ã¶nden bir sormak istedim. SaygÄ±larÄ±mla..",
    "->  ->  Toplu bir ilerleme saÄŸlayacaÄŸÄ±z. O yÃ¼zden yÃ¼zlerce kiÅŸi aynÄ± anda programÄ± takip ediyor zaten ğŸ™‚.",
    "->  merhaba , bu durumda pazartesi gÃ¼nÃ¼ egitim takvimi acÄ±klanacak degil mi? su an programÄ±n hepsi acÄ±k gÃ¶rÃ¼nÃ¼yor zira..",
    "->  ->  Evet, program pazartesi gÃ¼nÃ¼ ->  tarafÄ±ndan aÃ§Ä±klanacak.2 months ago Like ReportReply",
    "->  ->  Program detayÄ± iÃ§in http://community.globalaihub.com/community/status/176-176-1586157026/ bakabilirsiniz.2 months ago Like ReportReply",
    "->  merhaba videolarÄ± izliyorum ama izlendi veya su kadarÄ± tamamlandÄ± gibi bir seÃ§enek yok. YanlÄ±ÅŸ mÄ± yapÄ±yorum yoksa bu diger kurslarda oldugu gibi tamamlama oranÄ± yok mu?2 months ago Like ReportReply",
    "->  ->  AnladÄ±ÄŸÄ±m kadarÄ±yla zaten herkese aÃ§Ä±k bir eÄŸitim olduÄŸu iÃ§in tamamlama oranÄ± yok, buradan yaptÄ±klarÄ± yÃ¶nlendirme ile devam edeceÄŸiz tahminimce eÄŸitimin tamamlanma durumunu kontrol iÃ§in yorum veya beÄŸeni atabiliriz bir postun altÄ±na ama emin deÄŸilim tabiki ğŸ™‚2 months ago Like ReportReply",
    "->  ->  anladÄ±m, tÅŸk ederim2 months ago Like ReportReply",
    "->  Ã¼nlÃ¼ ISA beyin sorduÄŸu soru benim de aklÄ±ma takÄ±lÄ±yordu Fuat bey, O zaman takipteyiz2 months ago Like ReportReply",
    " "
]
},
{
"question_isim": "->   feeling Strong",
"quest": "Herkese iyi akÅŸamlar. Pazartesi gÃ¼nÃ¼nden itibaren Machine Learning Crash Course programÄ±nÄ± takip etmeye baÅŸlayacaÄŸÄ±z ğŸ™‚ Bu platforma katÄ±lÄ±mlar devam ediyor. GÃ¶nderdiÄŸimiz bazÄ± e-postalar spam'a dÃ¼ÅŸtÃ¼ÄŸÃ¼ iÃ§in geÃ§ gÃ¶renler var. Kimsenin maÄŸdur olmamasÄ±nÄ± istiyoruz. Cuma gÃ¼nÃ¼ itibariyle platformu dÄ±ÅŸarÄ±dan katÄ±lÄ±mlara tamamen kapatacaÄŸÄ±z.    Ä°sterseniz Ã¶ncelikle tanÄ±ÅŸalÄ±m. Åurada kendinizi tanÄ±tmanÄ±zÄ± rica ediyoruz: <a class=\"ps-media-link\" href=\"http://community.globalaihub.com/community/status/14-14-1585638056/\" rel=\"nofollow\" target=\"_blank\">http://community.globalaihub.com/community/status/14-14-1585638056/</a>  AyrÄ±ca herkesin bir profil resmi eklemesini rica ediyoruz.  GÃ¼zel bir program geÃ§ireceÄŸiz. Karantina dÃ¶neminden her birinizin Machine Learning alanÄ±nda yetkinliklerinizi artÄ±rarak Ã§Ä±kmanÄ±zÄ± gÃ¶nÃ¼lden istiyoruz.   Åurada ( <a class=\"ps-media-link\" href=\"http://community.globalaihub.com/community/status/14-14-1584877078/\" rel=\"nofollow\" target=\"_blank\">http://community.globalaihub.com/community/status/14-14-1584877078/</a> ) kendini tanÄ±tan mentor arkadaÅŸlarÄ±mla beraber sizlere buâ€¦ <a class=\"ps-stream-post-more ps-js-content-excerpt-toggle\" href=\"#\">Read more</a></div><div class=\"ps-js-content-full\" style=\"\">Herkese iyi akÅŸamlar. Pazartesi gÃ¼nÃ¼nden itibaren Machine Learning Crash Course programÄ±nÄ± takip etmeye baÅŸlayacaÄŸÄ±z ğŸ™‚ Bu platforma katÄ±lÄ±mlar devam ediyor. GÃ¶nderdiÄŸimiz bazÄ± e-postalar spam'a dÃ¼ÅŸtÃ¼ÄŸÃ¼ iÃ§in geÃ§ gÃ¶renler var. Kimsenin maÄŸdur olmamasÄ±nÄ± istiyoruz. Cuma gÃ¼nÃ¼ itibariyle platformu dÄ±ÅŸarÄ±dan katÄ±lÄ±mlara tamamen kapatacaÄŸÄ±z.    Ä°sterseniz Ã¶ncelikle tanÄ±ÅŸalÄ±m. Åurada kendinizi tanÄ±tmanÄ±zÄ± rica ediyoruz: <a class=\"ps-media-link\" href=\"http://community.globalaihub.com/community/status/14-14-1585638056/\" rel=\"nofollow\" target=\"_blank\">http://community.globalaihub.com/community/status/14-14-1585638056/</a>  AyrÄ±ca herkesin bir profil resmi eklemesini rica ediyoruz.  GÃ¼zel bir program geÃ§ireceÄŸiz. Karantina dÃ¶neminden her birinizin Machine Learning alanÄ±nda yetkinliklerinizi artÄ±rarak Ã§Ä±kmanÄ±zÄ± gÃ¶nÃ¼lden istiyoruz.   Åurada ( <a class=\"ps-media-link\" href=\"http://community.globalaihub.com/community/status/14-14-1584877078/\" rel=\"nofollow\" target=\"_blank\">http://community.globalaihub.com/community/status/14-14-1584877078/</a> ) kendini tanÄ±tan mentor arkadaÅŸlarÄ±mla beraber sizlere bu sÃ¼reÃ§te destek vermeye devam edeceÄŸiz.   Ä°yi ki geldiniz ????</div></div>",
"comment": [
    "",
    " "
]
},
{
"question_isim": "Ege Demir",
"quest": "ML ile ilgili bazÄ± temel soru ve cevaplar:  Makine Ã–ÄŸrenmesi Nedir? Makine Ã¶ÄŸrenimi (ML â€“ Machine Learning), yazÄ±lÄ±m programlarÄ±nÄ±n aÃ§Ä±k bir ÅŸekilde programlanmadan sonuÃ§larÄ± tahmin etmede daha doÄŸru olmasÄ±nÄ± saÄŸlayan bir algoritma kategorisidir. Makine Ã¶ÄŸrenmesinin temel dayanaÄŸÄ±, giriÅŸ verisini alabilen algoritmalar oluÅŸturmak ve Ã§Ä±ktÄ±larÄ± yeni veriler ortaya Ã§Ä±ktÄ±kÃ§a gÃ¼ncellerken bir Ã§Ä±ktÄ±yÄ± tahmin etmek iÃ§in istatistiksel analiz kullanmaktÄ±r.  Makine Ã–ÄŸrenmesinin KullanÄ±m AlanlarÄ± Nedir? HayatÄ±mÄ±za yerleÅŸmiÅŸ Ã§oÄŸu teknolojide makine Ã¶ÄŸrenmesi teknikleri kullanÄ±lmakta. KullanÄ±ldÄ±ÄŸÄ± alanlarÄ±n spektrumu ise ifade edilemeyecek kadar geniÅŸ.  Twitter nasÄ±l beÄŸendiklerime gÃ¶re anasayfamÄ± kiÅŸiselleÅŸtirebiliyor? LinkedIn bana nasÄ±l tanÄ±dÄ±ÄŸÄ±m insanlarÄ± Ã¶nerebiliyor? Mail kutuma dÃ¼ÅŸen spam mesajlar nasÄ±lâ€¦ <a class=\"ps-stream-post-more ps-js-content-excerpt-toggle\" href=\"#\" data-single-act=\"1\">Read more</a></div><div class=\"ps-js-content-full\" style=\"display:none\">ML ile ilgili bazÄ± temel soru ve cevaplar:  Makine Ã–ÄŸrenmesi Nedir? Makine Ã¶ÄŸrenimi (ML â€“ Machine Learning), yazÄ±lÄ±m programlarÄ±nÄ±n aÃ§Ä±k bir ÅŸekilde programlanmadan sonuÃ§larÄ± tahmin etmede daha doÄŸru olmasÄ±nÄ± saÄŸlayan bir algoritma kategorisidir. Makine Ã¶ÄŸrenmesinin temel dayanaÄŸÄ±, giriÅŸ verisini alabilen algoritmalar oluÅŸturmak ve Ã§Ä±ktÄ±larÄ± yeni veriler ortaya Ã§Ä±ktÄ±kÃ§a gÃ¼ncellerken bir Ã§Ä±ktÄ±yÄ± tahmin etmek iÃ§in istatistiksel analiz kullanmaktÄ±r.  Makine Ã–ÄŸrenmesinin KullanÄ±m AlanlarÄ± Nedir? HayatÄ±mÄ±za yerleÅŸmiÅŸ Ã§oÄŸu teknolojide makine Ã¶ÄŸrenmesi teknikleri kullanÄ±lmakta. KullanÄ±ldÄ±ÄŸÄ± alanlarÄ±n spektrumu ise ifade edilemeyecek kadar geniÅŸ.  Twitter nasÄ±l beÄŸendiklerime gÃ¶re anasayfamÄ± kiÅŸiselleÅŸtirebiliyor? LinkedIn bana nasÄ±l tanÄ±dÄ±ÄŸÄ±m insanlarÄ± Ã¶nerebiliyor? Mail kutuma dÃ¼ÅŸen spam mesajlar nasÄ±l belirleniyor?  Google Maps gibi trafik uygulamalarÄ±nda en hÄ±zlÄ± rota belirlenirken, Facebookâ€™a yÃ¼klenen fotoÄŸraflara kiÅŸiler otomatik etiketlenirken, online alÄ±ÅŸveriÅŸ sitelerinde bir Ã¼rÃ¼n arattÄ±ktan sonra size o Ã¼rÃ¼nlerle ilgili reklamlar gÃ¶sterilirken ve her gÃ¼n bir ÅŸekilde kullandÄ±ÄŸÄ±mÄ±z Siri, Alexa, Google ve Cortana gibi asistanlarda makine Ã¶ÄŸrenmesi teknikleri sÄ±kÃ§a kullanÄ±lÄ±yor.  Makine Ã–ÄŸrenmesinin Alt DallarÄ± Neledir? Makine Ã¶ÄŸrenmesinin baÅŸlÄ±ca alt dallarÄ± ÅŸunlardÄ±r:  DoÄŸal Dil Ä°ÅŸleme (Natural Language Processing - NLP) - Ä°nsanlarÄ±n gÃ¼nlÃ¼k hayatta kullandÄ±ÄŸÄ± dili â€œanlayÄ±pâ€ bu bilgiyi metin Ã¶zetleme, muhabbet edebileceÄŸiniz chatbotlar yaratma, ÅŸirketinizin sosyal medyada nasÄ±l algÄ±landÄ±ÄŸÄ±nÄ± tespit etme gibi iÃ§ine kelimelerin girdiÄŸi her alanda kullanan NLP her hayatÄ±mÄ±zda daha Ã¶nemli bir role sahip oluyor.  Bilgisayarla GÃ¶rÃ¼ (Computer Vision - CV) - Otonom araÃ§larÄ±n yolda gitmesini, Instagram filtrelerinin yÃ¼zÃ¼nÃ¼zÃ¼ bulmasÄ±nÄ±, derinizdeki polis kameralarÄ±nÄ±n kim olduÄŸunuzu tespit etmesini, geri dÃ¶nÃ¼ÅŸÃ¼m atÄ±klarÄ±nÄ±n tÃ¼rlerine gÃ¶re ayrÄ±ÅŸtÄ±rÄ±lmasÄ±nÄ± ve daha nicesini saÄŸlayan CV yarattÄ±ÄŸÄ± yeni olanaklarla hem hayatÄ±mÄ±zÄ± kolaylaÅŸtÄ±rÄ±yor hem de yapay zeka etiÄŸinin tartÄ±ÅŸÄ±lmasÄ±na sebep oluyor.  DolandÄ±rÄ±cÄ±lÄ±k Tespiti (Fraud Detection) - Bir alÄ±ÅŸveriÅŸin yaÅŸandÄ±ÄŸÄ± herhangi bir mecrada yaÅŸanabilecek dolandÄ±rÄ±cÄ±lÄ±k gÃ¼nÃ¼mÃ¼zde ML algoritmalarÄ± ile yaÅŸanmadan Ã¶nce tespit edilebilmektedir. Fraud Detectionâ€™Ä± Ã¶zellikle bankalar ve Amazon gibi e-alÄ±ÅŸveriÅŸ siteleri kullanmaktadÄ±r.</div></div>",
"comment": [
    "",
    " "
]
},
{
"question_isim": "-> ",
"quest": "{Ã–RNEK SORU} Yapay Ã¶ÄŸrenme modellerinin genelleÅŸtirme yeteneÄŸini artÄ±rmak iÃ§in hangi yÃ¶ntemleri kullanabilirim?",
"comment": [
    "",
    "->  GenelleÅŸtirmeyi arttÄ±rmak iÃ§in eÄŸitimi erken bitirme, baÅŸlangÄ±Ã§ weight deÄŸerlerini sÄ±nÄ±rlandÄ±rma, regularization ( Ã¶rnek PCA) , inputa biraz gÃ¼rÃ¼ltÃ¼(noise) eklemek Ã¶rnek olarak verilebilir..",
    "->  ->  Merhaba Enes bu bir Ã¶rnek sorudur ğŸ™‚ Ama yine de dikkate alÄ±p yanÄ±tladÄ±ÄŸÄ±n iÃ§in teÅŸekkÃ¼r ederim..",
    "->  Ã¼nlÃ¼ Merhaba Crash Course iÃ§eriÄŸinde Ã¶n gereksinimler kÄ±smÄ±ndan da baÅŸlasak olur mu acaba?.",
    " "
]
}
]
}